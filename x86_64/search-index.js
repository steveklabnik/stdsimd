var N = null;var searchIndex = {};
searchIndex["coresimd"]={"doc":"SIMD and vendor intrinsics support library.","items":[[0,"arch","coresimd","Platform dependent vendor intrinsics.",N,N],[0,"x86_64","coresimd::arch","Platform-specific intrinsics for the `x86_64` platform.",N,N],[3,"__m64","coresimd::arch::x86_64","64-bit wide integer vector type, x86-specific",N,N],[3,"__m128i","","128-bit wide integer vector type, x86-specific",N,N],[3,"__m128","","128-bit wide set of four `f32` types, x86-specific",N,N],[3,"__m128d","","128-bit wide set of two `f64` types, x86-specific",N,N],[3,"__m256i","","256-bit wide integer vector type, x86-specific",N,N],[3,"__m256","","256-bit wide set of eight `f32` types, x86-specific",N,N],[3,"__m256d","","256-bit wide set of four `f64` types, x86-specific",N,N],[3,"CpuidResult","","Result of the `cpuid` instruction.",N,N],[12,"eax","","EAX register.",0,N],[12,"ebx","","EBX register.",0,N],[12,"ecx","","ECX register.",0,N],[12,"edx","","EDX register.",0,N],[5,"_fxsave","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_fxrstor","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_bswap","","Return an integer with the reversed byte order of x",N,[[["i32"]],["i32"]]],[5,"_rdtsc","","Reads the current value of the processor’s time-stamp counter.",N,[[],["i64"]]],[5,"__rdtscp","","Reads the current value of the processor’s time-stamp counter and the `IA32_TSC_AUX MSR`.",N,N],[5,"__cpuid_count","","Returns the result of the `cpuid` instruction for a given `leaf` (`EAX`) and `sub_leaf` (`ECX`).",N,[[["u32"],["u32"]],["cpuidresult"]]],[5,"__cpuid","","See `__cpuid_count`.",N,[[["u32"]],["cpuidresult"]]],[5,"has_cpuid","","Does the host support the `cpuid` instruction?",N,[[],["bool"]]],[5,"__get_cpuid_max","","Returns the highest-supported `leaf` (`EAX`) and sub-leaf (`ECX`) `cpuid` values.",N,N],[5,"_xsave","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xrstor","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_xsetbv","","Copy 64-bits from `val` to the extended control register (`XCR`) specified by `a`.",N,[[["u32"],["u64"]]]],[5,"_xgetbv","","Reads the contents of the extended control register `XCR` specified in `xcr_no`.",N,[[["u32"]],["u64"]]],[5,"_xsaveopt","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsavec","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsaves","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[5,"_xrstors","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_add_ss","","Adds the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_add_ps","","Adds __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sub_ss","","Subtracts the first component of `b` from `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sub_ps","","Subtracts __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mul_ss","","Multiplies the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mul_ps","","Multiplies __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_div_ss","","Divides the first component of `b` by `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_div_ps","","Divides __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sqrt_ss","","Return the square root of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rcp_ss","","Return the approximate reciprocal of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rcp_ps","","Return the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rsqrt_ss","","Return the approximate reciprocal square root of the fist single-precision (32-bit) floating-point elements in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_rsqrt_ps","","Return the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_min_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the minimum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding minimum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_max_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the maximum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding maximum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_and_ps","","Bitwise AND of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_andnot_ps","","Bitwise AND-NOT of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_or_ps","","Bitwise OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_xor_ps","","Bitwise exclusive OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpeq_ss","","Compare the lowest `f32` of both inputs for equality. The lowest 32 bits of the result will be `0xffffffff` if the two inputs are equal, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmplt_ss","","Compare the lowest `f32` of both inputs for less than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmple_ss","","Compare the lowest `f32` of both inputs for less than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpgt_ss","","Compare the lowest `f32` of both inputs for greater than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpge_ss","","Compare the lowest `f32` of both inputs for greater than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpneq_ss","","Compare the lowest `f32` of both inputs for inequality. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnlt_ss","","Compare the lowest `f32` of both inputs for not-less-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnle_ss","","Compare the lowest `f32` of both inputs for not-less-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpngt_ss","","Compare the lowest `f32` of both inputs for not-greater-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnge_ss","","Compare the lowest `f32` of both inputs for not-greater-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpord_ss","","Check if the lowest `f32` of both inputs are ordered. The lowest 32 bits of the result will be `0xffffffff` if neither of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpunord_ss","","Check if the lowest `f32` of both inputs are unordered. The lowest 32 bits of the result will be `0xffffffff` if any of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpeq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements were equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmplt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmple_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpgt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpneq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnlt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnle_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpngt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpnge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are ordered (i.e., neither of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpunord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are unordered (i.e., at least on of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_comieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_comineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_ucomineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cvtss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvt_ss2si","","Alias for `_mm_cvtss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvttss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer with truncation.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvtt_ss2si","","Alias for `_mm_cvttss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm_cvtss_f32","","Extract the lowest 32 bit float from the input vector.",N,[[["__m128"]],["f32"]]],[5,"_mm_cvtsi32_ss","","Convert a 32 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_cvt_si2ss","","Alias for `_mm_cvtsi32_ss`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_set_ss","","Construct a `__m128` with the lowest element set to `a` and the rest set to zero.",N,[[["f32"]],["__m128"]]],[5,"_mm_set1_ps","","Construct a `__m128` with all element set to `a`.",N,[[["f32"]],["__m128"]]],[5,"_mm_set_ps1","","Alias for `_mm_set1_ps`",N,[[["f32"]],["__m128"]]],[5,"_mm_set_ps","","Construct a `__m128` from four floating point values highest to lowest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[5,"_mm_setr_ps","","Construct a `__m128` from four floating point values lowest to highest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[5,"_mm_setzero_ps","","Construct a `__m128` with all elements initialized to zero.",N,[[],["__m128"]]],[5,"_MM_SHUFFLE","","A utility function for creating masks to use with Intel shuffle and permute intrinsics.",N,[[["u32"],["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm_shuffle_ps","","Shuffle packed single-precision (32-bit) floating-point elements in `a` and `b` using `mask`.",N,[[["__m128"],["__m128"],["u32"]],["__m128"]]],[5,"_mm_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the higher half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the lower half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_movehl_ps","","Combine higher half of `a` and `b`. The highwe half of `b` occupies the lower half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_movelh_ps","","Combine lower half of `a` and `b`. The lower half of `b` occupies the higher half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_movemask_ps","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128"]],["i32"]]],[5,"_mm_loadh_pi","","Set the upper two single-precision floating-point values with 64 bits of data loaded from the address `p`; the lower two values are passed through from `a`.",N,N],[5,"_mm_loadl_pi","","Load two floats from `p` into the lower half of a `__m128`. The upper half is copied from the upper half of `a`.",N,N],[5,"_mm_load_ss","","Construct a `__m128` with the lowest element read from `p` and the other elements set to zero.",N,N],[5,"_mm_load1_ps","","Construct a `__m128` by duplicating the value read from `p` into all elements.",N,N],[5,"_mm_load_ps1","","Alias for `_mm_load1_ps`",N,N],[5,"_mm_load_ps","","Load four `f32` values from aligned memory into a `__m128`. If the pointer is not aligned to a 128-bit boundary (16 bytes) a general protection fault will be triggered (fatal program crash).",N,N],[5,"_mm_loadu_ps","","Load four `f32` values from memory into a `__m128`. There are no restrictions on memory alignment. For aligned memory `_mm_load_ps` may be faster.",N,N],[5,"_mm_loadr_ps","","Load four `f32` values from aligned memory into a `__m128` in reverse order.",N,N],[5,"_mm_storeh_pi","","Store the upper half of `a` (64 bits) into memory.",N,N],[5,"_mm_storel_pi","","Store the lower half of `a` (64 bits) into memory.",N,N],[5,"_mm_store_ss","","Store the lowest 32 bit float of `a` into memory.",N,N],[5,"_mm_store1_ps","","Store the lowest 32 bit float of `a` repeated four times into aligned memory.",N,N],[5,"_mm_store_ps1","","Alias for `_mm_store1_ps`",N,N],[5,"_mm_store_ps","","Store four 32-bit floats into aligned memory.",N,N],[5,"_mm_storeu_ps","","Store four 32-bit floats into memory. There are no restrictions on memory alignment. For aligned memory `_mm_store_ps` may be faster.",N,N],[5,"_mm_storer_ps","","Store four 32-bit floats into aligned memory in reverse order.",N,N],[5,"_mm_move_ss","","Return a `__m128` with the first component from `b` and the remaining components from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sfence","","Perform a serializing operation on all store-to-memory instructions that were issued prior to this instruction.",N,[[]]],[5,"_mm_getcsr","","Get the unsigned 32-bit value of the MXCSR control and status register.",N,[[],["u32"]]],[5,"_mm_setcsr","","Set the MXCSR register with the 32-bit unsigned integer value.",N,[[["u32"]]]],[5,"_MM_GET_EXCEPTION_MASK","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_GET_EXCEPTION_STATE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_GET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_GET_ROUNDING_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_MM_SET_EXCEPTION_MASK","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_MM_SET_EXCEPTION_STATE","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_MM_SET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_MM_SET_ROUNDING_MODE","","See `_mm_setcsr`",N,[[["u32"]]]],[5,"_mm_prefetch","","Fetch the cache line that contains address `p` using the given `strategy`.",N,N],[5,"_mm_undefined_ps","","Return vector of type __m128 with undefined elements.",N,[[],["__m128"]]],[5,"_MM_TRANSPOSE4_PS","","Transpose the 4x4 matrix formed by 4 rows of __m128 in place.",N,[[["__m128"],["__m128"],["__m128"],["__m128"]]]],[5,"_mm_stream_ps","","Stores `a` into the memory at `mem_addr` using a non-temporal memory hint.",N,N],[5,"_mm_stream_pi","","Store 64-bits of integer data from a into memory using a non-temporal memory hint.",N,N],[5,"_mm_max_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pmaxsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_max_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pmaxub","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_min_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pminsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_min_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pminub","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mulhi_pu16","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mullo_pi16","","Multiplies packed 16-bit integer values and writes the low-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pmulhuw","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_avg_pu8","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pavgb","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_avg_pu16","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pavgw","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sad_pu8","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psadbw","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtpi32_ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm_cvt_pi2ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm_cvtpi8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpu8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpi16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpu16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_cvtpi32x2_ps","","Converts the two 32-bit signed integer values from each 64-bit vector operand of `[2 x i32]` into a 128-bit vector of `[4 x float]`.",N,[[["__m64"],["__m64"]],["__m128"]]],[5,"_mm_maskmove_si64","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[5,"_m_maskmovq","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[5,"_mm_extract_pi16","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_m_pextrw","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_mm_insert_pi16","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_m_pinsrw","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_mm_movemask_pi8","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_m_pmovmskb","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_mm_shuffle_pi16","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_m_pshufw","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_mm_cvttps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtps_pi16","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 16-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm_cvtps_pi8","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 8-bit integers, and returns theem in the lower 4 elements of the result.",N,[[["__m128"]],["__m64"]]],[5,"_mm_pause","","Provide a hint to the processor that the code sequence is a spin-wait loop.",N,[[]]],[5,"_mm_clflush","","Invalidate and flush the cache line that contains `p` from all levels of the cache hierarchy.",N,N],[5,"_mm_lfence","","Perform a serializing operation on all load-from-memory instructions that were issued prior to this instruction.",N,[[]]],[5,"_mm_mfence","","Perform a serializing operation on all load-from-memory and store-to-memory instructions that were issued prior to this instruction.",N,[[]]],[5,"_mm_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_epi64","","Add packed 64-bit integers in `a` and \"b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_madd_epi16","","Multiply and then horizontally add signed 16 bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sad_epu8","","Sum the absolute differences of packed unsigned 8-bit integers.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 64-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_slli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_bslli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_bsrli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_and_si128","","Compute the bitwise AND of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_andnot_si128","","Compute the bitwise NOT of 128 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_or_si128","","Compute the bitwise OR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_xor_si128","","Compute the bitwise XOR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_epi8","","Compare packed 8-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_epi16","","Compare packed 16-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_epi32","","Compare packed 32-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi32_pd","","Convert the lower two packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m128d"]]],[5,"_mm_cvtsi32_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m128i"]],["__m128"]]],[5,"_mm_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m128i"]]],[5,"_mm_cvtsi32_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i32"]],["__m128i"]]],[5,"_mm_cvtsi128_si32","","Return the lowest element of `a`.",N,[[["__m128i"]],["i32"]]],[5,"_mm_set_epi64x","","Set packed 64-bit integers with the supplied values, from highest to lowest.",N,[[["i64"],["i64"]],["__m128i"]]],[5,"_mm_set_epi32","","Set packed 32-bit integers with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_set_epi16","","Set packed 16-bit integers with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm_set_epi8","","Set packed 8-bit integers with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_mm_set1_epi64x","","Broadcast 64-bit integer `a` to all elements.",N,[[["i64"]],["__m128i"]]],[5,"_mm_set1_epi32","","Broadcast 32-bit integer `a` to all elements.",N,[[["i32"]],["__m128i"]]],[5,"_mm_set1_epi16","","Broadcast 16-bit integer `a` to all elements.",N,[[["i16"]],["__m128i"]]],[5,"_mm_set1_epi8","","Broadcast 8-bit integer `a` to all elements.",N,[[["i8"]],["__m128i"]]],[5,"_mm_setr_epi32","","Set packed 32-bit integers with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_setr_epi16","","Set packed 16-bit integers with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm_setr_epi8","","Set packed 8-bit integers with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_mm_setzero_si128","","Returns a vector with all elements set to zero.",N,[[],["__m128i"]]],[5,"_mm_loadl_epi64","","Load 64-bit integer from memory into first element of returned vector.",N,N],[5,"_mm_load_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_mm_loadu_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_mm_maskmoveu_si128","","Conditionally store 8-bit integer elements from `a` into memory using `mask`.",N,N],[5,"_mm_store_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_mm_storeu_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_mm_storel_epi64","","Store the lower 64-bit integer `a` to a memory location.",N,N],[5,"_mm_stream_si128","","Stores a 128-bit integer vector to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_stream_si32","","Stores a 32-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_move_epi64","","Return a vector where the low element is extracted from `a` and its upper element is zero.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_extract_epi16","","Return the `imm8` element of `a`.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_insert_epi16","","Return a new vector where the `imm8` element of `a` is replaced with `i`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_movemask_epi8","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128i"]],["i32"]]],[5,"_mm_shuffle_epi32","","Shuffle 32-bit integers in `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_sd","","Return a new vector with the low element of `a` replaced by the sum of the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_div_sd","","Return a new vector with the low element of `a` replaced by the result of diving the lower element of `a` by the lower element of `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_div_pd","","Divide packed double-precision (64-bit) floating-point elements in `a` by packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_max_sd","","Return a new vector with the low element of `a` replaced by the maximum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_max_pd","","Return a new vector with the maximum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_min_sd","","Return a new vector with the low element of `a` replaced by the minimum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_min_pd","","Return a new vector with the minimum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_mul_sd","","Return a new vector with the low element of `a` replaced by multiplying the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_mul_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sqrt_sd","","Return a new vector with the low element of `a` replaced by the square root of the lower element `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sqrt_pd","","Return a new vector with the square root of each of the values in `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_sub_sd","","Return a new vector with the low element of `a` replaced by subtracting the low element by `b` from the low element of `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_and_pd","","Compute the bitwise AND of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_andnot_pd","","Compute the bitwise NOT of `a` and then AND with `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_or_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_xor_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpeq_sd","","Return a new vector with the low element of `a` replaced by the equality comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmplt_sd","","Return a new vector with the low element of `a` replaced by the less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmple_sd","","Return a new vector with the low element of `a` replaced by the less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpgt_sd","","Return a new vector with the low element of `a` replaced by the greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpge_sd","","Return a new vector with the low element of `a` replaced by the greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If neither are equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpunord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If either is equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpneq_sd","","Return a new vector with the low element of `a` replaced by the not-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnlt_sd","","Return a new vector with the low element of `a` replaced by the not-less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnle_sd","","Return a new vector with the low element of `a` replaced by the not-less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpngt_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnge_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpeq_pd","","Compare corresponding elements in `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmplt_pd","","Compare corresponding elements in `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmple_pd","","Compare corresponding elements in `a` and `b` for less-than-or-equal",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpgt_pd","","Compare corresponding elements in `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpge_pd","","Compare corresponding elements in `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpord_pd","","Compare corresponding elements in `a` and `b` to see if neither is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpunord_pd","","Compare corresponding elements in `a` and `b` to see if either is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpneq_pd","","Compare corresponding elements in `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnlt_pd","","Compare corresponding elements in `a` and `b` for not-less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnle_pd","","Compare corresponding elements in `a` and `b` for not-less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpngt_pd","","Compare corresponding elements in `a` and `b` for not-greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cmpnge_pd","","Compare corresponding elements in `a` and `b` for not-greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_comieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_comineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_ucomineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in \"a\" to packed single-precision (32-bit) floating-point elements",N,[[["__m128d"]],["__m128"]]],[5,"_mm_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_cvtsd_si32","","Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer.",N,[[["__m128d"]],["i32"]]],[5,"_mm_cvtsd_ss","","Convert the lower double-precision (64-bit) floating-point element in `b` to a single-precision (32-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128"],["__m128d"]],["__m128"]]],[5,"_mm_cvtsd_f64","","Return the lower double-precision (64-bit) floating-point element of \"a\".",N,[[["__m128d"]],["f64"]]],[5,"_mm_cvtss_sd","","Convert the lower single-precision (32-bit) floating-point element in `b` to a double-precision (64-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128d"],["__m128"]],["__m128d"]]],[5,"_mm_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_cvttsd_si32","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 32-bit integer with truncation.",N,[[["__m128d"]],["i32"]]],[5,"_mm_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m128i"]]],[5,"_mm_set_sd","","Copy double-precision (64-bit) floating-point element `a` to the lower element of the packed 64-bit return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_set1_pd","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_set_pd1","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm_set_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_mm_setr_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values in reverse order.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_mm_setzero_pd","","Returns packed double-precision (64-bit) floating-point elements with all zeros.",N,[[],["__m128d"]]],[5,"_mm_movemask_pd","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128d"]],["i32"]]],[5,"_mm_load_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_load_sd","","Loads a 64-bit double-precision value to the low element of a 128-bit integer vector and clears the upper element.",N,N],[5,"_mm_loadh_pd","","Loads a double-precision value into the high-order bits of a 128-bit vector of `[2 x double]`. The low-order bits are copied from the low-order bits of the first operand.",N,N],[5,"_mm_loadl_pd","","Loads a double-precision value into the low-order bits of a 128-bit vector of `[2 x double]`. The high-order bits are copied from the high-order bits of the first operand.",N,N],[5,"_mm_stream_pd","","Stores a 128-bit floating point vector of `[2 x double]` to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_store_sd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_store_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_storeu_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_store1_pd","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_store_pd1","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_storer_pd","","Store 2 double-precision (64-bit) floating-point elements from `a` into memory in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_storeh_pd","","Stores the upper 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_storel_pd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_load1_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[5,"_mm_load_pd1","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[5,"_mm_loadr_pd","","Load 2 double-precision (64-bit) floating-point elements from memory into the returned vector in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_loadu_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_shuffle_pd","","Constructs a 128-bit floating-point vector of `[2 x double]` from two 128-bit vector parameters of `[2 x double]`, using the immediate-value parameter as a specifier.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_move_sd","","Constructs a 128-bit floating-point vector of `[2 x double]`. The lower 64 bits are set to the lower 64 bits of the second parameter. The upper 64 bits are set to the upper 64 bits of the first parameter.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_castpd_ps","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128d"]],["__m128"]]],[5,"_mm_castpd_si128","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit integer vector.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_castps_pd","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_castps_si128","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit integer vector.",N,[[["__m128"]],["__m128i"]]],[5,"_mm_castsi128_pd","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128i"]],["__m128d"]]],[5,"_mm_castsi128_ps","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128i"]],["__m128"]]],[5,"_mm_undefined_pd","","Return vector of type __m128d with undefined elements.",N,[[],["__m128d"]]],[5,"_mm_undefined_si128","","Return vector of type __m128i with undefined elements.",N,[[],["__m128i"]]],[5,"_mm_unpackhi_pd","","The resulting `__m128d` element is composed by the low-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_unpacklo_pd","","The resulting `__m128d` element is composed by the high-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_add_si64","","Adds two signed or unsigned 64-bit integer values, returning the lower 64 bits of the sum.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mul_su32","","Multiplies 32-bit unsigned integer values contained in the lower bits of the two 64-bit integer vectors and returns the 64-bit unsigned product.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_si64","","Subtracts signed or unsigned 64-bit integer values and writes the difference to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtpi32_pd","","Converts the two signed 32-bit integer elements of a 64-bit vector of `[2 x i32]` into two double-precision floating-point values, returned in a 128-bit vector of `[2 x double]`.",N,[[["__m64"]],["__m128d"]]],[5,"_mm_set_epi64","","Initializes both 64-bit values in a 128-bit vector of `[2 x i64]` with the specified 64-bit integer values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_mm_set1_epi64","","Initializes both values in a 128-bit vector of `[2 x i64]` with the specified 64-bit value.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_setr_epi64","","Constructs a 128-bit integer vector, initialized in reverse order with the specified 64-bit integral values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_mm_movepi64_pi64","","Returns the lower 64 bits of a 128-bit integer vector as a 64-bit integer.",N,[[["__m128i"]],["__m64"]]],[5,"_mm_movpi64_epi64","","Moves the 64-bit operand to a 128-bit integer vector, zeroing the upper bits.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_cvtpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`.",N,[[["__m128d"]],["__m64"]]],[5,"_mm_cvttpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`. If the result of either conversion is inexact, the result is truncated (rounded towards zero) regardless of the current MXCSR setting.",N,[[["__m128d"]],["__m64"]]],[5,"_mm_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hadd_pd","","Horizontally add adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hadd_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_hsub_pd","","Horizontally subtract adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hsub_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_lddqu_si128","","Load 128-bits of integer data from unaligned memory. This intrinsic may perform better than `_mm_loadu_si128` when the data crosses a cache line boundary.",N,N],[5,"_mm_movedup_pd","","Duplicate the low double-precision (64-bit) floating-point element from `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_loaddup_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of return vector.",N,N],[5,"_mm_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_abs_epi8","","Compute the absolute value of packed 8-bit signed integers in `a` and return the unsigned results.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_abs_epi16","","Compute the absolute value of each of the packed 16-bit signed integers in `a` and return the 16-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_abs_epi32","","Compute the absolute value of each of the packed 32-bit signed integers in `a` and return the 32-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_alignr_epi8","","Concatenate 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_hadd_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hadds_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hadd_epi32","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hsub_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hsubs_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hsub_epi32","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_maddubs_epi16","","Multiply corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, add pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mulhrs_epi16","","Multiply packed 16-bit signed integer values, truncate the 32-bit product to the 18 most significant bits by right-shifting, round the truncated value by adding 1, and write bits `[16:1]` to the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the result. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_abs_pi8","","Compute the absolute value of packed 8-bit integers in `a` and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_abs_pi16","","Compute the absolute value of packed 8-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_abs_pi32","","Compute the absolute value of packed 32-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_shuffle_pi8","","Shuffle packed 8-bit integers in `a` according to shuffle control mask in the corresponding 8-bit element of `b`, and return the results",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_alignr_pi8","","Concatenates the two 64-bit integer vector operands, and right-shifts the result by the number of bytes specified in the immediate operand.",N,[[["__m64"],["__m64"],["i32"]],["__m64"]]],[5,"_mm_hadd_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hadd_pi32","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hadds_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hsub_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hsub_pi32","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_hsubs_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_maddubs_pi16","","Multiplies corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, adds pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mulhrs_pi16","","Multiplies packed 16-bit signed integer values, truncates the 32-bit products to the 18 most significant bits by right-shifting, rounds the truncated value by adding 1, and writes bits `[16:1]` to the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sign_pi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sign_pi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sign_pi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using the mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm2`",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using mask `imm4`",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_extract_ps","","Extract a single-precision (32-bit) floating-point element from `a`, selected with `imm8`",N,[[["__m128"],["i32"]],["i32"]]],[5,"_mm_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_extract_epi32","","Extract an 32-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm_insert_ps","","Select a single value in `a` to store at some position in `b`, Then zero elements according to `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_insert_epi8","","Return a copy of `a` with the 8-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_insert_epi32","","Return a copy of `a` with the 32-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_max_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed maximum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed maximum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed minimum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed minimum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi8_epi16","","Sign extend packed 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi8_epi32","","Sign extend packed 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi8_epi64","","Sign extend packed 8-bit integers in the low 8 bytes of `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi16_epi32","","Sign extend packed 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi16_epi64","","Sign extend packed 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi32_epi64","","Sign extend packed 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu8_epi16","","Zero extend packed unsigned 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu8_epi32","","Zero extend packed unsigned 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu8_epi64","","Zero extend packed unsigned 8-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu16_epi64","","Zero extend packed unsigned 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_cvtepu32_epi64","","Zero extend packed unsigned 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_dp_pd","","Returns the dot product of two __m128d vectors.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_dp_ps","","Returns the dot product of two __m128 vectors.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_floor_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` down to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_floor_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` down to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_mm_floor_sd","","Round the lower double-precision (64-bit) floating-point element in `b` down to an integer value, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_floor_ss","","Round the lower single-precision (32-bit) floating-point element in `b` down to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_ceil_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` up to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_ceil_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` up to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_mm_ceil_sd","","Round the lower double-precision (64-bit) floating-point element in `b` up to an integer value, store the result as a double-precision floating-point element in the lower element of the intrisic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_ceil_ss","","Round the lower single-precision (32-bit) floating-point element in `b` up to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_round_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed double-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_round_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed single-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_round_sd","","Round the lower double-precision (64-bit) floating-point element in `b` using the `rounding` parameter, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_round_ss","","Round the lower single-precision (32-bit) floating-point element in `b` using the `rounding` parameter, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the instrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_minpos_epu16","","Finds the minimum unsigned 16-bit element in the 128-bit __m128i vector, returning a vector containing its value in its first position, and its index in its second position; all other elements are set to zero.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`, and return the signed 64-bit result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and returns the lowest 32-bit, whatever they might be, reinterpreted as a signed integer. While `pmulld __m128i::splat(2), __m128i::splat(2)` returns the obvious `__m128i::splat(4)`, due to wrapping arithmetic `pmulld __m128i::splat(i32::MAX), __m128i::splat(2)` would return a negative number.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mpsadbw_epu8","","Subtracts 8-bit unsigned integer values and computes the absolute values of the differences to the corresponding bits in the destination. Then sums of the absolute differences are returned according to the bit fields in the immediate operand.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_testz_si128","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_testc_si128","","Tests whether the specified bits in a 128-bit integer vector are all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_testnzc_si128","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_test_all_zeros","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_test_all_ones","","Tests whether the specified bits in `a` 128-bit integer vector are all ones.",N,[[["__m128i"]],["i32"]]],[5,"_mm_test_mix_ones_zeros","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_cmpistrm","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_cmpistri","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpestri`] with the exception that [`_mm_cmpestri`] requires the lengths of `a` and `b` to be explicitly specified.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistrz","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if any character in `b` was null. and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistrc","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistrs","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and returns `1` if any character in `a` was null, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistro","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpistra","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpestrm","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_cmpestri","","Compare packed strings `a` and `b` with lengths `la` and `lb` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpistri`] with the exception that [`_mm_cmpistri`] implicitly determines the length of `a` and `b`.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestrz","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in `b` was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestrc","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestrs","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in a was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestro","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpestra","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_crc32_u8","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 8-bit integer `v`.",N,[[["u32"],["u8"]],["u32"]]],[5,"_mm_crc32_u16","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 16-bit integer `v`.",N,[[["u32"],["u16"]],["u32"]]],[5,"_mm_crc32_u32","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 32-bit integer `v`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than, return the results.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_add_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_and_pd","","Compute the bitwise AND of a packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_and_ps","","Compute the bitwise AND of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_or_pd","","Compute the bitwise OR packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_or_ps","","Compute the bitwise OR packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_shuffle_pd","","Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_shuffle_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_andnot_pd","","Compute the bitwise NOT of packed double-precision (64-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_andnot_ps","","Compute the bitwise NOT of packed single-precision (32-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_max_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_min_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_mul_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_mul_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_sub_ps","","Subtract packed single-precision (32-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_div_ps","","Compute the division of each of the 8 packed 32-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_div_pd","","Compute the division of each of the 4 packed 64-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_round_pd","","Round packed double-precision (64-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_ceil_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_floor_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_round_ps","","Round packed single-precision (32-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm256_ceil_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_floor_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating point elements in `a`.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_sqrt_pd","","Return the square root of packed double-precision (64-bit) floating point elements in `a`.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_dp_ps","","Conditionally multiply the packed single-precision (32-bit) floating-point elements in `a` and `b` using the high 4 bits in `imm8`, sum the four products, and conditionally return the sum  using the low 4 bits of `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_hadd_pd","","Horizontal addition of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_hadd_ps","","Horizontal addition of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_hsub_pd","","Horizontal subtraction of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_hsub_ps","","Horizontal subtraction of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_xor_pd","","Compute the bitwise XOR of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_xor_ps","","Compute the bitwise XOR of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm256_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm_cmp_sd","","Compare the lower double-precision (64-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper element from `a` to the upper element of returned vector.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cmp_ss","","Compare the lower single-precision (32-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper 3 packed elements from `a` to the upper elements of returned vector.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm256_cvtepi32_pd","","Convert packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m256d"]]],[5,"_mm256_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256i"]],["__m256"]]],[5,"_mm256_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256d"]],["__m128"]]],[5,"_mm256_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256"]],["__m256i"]]],[5,"_mm256_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m256d"]]],[5,"_mm256_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm256_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm256_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256"]],["__m256i"]]],[5,"_mm256_extractf128_ps","","Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256"],["i32"]],["__m128"]]],[5,"_mm256_extractf128_pd","","Extract 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256d"],["i32"]],["__m128d"]]],[5,"_mm256_extractf128_si256","","Extract 128 bits (composed of integer data) from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"_mm256_zeroall","","Zero the contents of all XMM or YMM registers.",N,[[]]],[5,"_mm256_zeroupper","","Zero the upper 128 bits of all YMM registers; the lower 128-bits of the registers are unmodified.",N,[[]]],[5,"_mm256_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `b`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_mm_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128"],["__m128i"]],["__m128"]]],[5,"_mm256_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm256_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 256-bit lanes using the control in `b`.",N,[[["__m256d"],["__m256i"]],["__m256d"]]],[5,"_mm_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128d"],["__m128i"]],["__m128d"]]],[5,"_mm256_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_permute2f128_ps","","Shuffle 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_permute2f128_pd","","Shuffle 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_permute2f128_si256","","Shuffle 258-bits (composed of integer data) selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m128"]]],[5,"_mm256_broadcast_sd","","Broadcast a double-precision (64-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm256_broadcast_ps","","Broadcast 128 bits from memory (composed of 4 packed single-precision (32-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_broadcast_pd","","Broadcast 128 bits from memory (composed of 2 packed double-precision (64-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_insertf128_ps","","Copy `a` to result, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256"],["__m128"],["i32"]],["__m256"]]],[5,"_mm256_insertf128_pd","","Copy `a` to result, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256d"],["__m128d"],["i32"]],["__m256d"]]],[5,"_mm256_insertf128_si256","","Copy `a` to result, then insert 128 bits from `b` into result at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[5,"_mm256_insert_epi8","","Copy `a` to result, and insert the 8-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i8"],["i32"]],["__m256i"]]],[5,"_mm256_insert_epi16","","Copy `a` to result, and insert the 16-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i16"],["i32"]],["__m256i"]]],[5,"_mm256_insert_epi32","","Copy `a` to result, and insert the 32-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i32"],["i32"]],["__m256i"]]],[5,"_mm256_load_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_store_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_load_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_store_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_loadu_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_loadu_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_load_si256","","Load 256-bits of integer data from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_store_si256","","Store 256-bits of integer data from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_loadu_si256","","Load 256-bits of integer data from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu_si256","","Store 256-bits of integer data from `a` into memory.    `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm256_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm256_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm256_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm256_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_movedup_pd","","Duplicate even-indexed double-precision (64-bit) floating-point elements from \"a\", and return the results.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_lddqu_si256","","Load 256-bits of integer data from unaligned memory into result. This intrinsic may perform better than `_mm256_loadu_si256` when the data crosses a cache line boundary.",N,N],[5,"_mm256_stream_si256","","Moves integer data from a 256-bit integer vector to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)",N,N],[5,"_mm256_stream_pd","","Moves double-precision values from a 256-bit vector of `[4 x double]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm256_stream_ps","","Moves single-precision floating point values from a 256-bit vector of `[8 x float]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm256_rcp_ps","","Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_rsqrt_ps","","Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[5,"_mm256_unpackhi_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_unpacklo_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_testz_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_testc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_testnzc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_testz_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm256_testc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm256_testnzc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm_testz_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_testc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_testnzc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_testz_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm256_testc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm256_testnzc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm_testz_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_testc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_testnzc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_movemask_pd","","Set each bit of the returned mask based on the most significant bit of the corresponding packed double-precision (64-bit) floating-point element in `a`.",N,[[["__m256d"]],["i32"]]],[5,"_mm256_movemask_ps","","Set each bit of the returned mask based on the most significant bit of the corresponding packed single-precision (32-bit) floating-point element in `a`.",N,[[["__m256"]],["i32"]]],[5,"_mm256_setzero_pd","","Return vector of type __m256d with all elements set to zero.",N,[[],["__m256d"]]],[5,"_mm256_setzero_ps","","Return vector of type __m256 with all elements set to zero.",N,[[],["__m256"]]],[5,"_mm256_setzero_si256","","Return vector of type __m256i with all elements set to zero.",N,[[],["__m256i"]]],[5,"_mm256_set_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_mm256_set_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm256_set_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[5,"_mm256_set_epi16","","Set packed 16-bit integers in returned vector with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm256_set_epi32","","Set packed 32-bit integers in returned vector with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm256_set_epi64x","","Set packed 64-bit integers in returned vector with the supplied values.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_mm256_setr_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_mm256_setr_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm256_setr_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[5,"_mm256_setr_epi16","","Set packed 16-bit integers in returned vector with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm256_setr_epi32","","Set packed 32-bit integers in returned vector with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm256_setr_epi64x","","Set packed 64-bit integers in returned vector with the supplied values in reverse order.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_mm256_set1_pd","","Broadcast double-precision (64-bit) floating-point value `a` to all elements of returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm256_set1_ps","","Broadcast single-precision (32-bit) floating-point value `a` to all elements of returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm256_set1_epi8","","Broadcast 8-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastb`.",N,[[["i8"]],["__m256i"]]],[5,"_mm256_set1_epi16","","Broadcast 16-bit integer `a` to all all elements of returned vector. This intrinsic may generate the `vpbroadcastw`.",N,[[["i16"]],["__m256i"]]],[5,"_mm256_set1_epi32","","Broadcast 32-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastd`.",N,[[["i32"]],["__m256i"]]],[5,"_mm256_set1_epi64x","","Broadcast 64-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastq`.",N,[[["i64"]],["__m256i"]]],[5,"_mm256_castpd_ps","","Cast vector of type __m256d to type __m256.",N,[[["__m256d"]],["__m256"]]],[5,"_mm256_castps_pd","","Cast vector of type __m256 to type __m256d.",N,[[["__m256"]],["__m256d"]]],[5,"_mm256_castps_si256","","Casts vector of type __m256 to type __m256i.",N,[[["__m256"]],["__m256i"]]],[5,"_mm256_castsi256_ps","","Casts vector of type __m256i to type __m256.",N,[[["__m256i"]],["__m256"]]],[5,"_mm256_castpd_si256","","Casts vector of type __m256d to type __m256i.",N,[[["__m256d"]],["__m256i"]]],[5,"_mm256_castsi256_pd","","Casts vector of type __m256i to type __m256d.",N,[[["__m256i"]],["__m256d"]]],[5,"_mm256_castps256_ps128","","Casts vector of type __m256 to type __m128.",N,[[["__m256"]],["__m128"]]],[5,"_mm256_castpd256_pd128","","Casts vector of type __m256d to type __m128d.",N,[[["__m256d"]],["__m128d"]]],[5,"_mm256_castsi256_si128","","Casts vector of type __m256i to type __m128i.",N,[[["__m256i"]],["__m128i"]]],[5,"_mm256_castps128_ps256","","Casts vector of type __m128 to type __m256; the upper 128 bits of the result are undefined.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_castpd128_pd256","","Casts vector of type __m128d to type __m256d; the upper 128 bits of the result are undefined.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_castsi128_si256","","Casts vector of type __m128i to type __m256i; the upper 128 bits of the result are undefined.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_zextps128_ps256","","Constructs a 256-bit floating-point vector of `[8 x float]` from a 128-bit floating-point vector of `[4 x float]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_zextsi128_si256","","Constructs a 256-bit integer vector from a 128-bit integer vector. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_zextpd128_pd256","","Constructs a 256-bit floating-point vector of `[4 x double]` from a 128-bit floating-point vector of `[2 x double]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_undefined_ps","","Return vector of type `__m256` with undefined elements.",N,[[],["__m256"]]],[5,"_mm256_undefined_pd","","Return vector of type `__m256d` with undefined elements.",N,[[],["__m256d"]]],[5,"_mm256_undefined_si256","","Return vector of type __m256i with undefined elements.",N,[[],["__m256i"]]],[5,"_mm256_set_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[5,"_mm256_set_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[5,"_mm256_set_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[5,"_mm256_setr_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[5,"_mm256_setr_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[5,"_mm256_setr_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[5,"_mm256_loadu2_m128","","Load two 128-bit values (composed of 4 packed single-precision (32-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_loadu2_m128d","","Load two 128-bit values (composed of 2 packed double-precision (64-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_loadu2_m128i","","Load two 128-bit values (composed of integer data) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu2_m128","","Store the high and low 128-bit halves (each composed of 4 packed single-precision (32-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu2_m128d","","Store the high and low 128-bit halves (each composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_storeu2_m128i","","Store the high and low 128-bit halves (each composed of integer data) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_cvtss_f32","","Returns the first element of the input vector of `[8 x float]`.",N,[[["__m256"]],["f32"]]],[5,"_mm256_abs_epi32","","Computes the absolute values of packed 32-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_abs_epi16","","Computes the absolute values of packed 16-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_abs_epi8","","Computes the absolute values of packed 8-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi64","","Add packed 64-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_alignr_epi8","","Concatenate pairs of 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_and_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_andnot_si256","","Compute the bitwise NOT of 256 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`.",N,[[["__m256i"],["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm256_broadcastsi128_si256","","Broadcast 128 bits of integer data from a to all 128-bit lanes in the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128"]],["__m256"]]],[5,"_mm_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 128-bit returned value",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 256-bit returned value",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cvtepi16_epi32","","Sign-extend 16-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi16_epi64","","Sign-extend 16-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi32_epi64","","Sign-extend 32-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi8_epi16","","Sign-extend 8-bit integers to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi8_epi32","","Sign-extend 8-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepi8_epi64","","Sign-extend 8-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers, and store the results in dst.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu16_epi64","","Zero-extend the lower four unsigned 16-bit integers in `a` to 64-bit integers. The upper four elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu32_epi64","","Zero-extend unsigned 32-bit integers in `a` to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu8_epi16","","Zero-extend unsigned 8-bit integers in `a` to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu8_epi32","","Zero-extend the lower eight unsigned 8-bit integers in `a` to 32-bit integers. The upper eight elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtepu8_epi64","","Zero-extend the lower four unsigned 8-bit integers in `a` to 64-bit integers. The upper twelve elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_extracti128_si256","","Extract 128 bits (of integer data) from `a` selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"_mm256_hadd_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hadd_epi32","","Horizontally add adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hadds_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hsub_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hsub_epi32","","Horizontally subtract adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hsubs_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_inserti128_si256","","Copy `a` to `dst`, then insert 128 bits (of integer data) from `b` at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[5,"_mm256_madd_epi16","","Multiply packed signed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_maddubs_epi16","","Vertically multiply each unsigned 8-bit integer from `a` with the corresponding signed 8-bit integer from `b`, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_movemask_epi8","","Create mask from the most significant bit of each 8-bit element in `a`, return the result.",N,[[["__m256i"]],["i32"]]],[5,"_mm256_mpsadbw_epu8","","Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in `a` compared to those in `b`, and store the 16-bit results in dst. Eight SADs are performed for each 128-bit lane using one quadruplet from `b` and eight quadruplets from `a`. One quadruplet is selected from `b` starting at on the offset specified in `imm8`. Eight quadruplets are formed from sequential 8-bit integers selected from `a` starting at the offset specified in `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mulhrs_epi16","","Multiply packed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and return bits `[16:1]`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_or_si256","","Compute the bitwise OR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_permutevar8x32_epi32","","Permutes packed 32-bit integers from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_permute4x64_epi64","","Permutes 64-bit integers from `a` using control mask `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_permute2x128_si256","","Shuffle 128-bits of integer data selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_permute4x64_pd","","Shuffle 64-bit floating-point elements in `a` across lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm256_permutevar8x32_ps","","Shuffle eight 32-bit foating-point elements in `a` across lanes using the corresponding 32-bit integer index in `idx`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_mm256_sad_epu8","","Compute the absolute differences of packed unsigned 8-bit integers in `a` and `b`, then horizontally sum each consecutive 8 differences to produce four unsigned 16-bit integers, and pack these unsigned 16-bit integers in the low 16 bits of the 64-bit return value",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_shuffle_epi32","","Shuffle 32-bit integers in 128-bit lanes of `a` using the control in `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of `a` using the control in `imm8`. The low 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of `a` using the control in `imm8`. The high 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_slli_si256","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_bslli_epi128","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_srli_si256","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_bsrli_epi128","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_xor_si256","","Compute the bitwise XOR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i8"]]],[5,"_mm256_extract_epi16","","Extract a 16-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i16"]]],[5,"_mm256_extract_epi32","","Extract a 32-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i32"]]],[5,"_mm256_cvtsd_f64","","Returns the first element of the input vector of `[4 x double]`.",N,[[["__m256d"]],["f64"]]],[5,"_mm256_cvtsi256_si32","","Returns the first element of the input vector of `[8 x i32]`.",N,[[["__m256i"]],["i32"]]],[5,"_mm_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`,  and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fnmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fnmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fnmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_fnmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_lzcnt_u32","","Counts the leading most significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_popcnt32","","Counts the bits that are set.",N,[[["i32"]],["i32"]]],[5,"_bextr_u32","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_bextr2_u32","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_andn_u32","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_blsi_u32","","Extract lowest set isolated bit.",N,[[["u32"]],["u32"]]],[5,"_blsmsk_u32","","Get mask up to lowest set bit.",N,[[["u32"]],["u32"]]],[5,"_blsr_u32","","Resets the lowest set bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_tzcnt_u32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_mm_tzcnt_32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["i32"]]],[5,"_mulx_u32","","Unsigned multiply without affecting flags.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_bzhi_u32","","Zero higher bits of `a` >= `index`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_pdep_u32","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_pext_u32","","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_extract_si64","","Extracts the bit range specified by `y` from the lower 64 bits of `x`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_insert_si64","","Inserts the `[length:0]` bits of `y` into `x` at `index`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_stream_sd","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_mm_stream_ss","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_blcfill_u32","","Clears all bits below the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_blcfill_u64","","Clears all bits below the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_blci_u32","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u32"]],["u32"]]],[5,"_blci_u64","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u64"]],["u64"]]],[5,"_blcic_u32","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_blcic_u64","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[5,"_blcmsk_u32","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u32"]],["u32"]]],[5,"_blcmsk_u64","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u64"]],["u64"]]],[5,"_blcs_u32","","Sets the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_blcs_u64","","Sets the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_blsfill_u32","","Sets all bits of `x` below the least significant one.",N,[[["u32"]],["u32"]]],[5,"_blsfill_u64","","Sets all bits of `x` below the least significant one.",N,[[["u64"]],["u64"]]],[5,"_blsic_u32","","Clears least significant bit and sets all other bits.",N,[[["u32"]],["u32"]]],[5,"_blsic_u64","","Clears least significant bit and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_t1mskc_u32","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u32"]],["u32"]]],[5,"_t1mskc_u64","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_tzmsk_u32","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_tzmsk_u64","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm_setzero_si64","","Constructs a 64-bit integer vector initialized to zero.",N,[[],["__m64"]]],[5,"_mm_add_pi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddb","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_add_pi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddw","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_add_pi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddd","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddsb","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddsw","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddusb","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_paddusw","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_sub_pi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubd","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubsb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubsw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubusb","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_subs_pu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_psubusw","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_packs_pi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_packs_pi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpgt_pi8","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpgt_pi16","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpgt_pi32","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpackhi_pi16","","Unpacks the upper two elements from two `i16x4` vectors and interleaves them into the result: `[a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpackhi_pi8","","Unpacks the upper four elements from two `i8x8` vectors and interleaves them into the result: `[a.4, b.4, a.5, b.5, a.6, b.6, a.7, b.7]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpacklo_pi8","","Unpacks the lower four elements from two `i8x8` vectors and interleaves them into the result: `[a.0, b.0, a.1, b.1, a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpacklo_pi16","","Unpacks the lower two elements from two `i16x4` vectors and interleaves them into the result: `[a.0 b.0 a.1 b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpackhi_pi32","","Unpacks the upper element from two `i32x2` vectors and interleaves them into the result: `[a.1, b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_unpacklo_pi32","","Unpacks the lower element from two `i32x2` vectors and interleaves them into the result: `[a.0, b.0]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_set_pi16","","Set packed 16-bit integers in dst with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm_set_pi32","","Set packed 32-bit integers in dst with the supplied values.",N,[[["i32"],["i32"]],["__m64"]]],[5,"_mm_set_pi8","","Set packed 8-bit integers in dst with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm_set1_pi16","","Broadcast 16-bit integer a to all all elements of dst.",N,[[["i16"]],["__m64"]]],[5,"_mm_set1_pi32","","Broadcast 32-bit integer a to all all elements of dst.",N,[[["i32"]],["__m64"]]],[5,"_mm_set1_pi8","","Broadcast 8-bit integer a to all all elements of dst.",N,[[["i8"]],["__m64"]]],[5,"_mm_setr_pi16","","Set packed 16-bit integers in dst with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm_setr_pi32","","Set packed 32-bit integers in dst with the supplied values in reverse order.",N,[[["i32"],["i32"]],["__m64"]]],[5,"_mm_setr_pi8","","Set packed 8-bit integers in dst with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm_clmulepi64_si128","","Perform a carry-less multiplication of two 64-bit polynomials over the finite field GF(2^k).",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_aesdec_si128","","Perform one round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesdeclast_si128","","Perform the last round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesenc_si128","","Perform one round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesenclast_si128","","Perform the last round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aesimc_si128","","Perform the `InvMixColumns` transformation on `a`.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_aeskeygenassist_si128","","Assist in expanding the AES cipher key.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_rdrand16_step","","Read a hardware generated 16-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_rdrand32_step","","Read a hardware generated 32-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[5,"_rdseed16_step","","Read a 16-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_rdseed32_step","","Read a 32-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[5,"_mm_sha1msg1_epu32","","Perform an intermediate calculation for the next four SHA1 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and returning the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha1msg2_epu32","","Perform the final calculation for the next four SHA1 message values (unsigned 32-bit integers) using the intermediate result in `a` and the previous message values in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha1nexte_epu32","","Calculate SHA1 state variable E after four rounds of operation from the current SHA1 state variable `a`, add that value to the scheduled values (unsigned 32-bit integers) in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha1rnds4_epu32","","Perform four rounds of SHA1 operation using an initial SHA1 state (A,B,C,D) from `a` and some pre-computed sum of the next 4 round message values (unsigned 32-bit integers), and state variable E from `b`, and return the updated SHA1 state (A,B,C,D). `func` contains the logic functions and round constants.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_sha256msg1_epu32","","Perform an intermediate calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha256msg2_epu32","","Perform the final calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sha256rnds2_epu32","","Perform 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from `a`, an initial SHA256 state (A,B,E,F) from `b`, and a pre-computed sum of the next 2 round message values (unsigned 32-bit integers) and the corresponding round constants from `k`, and store the updated SHA256 state (A,B,E,F) in dst.",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[5,"_fxsave64","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_fxrstor64","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm_cvtss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer.",N,[[["__m128"]],["i64"]]],[5,"_mm_cvttss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer with truncation.",N,[[["__m128"]],["i64"]]],[5,"_mm_cvtsi64_ss","","Convert a 64 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i64"]],["__m128"]]],[5,"_mm_cvtsd_si64","","Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer.",N,[[["__m128d"]],["i64"]]],[5,"_mm_cvtsd_si64x","","Alias for `_mm_cvtsd_si64`",N,[[["__m128d"]],["i64"]]],[5,"_mm_cvttsd_si64","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 64-bit integer with truncation.",N,[[["__m128d"]],["i64"]]],[5,"_mm_cvttsd_si64x","","Alias for `_mm_cvttsd_si64`",N,[[["__m128d"]],["i64"]]],[5,"_mm_stream_si64","","Stores a 64-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_cvtsi64_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[5,"_mm_cvtsi64x_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[5,"_mm_cvtsi128_si64","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[5,"_mm_cvtsi128_si64x","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[5,"_mm_cvtsi64_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[5,"_mm_cvtsi64x_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[5,"_mm_extract_epi64","","Extract an 64-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i64"]]],[5,"_mm_insert_epi64","","Return a copy of `a` with the 64-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i64"],["i32"]],["__m128i"]]],[5,"_mm_crc32_u64","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 64-bit integer `v`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_xsave64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xrstor64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_xsaveopt64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsavec64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_xsaves64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[5,"_xrstors64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_lzcnt_u64","","Counts the leading most significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_popcnt64","","Counts the bits that are set.",N,[[["i64"]],["i32"]]],[5,"_mm256_insert_epi64","","Copy `a` to result, and insert the 64-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i64"],["i32"]],["__m256i"]]],[5,"_bextr_u64","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u64"],["u32"],["u32"]],["u64"]]],[5,"_bextr2_u64","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_andn_u64","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_blsi_u64","","Extract lowest set isolated bit.",N,[[["u64"]],["u64"]]],[5,"_blsmsk_u64","","Get mask up to lowest set bit.",N,[[["u64"]],["u64"]]],[5,"_blsr_u64","","Resets the lowest set bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_tzcnt_u64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_mm_tzcnt_64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["i64"]]],[5,"_mulx_u64","","Unsigned multiply without affecting flags.",N,[[["u64"],["u64"],["u64"]],["u64"]]],[5,"_bzhi_u64","","Zero higher bits of `a` >= `index`.",N,[[["u64"],["u32"]],["u64"]]],[5,"_pdep_u64","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_pext_u64","","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm256_extract_epi64","","Extract a 64-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i64"]]],[5,"_bswap64","","Return an integer with the reversed byte order of x",N,[[["i64"]],["i64"]]],[5,"_rdrand64_step","","Read a hardware generated 64-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[5,"_rdseed64_step","","Read a 64-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[17,"_XCR_XFEATURE_ENABLED_MASK","","`XFEATURE_ENABLED_MASK` for `XCR`",N,N],[17,"_MM_EXCEPT_INVALID","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_DENORM","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_DIV_ZERO","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_OVERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_UNDERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_INEXACT","","See `_mm_setcsr`",N,N],[17,"_MM_EXCEPT_MASK","","See `_MM_GET_EXCEPTION_STATE`",N,N],[17,"_MM_MASK_INVALID","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_DENORM","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_DIV_ZERO","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_OVERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_UNDERFLOW","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_INEXACT","","See `_mm_setcsr`",N,N],[17,"_MM_MASK_MASK","","See `_MM_GET_EXCEPTION_MASK`",N,N],[17,"_MM_ROUND_NEAREST","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_DOWN","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_UP","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_TOWARD_ZERO","","See `_mm_setcsr`",N,N],[17,"_MM_ROUND_MASK","","See `_MM_GET_ROUNDING_MODE`",N,N],[17,"_MM_FLUSH_ZERO_MASK","","See `_MM_GET_FLUSH_ZERO_MODE`",N,N],[17,"_MM_FLUSH_ZERO_ON","","See `_mm_setcsr`",N,N],[17,"_MM_FLUSH_ZERO_OFF","","See `_mm_setcsr`",N,N],[17,"_MM_HINT_T0","","See `_mm_prefetch`.",N,N],[17,"_MM_HINT_T1","","See `_mm_prefetch`.",N,N],[17,"_MM_HINT_T2","","See `_mm_prefetch`.",N,N],[17,"_MM_HINT_NTA","","See `_mm_prefetch`.",N,N],[17,"_MM_FROUND_TO_NEAREST_INT","","round to nearest",N,N],[17,"_MM_FROUND_TO_NEG_INF","","round down",N,N],[17,"_MM_FROUND_TO_POS_INF","","round up",N,N],[17,"_MM_FROUND_TO_ZERO","","truncate",N,N],[17,"_MM_FROUND_CUR_DIRECTION","","use MXCSR.RC; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[17,"_MM_FROUND_RAISE_EXC","","do not suppress exceptions",N,N],[17,"_MM_FROUND_NO_EXC","","suppress exceptions",N,N],[17,"_MM_FROUND_NINT","","round to nearest and do not suppress exceptions",N,N],[17,"_MM_FROUND_FLOOR","","round down and do not suppress exceptions",N,N],[17,"_MM_FROUND_CEIL","","round up and do not suppress exceptions",N,N],[17,"_MM_FROUND_TRUNC","","truncate and do not suppress exceptions",N,N],[17,"_MM_FROUND_RINT","","use MXCSR.RC and do not suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[17,"_MM_FROUND_NEARBYINT","","use MXCSR.RC and suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[17,"_SIDD_UBYTE_OPS","","String contains unsigned 8-bit characters (Default)",N,N],[17,"_SIDD_UWORD_OPS","","String contains unsigned 16-bit characters",N,N],[17,"_SIDD_SBYTE_OPS","","String contains signed 8-bit characters",N,N],[17,"_SIDD_SWORD_OPS","","String contains unsigned 16-bit characters",N,N],[17,"_SIDD_CMP_EQUAL_ANY","","For each character in `a`, find if it is in `b` (Default)",N,N],[17,"_SIDD_CMP_RANGES","","For each character in `a`, determine if `b[0] <= c <= b[1] or b[1] <= c <= b[2]...`",N,N],[17,"_SIDD_CMP_EQUAL_EACH","","The strings defined by `a` and `b` are equal",N,N],[17,"_SIDD_CMP_EQUAL_ORDERED","","Search for the defined substring in the target",N,N],[17,"_SIDD_POSITIVE_POLARITY","","Do not negate results (Default)",N,N],[17,"_SIDD_NEGATIVE_POLARITY","","Negate results",N,N],[17,"_SIDD_MASKED_POSITIVE_POLARITY","","Do not negate results before the end of the string",N,N],[17,"_SIDD_MASKED_NEGATIVE_POLARITY","","Negate results only before the end of the string",N,N],[17,"_SIDD_LEAST_SIGNIFICANT","","Index only: return the least significant bit (Default)",N,N],[17,"_SIDD_MOST_SIGNIFICANT","","Index only: return the most significant bit",N,N],[17,"_SIDD_BIT_MASK","","Mask only: return the bit mask",N,N],[17,"_SIDD_UNIT_MASK","","Mask only: return the byte mask",N,N],[17,"_CMP_EQ_OQ","","Equal (ordered, non-signaling)",N,N],[17,"_CMP_LT_OS","","Less-than (ordered, signaling)",N,N],[17,"_CMP_LE_OS","","Less-than-or-equal (ordered, signaling)",N,N],[17,"_CMP_UNORD_Q","","Unordered (non-signaling)",N,N],[17,"_CMP_NEQ_UQ","","Not-equal (unordered, non-signaling)",N,N],[17,"_CMP_NLT_US","","Not-less-than (unordered, signaling)",N,N],[17,"_CMP_NLE_US","","Not-less-than-or-equal (unordered, signaling)",N,N],[17,"_CMP_ORD_Q","","Ordered (non-signaling)",N,N],[17,"_CMP_EQ_UQ","","Equal (unordered, non-signaling)",N,N],[17,"_CMP_NGE_US","","Not-greater-than-or-equal (unordered, signaling)",N,N],[17,"_CMP_NGT_US","","Not-greater-than (unordered, signaling)",N,N],[17,"_CMP_FALSE_OQ","","False (ordered, non-signaling)",N,N],[17,"_CMP_NEQ_OQ","","Not-equal (ordered, non-signaling)",N,N],[17,"_CMP_GE_OS","","Greater-than-or-equal (ordered, signaling)",N,N],[17,"_CMP_GT_OS","","Greater-than (ordered, signaling)",N,N],[17,"_CMP_TRUE_UQ","","True (unordered, non-signaling)",N,N],[17,"_CMP_EQ_OS","","Equal (ordered, signaling)",N,N],[17,"_CMP_LT_OQ","","Less-than (ordered, non-signaling)",N,N],[17,"_CMP_LE_OQ","","Less-than-or-equal (ordered, non-signaling)",N,N],[17,"_CMP_UNORD_S","","Unordered (signaling)",N,N],[17,"_CMP_NEQ_US","","Not-equal (unordered, signaling)",N,N],[17,"_CMP_NLT_UQ","","Not-less-than (unordered, non-signaling)",N,N],[17,"_CMP_NLE_UQ","","Not-less-than-or-equal (unordered, non-signaling)",N,N],[17,"_CMP_ORD_S","","Ordered (signaling)",N,N],[17,"_CMP_EQ_US","","Equal (unordered, signaling)",N,N],[17,"_CMP_NGE_UQ","","Not-greater-than-or-equal (unordered, non-signaling)",N,N],[17,"_CMP_NGT_UQ","","Not-greater-than (unordered, non-signaling)",N,N],[17,"_CMP_FALSE_OS","","False (ordered, signaling)",N,N],[17,"_CMP_NEQ_OS","","Not-equal (ordered, signaling)",N,N],[17,"_CMP_GE_OQ","","Greater-than-or-equal (ordered, non-signaling)",N,N],[17,"_CMP_GT_OQ","","Greater-than (ordered, non-signaling)",N,N],[17,"_CMP_TRUE_US","","True (unordered, signaling)",N,N],[0,"simd","coresimd","Platform independent SIMD vector types and operations.",N,N],[3,"i8x16","coresimd::simd","A 128-bit vector with 16 `i8` lanes.",N,N],[3,"u8x16","","A 128-bit vector with 16 `u8` lanes.",N,N],[3,"m8x16","","A 128-bit vector mask with 16 lanes.",N,N],[3,"i16x8","","A 128-bit vector with 8 `i16` lanes.",N,N],[3,"u16x8","","A 128-bit vector with 8 `u16` lanes.",N,N],[3,"m16x8","","A 128-bit vector mask with 8 lanes.",N,N],[3,"i32x4","","A 128-bit vector with 4 `i32` lanes.",N,N],[3,"u32x4","","A 128-bit vector with 4 `u32` lanes.",N,N],[3,"f32x4","","A 128-bit vector with 4 `f32` lanes.",N,N],[3,"m32x4","","A 128-bit vector mask with 4 lanes.",N,N],[3,"i64x2","","A 128-bit vector with 2 `u64` lanes.",N,N],[3,"u64x2","","A 128-bit vector with 2 `u64` lanes.",N,N],[3,"f64x2","","A 128-bit vector with 2 `f64` lanes.",N,N],[3,"m64x2","","A 128-bit vector mask with 2 lanes.",N,N],[3,"i8x2","","A 16-bit wide vector with 2 `i8` lanes.",N,N],[3,"u8x2","","A 16-bit wide vector with 2 `u8` lanes.",N,N],[3,"m8x2","","A 16-bit wide vector mask with 2 lanes.",N,N],[3,"i8x32","","A 256-bit vector with 32 `i8` lanes.",N,N],[3,"u8x32","","A 256-bit vector with 32 `u8` lanes.",N,N],[3,"m8x32","","A 256-bit vector mask with 32 lanes.",N,N],[3,"i16x16","","A 256-bit vector with 16 `i16` lanes.",N,N],[3,"u16x16","","A 256-bit vector with 16 `u16` lanes.",N,N],[3,"m16x16","","A 256-bit vector mask with 16 lanes.",N,N],[3,"i32x8","","A 256-bit vector with 8 `i32` lanes.",N,N],[3,"u32x8","","A 256-bit vector with 8 `u32` lanes.",N,N],[3,"f32x8","","A 256-bit vector with 8 `f32` lanes.",N,N],[3,"m32x8","","A 256-bit vector mask with 8 lanes.",N,N],[3,"i64x4","","A 256-bit vector with 4 `i64` lanes.",N,N],[3,"u64x4","","A 256-bit vector with 4 `u64` lanes.",N,N],[3,"f64x4","","A 256-bit vector with 4 `f64` lanes.",N,N],[3,"m64x4","","A 256-bit vector mask with 4 lanes.",N,N],[3,"i16x2","","A 32-bit wide vector with 2 `i16` lanes.",N,N],[3,"u16x2","","A 32-bit wide vector with 2 `u16` lanes.",N,N],[3,"m16x2","","A 32-bit wide vector mask with 2 lanes.",N,N],[3,"i8x4","","A 32-bit wide vector with 4 `i8` lanes.",N,N],[3,"u8x4","","A 32-bit wide vector with 4 `u8` lanes.",N,N],[3,"m8x4","","A 32-bit wide vector mask 4 lanes.",N,N],[3,"i8x64","","A 512-bit vector with 64 `i8` lanes.",N,N],[3,"u8x64","","A 512-bit vector with 64 `u8` lanes.",N,N],[3,"m1x64","","A 64-bit vector mask with 64 lanes (FIXME: 512-bit wide).",N,N],[3,"i16x32","","A 512-bit vector with 32 `i16` lanes.",N,N],[3,"u16x32","","A 512-bit vector with 32 `u16` lanes.",N,N],[3,"m1x32","","A 32-bit vector mask with 32 lanes (FIXME: 512-bit wide).",N,N],[3,"i32x16","","A 512-bit vector with 16 `i32` lanes.",N,N],[3,"u32x16","","A 512-bit vector with 16 `u32` lanes.",N,N],[3,"f32x16","","A 512-bit vector with 16 `f32` lanes.",N,N],[3,"m1x16","","A 16-bit vector mask with 16 lanes (FIXME: 512-bit wide).",N,N],[3,"i64x8","","A 512-bit vector with 8 `i64` lanes.",N,N],[3,"u64x8","","A 512-bit vector with 8 `u64` lanes.",N,N],[3,"f64x8","","A 512-bit vector with 8 `f64` lanes.",N,N],[3,"m1x8","","A 8-bit vector mask with 8 lanes (FIXME: 512-bit wide).",N,N],[3,"i8x8","","A 64-bit vector with 8 `i8` lanes.",N,N],[3,"u8x8","","A 64-bit vector with 8 `u8` lanes.",N,N],[3,"m8x8","","A 64-bit vector mask with 8 lanes.",N,N],[3,"i16x4","","A 64-bit vector with 4 `i16` lanes.",N,N],[3,"u16x4","","A 64-bit vector with 4 `u16` lanes.",N,N],[3,"m16x4","","A 64-bit vector mask with 4 lanes.",N,N],[3,"i32x2","","A 64-bit vector with 2 `i32` lanes.",N,N],[3,"u32x2","","A 64-bit vector with 2 `u32` lanes.",N,N],[3,"m32x2","","A 64-bit vector mask with 2 lanes.",N,N],[3,"f32x2","","A 64-bit vector with 2 `f32` lanes.",N,N],[8,"FromBits","","Safe lossless bitwise conversion from `T` to `Self`.",N,N],[10,"from_bits","","Safe lossless bitwise from `T` to `Self`.",1,[[["t"]],["self"]]],[8,"IntoBits","","Safe lossless bitwise conversion from `Self` to `T`.",N,N],[10,"into_bits","","Safe lossless bitwise transmute from `self` to `T`.",2,[[["self"]],["t"]]],[11,"clone","","",3,[[["self"]],["i8x16"]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",3,[[["self"],["i8x16"]],["option",["ordering"]]]],[11,"lt","","",3,[[["self"],["i8x16"]],["bool"]]],[11,"le","","",3,[[["self"],["i8x16"]],["bool"]]],[11,"gt","","",3,[[["self"],["i8x16"]],["bool"]]],[11,"ge","","",3,[[["self"],["i8x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",3,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",3,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",3,[[["i8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",3,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",3,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",3,[[["self"],["usize"],["i8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",3,[[["self"],["usize"],["i8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",3,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",3,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",3,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",3,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",3,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",3,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",3,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",3,N],[11,"eq","","Lane-wise equality comparison.",3,[[["self"],["i8x16"]],["m8x16"]]],[11,"ne","","Lane-wise inequality comparison.",3,[[["self"],["i8x16"]],["m8x16"]]],[11,"lt","","Lane-wise less-than comparison.",3,[[["self"],["i8x16"]],["m8x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",3,[[["self"],["i8x16"]],["m8x16"]]],[11,"gt","","Lane-wise greater-than comparison.",3,[[["self"],["i8x16"]],["m8x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",3,[[["self"],["i8x16"]],["m8x16"]]],[11,"hash","","",3,[[["self"],["h"]]]],[11,"add","","",3,[[["self"],["self"]],["self"]]],[11,"sub","","",3,[[["self"],["self"]],["self"]]],[11,"mul","","",3,[[["self"],["self"]],["self"]]],[11,"div","","",3,[[["self"],["self"]],["self"]]],[11,"rem","","",3,[[["self"],["self"]],["self"]]],[11,"add_assign","","",3,[[["self"],["self"]]]],[11,"sub_assign","","",3,[[["self"],["self"]]]],[11,"mul_assign","","",3,[[["self"],["self"]]]],[11,"div_assign","","",3,[[["self"],["self"]]]],[11,"rem_assign","","",3,[[["self"],["self"]]]],[11,"add","","",3,[[["self"],["i8"]],["self"]]],[11,"sub","","",3,[[["self"],["i8"]],["self"]]],[11,"mul","","",3,[[["self"],["i8"]],["self"]]],[11,"div","","",3,[[["self"],["i8"]],["self"]]],[11,"rem","","",3,[[["self"],["i8"]],["self"]]],[11,"add_assign","","",3,[[["self"],["i8"]]]],[11,"sub_assign","","",3,[[["self"],["i8"]]]],[11,"mul_assign","","",3,[[["self"],["i8"]]]],[11,"div_assign","","",3,[[["self"],["i8"]]]],[11,"rem_assign","","",3,[[["self"],["i8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",3,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",3,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",3,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",3,[[["self"]],["i8"]]],[11,"neg","","",3,[[["self"]],["self"]]],[11,"not","","",3,[[["self"]],["self"]]],[11,"bitxor","","",3,[[["self"],["self"]],["self"]]],[11,"bitand","","",3,[[["self"],["self"]],["self"]]],[11,"bitor","","",3,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",3,[[["self"],["self"]]]],[11,"bitor_assign","","",3,[[["self"],["self"]]]],[11,"bitxor_assign","","",3,[[["self"],["self"]]]],[11,"bitxor","","",3,[[["self"],["i8"]],["self"]]],[11,"bitand","","",3,[[["self"],["i8"]],["self"]]],[11,"bitor","","",3,[[["self"],["i8"]],["self"]]],[11,"bitand_assign","","",3,[[["self"],["i8"]]]],[11,"bitor_assign","","",3,[[["self"],["i8"]]]],[11,"bitxor_assign","","",3,[[["self"],["i8"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",3,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",3,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",3,[[["self"]],["i8"]]],[11,"shl","","",3,[[["self"],["u8"]],["self"]]],[11,"shr","","",3,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["u8"]]]],[11,"shr_assign","","",3,[[["self"],["u8"]]]],[11,"shl","","",3,[[["self"],["u16"]],["self"]]],[11,"shr","","",3,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["u16"]]]],[11,"shr_assign","","",3,[[["self"],["u16"]]]],[11,"shl","","",3,[[["self"],["u32"]],["self"]]],[11,"shr","","",3,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["u32"]]]],[11,"shr_assign","","",3,[[["self"],["u32"]]]],[11,"shl","","",3,[[["self"],["u64"]],["self"]]],[11,"shr","","",3,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["u64"]]]],[11,"shr_assign","","",3,[[["self"],["u64"]]]],[11,"shl","","",3,[[["self"],["usize"]],["self"]]],[11,"shr","","",3,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["usize"]]]],[11,"shr_assign","","",3,[[["self"],["usize"]]]],[11,"shl","","",3,[[["self"],["i8"]],["self"]]],[11,"shr","","",3,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["i8"]]]],[11,"shr_assign","","",3,[[["self"],["i8"]]]],[11,"shl","","",3,[[["self"],["i16"]],["self"]]],[11,"shr","","",3,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["i16"]]]],[11,"shr_assign","","",3,[[["self"],["i16"]]]],[11,"shl","","",3,[[["self"],["i32"]],["self"]]],[11,"shr","","",3,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["i32"]]]],[11,"shr_assign","","",3,[[["self"],["i32"]]]],[11,"shl","","",3,[[["self"],["i64"]],["self"]]],[11,"shr","","",3,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["i64"]]]],[11,"shr_assign","","",3,[[["self"],["i64"]]]],[11,"shl","","",3,[[["self"],["isize"]],["self"]]],[11,"shr","","",3,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["isize"]]]],[11,"shr_assign","","",3,[[["self"],["isize"]]]],[11,"shl","","",3,[[["self"],["self"]],["self"]]],[11,"shr","","",3,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",3,[[["self"],["self"]]]],[11,"shr_assign","","",3,[[["self"],["self"]]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",3,[[["self"],["formatter"]],["result"]]],[11,"eq","","",3,[[["self"],["self"]],["bool"]]],[11,"ne","","",3,[[["self"],["self"]],["bool"]]],[11,"default","","",3,[[],["self"]]],[11,"min","","Minimum of two vectors.",3,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",3,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",3,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",3,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",3,[[["self"]],["self"]]],[11,"clone","","",4,[[["self"]],["u8x16"]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",4,[[["self"],["u8x16"]],["option",["ordering"]]]],[11,"lt","","",4,[[["self"],["u8x16"]],["bool"]]],[11,"le","","",4,[[["self"],["u8x16"]],["bool"]]],[11,"gt","","",4,[[["self"],["u8x16"]],["bool"]]],[11,"ge","","",4,[[["self"],["u8x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",4,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",4,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",4,[[["u8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",4,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",4,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",4,[[["self"],["usize"],["u8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",4,[[["self"],["usize"],["u8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",4,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",4,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",4,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",4,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"eq","","Lane-wise equality comparison.",4,[[["self"],["u8x16"]],["m8x16"]]],[11,"ne","","Lane-wise inequality comparison.",4,[[["self"],["u8x16"]],["m8x16"]]],[11,"lt","","Lane-wise less-than comparison.",4,[[["self"],["u8x16"]],["m8x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",4,[[["self"],["u8x16"]],["m8x16"]]],[11,"gt","","Lane-wise greater-than comparison.",4,[[["self"],["u8x16"]],["m8x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",4,[[["self"],["u8x16"]],["m8x16"]]],[11,"hash","","",4,[[["self"],["h"]]]],[11,"add","","",4,[[["self"],["self"]],["self"]]],[11,"sub","","",4,[[["self"],["self"]],["self"]]],[11,"mul","","",4,[[["self"],["self"]],["self"]]],[11,"div","","",4,[[["self"],["self"]],["self"]]],[11,"rem","","",4,[[["self"],["self"]],["self"]]],[11,"add_assign","","",4,[[["self"],["self"]]]],[11,"sub_assign","","",4,[[["self"],["self"]]]],[11,"mul_assign","","",4,[[["self"],["self"]]]],[11,"div_assign","","",4,[[["self"],["self"]]]],[11,"rem_assign","","",4,[[["self"],["self"]]]],[11,"add","","",4,[[["self"],["u8"]],["self"]]],[11,"sub","","",4,[[["self"],["u8"]],["self"]]],[11,"mul","","",4,[[["self"],["u8"]],["self"]]],[11,"div","","",4,[[["self"],["u8"]],["self"]]],[11,"rem","","",4,[[["self"],["u8"]],["self"]]],[11,"add_assign","","",4,[[["self"],["u8"]]]],[11,"sub_assign","","",4,[[["self"],["u8"]]]],[11,"mul_assign","","",4,[[["self"],["u8"]]]],[11,"div_assign","","",4,[[["self"],["u8"]]]],[11,"rem_assign","","",4,[[["self"],["u8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",4,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",4,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",4,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",4,[[["self"]],["u8"]]],[11,"bitxor","","",4,[[["self"],["u8"]],["self"]]],[11,"bitand","","",4,[[["self"],["u8"]],["self"]]],[11,"bitor","","",4,[[["self"],["u8"]],["self"]]],[11,"bitand_assign","","",4,[[["self"],["u8"]]]],[11,"bitor_assign","","",4,[[["self"],["u8"]]]],[11,"bitxor_assign","","",4,[[["self"],["u8"]]]],[11,"not","","",4,[[["self"]],["self"]]],[11,"bitxor","","",4,[[["self"],["self"]],["self"]]],[11,"bitand","","",4,[[["self"],["self"]],["self"]]],[11,"bitor","","",4,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",4,[[["self"],["self"]]]],[11,"bitor_assign","","",4,[[["self"],["self"]]]],[11,"bitxor_assign","","",4,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",4,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",4,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",4,[[["self"]],["u8"]]],[11,"shl","","",4,[[["self"],["u8"]],["self"]]],[11,"shr","","",4,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["u8"]]]],[11,"shr_assign","","",4,[[["self"],["u8"]]]],[11,"shl","","",4,[[["self"],["u16"]],["self"]]],[11,"shr","","",4,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["u16"]]]],[11,"shr_assign","","",4,[[["self"],["u16"]]]],[11,"shl","","",4,[[["self"],["u32"]],["self"]]],[11,"shr","","",4,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["u32"]]]],[11,"shr_assign","","",4,[[["self"],["u32"]]]],[11,"shl","","",4,[[["self"],["u64"]],["self"]]],[11,"shr","","",4,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["u64"]]]],[11,"shr_assign","","",4,[[["self"],["u64"]]]],[11,"shl","","",4,[[["self"],["usize"]],["self"]]],[11,"shr","","",4,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["usize"]]]],[11,"shr_assign","","",4,[[["self"],["usize"]]]],[11,"shl","","",4,[[["self"],["i8"]],["self"]]],[11,"shr","","",4,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["i8"]]]],[11,"shr_assign","","",4,[[["self"],["i8"]]]],[11,"shl","","",4,[[["self"],["i16"]],["self"]]],[11,"shr","","",4,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["i16"]]]],[11,"shr_assign","","",4,[[["self"],["i16"]]]],[11,"shl","","",4,[[["self"],["i32"]],["self"]]],[11,"shr","","",4,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["i32"]]]],[11,"shr_assign","","",4,[[["self"],["i32"]]]],[11,"shl","","",4,[[["self"],["i64"]],["self"]]],[11,"shr","","",4,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["i64"]]]],[11,"shr_assign","","",4,[[["self"],["i64"]]]],[11,"shl","","",4,[[["self"],["isize"]],["self"]]],[11,"shr","","",4,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["isize"]]]],[11,"shr_assign","","",4,[[["self"],["isize"]]]],[11,"shl","","",4,[[["self"],["self"]],["self"]]],[11,"shr","","",4,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",4,[[["self"],["self"]]]],[11,"shr_assign","","",4,[[["self"],["self"]]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result"]]],[11,"eq","","",4,[[["self"],["self"]],["bool"]]],[11,"ne","","",4,[[["self"],["self"]],["bool"]]],[11,"default","","",4,[[],["self"]]],[11,"min","","Minimum of two vectors.",4,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",4,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",4,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",4,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",4,[[["self"]],["self"]]],[11,"clone","","",5,[[["self"]],["m8x16"]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",5,[[["self"],["m8x16"]],["option",["ordering"]]]],[11,"lt","","",5,[[["self"],["m8x16"]],["bool"]]],[11,"le","","",5,[[["self"],["m8x16"]],["bool"]]],[11,"gt","","",5,[[["self"],["m8x16"]],["bool"]]],[11,"ge","","",5,[[["self"],["m8x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",5,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",5,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",5,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",5,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",5,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",5,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",5,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",5,[[["self"]],["self"]]],[11,"bitxor","","",5,[[["self"],["self"]],["self"]]],[11,"bitand","","",5,[[["self"],["self"]],["self"]]],[11,"bitor","","",5,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",5,[[["self"],["self"]]]],[11,"bitor_assign","","",5,[[["self"],["self"]]]],[11,"bitxor_assign","","",5,[[["self"],["self"]]]],[11,"bitxor","","",5,[[["self"],["bool"]],["self"]]],[11,"bitand","","",5,[[["self"],["bool"]],["self"]]],[11,"bitor","","",5,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",5,[[["self"],["bool"]]]],[11,"bitor_assign","","",5,[[["self"],["bool"]]]],[11,"bitxor_assign","","",5,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",5,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",5,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",5,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",5,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",5,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",5,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",5,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",5,[[["self"],["m8x16"]],["m8x16"]]],[11,"ne","","Lane-wise inequality comparison.",5,[[["self"],["m8x16"]],["m8x16"]]],[11,"lt","","Lane-wise less-than comparison.",5,[[["self"],["m8x16"]],["m8x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",5,[[["self"],["m8x16"]],["m8x16"]]],[11,"gt","","Lane-wise greater-than comparison.",5,[[["self"],["m8x16"]],["m8x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",5,[[["self"],["m8x16"]],["m8x16"]]],[11,"eq","","",5,[[["self"],["self"]],["bool"]]],[11,"ne","","",5,[[["self"],["self"]],["bool"]]],[11,"default","","",5,[[],["self"]]],[11,"clone","","",6,[[["self"]],["i16x8"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",6,[[["self"],["i16x8"]],["option",["ordering"]]]],[11,"lt","","",6,[[["self"],["i16x8"]],["bool"]]],[11,"le","","",6,[[["self"],["i16x8"]],["bool"]]],[11,"gt","","",6,[[["self"],["i16x8"]],["bool"]]],[11,"ge","","",6,[[["self"],["i16x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",6,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",6,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",6,[[["i16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",6,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",6,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",6,[[["self"],["usize"],["i16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",6,[[["self"],["usize"],["i16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",6,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",6,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",6,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",6,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"eq","","Lane-wise equality comparison.",6,[[["self"],["i16x8"]],["m16x8"]]],[11,"ne","","Lane-wise inequality comparison.",6,[[["self"],["i16x8"]],["m16x8"]]],[11,"lt","","Lane-wise less-than comparison.",6,[[["self"],["i16x8"]],["m16x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",6,[[["self"],["i16x8"]],["m16x8"]]],[11,"gt","","Lane-wise greater-than comparison.",6,[[["self"],["i16x8"]],["m16x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",6,[[["self"],["i16x8"]],["m16x8"]]],[11,"hash","","",6,[[["self"],["h"]]]],[11,"add","","",6,[[["self"],["self"]],["self"]]],[11,"sub","","",6,[[["self"],["self"]],["self"]]],[11,"mul","","",6,[[["self"],["self"]],["self"]]],[11,"div","","",6,[[["self"],["self"]],["self"]]],[11,"rem","","",6,[[["self"],["self"]],["self"]]],[11,"add_assign","","",6,[[["self"],["self"]]]],[11,"sub_assign","","",6,[[["self"],["self"]]]],[11,"mul_assign","","",6,[[["self"],["self"]]]],[11,"div_assign","","",6,[[["self"],["self"]]]],[11,"rem_assign","","",6,[[["self"],["self"]]]],[11,"add","","",6,[[["self"],["i16"]],["self"]]],[11,"sub","","",6,[[["self"],["i16"]],["self"]]],[11,"mul","","",6,[[["self"],["i16"]],["self"]]],[11,"div","","",6,[[["self"],["i16"]],["self"]]],[11,"rem","","",6,[[["self"],["i16"]],["self"]]],[11,"add_assign","","",6,[[["self"],["i16"]]]],[11,"sub_assign","","",6,[[["self"],["i16"]]]],[11,"mul_assign","","",6,[[["self"],["i16"]]]],[11,"div_assign","","",6,[[["self"],["i16"]]]],[11,"rem_assign","","",6,[[["self"],["i16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",6,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",6,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",6,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",6,[[["self"]],["i16"]]],[11,"neg","","",6,[[["self"]],["self"]]],[11,"not","","",6,[[["self"]],["self"]]],[11,"bitxor","","",6,[[["self"],["self"]],["self"]]],[11,"bitand","","",6,[[["self"],["self"]],["self"]]],[11,"bitor","","",6,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",6,[[["self"],["self"]]]],[11,"bitor_assign","","",6,[[["self"],["self"]]]],[11,"bitxor_assign","","",6,[[["self"],["self"]]]],[11,"bitxor","","",6,[[["self"],["i16"]],["self"]]],[11,"bitand","","",6,[[["self"],["i16"]],["self"]]],[11,"bitor","","",6,[[["self"],["i16"]],["self"]]],[11,"bitand_assign","","",6,[[["self"],["i16"]]]],[11,"bitor_assign","","",6,[[["self"],["i16"]]]],[11,"bitxor_assign","","",6,[[["self"],["i16"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",6,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",6,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",6,[[["self"]],["i16"]]],[11,"shl","","",6,[[["self"],["u8"]],["self"]]],[11,"shr","","",6,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["u8"]]]],[11,"shr_assign","","",6,[[["self"],["u8"]]]],[11,"shl","","",6,[[["self"],["u16"]],["self"]]],[11,"shr","","",6,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["u16"]]]],[11,"shr_assign","","",6,[[["self"],["u16"]]]],[11,"shl","","",6,[[["self"],["u32"]],["self"]]],[11,"shr","","",6,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["u32"]]]],[11,"shr_assign","","",6,[[["self"],["u32"]]]],[11,"shl","","",6,[[["self"],["u64"]],["self"]]],[11,"shr","","",6,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["u64"]]]],[11,"shr_assign","","",6,[[["self"],["u64"]]]],[11,"shl","","",6,[[["self"],["usize"]],["self"]]],[11,"shr","","",6,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["usize"]]]],[11,"shr_assign","","",6,[[["self"],["usize"]]]],[11,"shl","","",6,[[["self"],["i8"]],["self"]]],[11,"shr","","",6,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["i8"]]]],[11,"shr_assign","","",6,[[["self"],["i8"]]]],[11,"shl","","",6,[[["self"],["i16"]],["self"]]],[11,"shr","","",6,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["i16"]]]],[11,"shr_assign","","",6,[[["self"],["i16"]]]],[11,"shl","","",6,[[["self"],["i32"]],["self"]]],[11,"shr","","",6,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["i32"]]]],[11,"shr_assign","","",6,[[["self"],["i32"]]]],[11,"shl","","",6,[[["self"],["i64"]],["self"]]],[11,"shr","","",6,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["i64"]]]],[11,"shr_assign","","",6,[[["self"],["i64"]]]],[11,"shl","","",6,[[["self"],["isize"]],["self"]]],[11,"shr","","",6,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["isize"]]]],[11,"shr_assign","","",6,[[["self"],["isize"]]]],[11,"shl","","",6,[[["self"],["self"]],["self"]]],[11,"shr","","",6,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",6,[[["self"],["self"]]]],[11,"shr_assign","","",6,[[["self"],["self"]]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result"]]],[11,"eq","","",6,[[["self"],["self"]],["bool"]]],[11,"ne","","",6,[[["self"],["self"]],["bool"]]],[11,"default","","",6,[[],["self"]]],[11,"min","","Minimum of two vectors.",6,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",6,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",6,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",6,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",6,[[["self"]],["self"]]],[11,"clone","","",7,[[["self"]],["u16x8"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",7,[[["self"],["u16x8"]],["option",["ordering"]]]],[11,"lt","","",7,[[["self"],["u16x8"]],["bool"]]],[11,"le","","",7,[[["self"],["u16x8"]],["bool"]]],[11,"gt","","",7,[[["self"],["u16x8"]],["bool"]]],[11,"ge","","",7,[[["self"],["u16x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",7,[[["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",7,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",7,[[["u16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",7,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",7,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",7,[[["self"],["usize"],["u16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",7,[[["self"],["usize"],["u16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",7,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",7,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",7,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",7,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"eq","","Lane-wise equality comparison.",7,[[["self"],["u16x8"]],["m16x8"]]],[11,"ne","","Lane-wise inequality comparison.",7,[[["self"],["u16x8"]],["m16x8"]]],[11,"lt","","Lane-wise less-than comparison.",7,[[["self"],["u16x8"]],["m16x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",7,[[["self"],["u16x8"]],["m16x8"]]],[11,"gt","","Lane-wise greater-than comparison.",7,[[["self"],["u16x8"]],["m16x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",7,[[["self"],["u16x8"]],["m16x8"]]],[11,"hash","","",7,[[["self"],["h"]]]],[11,"add","","",7,[[["self"],["self"]],["self"]]],[11,"sub","","",7,[[["self"],["self"]],["self"]]],[11,"mul","","",7,[[["self"],["self"]],["self"]]],[11,"div","","",7,[[["self"],["self"]],["self"]]],[11,"rem","","",7,[[["self"],["self"]],["self"]]],[11,"add_assign","","",7,[[["self"],["self"]]]],[11,"sub_assign","","",7,[[["self"],["self"]]]],[11,"mul_assign","","",7,[[["self"],["self"]]]],[11,"div_assign","","",7,[[["self"],["self"]]]],[11,"rem_assign","","",7,[[["self"],["self"]]]],[11,"add","","",7,[[["self"],["u16"]],["self"]]],[11,"sub","","",7,[[["self"],["u16"]],["self"]]],[11,"mul","","",7,[[["self"],["u16"]],["self"]]],[11,"div","","",7,[[["self"],["u16"]],["self"]]],[11,"rem","","",7,[[["self"],["u16"]],["self"]]],[11,"add_assign","","",7,[[["self"],["u16"]]]],[11,"sub_assign","","",7,[[["self"],["u16"]]]],[11,"mul_assign","","",7,[[["self"],["u16"]]]],[11,"div_assign","","",7,[[["self"],["u16"]]]],[11,"rem_assign","","",7,[[["self"],["u16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",7,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",7,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",7,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",7,[[["self"]],["u16"]]],[11,"bitxor","","",7,[[["self"],["u16"]],["self"]]],[11,"bitand","","",7,[[["self"],["u16"]],["self"]]],[11,"bitor","","",7,[[["self"],["u16"]],["self"]]],[11,"bitand_assign","","",7,[[["self"],["u16"]]]],[11,"bitor_assign","","",7,[[["self"],["u16"]]]],[11,"bitxor_assign","","",7,[[["self"],["u16"]]]],[11,"not","","",7,[[["self"]],["self"]]],[11,"bitxor","","",7,[[["self"],["self"]],["self"]]],[11,"bitand","","",7,[[["self"],["self"]],["self"]]],[11,"bitor","","",7,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",7,[[["self"],["self"]]]],[11,"bitor_assign","","",7,[[["self"],["self"]]]],[11,"bitxor_assign","","",7,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",7,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",7,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",7,[[["self"]],["u16"]]],[11,"shl","","",7,[[["self"],["u8"]],["self"]]],[11,"shr","","",7,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["u8"]]]],[11,"shr_assign","","",7,[[["self"],["u8"]]]],[11,"shl","","",7,[[["self"],["u16"]],["self"]]],[11,"shr","","",7,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["u16"]]]],[11,"shr_assign","","",7,[[["self"],["u16"]]]],[11,"shl","","",7,[[["self"],["u32"]],["self"]]],[11,"shr","","",7,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["u32"]]]],[11,"shr_assign","","",7,[[["self"],["u32"]]]],[11,"shl","","",7,[[["self"],["u64"]],["self"]]],[11,"shr","","",7,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["u64"]]]],[11,"shr_assign","","",7,[[["self"],["u64"]]]],[11,"shl","","",7,[[["self"],["usize"]],["self"]]],[11,"shr","","",7,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["usize"]]]],[11,"shr_assign","","",7,[[["self"],["usize"]]]],[11,"shl","","",7,[[["self"],["i8"]],["self"]]],[11,"shr","","",7,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["i8"]]]],[11,"shr_assign","","",7,[[["self"],["i8"]]]],[11,"shl","","",7,[[["self"],["i16"]],["self"]]],[11,"shr","","",7,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["i16"]]]],[11,"shr_assign","","",7,[[["self"],["i16"]]]],[11,"shl","","",7,[[["self"],["i32"]],["self"]]],[11,"shr","","",7,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["i32"]]]],[11,"shr_assign","","",7,[[["self"],["i32"]]]],[11,"shl","","",7,[[["self"],["i64"]],["self"]]],[11,"shr","","",7,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["i64"]]]],[11,"shr_assign","","",7,[[["self"],["i64"]]]],[11,"shl","","",7,[[["self"],["isize"]],["self"]]],[11,"shr","","",7,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["isize"]]]],[11,"shr_assign","","",7,[[["self"],["isize"]]]],[11,"shl","","",7,[[["self"],["self"]],["self"]]],[11,"shr","","",7,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",7,[[["self"],["self"]]]],[11,"shr_assign","","",7,[[["self"],["self"]]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result"]]],[11,"eq","","",7,[[["self"],["self"]],["bool"]]],[11,"ne","","",7,[[["self"],["self"]],["bool"]]],[11,"default","","",7,[[],["self"]]],[11,"min","","Minimum of two vectors.",7,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",7,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",7,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",7,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",7,[[["self"]],["self"]]],[11,"clone","","",8,[[["self"]],["m16x8"]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",8,[[["self"],["m16x8"]],["option",["ordering"]]]],[11,"lt","","",8,[[["self"],["m16x8"]],["bool"]]],[11,"le","","",8,[[["self"],["m16x8"]],["bool"]]],[11,"gt","","",8,[[["self"],["m16x8"]],["bool"]]],[11,"ge","","",8,[[["self"],["m16x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",8,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",8,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",8,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",8,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",8,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",8,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",8,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",8,[[["self"]],["self"]]],[11,"bitxor","","",8,[[["self"],["self"]],["self"]]],[11,"bitand","","",8,[[["self"],["self"]],["self"]]],[11,"bitor","","",8,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",8,[[["self"],["self"]]]],[11,"bitor_assign","","",8,[[["self"],["self"]]]],[11,"bitxor_assign","","",8,[[["self"],["self"]]]],[11,"bitxor","","",8,[[["self"],["bool"]],["self"]]],[11,"bitand","","",8,[[["self"],["bool"]],["self"]]],[11,"bitor","","",8,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",8,[[["self"],["bool"]]]],[11,"bitor_assign","","",8,[[["self"],["bool"]]]],[11,"bitxor_assign","","",8,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",8,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",8,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",8,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",8,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",8,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",8,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",8,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",8,[[["self"],["m16x8"]],["m16x8"]]],[11,"ne","","Lane-wise inequality comparison.",8,[[["self"],["m16x8"]],["m16x8"]]],[11,"lt","","Lane-wise less-than comparison.",8,[[["self"],["m16x8"]],["m16x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",8,[[["self"],["m16x8"]],["m16x8"]]],[11,"gt","","Lane-wise greater-than comparison.",8,[[["self"],["m16x8"]],["m16x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",8,[[["self"],["m16x8"]],["m16x8"]]],[11,"eq","","",8,[[["self"],["self"]],["bool"]]],[11,"ne","","",8,[[["self"],["self"]],["bool"]]],[11,"default","","",8,[[],["self"]]],[11,"clone","","",9,[[["self"]],["i32x4"]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",9,[[["self"],["i32x4"]],["option",["ordering"]]]],[11,"lt","","",9,[[["self"],["i32x4"]],["bool"]]],[11,"le","","",9,[[["self"],["i32x4"]],["bool"]]],[11,"gt","","",9,[[["self"],["i32x4"]],["bool"]]],[11,"ge","","",9,[[["self"],["i32x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",9,[[["i32"],["i32"],["i32"],["i32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",9,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",9,[[["i32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",9,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",9,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",9,[[["self"],["usize"],["i32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",9,[[["self"],["usize"],["i32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",9,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",9,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",9,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",9,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"eq","","Lane-wise equality comparison.",9,[[["self"],["i32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",9,[[["self"],["i32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",9,[[["self"],["i32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",9,[[["self"],["i32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",9,[[["self"],["i32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",9,[[["self"],["i32x4"]],["m32x4"]]],[11,"hash","","",9,[[["self"],["h"]]]],[11,"add","","",9,[[["self"],["self"]],["self"]]],[11,"sub","","",9,[[["self"],["self"]],["self"]]],[11,"mul","","",9,[[["self"],["self"]],["self"]]],[11,"div","","",9,[[["self"],["self"]],["self"]]],[11,"rem","","",9,[[["self"],["self"]],["self"]]],[11,"add_assign","","",9,[[["self"],["self"]]]],[11,"sub_assign","","",9,[[["self"],["self"]]]],[11,"mul_assign","","",9,[[["self"],["self"]]]],[11,"div_assign","","",9,[[["self"],["self"]]]],[11,"rem_assign","","",9,[[["self"],["self"]]]],[11,"add","","",9,[[["self"],["i32"]],["self"]]],[11,"sub","","",9,[[["self"],["i32"]],["self"]]],[11,"mul","","",9,[[["self"],["i32"]],["self"]]],[11,"div","","",9,[[["self"],["i32"]],["self"]]],[11,"rem","","",9,[[["self"],["i32"]],["self"]]],[11,"add_assign","","",9,[[["self"],["i32"]]]],[11,"sub_assign","","",9,[[["self"],["i32"]]]],[11,"mul_assign","","",9,[[["self"],["i32"]]]],[11,"div_assign","","",9,[[["self"],["i32"]]]],[11,"rem_assign","","",9,[[["self"],["i32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",9,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",9,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",9,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",9,[[["self"]],["i32"]]],[11,"neg","","",9,[[["self"]],["self"]]],[11,"not","","",9,[[["self"]],["self"]]],[11,"bitxor","","",9,[[["self"],["self"]],["self"]]],[11,"bitand","","",9,[[["self"],["self"]],["self"]]],[11,"bitor","","",9,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",9,[[["self"],["self"]]]],[11,"bitor_assign","","",9,[[["self"],["self"]]]],[11,"bitxor_assign","","",9,[[["self"],["self"]]]],[11,"bitxor","","",9,[[["self"],["i32"]],["self"]]],[11,"bitand","","",9,[[["self"],["i32"]],["self"]]],[11,"bitor","","",9,[[["self"],["i32"]],["self"]]],[11,"bitand_assign","","",9,[[["self"],["i32"]]]],[11,"bitor_assign","","",9,[[["self"],["i32"]]]],[11,"bitxor_assign","","",9,[[["self"],["i32"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",9,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",9,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",9,[[["self"]],["i32"]]],[11,"shl","","",9,[[["self"],["u8"]],["self"]]],[11,"shr","","",9,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["u8"]]]],[11,"shr_assign","","",9,[[["self"],["u8"]]]],[11,"shl","","",9,[[["self"],["u16"]],["self"]]],[11,"shr","","",9,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["u16"]]]],[11,"shr_assign","","",9,[[["self"],["u16"]]]],[11,"shl","","",9,[[["self"],["u32"]],["self"]]],[11,"shr","","",9,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["u32"]]]],[11,"shr_assign","","",9,[[["self"],["u32"]]]],[11,"shl","","",9,[[["self"],["u64"]],["self"]]],[11,"shr","","",9,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["u64"]]]],[11,"shr_assign","","",9,[[["self"],["u64"]]]],[11,"shl","","",9,[[["self"],["usize"]],["self"]]],[11,"shr","","",9,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["usize"]]]],[11,"shr_assign","","",9,[[["self"],["usize"]]]],[11,"shl","","",9,[[["self"],["i8"]],["self"]]],[11,"shr","","",9,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["i8"]]]],[11,"shr_assign","","",9,[[["self"],["i8"]]]],[11,"shl","","",9,[[["self"],["i16"]],["self"]]],[11,"shr","","",9,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["i16"]]]],[11,"shr_assign","","",9,[[["self"],["i16"]]]],[11,"shl","","",9,[[["self"],["i32"]],["self"]]],[11,"shr","","",9,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["i32"]]]],[11,"shr_assign","","",9,[[["self"],["i32"]]]],[11,"shl","","",9,[[["self"],["i64"]],["self"]]],[11,"shr","","",9,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["i64"]]]],[11,"shr_assign","","",9,[[["self"],["i64"]]]],[11,"shl","","",9,[[["self"],["isize"]],["self"]]],[11,"shr","","",9,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["isize"]]]],[11,"shr_assign","","",9,[[["self"],["isize"]]]],[11,"shl","","",9,[[["self"],["self"]],["self"]]],[11,"shr","","",9,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",9,[[["self"],["self"]]]],[11,"shr_assign","","",9,[[["self"],["self"]]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result"]]],[11,"eq","","",9,[[["self"],["self"]],["bool"]]],[11,"ne","","",9,[[["self"],["self"]],["bool"]]],[11,"default","","",9,[[],["self"]]],[11,"min","","Minimum of two vectors.",9,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",9,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",9,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",9,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",9,[[["self"]],["self"]]],[11,"clone","","",10,[[["self"]],["u32x4"]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",10,[[["self"],["u32x4"]],["option",["ordering"]]]],[11,"lt","","",10,[[["self"],["u32x4"]],["bool"]]],[11,"le","","",10,[[["self"],["u32x4"]],["bool"]]],[11,"gt","","",10,[[["self"],["u32x4"]],["bool"]]],[11,"ge","","",10,[[["self"],["u32x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",10,[[["u32"],["u32"],["u32"],["u32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",10,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",10,[[["u32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",10,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",10,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",10,[[["self"],["usize"],["u32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",10,[[["self"],["usize"],["u32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",10,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",10,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",10,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",10,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"eq","","Lane-wise equality comparison.",10,[[["self"],["u32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",10,[[["self"],["u32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",10,[[["self"],["u32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",10,[[["self"],["u32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",10,[[["self"],["u32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",10,[[["self"],["u32x4"]],["m32x4"]]],[11,"hash","","",10,[[["self"],["h"]]]],[11,"add","","",10,[[["self"],["self"]],["self"]]],[11,"sub","","",10,[[["self"],["self"]],["self"]]],[11,"mul","","",10,[[["self"],["self"]],["self"]]],[11,"div","","",10,[[["self"],["self"]],["self"]]],[11,"rem","","",10,[[["self"],["self"]],["self"]]],[11,"add_assign","","",10,[[["self"],["self"]]]],[11,"sub_assign","","",10,[[["self"],["self"]]]],[11,"mul_assign","","",10,[[["self"],["self"]]]],[11,"div_assign","","",10,[[["self"],["self"]]]],[11,"rem_assign","","",10,[[["self"],["self"]]]],[11,"add","","",10,[[["self"],["u32"]],["self"]]],[11,"sub","","",10,[[["self"],["u32"]],["self"]]],[11,"mul","","",10,[[["self"],["u32"]],["self"]]],[11,"div","","",10,[[["self"],["u32"]],["self"]]],[11,"rem","","",10,[[["self"],["u32"]],["self"]]],[11,"add_assign","","",10,[[["self"],["u32"]]]],[11,"sub_assign","","",10,[[["self"],["u32"]]]],[11,"mul_assign","","",10,[[["self"],["u32"]]]],[11,"div_assign","","",10,[[["self"],["u32"]]]],[11,"rem_assign","","",10,[[["self"],["u32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",10,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",10,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",10,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",10,[[["self"]],["u32"]]],[11,"bitxor","","",10,[[["self"],["u32"]],["self"]]],[11,"bitand","","",10,[[["self"],["u32"]],["self"]]],[11,"bitor","","",10,[[["self"],["u32"]],["self"]]],[11,"bitand_assign","","",10,[[["self"],["u32"]]]],[11,"bitor_assign","","",10,[[["self"],["u32"]]]],[11,"bitxor_assign","","",10,[[["self"],["u32"]]]],[11,"not","","",10,[[["self"]],["self"]]],[11,"bitxor","","",10,[[["self"],["self"]],["self"]]],[11,"bitand","","",10,[[["self"],["self"]],["self"]]],[11,"bitor","","",10,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",10,[[["self"],["self"]]]],[11,"bitor_assign","","",10,[[["self"],["self"]]]],[11,"bitxor_assign","","",10,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",10,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",10,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",10,[[["self"]],["u32"]]],[11,"shl","","",10,[[["self"],["u8"]],["self"]]],[11,"shr","","",10,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["u8"]]]],[11,"shr_assign","","",10,[[["self"],["u8"]]]],[11,"shl","","",10,[[["self"],["u16"]],["self"]]],[11,"shr","","",10,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["u16"]]]],[11,"shr_assign","","",10,[[["self"],["u16"]]]],[11,"shl","","",10,[[["self"],["u32"]],["self"]]],[11,"shr","","",10,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["u32"]]]],[11,"shr_assign","","",10,[[["self"],["u32"]]]],[11,"shl","","",10,[[["self"],["u64"]],["self"]]],[11,"shr","","",10,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["u64"]]]],[11,"shr_assign","","",10,[[["self"],["u64"]]]],[11,"shl","","",10,[[["self"],["usize"]],["self"]]],[11,"shr","","",10,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["usize"]]]],[11,"shr_assign","","",10,[[["self"],["usize"]]]],[11,"shl","","",10,[[["self"],["i8"]],["self"]]],[11,"shr","","",10,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["i8"]]]],[11,"shr_assign","","",10,[[["self"],["i8"]]]],[11,"shl","","",10,[[["self"],["i16"]],["self"]]],[11,"shr","","",10,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["i16"]]]],[11,"shr_assign","","",10,[[["self"],["i16"]]]],[11,"shl","","",10,[[["self"],["i32"]],["self"]]],[11,"shr","","",10,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["i32"]]]],[11,"shr_assign","","",10,[[["self"],["i32"]]]],[11,"shl","","",10,[[["self"],["i64"]],["self"]]],[11,"shr","","",10,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["i64"]]]],[11,"shr_assign","","",10,[[["self"],["i64"]]]],[11,"shl","","",10,[[["self"],["isize"]],["self"]]],[11,"shr","","",10,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["isize"]]]],[11,"shr_assign","","",10,[[["self"],["isize"]]]],[11,"shl","","",10,[[["self"],["self"]],["self"]]],[11,"shr","","",10,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",10,[[["self"],["self"]]]],[11,"shr_assign","","",10,[[["self"],["self"]]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result"]]],[11,"eq","","",10,[[["self"],["self"]],["bool"]]],[11,"ne","","",10,[[["self"],["self"]],["bool"]]],[11,"default","","",10,[[],["self"]]],[11,"min","","Minimum of two vectors.",10,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",10,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",10,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",10,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",10,[[["self"]],["self"]]],[11,"clone","","",11,[[["self"]],["f32x4"]]],[11,"fmt","","",11,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",11,[[["self"],["f32x4"]],["option",["ordering"]]]],[11,"lt","","",11,[[["self"],["f32x4"]],["bool"]]],[11,"le","","",11,[[["self"],["f32x4"]],["bool"]]],[11,"gt","","",11,[[["self"],["f32x4"]],["bool"]]],[11,"ge","","",11,[[["self"],["f32x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",11,[[["f32"],["f32"],["f32"],["f32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",11,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",11,[[["f32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",11,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",11,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",11,[[["self"],["usize"],["f32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",11,[[["self"],["usize"],["f32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",11,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",11,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",11,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",11,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",11,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",11,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",11,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",11,N],[11,"eq","","Lane-wise equality comparison.",11,[[["self"],["f32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",11,[[["self"],["f32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",11,[[["self"],["f32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",11,[[["self"],["f32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",11,[[["self"],["f32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",11,[[["self"],["f32x4"]],["m32x4"]]],[11,"add","","",11,[[["self"],["self"]],["self"]]],[11,"sub","","",11,[[["self"],["self"]],["self"]]],[11,"mul","","",11,[[["self"],["self"]],["self"]]],[11,"div","","",11,[[["self"],["self"]],["self"]]],[11,"rem","","",11,[[["self"],["self"]],["self"]]],[11,"add_assign","","",11,[[["self"],["self"]]]],[11,"sub_assign","","",11,[[["self"],["self"]]]],[11,"mul_assign","","",11,[[["self"],["self"]]]],[11,"div_assign","","",11,[[["self"],["self"]]]],[11,"rem_assign","","",11,[[["self"],["self"]]]],[11,"add","","",11,[[["self"],["f32"]],["self"]]],[11,"sub","","",11,[[["self"],["f32"]],["self"]]],[11,"mul","","",11,[[["self"],["f32"]],["self"]]],[11,"div","","",11,[[["self"],["f32"]],["self"]]],[11,"rem","","",11,[[["self"],["f32"]],["self"]]],[11,"add_assign","","",11,[[["self"],["f32"]]]],[11,"sub_assign","","",11,[[["self"],["f32"]]]],[11,"mul_assign","","",11,[[["self"],["f32"]]]],[11,"div_assign","","",11,[[["self"],["f32"]]]],[11,"rem_assign","","",11,[[["self"],["f32"]]]],[11,"sum","","Horizontal sum of the vector elements.",11,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",11,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",11,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",11,[[["self"]],["f32"]]],[11,"neg","","",11,[[["self"]],["self"]]],[11,"eq","","",11,[[["self"],["self"]],["bool"]]],[11,"ne","","",11,[[["self"],["self"]],["bool"]]],[11,"default","","",11,[[],["self"]]],[11,"min","","Minimum of two vectors.",11,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",11,[[["self"],["self"]],["self"]]],[11,"abs","","Absolute-value",11,[[["self"]],["self"]]],[11,"sqrt","","Square-root",11,[[["self"]],["self"]]],[11,"sqrte","","Square-root estimate",11,[[["self"]],["self"]]],[11,"rsqrte","","Reciprocal square-root estimate",11,[[["self"]],["self"]]],[11,"fma","","Fused multiply add: `self * y + z`",11,[[["self"],["self"],["self"]],["self"]]],[11,"sin","","Sin",11,[[["self"]],["self"]]],[11,"cos","","Cos",11,[[["self"]],["self"]]],[11,"clone","","",12,[[["self"]],["m32x4"]]],[11,"fmt","","",12,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",12,[[["self"],["m32x4"]],["option",["ordering"]]]],[11,"lt","","",12,[[["self"],["m32x4"]],["bool"]]],[11,"le","","",12,[[["self"],["m32x4"]],["bool"]]],[11,"gt","","",12,[[["self"],["m32x4"]],["bool"]]],[11,"ge","","",12,[[["self"],["m32x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",12,[[["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",12,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",12,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",12,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",12,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",12,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",12,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",12,[[["self"]],["self"]]],[11,"bitxor","","",12,[[["self"],["self"]],["self"]]],[11,"bitand","","",12,[[["self"],["self"]],["self"]]],[11,"bitor","","",12,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",12,[[["self"],["self"]]]],[11,"bitor_assign","","",12,[[["self"],["self"]]]],[11,"bitxor_assign","","",12,[[["self"],["self"]]]],[11,"bitxor","","",12,[[["self"],["bool"]],["self"]]],[11,"bitand","","",12,[[["self"],["bool"]],["self"]]],[11,"bitor","","",12,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",12,[[["self"],["bool"]]]],[11,"bitor_assign","","",12,[[["self"],["bool"]]]],[11,"bitxor_assign","","",12,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",12,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",12,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",12,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",12,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",12,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",12,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",12,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",12,[[["self"],["m32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",12,[[["self"],["m32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",12,[[["self"],["m32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",12,[[["self"],["m32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",12,[[["self"],["m32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",12,[[["self"],["m32x4"]],["m32x4"]]],[11,"eq","","",12,[[["self"],["self"]],["bool"]]],[11,"ne","","",12,[[["self"],["self"]],["bool"]]],[11,"default","","",12,[[],["self"]]],[11,"clone","","",13,[[["self"]],["i64x2"]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",13,[[["self"],["i64x2"]],["option",["ordering"]]]],[11,"lt","","",13,[[["self"],["i64x2"]],["bool"]]],[11,"le","","",13,[[["self"],["i64x2"]],["bool"]]],[11,"gt","","",13,[[["self"],["i64x2"]],["bool"]]],[11,"ge","","",13,[[["self"],["i64x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",13,[[["i64"],["i64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",13,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",13,[[["i64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",13,[[["self"],["usize"]],["i64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",13,[[["self"],["usize"]],["i64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",13,[[["self"],["usize"],["i64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",13,[[["self"],["usize"],["i64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",13,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",13,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",13,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",13,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"eq","","Lane-wise equality comparison.",13,[[["self"],["i64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",13,[[["self"],["i64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",13,[[["self"],["i64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",13,[[["self"],["i64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",13,[[["self"],["i64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",13,[[["self"],["i64x2"]],["m64x2"]]],[11,"hash","","",13,[[["self"],["h"]]]],[11,"add","","",13,[[["self"],["self"]],["self"]]],[11,"sub","","",13,[[["self"],["self"]],["self"]]],[11,"mul","","",13,[[["self"],["self"]],["self"]]],[11,"div","","",13,[[["self"],["self"]],["self"]]],[11,"rem","","",13,[[["self"],["self"]],["self"]]],[11,"add_assign","","",13,[[["self"],["self"]]]],[11,"sub_assign","","",13,[[["self"],["self"]]]],[11,"mul_assign","","",13,[[["self"],["self"]]]],[11,"div_assign","","",13,[[["self"],["self"]]]],[11,"rem_assign","","",13,[[["self"],["self"]]]],[11,"add","","",13,[[["self"],["i64"]],["self"]]],[11,"sub","","",13,[[["self"],["i64"]],["self"]]],[11,"mul","","",13,[[["self"],["i64"]],["self"]]],[11,"div","","",13,[[["self"],["i64"]],["self"]]],[11,"rem","","",13,[[["self"],["i64"]],["self"]]],[11,"add_assign","","",13,[[["self"],["i64"]]]],[11,"sub_assign","","",13,[[["self"],["i64"]]]],[11,"mul_assign","","",13,[[["self"],["i64"]]]],[11,"div_assign","","",13,[[["self"],["i64"]]]],[11,"rem_assign","","",13,[[["self"],["i64"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",13,[[["self"]],["i64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",13,[[["self"]],["i64"]]],[11,"max_element","","Largest vector element value.",13,[[["self"]],["i64"]]],[11,"min_element","","Smallest vector element value.",13,[[["self"]],["i64"]]],[11,"neg","","",13,[[["self"]],["self"]]],[11,"not","","",13,[[["self"]],["self"]]],[11,"bitxor","","",13,[[["self"],["self"]],["self"]]],[11,"bitand","","",13,[[["self"],["self"]],["self"]]],[11,"bitor","","",13,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",13,[[["self"],["self"]]]],[11,"bitor_assign","","",13,[[["self"],["self"]]]],[11,"bitxor_assign","","",13,[[["self"],["self"]]]],[11,"bitxor","","",13,[[["self"],["i64"]],["self"]]],[11,"bitand","","",13,[[["self"],["i64"]],["self"]]],[11,"bitor","","",13,[[["self"],["i64"]],["self"]]],[11,"bitand_assign","","",13,[[["self"],["i64"]]]],[11,"bitor_assign","","",13,[[["self"],["i64"]]]],[11,"bitxor_assign","","",13,[[["self"],["i64"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",13,[[["self"]],["i64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",13,[[["self"]],["i64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",13,[[["self"]],["i64"]]],[11,"shl","","",13,[[["self"],["u8"]],["self"]]],[11,"shr","","",13,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["u8"]]]],[11,"shr_assign","","",13,[[["self"],["u8"]]]],[11,"shl","","",13,[[["self"],["u16"]],["self"]]],[11,"shr","","",13,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["u16"]]]],[11,"shr_assign","","",13,[[["self"],["u16"]]]],[11,"shl","","",13,[[["self"],["u32"]],["self"]]],[11,"shr","","",13,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["u32"]]]],[11,"shr_assign","","",13,[[["self"],["u32"]]]],[11,"shl","","",13,[[["self"],["u64"]],["self"]]],[11,"shr","","",13,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["u64"]]]],[11,"shr_assign","","",13,[[["self"],["u64"]]]],[11,"shl","","",13,[[["self"],["usize"]],["self"]]],[11,"shr","","",13,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["usize"]]]],[11,"shr_assign","","",13,[[["self"],["usize"]]]],[11,"shl","","",13,[[["self"],["i8"]],["self"]]],[11,"shr","","",13,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["i8"]]]],[11,"shr_assign","","",13,[[["self"],["i8"]]]],[11,"shl","","",13,[[["self"],["i16"]],["self"]]],[11,"shr","","",13,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["i16"]]]],[11,"shr_assign","","",13,[[["self"],["i16"]]]],[11,"shl","","",13,[[["self"],["i32"]],["self"]]],[11,"shr","","",13,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["i32"]]]],[11,"shr_assign","","",13,[[["self"],["i32"]]]],[11,"shl","","",13,[[["self"],["i64"]],["self"]]],[11,"shr","","",13,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["i64"]]]],[11,"shr_assign","","",13,[[["self"],["i64"]]]],[11,"shl","","",13,[[["self"],["isize"]],["self"]]],[11,"shr","","",13,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["isize"]]]],[11,"shr_assign","","",13,[[["self"],["isize"]]]],[11,"shl","","",13,[[["self"],["self"]],["self"]]],[11,"shr","","",13,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",13,[[["self"],["self"]]]],[11,"shr_assign","","",13,[[["self"],["self"]]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result"]]],[11,"eq","","",13,[[["self"],["self"]],["bool"]]],[11,"ne","","",13,[[["self"],["self"]],["bool"]]],[11,"default","","",13,[[],["self"]]],[11,"min","","Minimum of two vectors.",13,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",13,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",13,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",13,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",13,[[["self"]],["self"]]],[11,"clone","","",14,[[["self"]],["u64x2"]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",14,[[["self"],["u64x2"]],["option",["ordering"]]]],[11,"lt","","",14,[[["self"],["u64x2"]],["bool"]]],[11,"le","","",14,[[["self"],["u64x2"]],["bool"]]],[11,"gt","","",14,[[["self"],["u64x2"]],["bool"]]],[11,"ge","","",14,[[["self"],["u64x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",14,[[["u64"],["u64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",14,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",14,[[["u64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",14,[[["self"],["usize"]],["u64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",14,[[["self"],["usize"]],["u64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",14,[[["self"],["usize"],["u64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",14,[[["self"],["usize"],["u64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",14,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",14,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",14,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",14,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"eq","","Lane-wise equality comparison.",14,[[["self"],["u64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",14,[[["self"],["u64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",14,[[["self"],["u64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",14,[[["self"],["u64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",14,[[["self"],["u64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",14,[[["self"],["u64x2"]],["m64x2"]]],[11,"hash","","",14,[[["self"],["h"]]]],[11,"add","","",14,[[["self"],["self"]],["self"]]],[11,"sub","","",14,[[["self"],["self"]],["self"]]],[11,"mul","","",14,[[["self"],["self"]],["self"]]],[11,"div","","",14,[[["self"],["self"]],["self"]]],[11,"rem","","",14,[[["self"],["self"]],["self"]]],[11,"add_assign","","",14,[[["self"],["self"]]]],[11,"sub_assign","","",14,[[["self"],["self"]]]],[11,"mul_assign","","",14,[[["self"],["self"]]]],[11,"div_assign","","",14,[[["self"],["self"]]]],[11,"rem_assign","","",14,[[["self"],["self"]]]],[11,"add","","",14,[[["self"],["u64"]],["self"]]],[11,"sub","","",14,[[["self"],["u64"]],["self"]]],[11,"mul","","",14,[[["self"],["u64"]],["self"]]],[11,"div","","",14,[[["self"],["u64"]],["self"]]],[11,"rem","","",14,[[["self"],["u64"]],["self"]]],[11,"add_assign","","",14,[[["self"],["u64"]]]],[11,"sub_assign","","",14,[[["self"],["u64"]]]],[11,"mul_assign","","",14,[[["self"],["u64"]]]],[11,"div_assign","","",14,[[["self"],["u64"]]]],[11,"rem_assign","","",14,[[["self"],["u64"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",14,[[["self"]],["u64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",14,[[["self"]],["u64"]]],[11,"max_element","","Largest vector element value.",14,[[["self"]],["u64"]]],[11,"min_element","","Smallest vector element value.",14,[[["self"]],["u64"]]],[11,"bitxor","","",14,[[["self"],["u64"]],["self"]]],[11,"bitand","","",14,[[["self"],["u64"]],["self"]]],[11,"bitor","","",14,[[["self"],["u64"]],["self"]]],[11,"bitand_assign","","",14,[[["self"],["u64"]]]],[11,"bitor_assign","","",14,[[["self"],["u64"]]]],[11,"bitxor_assign","","",14,[[["self"],["u64"]]]],[11,"not","","",14,[[["self"]],["self"]]],[11,"bitxor","","",14,[[["self"],["self"]],["self"]]],[11,"bitand","","",14,[[["self"],["self"]],["self"]]],[11,"bitor","","",14,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",14,[[["self"],["self"]]]],[11,"bitor_assign","","",14,[[["self"],["self"]]]],[11,"bitxor_assign","","",14,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",14,[[["self"]],["u64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",14,[[["self"]],["u64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",14,[[["self"]],["u64"]]],[11,"shl","","",14,[[["self"],["u8"]],["self"]]],[11,"shr","","",14,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["u8"]]]],[11,"shr_assign","","",14,[[["self"],["u8"]]]],[11,"shl","","",14,[[["self"],["u16"]],["self"]]],[11,"shr","","",14,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["u16"]]]],[11,"shr_assign","","",14,[[["self"],["u16"]]]],[11,"shl","","",14,[[["self"],["u32"]],["self"]]],[11,"shr","","",14,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["u32"]]]],[11,"shr_assign","","",14,[[["self"],["u32"]]]],[11,"shl","","",14,[[["self"],["u64"]],["self"]]],[11,"shr","","",14,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["u64"]]]],[11,"shr_assign","","",14,[[["self"],["u64"]]]],[11,"shl","","",14,[[["self"],["usize"]],["self"]]],[11,"shr","","",14,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["usize"]]]],[11,"shr_assign","","",14,[[["self"],["usize"]]]],[11,"shl","","",14,[[["self"],["i8"]],["self"]]],[11,"shr","","",14,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["i8"]]]],[11,"shr_assign","","",14,[[["self"],["i8"]]]],[11,"shl","","",14,[[["self"],["i16"]],["self"]]],[11,"shr","","",14,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["i16"]]]],[11,"shr_assign","","",14,[[["self"],["i16"]]]],[11,"shl","","",14,[[["self"],["i32"]],["self"]]],[11,"shr","","",14,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["i32"]]]],[11,"shr_assign","","",14,[[["self"],["i32"]]]],[11,"shl","","",14,[[["self"],["i64"]],["self"]]],[11,"shr","","",14,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["i64"]]]],[11,"shr_assign","","",14,[[["self"],["i64"]]]],[11,"shl","","",14,[[["self"],["isize"]],["self"]]],[11,"shr","","",14,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["isize"]]]],[11,"shr_assign","","",14,[[["self"],["isize"]]]],[11,"shl","","",14,[[["self"],["self"]],["self"]]],[11,"shr","","",14,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",14,[[["self"],["self"]]]],[11,"shr_assign","","",14,[[["self"],["self"]]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result"]]],[11,"eq","","",14,[[["self"],["self"]],["bool"]]],[11,"ne","","",14,[[["self"],["self"]],["bool"]]],[11,"default","","",14,[[],["self"]]],[11,"min","","Minimum of two vectors.",14,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",14,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",14,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",14,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",14,[[["self"]],["self"]]],[11,"clone","","",15,[[["self"]],["f64x2"]]],[11,"fmt","","",15,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",15,[[["self"],["f64x2"]],["option",["ordering"]]]],[11,"lt","","",15,[[["self"],["f64x2"]],["bool"]]],[11,"le","","",15,[[["self"],["f64x2"]],["bool"]]],[11,"gt","","",15,[[["self"],["f64x2"]],["bool"]]],[11,"ge","","",15,[[["self"],["f64x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",15,[[["f64"],["f64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",15,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",15,[[["f64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",15,[[["self"],["usize"]],["f64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",15,[[["self"],["usize"]],["f64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",15,[[["self"],["usize"],["f64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",15,[[["self"],["usize"],["f64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",15,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",15,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",15,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",15,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",15,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",15,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",15,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",15,N],[11,"eq","","Lane-wise equality comparison.",15,[[["self"],["f64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",15,[[["self"],["f64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",15,[[["self"],["f64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",15,[[["self"],["f64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",15,[[["self"],["f64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",15,[[["self"],["f64x2"]],["m64x2"]]],[11,"add","","",15,[[["self"],["self"]],["self"]]],[11,"sub","","",15,[[["self"],["self"]],["self"]]],[11,"mul","","",15,[[["self"],["self"]],["self"]]],[11,"div","","",15,[[["self"],["self"]],["self"]]],[11,"rem","","",15,[[["self"],["self"]],["self"]]],[11,"add_assign","","",15,[[["self"],["self"]]]],[11,"sub_assign","","",15,[[["self"],["self"]]]],[11,"mul_assign","","",15,[[["self"],["self"]]]],[11,"div_assign","","",15,[[["self"],["self"]]]],[11,"rem_assign","","",15,[[["self"],["self"]]]],[11,"add","","",15,[[["self"],["f64"]],["self"]]],[11,"sub","","",15,[[["self"],["f64"]],["self"]]],[11,"mul","","",15,[[["self"],["f64"]],["self"]]],[11,"div","","",15,[[["self"],["f64"]],["self"]]],[11,"rem","","",15,[[["self"],["f64"]],["self"]]],[11,"add_assign","","",15,[[["self"],["f64"]]]],[11,"sub_assign","","",15,[[["self"],["f64"]]]],[11,"mul_assign","","",15,[[["self"],["f64"]]]],[11,"div_assign","","",15,[[["self"],["f64"]]]],[11,"rem_assign","","",15,[[["self"],["f64"]]]],[11,"sum","","Horizontal sum of the vector elements.",15,[[["self"]],["f64"]]],[11,"product","","Horizontal product of the vector elements.",15,[[["self"]],["f64"]]],[11,"max_element","","Largest vector element value.",15,[[["self"]],["f64"]]],[11,"min_element","","Smallest vector element value.",15,[[["self"]],["f64"]]],[11,"neg","","",15,[[["self"]],["self"]]],[11,"eq","","",15,[[["self"],["self"]],["bool"]]],[11,"ne","","",15,[[["self"],["self"]],["bool"]]],[11,"default","","",15,[[],["self"]]],[11,"min","","Minimum of two vectors.",15,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",15,[[["self"],["self"]],["self"]]],[11,"abs","","Absolute-value",15,[[["self"]],["self"]]],[11,"sqrt","","Square-root",15,[[["self"]],["self"]]],[11,"sqrte","","Square-root estimate",15,[[["self"]],["self"]]],[11,"rsqrte","","Reciprocal square-root estimate",15,[[["self"]],["self"]]],[11,"fma","","Fused multiply add: `self * y + z`",15,[[["self"],["self"],["self"]],["self"]]],[11,"sin","","Sin",15,[[["self"]],["self"]]],[11,"cos","","Cos",15,[[["self"]],["self"]]],[11,"clone","","",16,[[["self"]],["m64x2"]]],[11,"fmt","","",16,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",16,[[["self"],["m64x2"]],["option",["ordering"]]]],[11,"lt","","",16,[[["self"],["m64x2"]],["bool"]]],[11,"le","","",16,[[["self"],["m64x2"]],["bool"]]],[11,"gt","","",16,[[["self"],["m64x2"]],["bool"]]],[11,"ge","","",16,[[["self"],["m64x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",16,[[["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",16,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",16,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",16,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",16,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",16,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",16,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",16,[[["self"]],["self"]]],[11,"bitxor","","",16,[[["self"],["self"]],["self"]]],[11,"bitand","","",16,[[["self"],["self"]],["self"]]],[11,"bitor","","",16,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",16,[[["self"],["self"]]]],[11,"bitor_assign","","",16,[[["self"],["self"]]]],[11,"bitxor_assign","","",16,[[["self"],["self"]]]],[11,"bitxor","","",16,[[["self"],["bool"]],["self"]]],[11,"bitand","","",16,[[["self"],["bool"]],["self"]]],[11,"bitor","","",16,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",16,[[["self"],["bool"]]]],[11,"bitor_assign","","",16,[[["self"],["bool"]]]],[11,"bitxor_assign","","",16,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",16,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",16,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",16,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",16,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",16,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",16,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",16,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",16,[[["self"],["m64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",16,[[["self"],["m64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",16,[[["self"],["m64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",16,[[["self"],["m64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",16,[[["self"],["m64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",16,[[["self"],["m64x2"]],["m64x2"]]],[11,"eq","","",16,[[["self"],["self"]],["bool"]]],[11,"ne","","",16,[[["self"],["self"]],["bool"]]],[11,"default","","",16,[[],["self"]]],[11,"from_bits","","",14,[[["i64x2"]],["u64x2"]]],[11,"from_bits","","",14,[[["f64x2"]],["u64x2"]]],[11,"from_bits","","",14,[[["m64x2"]],["u64x2"]]],[11,"from_bits","","",14,[[["u32x4"]],["u64x2"]]],[11,"from_bits","","",14,[[["i32x4"]],["u64x2"]]],[11,"from_bits","","",14,[[["f32x4"]],["u64x2"]]],[11,"from_bits","","",14,[[["m32x4"]],["u64x2"]]],[11,"from_bits","","",14,[[["u16x8"]],["u64x2"]]],[11,"from_bits","","",14,[[["i16x8"]],["u64x2"]]],[11,"from_bits","","",14,[[["m16x8"]],["u64x2"]]],[11,"from_bits","","",14,[[["u8x16"]],["u64x2"]]],[11,"from_bits","","",14,[[["i8x16"]],["u64x2"]]],[11,"from_bits","","",14,[[["m8x16"]],["u64x2"]]],[11,"from_bits","","",14,[[["__m128"]],["u64x2"]]],[11,"from_bits","","",14,[[["__m128i"]],["u64x2"]]],[11,"from_bits","","",14,[[["__m128d"]],["u64x2"]]],[11,"from_bits","","",13,[[["u64x2"]],["i64x2"]]],[11,"from_bits","","",13,[[["f64x2"]],["i64x2"]]],[11,"from_bits","","",13,[[["m64x2"]],["i64x2"]]],[11,"from_bits","","",13,[[["u32x4"]],["i64x2"]]],[11,"from_bits","","",13,[[["i32x4"]],["i64x2"]]],[11,"from_bits","","",13,[[["f32x4"]],["i64x2"]]],[11,"from_bits","","",13,[[["m32x4"]],["i64x2"]]],[11,"from_bits","","",13,[[["u16x8"]],["i64x2"]]],[11,"from_bits","","",13,[[["i16x8"]],["i64x2"]]],[11,"from_bits","","",13,[[["m16x8"]],["i64x2"]]],[11,"from_bits","","",13,[[["u8x16"]],["i64x2"]]],[11,"from_bits","","",13,[[["i8x16"]],["i64x2"]]],[11,"from_bits","","",13,[[["m8x16"]],["i64x2"]]],[11,"from_bits","","",13,[[["__m128"]],["i64x2"]]],[11,"from_bits","","",13,[[["__m128i"]],["i64x2"]]],[11,"from_bits","","",13,[[["__m128d"]],["i64x2"]]],[11,"from_bits","","",15,[[["i64x2"]],["f64x2"]]],[11,"from_bits","","",15,[[["u64x2"]],["f64x2"]]],[11,"from_bits","","",15,[[["m64x2"]],["f64x2"]]],[11,"from_bits","","",15,[[["u32x4"]],["f64x2"]]],[11,"from_bits","","",15,[[["i32x4"]],["f64x2"]]],[11,"from_bits","","",15,[[["f32x4"]],["f64x2"]]],[11,"from_bits","","",15,[[["m32x4"]],["f64x2"]]],[11,"from_bits","","",15,[[["u16x8"]],["f64x2"]]],[11,"from_bits","","",15,[[["i16x8"]],["f64x2"]]],[11,"from_bits","","",15,[[["m16x8"]],["f64x2"]]],[11,"from_bits","","",15,[[["u8x16"]],["f64x2"]]],[11,"from_bits","","",15,[[["i8x16"]],["f64x2"]]],[11,"from_bits","","",15,[[["m8x16"]],["f64x2"]]],[11,"from_bits","","",15,[[["__m128"]],["f64x2"]]],[11,"from_bits","","",15,[[["__m128i"]],["f64x2"]]],[11,"from_bits","","",15,[[["__m128d"]],["f64x2"]]],[11,"from_bits","","",10,[[["u64x2"]],["u32x4"]]],[11,"from_bits","","",10,[[["i64x2"]],["u32x4"]]],[11,"from_bits","","",10,[[["f64x2"]],["u32x4"]]],[11,"from_bits","","",10,[[["m64x2"]],["u32x4"]]],[11,"from_bits","","",10,[[["i32x4"]],["u32x4"]]],[11,"from_bits","","",10,[[["f32x4"]],["u32x4"]]],[11,"from_bits","","",10,[[["m32x4"]],["u32x4"]]],[11,"from_bits","","",10,[[["u16x8"]],["u32x4"]]],[11,"from_bits","","",10,[[["i16x8"]],["u32x4"]]],[11,"from_bits","","",10,[[["m16x8"]],["u32x4"]]],[11,"from_bits","","",10,[[["u8x16"]],["u32x4"]]],[11,"from_bits","","",10,[[["i8x16"]],["u32x4"]]],[11,"from_bits","","",10,[[["m8x16"]],["u32x4"]]],[11,"from_bits","","",10,[[["__m128"]],["u32x4"]]],[11,"from_bits","","",10,[[["__m128i"]],["u32x4"]]],[11,"from_bits","","",10,[[["__m128d"]],["u32x4"]]],[11,"from_bits","","",9,[[["u64x2"]],["i32x4"]]],[11,"from_bits","","",9,[[["i64x2"]],["i32x4"]]],[11,"from_bits","","",9,[[["f64x2"]],["i32x4"]]],[11,"from_bits","","",9,[[["m64x2"]],["i32x4"]]],[11,"from_bits","","",9,[[["u32x4"]],["i32x4"]]],[11,"from_bits","","",9,[[["f32x4"]],["i32x4"]]],[11,"from_bits","","",9,[[["m32x4"]],["i32x4"]]],[11,"from_bits","","",9,[[["u16x8"]],["i32x4"]]],[11,"from_bits","","",9,[[["i16x8"]],["i32x4"]]],[11,"from_bits","","",9,[[["m16x8"]],["i32x4"]]],[11,"from_bits","","",9,[[["u8x16"]],["i32x4"]]],[11,"from_bits","","",9,[[["i8x16"]],["i32x4"]]],[11,"from_bits","","",9,[[["m8x16"]],["i32x4"]]],[11,"from_bits","","",9,[[["__m128"]],["i32x4"]]],[11,"from_bits","","",9,[[["__m128i"]],["i32x4"]]],[11,"from_bits","","",9,[[["__m128d"]],["i32x4"]]],[11,"from_bits","","",11,[[["u64x2"]],["f32x4"]]],[11,"from_bits","","",11,[[["i64x2"]],["f32x4"]]],[11,"from_bits","","",11,[[["f64x2"]],["f32x4"]]],[11,"from_bits","","",11,[[["m64x2"]],["f32x4"]]],[11,"from_bits","","",11,[[["i32x4"]],["f32x4"]]],[11,"from_bits","","",11,[[["u32x4"]],["f32x4"]]],[11,"from_bits","","",11,[[["m32x4"]],["f32x4"]]],[11,"from_bits","","",11,[[["u16x8"]],["f32x4"]]],[11,"from_bits","","",11,[[["i16x8"]],["f32x4"]]],[11,"from_bits","","",11,[[["m16x8"]],["f32x4"]]],[11,"from_bits","","",11,[[["u8x16"]],["f32x4"]]],[11,"from_bits","","",11,[[["i8x16"]],["f32x4"]]],[11,"from_bits","","",11,[[["m8x16"]],["f32x4"]]],[11,"from_bits","","",11,[[["__m128"]],["f32x4"]]],[11,"from_bits","","",11,[[["__m128i"]],["f32x4"]]],[11,"from_bits","","",11,[[["__m128d"]],["f32x4"]]],[11,"from_bits","","",7,[[["u64x2"]],["u16x8"]]],[11,"from_bits","","",7,[[["i64x2"]],["u16x8"]]],[11,"from_bits","","",7,[[["f64x2"]],["u16x8"]]],[11,"from_bits","","",7,[[["m64x2"]],["u16x8"]]],[11,"from_bits","","",7,[[["u32x4"]],["u16x8"]]],[11,"from_bits","","",7,[[["i32x4"]],["u16x8"]]],[11,"from_bits","","",7,[[["f32x4"]],["u16x8"]]],[11,"from_bits","","",7,[[["m32x4"]],["u16x8"]]],[11,"from_bits","","",7,[[["i16x8"]],["u16x8"]]],[11,"from_bits","","",7,[[["m16x8"]],["u16x8"]]],[11,"from_bits","","",7,[[["u8x16"]],["u16x8"]]],[11,"from_bits","","",7,[[["i8x16"]],["u16x8"]]],[11,"from_bits","","",7,[[["m8x16"]],["u16x8"]]],[11,"from_bits","","",7,[[["__m128"]],["u16x8"]]],[11,"from_bits","","",7,[[["__m128i"]],["u16x8"]]],[11,"from_bits","","",7,[[["__m128d"]],["u16x8"]]],[11,"from_bits","","",6,[[["u64x2"]],["i16x8"]]],[11,"from_bits","","",6,[[["i64x2"]],["i16x8"]]],[11,"from_bits","","",6,[[["f64x2"]],["i16x8"]]],[11,"from_bits","","",6,[[["m64x2"]],["i16x8"]]],[11,"from_bits","","",6,[[["u32x4"]],["i16x8"]]],[11,"from_bits","","",6,[[["i32x4"]],["i16x8"]]],[11,"from_bits","","",6,[[["f32x4"]],["i16x8"]]],[11,"from_bits","","",6,[[["m32x4"]],["i16x8"]]],[11,"from_bits","","",6,[[["u16x8"]],["i16x8"]]],[11,"from_bits","","",6,[[["m16x8"]],["i16x8"]]],[11,"from_bits","","",6,[[["u8x16"]],["i16x8"]]],[11,"from_bits","","",6,[[["i8x16"]],["i16x8"]]],[11,"from_bits","","",6,[[["m8x16"]],["i16x8"]]],[11,"from_bits","","",6,[[["__m128"]],["i16x8"]]],[11,"from_bits","","",6,[[["__m128i"]],["i16x8"]]],[11,"from_bits","","",6,[[["__m128d"]],["i16x8"]]],[11,"from_bits","","",4,[[["u64x2"]],["u8x16"]]],[11,"from_bits","","",4,[[["i64x2"]],["u8x16"]]],[11,"from_bits","","",4,[[["f64x2"]],["u8x16"]]],[11,"from_bits","","",4,[[["m64x2"]],["u8x16"]]],[11,"from_bits","","",4,[[["u32x4"]],["u8x16"]]],[11,"from_bits","","",4,[[["i32x4"]],["u8x16"]]],[11,"from_bits","","",4,[[["f32x4"]],["u8x16"]]],[11,"from_bits","","",4,[[["m32x4"]],["u8x16"]]],[11,"from_bits","","",4,[[["u16x8"]],["u8x16"]]],[11,"from_bits","","",4,[[["i16x8"]],["u8x16"]]],[11,"from_bits","","",4,[[["m16x8"]],["u8x16"]]],[11,"from_bits","","",4,[[["i8x16"]],["u8x16"]]],[11,"from_bits","","",4,[[["m8x16"]],["u8x16"]]],[11,"from_bits","","",4,[[["__m128"]],["u8x16"]]],[11,"from_bits","","",4,[[["__m128i"]],["u8x16"]]],[11,"from_bits","","",4,[[["__m128d"]],["u8x16"]]],[11,"from_bits","","",3,[[["u64x2"]],["i8x16"]]],[11,"from_bits","","",3,[[["i64x2"]],["i8x16"]]],[11,"from_bits","","",3,[[["f64x2"]],["i8x16"]]],[11,"from_bits","","",3,[[["m64x2"]],["i8x16"]]],[11,"from_bits","","",3,[[["u32x4"]],["i8x16"]]],[11,"from_bits","","",3,[[["i32x4"]],["i8x16"]]],[11,"from_bits","","",3,[[["f32x4"]],["i8x16"]]],[11,"from_bits","","",3,[[["m32x4"]],["i8x16"]]],[11,"from_bits","","",3,[[["u16x8"]],["i8x16"]]],[11,"from_bits","","",3,[[["i16x8"]],["i8x16"]]],[11,"from_bits","","",3,[[["m16x8"]],["i8x16"]]],[11,"from_bits","","",3,[[["u8x16"]],["i8x16"]]],[11,"from_bits","","",3,[[["m8x16"]],["i8x16"]]],[11,"from_bits","","",3,[[["__m128"]],["i8x16"]]],[11,"from_bits","","",3,[[["__m128i"]],["i8x16"]]],[11,"from_bits","","",3,[[["__m128d"]],["i8x16"]]],[11,"from","","",15,[[["f32x2"]],["f64x2"]]],[11,"from","","",15,[[["u64x2"]],["f64x2"]]],[11,"from","","",15,[[["i64x2"]],["f64x2"]]],[11,"from","","",15,[[["m64x2"]],["f64x2"]]],[11,"from","","",15,[[["u32x2"]],["f64x2"]]],[11,"from","","",15,[[["i32x2"]],["f64x2"]]],[11,"from","","",15,[[["m32x2"]],["f64x2"]]],[11,"from","","",15,[[["u16x2"]],["f64x2"]]],[11,"from","","",15,[[["i16x2"]],["f64x2"]]],[11,"from","","",15,[[["m16x2"]],["f64x2"]]],[11,"from","","",15,[[["u8x2"]],["f64x2"]]],[11,"from","","",15,[[["i8x2"]],["f64x2"]]],[11,"from","","",15,[[["m8x2"]],["f64x2"]]],[11,"from","","",14,[[["f64x2"]],["u64x2"]]],[11,"from","","",14,[[["i64x2"]],["u64x2"]]],[11,"from","","",14,[[["m64x2"]],["u64x2"]]],[11,"from","","",14,[[["f32x2"]],["u64x2"]]],[11,"from","","",14,[[["i32x2"]],["u64x2"]]],[11,"from","","",14,[[["u32x2"]],["u64x2"]]],[11,"from","","",14,[[["m32x2"]],["u64x2"]]],[11,"from","","",14,[[["i16x2"]],["u64x2"]]],[11,"from","","",14,[[["u16x2"]],["u64x2"]]],[11,"from","","",14,[[["m16x2"]],["u64x2"]]],[11,"from","","",14,[[["i8x2"]],["u64x2"]]],[11,"from","","",14,[[["u8x2"]],["u64x2"]]],[11,"from","","",14,[[["m8x2"]],["u64x2"]]],[11,"from","","",13,[[["f64x2"]],["i64x2"]]],[11,"from","","",13,[[["u64x2"]],["i64x2"]]],[11,"from","","",13,[[["m64x2"]],["i64x2"]]],[11,"from","","",13,[[["i32x2"]],["i64x2"]]],[11,"from","","",13,[[["u32x2"]],["i64x2"]]],[11,"from","","",13,[[["f32x2"]],["i64x2"]]],[11,"from","","",13,[[["m32x2"]],["i64x2"]]],[11,"from","","",13,[[["i16x2"]],["i64x2"]]],[11,"from","","",13,[[["u16x2"]],["i64x2"]]],[11,"from","","",13,[[["m16x2"]],["i64x2"]]],[11,"from","","",13,[[["i8x2"]],["i64x2"]]],[11,"from","","",13,[[["u8x2"]],["i64x2"]]],[11,"from","","",13,[[["m8x2"]],["i64x2"]]],[11,"from","","",10,[[["f64x4"]],["u32x4"]]],[11,"from","","",10,[[["u64x4"]],["u32x4"]]],[11,"from","","",10,[[["i64x4"]],["u32x4"]]],[11,"from","","",10,[[["m64x4"]],["u32x4"]]],[11,"from","","",10,[[["f32x4"]],["u32x4"]]],[11,"from","","",10,[[["i32x4"]],["u32x4"]]],[11,"from","","",10,[[["m32x4"]],["u32x4"]]],[11,"from","","",10,[[["u16x4"]],["u32x4"]]],[11,"from","","",10,[[["i16x4"]],["u32x4"]]],[11,"from","","",10,[[["m16x4"]],["u32x4"]]],[11,"from","","",10,[[["u8x4"]],["u32x4"]]],[11,"from","","",10,[[["i8x4"]],["u32x4"]]],[11,"from","","",10,[[["m8x4"]],["u32x4"]]],[11,"from","","",9,[[["f64x4"]],["i32x4"]]],[11,"from","","",9,[[["u64x4"]],["i32x4"]]],[11,"from","","",9,[[["i64x4"]],["i32x4"]]],[11,"from","","",9,[[["m64x4"]],["i32x4"]]],[11,"from","","",9,[[["f32x4"]],["i32x4"]]],[11,"from","","",9,[[["u32x4"]],["i32x4"]]],[11,"from","","",9,[[["m32x4"]],["i32x4"]]],[11,"from","","",9,[[["u16x4"]],["i32x4"]]],[11,"from","","",9,[[["i16x4"]],["i32x4"]]],[11,"from","","",9,[[["m16x4"]],["i32x4"]]],[11,"from","","",9,[[["u8x4"]],["i32x4"]]],[11,"from","","",9,[[["i8x4"]],["i32x4"]]],[11,"from","","",9,[[["m8x4"]],["i32x4"]]],[11,"from","","",11,[[["f64x4"]],["f32x4"]]],[11,"from","","",11,[[["u64x4"]],["f32x4"]]],[11,"from","","",11,[[["i64x4"]],["f32x4"]]],[11,"from","","",11,[[["m64x4"]],["f32x4"]]],[11,"from","","",11,[[["u32x4"]],["f32x4"]]],[11,"from","","",11,[[["i32x4"]],["f32x4"]]],[11,"from","","",11,[[["m32x4"]],["f32x4"]]],[11,"from","","",11,[[["u16x4"]],["f32x4"]]],[11,"from","","",11,[[["i16x4"]],["f32x4"]]],[11,"from","","",11,[[["m16x4"]],["f32x4"]]],[11,"from","","",11,[[["u8x4"]],["f32x4"]]],[11,"from","","",11,[[["i8x4"]],["f32x4"]]],[11,"from","","",11,[[["m8x4"]],["f32x4"]]],[11,"from","","",6,[[["f64x8"]],["i16x8"]]],[11,"from","","",6,[[["u64x8"]],["i16x8"]]],[11,"from","","",6,[[["i64x8"]],["i16x8"]]],[11,"from","","",6,[[["m1x8"]],["i16x8"]]],[11,"from","","",6,[[["f32x8"]],["i16x8"]]],[11,"from","","",6,[[["u32x8"]],["i16x8"]]],[11,"from","","",6,[[["i32x8"]],["i16x8"]]],[11,"from","","",6,[[["m32x8"]],["i16x8"]]],[11,"from","","",6,[[["u16x8"]],["i16x8"]]],[11,"from","","",6,[[["m16x8"]],["i16x8"]]],[11,"from","","",6,[[["u8x8"]],["i16x8"]]],[11,"from","","",6,[[["i8x8"]],["i16x8"]]],[11,"from","","",6,[[["m8x8"]],["i16x8"]]],[11,"from","","",7,[[["f64x8"]],["u16x8"]]],[11,"from","","",7,[[["u64x8"]],["u16x8"]]],[11,"from","","",7,[[["i64x8"]],["u16x8"]]],[11,"from","","",7,[[["m1x8"]],["u16x8"]]],[11,"from","","",7,[[["f32x8"]],["u16x8"]]],[11,"from","","",7,[[["u32x8"]],["u16x8"]]],[11,"from","","",7,[[["i32x8"]],["u16x8"]]],[11,"from","","",7,[[["m32x8"]],["u16x8"]]],[11,"from","","",7,[[["i16x8"]],["u16x8"]]],[11,"from","","",7,[[["m16x8"]],["u16x8"]]],[11,"from","","",7,[[["u8x8"]],["u16x8"]]],[11,"from","","",7,[[["i8x8"]],["u16x8"]]],[11,"from","","",7,[[["m8x8"]],["u16x8"]]],[11,"from","","",4,[[["i32x16"]],["u8x16"]]],[11,"from","","",4,[[["u32x16"]],["u8x16"]]],[11,"from","","",4,[[["f32x16"]],["u8x16"]]],[11,"from","","",4,[[["m1x16"]],["u8x16"]]],[11,"from","","",4,[[["i16x16"]],["u8x16"]]],[11,"from","","",4,[[["u16x16"]],["u8x16"]]],[11,"from","","",4,[[["m16x16"]],["u8x16"]]],[11,"from","","",4,[[["i8x16"]],["u8x16"]]],[11,"from","","",4,[[["m8x16"]],["u8x16"]]],[11,"from","","",3,[[["i32x16"]],["i8x16"]]],[11,"from","","",3,[[["u32x16"]],["i8x16"]]],[11,"from","","",3,[[["f32x16"]],["i8x16"]]],[11,"from","","",3,[[["m1x16"]],["i8x16"]]],[11,"from","","",3,[[["i16x16"]],["i8x16"]]],[11,"from","","",3,[[["u16x16"]],["i8x16"]]],[11,"from","","",3,[[["m16x16"]],["i8x16"]]],[11,"from","","",3,[[["u8x16"]],["i8x16"]]],[11,"from","","",3,[[["m8x16"]],["i8x16"]]],[11,"from","","",5,[[["m1x16"]],["m8x16"]]],[11,"from","","",5,[[["m16x16"]],["m8x16"]]],[11,"from","","",8,[[["m1x8"]],["m16x8"]]],[11,"from","","",8,[[["m32x8"]],["m16x8"]]],[11,"from","","",8,[[["m8x8"]],["m16x8"]]],[11,"from","","",12,[[["m64x4"]],["m32x4"]]],[11,"from","","",12,[[["m16x4"]],["m32x4"]]],[11,"from","","",12,[[["m8x4"]],["m32x4"]]],[11,"from","","",16,[[["m32x2"]],["m64x2"]]],[11,"from","","",16,[[["m16x2"]],["m64x2"]]],[11,"from","","",16,[[["m8x2"]],["m64x2"]]],[11,"clone","","",17,[[["self"]],["i8x2"]]],[11,"fmt","","",17,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",17,[[["self"],["i8x2"]],["option",["ordering"]]]],[11,"lt","","",17,[[["self"],["i8x2"]],["bool"]]],[11,"le","","",17,[[["self"],["i8x2"]],["bool"]]],[11,"gt","","",17,[[["self"],["i8x2"]],["bool"]]],[11,"ge","","",17,[[["self"],["i8x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",17,[[["i8"],["i8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",17,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",17,[[["i8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",17,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",17,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",17,[[["self"],["usize"],["i8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",17,[[["self"],["usize"],["i8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",17,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",17,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",17,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",17,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",17,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",17,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",17,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",17,N],[11,"eq","","Lane-wise equality comparison.",17,[[["self"],["i8x2"]],["m8x2"]]],[11,"ne","","Lane-wise inequality comparison.",17,[[["self"],["i8x2"]],["m8x2"]]],[11,"lt","","Lane-wise less-than comparison.",17,[[["self"],["i8x2"]],["m8x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",17,[[["self"],["i8x2"]],["m8x2"]]],[11,"gt","","Lane-wise greater-than comparison.",17,[[["self"],["i8x2"]],["m8x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",17,[[["self"],["i8x2"]],["m8x2"]]],[11,"hash","","",17,[[["self"],["h"]]]],[11,"add","","",17,[[["self"],["self"]],["self"]]],[11,"sub","","",17,[[["self"],["self"]],["self"]]],[11,"mul","","",17,[[["self"],["self"]],["self"]]],[11,"div","","",17,[[["self"],["self"]],["self"]]],[11,"rem","","",17,[[["self"],["self"]],["self"]]],[11,"add_assign","","",17,[[["self"],["self"]]]],[11,"sub_assign","","",17,[[["self"],["self"]]]],[11,"mul_assign","","",17,[[["self"],["self"]]]],[11,"div_assign","","",17,[[["self"],["self"]]]],[11,"rem_assign","","",17,[[["self"],["self"]]]],[11,"add","","",17,[[["self"],["i8"]],["self"]]],[11,"sub","","",17,[[["self"],["i8"]],["self"]]],[11,"mul","","",17,[[["self"],["i8"]],["self"]]],[11,"div","","",17,[[["self"],["i8"]],["self"]]],[11,"rem","","",17,[[["self"],["i8"]],["self"]]],[11,"add_assign","","",17,[[["self"],["i8"]]]],[11,"sub_assign","","",17,[[["self"],["i8"]]]],[11,"mul_assign","","",17,[[["self"],["i8"]]]],[11,"div_assign","","",17,[[["self"],["i8"]]]],[11,"rem_assign","","",17,[[["self"],["i8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",17,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",17,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",17,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",17,[[["self"]],["i8"]]],[11,"neg","","",17,[[["self"]],["self"]]],[11,"not","","",17,[[["self"]],["self"]]],[11,"bitxor","","",17,[[["self"],["self"]],["self"]]],[11,"bitand","","",17,[[["self"],["self"]],["self"]]],[11,"bitor","","",17,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",17,[[["self"],["self"]]]],[11,"bitor_assign","","",17,[[["self"],["self"]]]],[11,"bitxor_assign","","",17,[[["self"],["self"]]]],[11,"bitxor","","",17,[[["self"],["i8"]],["self"]]],[11,"bitand","","",17,[[["self"],["i8"]],["self"]]],[11,"bitor","","",17,[[["self"],["i8"]],["self"]]],[11,"bitand_assign","","",17,[[["self"],["i8"]]]],[11,"bitor_assign","","",17,[[["self"],["i8"]]]],[11,"bitxor_assign","","",17,[[["self"],["i8"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",17,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",17,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",17,[[["self"]],["i8"]]],[11,"shl","","",17,[[["self"],["u8"]],["self"]]],[11,"shr","","",17,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["u8"]]]],[11,"shr_assign","","",17,[[["self"],["u8"]]]],[11,"shl","","",17,[[["self"],["u16"]],["self"]]],[11,"shr","","",17,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["u16"]]]],[11,"shr_assign","","",17,[[["self"],["u16"]]]],[11,"shl","","",17,[[["self"],["u32"]],["self"]]],[11,"shr","","",17,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["u32"]]]],[11,"shr_assign","","",17,[[["self"],["u32"]]]],[11,"shl","","",17,[[["self"],["u64"]],["self"]]],[11,"shr","","",17,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["u64"]]]],[11,"shr_assign","","",17,[[["self"],["u64"]]]],[11,"shl","","",17,[[["self"],["usize"]],["self"]]],[11,"shr","","",17,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["usize"]]]],[11,"shr_assign","","",17,[[["self"],["usize"]]]],[11,"shl","","",17,[[["self"],["i8"]],["self"]]],[11,"shr","","",17,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["i8"]]]],[11,"shr_assign","","",17,[[["self"],["i8"]]]],[11,"shl","","",17,[[["self"],["i16"]],["self"]]],[11,"shr","","",17,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["i16"]]]],[11,"shr_assign","","",17,[[["self"],["i16"]]]],[11,"shl","","",17,[[["self"],["i32"]],["self"]]],[11,"shr","","",17,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["i32"]]]],[11,"shr_assign","","",17,[[["self"],["i32"]]]],[11,"shl","","",17,[[["self"],["i64"]],["self"]]],[11,"shr","","",17,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["i64"]]]],[11,"shr_assign","","",17,[[["self"],["i64"]]]],[11,"shl","","",17,[[["self"],["isize"]],["self"]]],[11,"shr","","",17,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["isize"]]]],[11,"shr_assign","","",17,[[["self"],["isize"]]]],[11,"shl","","",17,[[["self"],["self"]],["self"]]],[11,"shr","","",17,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",17,[[["self"],["self"]]]],[11,"shr_assign","","",17,[[["self"],["self"]]]],[11,"fmt","","",17,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",17,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",17,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",17,[[["self"],["formatter"]],["result"]]],[11,"eq","","",17,[[["self"],["self"]],["bool"]]],[11,"ne","","",17,[[["self"],["self"]],["bool"]]],[11,"default","","",17,[[],["self"]]],[11,"min","","Minimum of two vectors.",17,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",17,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",17,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",17,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",17,[[["self"]],["self"]]],[11,"clone","","",18,[[["self"]],["u8x2"]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",18,[[["self"],["u8x2"]],["option",["ordering"]]]],[11,"lt","","",18,[[["self"],["u8x2"]],["bool"]]],[11,"le","","",18,[[["self"],["u8x2"]],["bool"]]],[11,"gt","","",18,[[["self"],["u8x2"]],["bool"]]],[11,"ge","","",18,[[["self"],["u8x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",18,[[["u8"],["u8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",18,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",18,[[["u8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",18,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",18,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",18,[[["self"],["usize"],["u8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",18,[[["self"],["usize"],["u8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",18,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",18,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",18,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",18,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"eq","","Lane-wise equality comparison.",18,[[["self"],["u8x2"]],["m8x2"]]],[11,"ne","","Lane-wise inequality comparison.",18,[[["self"],["u8x2"]],["m8x2"]]],[11,"lt","","Lane-wise less-than comparison.",18,[[["self"],["u8x2"]],["m8x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",18,[[["self"],["u8x2"]],["m8x2"]]],[11,"gt","","Lane-wise greater-than comparison.",18,[[["self"],["u8x2"]],["m8x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",18,[[["self"],["u8x2"]],["m8x2"]]],[11,"hash","","",18,[[["self"],["h"]]]],[11,"add","","",18,[[["self"],["self"]],["self"]]],[11,"sub","","",18,[[["self"],["self"]],["self"]]],[11,"mul","","",18,[[["self"],["self"]],["self"]]],[11,"div","","",18,[[["self"],["self"]],["self"]]],[11,"rem","","",18,[[["self"],["self"]],["self"]]],[11,"add_assign","","",18,[[["self"],["self"]]]],[11,"sub_assign","","",18,[[["self"],["self"]]]],[11,"mul_assign","","",18,[[["self"],["self"]]]],[11,"div_assign","","",18,[[["self"],["self"]]]],[11,"rem_assign","","",18,[[["self"],["self"]]]],[11,"add","","",18,[[["self"],["u8"]],["self"]]],[11,"sub","","",18,[[["self"],["u8"]],["self"]]],[11,"mul","","",18,[[["self"],["u8"]],["self"]]],[11,"div","","",18,[[["self"],["u8"]],["self"]]],[11,"rem","","",18,[[["self"],["u8"]],["self"]]],[11,"add_assign","","",18,[[["self"],["u8"]]]],[11,"sub_assign","","",18,[[["self"],["u8"]]]],[11,"mul_assign","","",18,[[["self"],["u8"]]]],[11,"div_assign","","",18,[[["self"],["u8"]]]],[11,"rem_assign","","",18,[[["self"],["u8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",18,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",18,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",18,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",18,[[["self"]],["u8"]]],[11,"bitxor","","",18,[[["self"],["u8"]],["self"]]],[11,"bitand","","",18,[[["self"],["u8"]],["self"]]],[11,"bitor","","",18,[[["self"],["u8"]],["self"]]],[11,"bitand_assign","","",18,[[["self"],["u8"]]]],[11,"bitor_assign","","",18,[[["self"],["u8"]]]],[11,"bitxor_assign","","",18,[[["self"],["u8"]]]],[11,"not","","",18,[[["self"]],["self"]]],[11,"bitxor","","",18,[[["self"],["self"]],["self"]]],[11,"bitand","","",18,[[["self"],["self"]],["self"]]],[11,"bitor","","",18,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",18,[[["self"],["self"]]]],[11,"bitor_assign","","",18,[[["self"],["self"]]]],[11,"bitxor_assign","","",18,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",18,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",18,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",18,[[["self"]],["u8"]]],[11,"shl","","",18,[[["self"],["u8"]],["self"]]],[11,"shr","","",18,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["u8"]]]],[11,"shr_assign","","",18,[[["self"],["u8"]]]],[11,"shl","","",18,[[["self"],["u16"]],["self"]]],[11,"shr","","",18,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["u16"]]]],[11,"shr_assign","","",18,[[["self"],["u16"]]]],[11,"shl","","",18,[[["self"],["u32"]],["self"]]],[11,"shr","","",18,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["u32"]]]],[11,"shr_assign","","",18,[[["self"],["u32"]]]],[11,"shl","","",18,[[["self"],["u64"]],["self"]]],[11,"shr","","",18,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["u64"]]]],[11,"shr_assign","","",18,[[["self"],["u64"]]]],[11,"shl","","",18,[[["self"],["usize"]],["self"]]],[11,"shr","","",18,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["usize"]]]],[11,"shr_assign","","",18,[[["self"],["usize"]]]],[11,"shl","","",18,[[["self"],["i8"]],["self"]]],[11,"shr","","",18,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["i8"]]]],[11,"shr_assign","","",18,[[["self"],["i8"]]]],[11,"shl","","",18,[[["self"],["i16"]],["self"]]],[11,"shr","","",18,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["i16"]]]],[11,"shr_assign","","",18,[[["self"],["i16"]]]],[11,"shl","","",18,[[["self"],["i32"]],["self"]]],[11,"shr","","",18,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["i32"]]]],[11,"shr_assign","","",18,[[["self"],["i32"]]]],[11,"shl","","",18,[[["self"],["i64"]],["self"]]],[11,"shr","","",18,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["i64"]]]],[11,"shr_assign","","",18,[[["self"],["i64"]]]],[11,"shl","","",18,[[["self"],["isize"]],["self"]]],[11,"shr","","",18,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["isize"]]]],[11,"shr_assign","","",18,[[["self"],["isize"]]]],[11,"shl","","",18,[[["self"],["self"]],["self"]]],[11,"shr","","",18,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",18,[[["self"],["self"]]]],[11,"shr_assign","","",18,[[["self"],["self"]]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result"]]],[11,"eq","","",18,[[["self"],["self"]],["bool"]]],[11,"ne","","",18,[[["self"],["self"]],["bool"]]],[11,"default","","",18,[[],["self"]]],[11,"min","","Minimum of two vectors.",18,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",18,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",18,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",18,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",18,[[["self"]],["self"]]],[11,"clone","","",19,[[["self"]],["m8x2"]]],[11,"fmt","","",19,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",19,[[["self"],["m8x2"]],["option",["ordering"]]]],[11,"lt","","",19,[[["self"],["m8x2"]],["bool"]]],[11,"le","","",19,[[["self"],["m8x2"]],["bool"]]],[11,"gt","","",19,[[["self"],["m8x2"]],["bool"]]],[11,"ge","","",19,[[["self"],["m8x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",19,[[["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",19,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",19,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",19,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",19,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",19,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",19,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",19,[[["self"]],["self"]]],[11,"bitxor","","",19,[[["self"],["self"]],["self"]]],[11,"bitand","","",19,[[["self"],["self"]],["self"]]],[11,"bitor","","",19,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",19,[[["self"],["self"]]]],[11,"bitor_assign","","",19,[[["self"],["self"]]]],[11,"bitxor_assign","","",19,[[["self"],["self"]]]],[11,"bitxor","","",19,[[["self"],["bool"]],["self"]]],[11,"bitand","","",19,[[["self"],["bool"]],["self"]]],[11,"bitor","","",19,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",19,[[["self"],["bool"]]]],[11,"bitor_assign","","",19,[[["self"],["bool"]]]],[11,"bitxor_assign","","",19,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",19,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",19,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",19,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",19,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",19,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",19,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",19,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",19,[[["self"],["m8x2"]],["m8x2"]]],[11,"ne","","Lane-wise inequality comparison.",19,[[["self"],["m8x2"]],["m8x2"]]],[11,"lt","","Lane-wise less-than comparison.",19,[[["self"],["m8x2"]],["m8x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",19,[[["self"],["m8x2"]],["m8x2"]]],[11,"gt","","Lane-wise greater-than comparison.",19,[[["self"],["m8x2"]],["m8x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",19,[[["self"],["m8x2"]],["m8x2"]]],[11,"eq","","",19,[[["self"],["self"]],["bool"]]],[11,"ne","","",19,[[["self"],["self"]],["bool"]]],[11,"default","","",19,[[],["self"]]],[11,"from_bits","","",17,[[["u8x2"]],["i8x2"]]],[11,"from_bits","","",17,[[["m8x2"]],["i8x2"]]],[11,"from_bits","","",18,[[["i8x2"]],["u8x2"]]],[11,"from_bits","","",18,[[["m8x2"]],["u8x2"]]],[11,"from","","",17,[[["f64x2"]],["i8x2"]]],[11,"from","","",17,[[["u64x2"]],["i8x2"]]],[11,"from","","",17,[[["m64x2"]],["i8x2"]]],[11,"from","","",17,[[["i64x2"]],["i8x2"]]],[11,"from","","",17,[[["f32x2"]],["i8x2"]]],[11,"from","","",17,[[["u32x2"]],["i8x2"]]],[11,"from","","",17,[[["i32x2"]],["i8x2"]]],[11,"from","","",17,[[["m32x2"]],["i8x2"]]],[11,"from","","",17,[[["u16x2"]],["i8x2"]]],[11,"from","","",17,[[["m16x2"]],["i8x2"]]],[11,"from","","",17,[[["u8x2"]],["i8x2"]]],[11,"from","","",17,[[["m8x2"]],["i8x2"]]],[11,"from","","",18,[[["f64x2"]],["u8x2"]]],[11,"from","","",18,[[["u64x2"]],["u8x2"]]],[11,"from","","",18,[[["i64x2"]],["u8x2"]]],[11,"from","","",18,[[["m64x2"]],["u8x2"]]],[11,"from","","",18,[[["f32x2"]],["u8x2"]]],[11,"from","","",18,[[["u32x2"]],["u8x2"]]],[11,"from","","",18,[[["i32x2"]],["u8x2"]]],[11,"from","","",18,[[["m32x2"]],["u8x2"]]],[11,"from","","",18,[[["u16x2"]],["u8x2"]]],[11,"from","","",18,[[["m16x2"]],["u8x2"]]],[11,"from","","",18,[[["i8x2"]],["u8x2"]]],[11,"from","","",18,[[["m8x2"]],["u8x2"]]],[11,"from","","",19,[[["m64x2"]],["m8x2"]]],[11,"from","","",19,[[["m32x2"]],["m8x2"]]],[11,"from","","",19,[[["m16x2"]],["m8x2"]]],[11,"clone","","",20,[[["self"]],["i8x32"]]],[11,"fmt","","",20,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",20,[[["self"],["i8x32"]],["option",["ordering"]]]],[11,"lt","","",20,[[["self"],["i8x32"]],["bool"]]],[11,"le","","",20,[[["self"],["i8x32"]],["bool"]]],[11,"gt","","",20,[[["self"],["i8x32"]],["bool"]]],[11,"ge","","",20,[[["self"],["i8x32"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",20,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",20,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",20,[[["i8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",20,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",20,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",20,[[["self"],["usize"],["i8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",20,[[["self"],["usize"],["i8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",20,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",20,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",20,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",20,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",20,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",20,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",20,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",20,N],[11,"eq","","Lane-wise equality comparison.",20,[[["self"],["i8x32"]],["m8x32"]]],[11,"ne","","Lane-wise inequality comparison.",20,[[["self"],["i8x32"]],["m8x32"]]],[11,"lt","","Lane-wise less-than comparison.",20,[[["self"],["i8x32"]],["m8x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",20,[[["self"],["i8x32"]],["m8x32"]]],[11,"gt","","Lane-wise greater-than comparison.",20,[[["self"],["i8x32"]],["m8x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",20,[[["self"],["i8x32"]],["m8x32"]]],[11,"hash","","",20,[[["self"],["h"]]]],[11,"add","","",20,[[["self"],["self"]],["self"]]],[11,"sub","","",20,[[["self"],["self"]],["self"]]],[11,"mul","","",20,[[["self"],["self"]],["self"]]],[11,"div","","",20,[[["self"],["self"]],["self"]]],[11,"rem","","",20,[[["self"],["self"]],["self"]]],[11,"add_assign","","",20,[[["self"],["self"]]]],[11,"sub_assign","","",20,[[["self"],["self"]]]],[11,"mul_assign","","",20,[[["self"],["self"]]]],[11,"div_assign","","",20,[[["self"],["self"]]]],[11,"rem_assign","","",20,[[["self"],["self"]]]],[11,"add","","",20,[[["self"],["i8"]],["self"]]],[11,"sub","","",20,[[["self"],["i8"]],["self"]]],[11,"mul","","",20,[[["self"],["i8"]],["self"]]],[11,"div","","",20,[[["self"],["i8"]],["self"]]],[11,"rem","","",20,[[["self"],["i8"]],["self"]]],[11,"add_assign","","",20,[[["self"],["i8"]]]],[11,"sub_assign","","",20,[[["self"],["i8"]]]],[11,"mul_assign","","",20,[[["self"],["i8"]]]],[11,"div_assign","","",20,[[["self"],["i8"]]]],[11,"rem_assign","","",20,[[["self"],["i8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",20,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",20,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",20,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",20,[[["self"]],["i8"]]],[11,"neg","","",20,[[["self"]],["self"]]],[11,"not","","",20,[[["self"]],["self"]]],[11,"bitxor","","",20,[[["self"],["self"]],["self"]]],[11,"bitand","","",20,[[["self"],["self"]],["self"]]],[11,"bitor","","",20,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",20,[[["self"],["self"]]]],[11,"bitor_assign","","",20,[[["self"],["self"]]]],[11,"bitxor_assign","","",20,[[["self"],["self"]]]],[11,"bitxor","","",20,[[["self"],["i8"]],["self"]]],[11,"bitand","","",20,[[["self"],["i8"]],["self"]]],[11,"bitor","","",20,[[["self"],["i8"]],["self"]]],[11,"bitand_assign","","",20,[[["self"],["i8"]]]],[11,"bitor_assign","","",20,[[["self"],["i8"]]]],[11,"bitxor_assign","","",20,[[["self"],["i8"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",20,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",20,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",20,[[["self"]],["i8"]]],[11,"shl","","",20,[[["self"],["u8"]],["self"]]],[11,"shr","","",20,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["u8"]]]],[11,"shr_assign","","",20,[[["self"],["u8"]]]],[11,"shl","","",20,[[["self"],["u16"]],["self"]]],[11,"shr","","",20,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["u16"]]]],[11,"shr_assign","","",20,[[["self"],["u16"]]]],[11,"shl","","",20,[[["self"],["u32"]],["self"]]],[11,"shr","","",20,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["u32"]]]],[11,"shr_assign","","",20,[[["self"],["u32"]]]],[11,"shl","","",20,[[["self"],["u64"]],["self"]]],[11,"shr","","",20,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["u64"]]]],[11,"shr_assign","","",20,[[["self"],["u64"]]]],[11,"shl","","",20,[[["self"],["usize"]],["self"]]],[11,"shr","","",20,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["usize"]]]],[11,"shr_assign","","",20,[[["self"],["usize"]]]],[11,"shl","","",20,[[["self"],["i8"]],["self"]]],[11,"shr","","",20,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["i8"]]]],[11,"shr_assign","","",20,[[["self"],["i8"]]]],[11,"shl","","",20,[[["self"],["i16"]],["self"]]],[11,"shr","","",20,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["i16"]]]],[11,"shr_assign","","",20,[[["self"],["i16"]]]],[11,"shl","","",20,[[["self"],["i32"]],["self"]]],[11,"shr","","",20,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["i32"]]]],[11,"shr_assign","","",20,[[["self"],["i32"]]]],[11,"shl","","",20,[[["self"],["i64"]],["self"]]],[11,"shr","","",20,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["i64"]]]],[11,"shr_assign","","",20,[[["self"],["i64"]]]],[11,"shl","","",20,[[["self"],["isize"]],["self"]]],[11,"shr","","",20,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["isize"]]]],[11,"shr_assign","","",20,[[["self"],["isize"]]]],[11,"shl","","",20,[[["self"],["self"]],["self"]]],[11,"shr","","",20,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",20,[[["self"],["self"]]]],[11,"shr_assign","","",20,[[["self"],["self"]]]],[11,"fmt","","",20,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",20,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",20,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",20,[[["self"],["formatter"]],["result"]]],[11,"eq","","",20,[[["self"],["self"]],["bool"]]],[11,"ne","","",20,[[["self"],["self"]],["bool"]]],[11,"default","","",20,[[],["self"]]],[11,"min","","Minimum of two vectors.",20,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",20,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",20,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",20,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",20,[[["self"]],["self"]]],[11,"clone","","",21,[[["self"]],["u8x32"]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",21,[[["self"],["u8x32"]],["option",["ordering"]]]],[11,"lt","","",21,[[["self"],["u8x32"]],["bool"]]],[11,"le","","",21,[[["self"],["u8x32"]],["bool"]]],[11,"gt","","",21,[[["self"],["u8x32"]],["bool"]]],[11,"ge","","",21,[[["self"],["u8x32"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",21,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",21,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",21,[[["u8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",21,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",21,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",21,[[["self"],["usize"],["u8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",21,[[["self"],["usize"],["u8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",21,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",21,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",21,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",21,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"eq","","Lane-wise equality comparison.",21,[[["self"],["u8x32"]],["m8x32"]]],[11,"ne","","Lane-wise inequality comparison.",21,[[["self"],["u8x32"]],["m8x32"]]],[11,"lt","","Lane-wise less-than comparison.",21,[[["self"],["u8x32"]],["m8x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",21,[[["self"],["u8x32"]],["m8x32"]]],[11,"gt","","Lane-wise greater-than comparison.",21,[[["self"],["u8x32"]],["m8x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",21,[[["self"],["u8x32"]],["m8x32"]]],[11,"hash","","",21,[[["self"],["h"]]]],[11,"add","","",21,[[["self"],["self"]],["self"]]],[11,"sub","","",21,[[["self"],["self"]],["self"]]],[11,"mul","","",21,[[["self"],["self"]],["self"]]],[11,"div","","",21,[[["self"],["self"]],["self"]]],[11,"rem","","",21,[[["self"],["self"]],["self"]]],[11,"add_assign","","",21,[[["self"],["self"]]]],[11,"sub_assign","","",21,[[["self"],["self"]]]],[11,"mul_assign","","",21,[[["self"],["self"]]]],[11,"div_assign","","",21,[[["self"],["self"]]]],[11,"rem_assign","","",21,[[["self"],["self"]]]],[11,"add","","",21,[[["self"],["u8"]],["self"]]],[11,"sub","","",21,[[["self"],["u8"]],["self"]]],[11,"mul","","",21,[[["self"],["u8"]],["self"]]],[11,"div","","",21,[[["self"],["u8"]],["self"]]],[11,"rem","","",21,[[["self"],["u8"]],["self"]]],[11,"add_assign","","",21,[[["self"],["u8"]]]],[11,"sub_assign","","",21,[[["self"],["u8"]]]],[11,"mul_assign","","",21,[[["self"],["u8"]]]],[11,"div_assign","","",21,[[["self"],["u8"]]]],[11,"rem_assign","","",21,[[["self"],["u8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",21,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",21,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",21,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",21,[[["self"]],["u8"]]],[11,"bitxor","","",21,[[["self"],["u8"]],["self"]]],[11,"bitand","","",21,[[["self"],["u8"]],["self"]]],[11,"bitor","","",21,[[["self"],["u8"]],["self"]]],[11,"bitand_assign","","",21,[[["self"],["u8"]]]],[11,"bitor_assign","","",21,[[["self"],["u8"]]]],[11,"bitxor_assign","","",21,[[["self"],["u8"]]]],[11,"not","","",21,[[["self"]],["self"]]],[11,"bitxor","","",21,[[["self"],["self"]],["self"]]],[11,"bitand","","",21,[[["self"],["self"]],["self"]]],[11,"bitor","","",21,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",21,[[["self"],["self"]]]],[11,"bitor_assign","","",21,[[["self"],["self"]]]],[11,"bitxor_assign","","",21,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",21,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",21,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",21,[[["self"]],["u8"]]],[11,"shl","","",21,[[["self"],["u8"]],["self"]]],[11,"shr","","",21,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["u8"]]]],[11,"shr_assign","","",21,[[["self"],["u8"]]]],[11,"shl","","",21,[[["self"],["u16"]],["self"]]],[11,"shr","","",21,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["u16"]]]],[11,"shr_assign","","",21,[[["self"],["u16"]]]],[11,"shl","","",21,[[["self"],["u32"]],["self"]]],[11,"shr","","",21,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["u32"]]]],[11,"shr_assign","","",21,[[["self"],["u32"]]]],[11,"shl","","",21,[[["self"],["u64"]],["self"]]],[11,"shr","","",21,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["u64"]]]],[11,"shr_assign","","",21,[[["self"],["u64"]]]],[11,"shl","","",21,[[["self"],["usize"]],["self"]]],[11,"shr","","",21,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["usize"]]]],[11,"shr_assign","","",21,[[["self"],["usize"]]]],[11,"shl","","",21,[[["self"],["i8"]],["self"]]],[11,"shr","","",21,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["i8"]]]],[11,"shr_assign","","",21,[[["self"],["i8"]]]],[11,"shl","","",21,[[["self"],["i16"]],["self"]]],[11,"shr","","",21,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["i16"]]]],[11,"shr_assign","","",21,[[["self"],["i16"]]]],[11,"shl","","",21,[[["self"],["i32"]],["self"]]],[11,"shr","","",21,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["i32"]]]],[11,"shr_assign","","",21,[[["self"],["i32"]]]],[11,"shl","","",21,[[["self"],["i64"]],["self"]]],[11,"shr","","",21,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["i64"]]]],[11,"shr_assign","","",21,[[["self"],["i64"]]]],[11,"shl","","",21,[[["self"],["isize"]],["self"]]],[11,"shr","","",21,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["isize"]]]],[11,"shr_assign","","",21,[[["self"],["isize"]]]],[11,"shl","","",21,[[["self"],["self"]],["self"]]],[11,"shr","","",21,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",21,[[["self"],["self"]]]],[11,"shr_assign","","",21,[[["self"],["self"]]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result"]]],[11,"eq","","",21,[[["self"],["self"]],["bool"]]],[11,"ne","","",21,[[["self"],["self"]],["bool"]]],[11,"default","","",21,[[],["self"]]],[11,"min","","Minimum of two vectors.",21,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",21,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",21,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",21,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",21,[[["self"]],["self"]]],[11,"clone","","",22,[[["self"]],["m8x32"]]],[11,"fmt","","",22,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",22,[[["self"],["m8x32"]],["option",["ordering"]]]],[11,"lt","","",22,[[["self"],["m8x32"]],["bool"]]],[11,"le","","",22,[[["self"],["m8x32"]],["bool"]]],[11,"gt","","",22,[[["self"],["m8x32"]],["bool"]]],[11,"ge","","",22,[[["self"],["m8x32"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",22,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",22,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",22,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",22,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",22,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",22,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",22,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",22,[[["self"]],["self"]]],[11,"bitxor","","",22,[[["self"],["self"]],["self"]]],[11,"bitand","","",22,[[["self"],["self"]],["self"]]],[11,"bitor","","",22,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",22,[[["self"],["self"]]]],[11,"bitor_assign","","",22,[[["self"],["self"]]]],[11,"bitxor_assign","","",22,[[["self"],["self"]]]],[11,"bitxor","","",22,[[["self"],["bool"]],["self"]]],[11,"bitand","","",22,[[["self"],["bool"]],["self"]]],[11,"bitor","","",22,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",22,[[["self"],["bool"]]]],[11,"bitor_assign","","",22,[[["self"],["bool"]]]],[11,"bitxor_assign","","",22,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",22,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",22,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",22,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",22,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",22,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",22,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",22,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",22,[[["self"],["m8x32"]],["m8x32"]]],[11,"ne","","Lane-wise inequality comparison.",22,[[["self"],["m8x32"]],["m8x32"]]],[11,"lt","","Lane-wise less-than comparison.",22,[[["self"],["m8x32"]],["m8x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",22,[[["self"],["m8x32"]],["m8x32"]]],[11,"gt","","Lane-wise greater-than comparison.",22,[[["self"],["m8x32"]],["m8x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",22,[[["self"],["m8x32"]],["m8x32"]]],[11,"eq","","",22,[[["self"],["self"]],["bool"]]],[11,"ne","","",22,[[["self"],["self"]],["bool"]]],[11,"default","","",22,[[],["self"]]],[11,"clone","","",23,[[["self"]],["i16x16"]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",23,[[["self"],["i16x16"]],["option",["ordering"]]]],[11,"lt","","",23,[[["self"],["i16x16"]],["bool"]]],[11,"le","","",23,[[["self"],["i16x16"]],["bool"]]],[11,"gt","","",23,[[["self"],["i16x16"]],["bool"]]],[11,"ge","","",23,[[["self"],["i16x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",23,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",23,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",23,[[["i16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",23,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",23,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",23,[[["self"],["usize"],["i16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",23,[[["self"],["usize"],["i16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",23,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",23,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",23,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",23,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"eq","","Lane-wise equality comparison.",23,[[["self"],["i16x16"]],["m16x16"]]],[11,"ne","","Lane-wise inequality comparison.",23,[[["self"],["i16x16"]],["m16x16"]]],[11,"lt","","Lane-wise less-than comparison.",23,[[["self"],["i16x16"]],["m16x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",23,[[["self"],["i16x16"]],["m16x16"]]],[11,"gt","","Lane-wise greater-than comparison.",23,[[["self"],["i16x16"]],["m16x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",23,[[["self"],["i16x16"]],["m16x16"]]],[11,"hash","","",23,[[["self"],["h"]]]],[11,"add","","",23,[[["self"],["self"]],["self"]]],[11,"sub","","",23,[[["self"],["self"]],["self"]]],[11,"mul","","",23,[[["self"],["self"]],["self"]]],[11,"div","","",23,[[["self"],["self"]],["self"]]],[11,"rem","","",23,[[["self"],["self"]],["self"]]],[11,"add_assign","","",23,[[["self"],["self"]]]],[11,"sub_assign","","",23,[[["self"],["self"]]]],[11,"mul_assign","","",23,[[["self"],["self"]]]],[11,"div_assign","","",23,[[["self"],["self"]]]],[11,"rem_assign","","",23,[[["self"],["self"]]]],[11,"add","","",23,[[["self"],["i16"]],["self"]]],[11,"sub","","",23,[[["self"],["i16"]],["self"]]],[11,"mul","","",23,[[["self"],["i16"]],["self"]]],[11,"div","","",23,[[["self"],["i16"]],["self"]]],[11,"rem","","",23,[[["self"],["i16"]],["self"]]],[11,"add_assign","","",23,[[["self"],["i16"]]]],[11,"sub_assign","","",23,[[["self"],["i16"]]]],[11,"mul_assign","","",23,[[["self"],["i16"]]]],[11,"div_assign","","",23,[[["self"],["i16"]]]],[11,"rem_assign","","",23,[[["self"],["i16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",23,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",23,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",23,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",23,[[["self"]],["i16"]]],[11,"neg","","",23,[[["self"]],["self"]]],[11,"not","","",23,[[["self"]],["self"]]],[11,"bitxor","","",23,[[["self"],["self"]],["self"]]],[11,"bitand","","",23,[[["self"],["self"]],["self"]]],[11,"bitor","","",23,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",23,[[["self"],["self"]]]],[11,"bitor_assign","","",23,[[["self"],["self"]]]],[11,"bitxor_assign","","",23,[[["self"],["self"]]]],[11,"bitxor","","",23,[[["self"],["i16"]],["self"]]],[11,"bitand","","",23,[[["self"],["i16"]],["self"]]],[11,"bitor","","",23,[[["self"],["i16"]],["self"]]],[11,"bitand_assign","","",23,[[["self"],["i16"]]]],[11,"bitor_assign","","",23,[[["self"],["i16"]]]],[11,"bitxor_assign","","",23,[[["self"],["i16"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",23,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",23,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",23,[[["self"]],["i16"]]],[11,"shl","","",23,[[["self"],["u8"]],["self"]]],[11,"shr","","",23,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["u8"]]]],[11,"shr_assign","","",23,[[["self"],["u8"]]]],[11,"shl","","",23,[[["self"],["u16"]],["self"]]],[11,"shr","","",23,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["u16"]]]],[11,"shr_assign","","",23,[[["self"],["u16"]]]],[11,"shl","","",23,[[["self"],["u32"]],["self"]]],[11,"shr","","",23,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["u32"]]]],[11,"shr_assign","","",23,[[["self"],["u32"]]]],[11,"shl","","",23,[[["self"],["u64"]],["self"]]],[11,"shr","","",23,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["u64"]]]],[11,"shr_assign","","",23,[[["self"],["u64"]]]],[11,"shl","","",23,[[["self"],["usize"]],["self"]]],[11,"shr","","",23,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["usize"]]]],[11,"shr_assign","","",23,[[["self"],["usize"]]]],[11,"shl","","",23,[[["self"],["i8"]],["self"]]],[11,"shr","","",23,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["i8"]]]],[11,"shr_assign","","",23,[[["self"],["i8"]]]],[11,"shl","","",23,[[["self"],["i16"]],["self"]]],[11,"shr","","",23,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["i16"]]]],[11,"shr_assign","","",23,[[["self"],["i16"]]]],[11,"shl","","",23,[[["self"],["i32"]],["self"]]],[11,"shr","","",23,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["i32"]]]],[11,"shr_assign","","",23,[[["self"],["i32"]]]],[11,"shl","","",23,[[["self"],["i64"]],["self"]]],[11,"shr","","",23,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["i64"]]]],[11,"shr_assign","","",23,[[["self"],["i64"]]]],[11,"shl","","",23,[[["self"],["isize"]],["self"]]],[11,"shr","","",23,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["isize"]]]],[11,"shr_assign","","",23,[[["self"],["isize"]]]],[11,"shl","","",23,[[["self"],["self"]],["self"]]],[11,"shr","","",23,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",23,[[["self"],["self"]]]],[11,"shr_assign","","",23,[[["self"],["self"]]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result"]]],[11,"eq","","",23,[[["self"],["self"]],["bool"]]],[11,"ne","","",23,[[["self"],["self"]],["bool"]]],[11,"default","","",23,[[],["self"]]],[11,"min","","Minimum of two vectors.",23,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",23,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",23,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",23,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",23,[[["self"]],["self"]]],[11,"clone","","",24,[[["self"]],["u16x16"]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",24,[[["self"],["u16x16"]],["option",["ordering"]]]],[11,"lt","","",24,[[["self"],["u16x16"]],["bool"]]],[11,"le","","",24,[[["self"],["u16x16"]],["bool"]]],[11,"gt","","",24,[[["self"],["u16x16"]],["bool"]]],[11,"ge","","",24,[[["self"],["u16x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",24,[[["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",24,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",24,[[["u16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",24,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",24,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",24,[[["self"],["usize"],["u16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",24,[[["self"],["usize"],["u16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",24,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",24,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",24,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",24,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"eq","","Lane-wise equality comparison.",24,[[["self"],["u16x16"]],["m16x16"]]],[11,"ne","","Lane-wise inequality comparison.",24,[[["self"],["u16x16"]],["m16x16"]]],[11,"lt","","Lane-wise less-than comparison.",24,[[["self"],["u16x16"]],["m16x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",24,[[["self"],["u16x16"]],["m16x16"]]],[11,"gt","","Lane-wise greater-than comparison.",24,[[["self"],["u16x16"]],["m16x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",24,[[["self"],["u16x16"]],["m16x16"]]],[11,"hash","","",24,[[["self"],["h"]]]],[11,"add","","",24,[[["self"],["self"]],["self"]]],[11,"sub","","",24,[[["self"],["self"]],["self"]]],[11,"mul","","",24,[[["self"],["self"]],["self"]]],[11,"div","","",24,[[["self"],["self"]],["self"]]],[11,"rem","","",24,[[["self"],["self"]],["self"]]],[11,"add_assign","","",24,[[["self"],["self"]]]],[11,"sub_assign","","",24,[[["self"],["self"]]]],[11,"mul_assign","","",24,[[["self"],["self"]]]],[11,"div_assign","","",24,[[["self"],["self"]]]],[11,"rem_assign","","",24,[[["self"],["self"]]]],[11,"add","","",24,[[["self"],["u16"]],["self"]]],[11,"sub","","",24,[[["self"],["u16"]],["self"]]],[11,"mul","","",24,[[["self"],["u16"]],["self"]]],[11,"div","","",24,[[["self"],["u16"]],["self"]]],[11,"rem","","",24,[[["self"],["u16"]],["self"]]],[11,"add_assign","","",24,[[["self"],["u16"]]]],[11,"sub_assign","","",24,[[["self"],["u16"]]]],[11,"mul_assign","","",24,[[["self"],["u16"]]]],[11,"div_assign","","",24,[[["self"],["u16"]]]],[11,"rem_assign","","",24,[[["self"],["u16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",24,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",24,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",24,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",24,[[["self"]],["u16"]]],[11,"bitxor","","",24,[[["self"],["u16"]],["self"]]],[11,"bitand","","",24,[[["self"],["u16"]],["self"]]],[11,"bitor","","",24,[[["self"],["u16"]],["self"]]],[11,"bitand_assign","","",24,[[["self"],["u16"]]]],[11,"bitor_assign","","",24,[[["self"],["u16"]]]],[11,"bitxor_assign","","",24,[[["self"],["u16"]]]],[11,"not","","",24,[[["self"]],["self"]]],[11,"bitxor","","",24,[[["self"],["self"]],["self"]]],[11,"bitand","","",24,[[["self"],["self"]],["self"]]],[11,"bitor","","",24,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",24,[[["self"],["self"]]]],[11,"bitor_assign","","",24,[[["self"],["self"]]]],[11,"bitxor_assign","","",24,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",24,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",24,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",24,[[["self"]],["u16"]]],[11,"shl","","",24,[[["self"],["u8"]],["self"]]],[11,"shr","","",24,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["u8"]]]],[11,"shr_assign","","",24,[[["self"],["u8"]]]],[11,"shl","","",24,[[["self"],["u16"]],["self"]]],[11,"shr","","",24,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["u16"]]]],[11,"shr_assign","","",24,[[["self"],["u16"]]]],[11,"shl","","",24,[[["self"],["u32"]],["self"]]],[11,"shr","","",24,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["u32"]]]],[11,"shr_assign","","",24,[[["self"],["u32"]]]],[11,"shl","","",24,[[["self"],["u64"]],["self"]]],[11,"shr","","",24,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["u64"]]]],[11,"shr_assign","","",24,[[["self"],["u64"]]]],[11,"shl","","",24,[[["self"],["usize"]],["self"]]],[11,"shr","","",24,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["usize"]]]],[11,"shr_assign","","",24,[[["self"],["usize"]]]],[11,"shl","","",24,[[["self"],["i8"]],["self"]]],[11,"shr","","",24,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["i8"]]]],[11,"shr_assign","","",24,[[["self"],["i8"]]]],[11,"shl","","",24,[[["self"],["i16"]],["self"]]],[11,"shr","","",24,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["i16"]]]],[11,"shr_assign","","",24,[[["self"],["i16"]]]],[11,"shl","","",24,[[["self"],["i32"]],["self"]]],[11,"shr","","",24,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["i32"]]]],[11,"shr_assign","","",24,[[["self"],["i32"]]]],[11,"shl","","",24,[[["self"],["i64"]],["self"]]],[11,"shr","","",24,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["i64"]]]],[11,"shr_assign","","",24,[[["self"],["i64"]]]],[11,"shl","","",24,[[["self"],["isize"]],["self"]]],[11,"shr","","",24,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["isize"]]]],[11,"shr_assign","","",24,[[["self"],["isize"]]]],[11,"shl","","",24,[[["self"],["self"]],["self"]]],[11,"shr","","",24,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",24,[[["self"],["self"]]]],[11,"shr_assign","","",24,[[["self"],["self"]]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result"]]],[11,"eq","","",24,[[["self"],["self"]],["bool"]]],[11,"ne","","",24,[[["self"],["self"]],["bool"]]],[11,"default","","",24,[[],["self"]]],[11,"min","","Minimum of two vectors.",24,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",24,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",24,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",24,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",24,[[["self"]],["self"]]],[11,"clone","","",25,[[["self"]],["m16x16"]]],[11,"fmt","","",25,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",25,[[["self"],["m16x16"]],["option",["ordering"]]]],[11,"lt","","",25,[[["self"],["m16x16"]],["bool"]]],[11,"le","","",25,[[["self"],["m16x16"]],["bool"]]],[11,"gt","","",25,[[["self"],["m16x16"]],["bool"]]],[11,"ge","","",25,[[["self"],["m16x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",25,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",25,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",25,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",25,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",25,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",25,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",25,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",25,[[["self"]],["self"]]],[11,"bitxor","","",25,[[["self"],["self"]],["self"]]],[11,"bitand","","",25,[[["self"],["self"]],["self"]]],[11,"bitor","","",25,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",25,[[["self"],["self"]]]],[11,"bitor_assign","","",25,[[["self"],["self"]]]],[11,"bitxor_assign","","",25,[[["self"],["self"]]]],[11,"bitxor","","",25,[[["self"],["bool"]],["self"]]],[11,"bitand","","",25,[[["self"],["bool"]],["self"]]],[11,"bitor","","",25,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",25,[[["self"],["bool"]]]],[11,"bitor_assign","","",25,[[["self"],["bool"]]]],[11,"bitxor_assign","","",25,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",25,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",25,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",25,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",25,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",25,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",25,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",25,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",25,[[["self"],["m16x16"]],["m16x16"]]],[11,"ne","","Lane-wise inequality comparison.",25,[[["self"],["m16x16"]],["m16x16"]]],[11,"lt","","Lane-wise less-than comparison.",25,[[["self"],["m16x16"]],["m16x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",25,[[["self"],["m16x16"]],["m16x16"]]],[11,"gt","","Lane-wise greater-than comparison.",25,[[["self"],["m16x16"]],["m16x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",25,[[["self"],["m16x16"]],["m16x16"]]],[11,"eq","","",25,[[["self"],["self"]],["bool"]]],[11,"ne","","",25,[[["self"],["self"]],["bool"]]],[11,"default","","",25,[[],["self"]]],[11,"clone","","",26,[[["self"]],["i32x8"]]],[11,"fmt","","",26,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",26,[[["self"],["i32x8"]],["option",["ordering"]]]],[11,"lt","","",26,[[["self"],["i32x8"]],["bool"]]],[11,"le","","",26,[[["self"],["i32x8"]],["bool"]]],[11,"gt","","",26,[[["self"],["i32x8"]],["bool"]]],[11,"ge","","",26,[[["self"],["i32x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",26,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",26,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",26,[[["i32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",26,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",26,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",26,[[["self"],["usize"],["i32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",26,[[["self"],["usize"],["i32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",26,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",26,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",26,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",26,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",26,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",26,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",26,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",26,N],[11,"eq","","Lane-wise equality comparison.",26,[[["self"],["i32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",26,[[["self"],["i32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",26,[[["self"],["i32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",26,[[["self"],["i32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",26,[[["self"],["i32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",26,[[["self"],["i32x8"]],["m32x8"]]],[11,"hash","","",26,[[["self"],["h"]]]],[11,"add","","",26,[[["self"],["self"]],["self"]]],[11,"sub","","",26,[[["self"],["self"]],["self"]]],[11,"mul","","",26,[[["self"],["self"]],["self"]]],[11,"div","","",26,[[["self"],["self"]],["self"]]],[11,"rem","","",26,[[["self"],["self"]],["self"]]],[11,"add_assign","","",26,[[["self"],["self"]]]],[11,"sub_assign","","",26,[[["self"],["self"]]]],[11,"mul_assign","","",26,[[["self"],["self"]]]],[11,"div_assign","","",26,[[["self"],["self"]]]],[11,"rem_assign","","",26,[[["self"],["self"]]]],[11,"add","","",26,[[["self"],["i32"]],["self"]]],[11,"sub","","",26,[[["self"],["i32"]],["self"]]],[11,"mul","","",26,[[["self"],["i32"]],["self"]]],[11,"div","","",26,[[["self"],["i32"]],["self"]]],[11,"rem","","",26,[[["self"],["i32"]],["self"]]],[11,"add_assign","","",26,[[["self"],["i32"]]]],[11,"sub_assign","","",26,[[["self"],["i32"]]]],[11,"mul_assign","","",26,[[["self"],["i32"]]]],[11,"div_assign","","",26,[[["self"],["i32"]]]],[11,"rem_assign","","",26,[[["self"],["i32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",26,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",26,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",26,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",26,[[["self"]],["i32"]]],[11,"neg","","",26,[[["self"]],["self"]]],[11,"not","","",26,[[["self"]],["self"]]],[11,"bitxor","","",26,[[["self"],["self"]],["self"]]],[11,"bitand","","",26,[[["self"],["self"]],["self"]]],[11,"bitor","","",26,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",26,[[["self"],["self"]]]],[11,"bitor_assign","","",26,[[["self"],["self"]]]],[11,"bitxor_assign","","",26,[[["self"],["self"]]]],[11,"bitxor","","",26,[[["self"],["i32"]],["self"]]],[11,"bitand","","",26,[[["self"],["i32"]],["self"]]],[11,"bitor","","",26,[[["self"],["i32"]],["self"]]],[11,"bitand_assign","","",26,[[["self"],["i32"]]]],[11,"bitor_assign","","",26,[[["self"],["i32"]]]],[11,"bitxor_assign","","",26,[[["self"],["i32"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",26,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",26,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",26,[[["self"]],["i32"]]],[11,"shl","","",26,[[["self"],["u8"]],["self"]]],[11,"shr","","",26,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["u8"]]]],[11,"shr_assign","","",26,[[["self"],["u8"]]]],[11,"shl","","",26,[[["self"],["u16"]],["self"]]],[11,"shr","","",26,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["u16"]]]],[11,"shr_assign","","",26,[[["self"],["u16"]]]],[11,"shl","","",26,[[["self"],["u32"]],["self"]]],[11,"shr","","",26,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["u32"]]]],[11,"shr_assign","","",26,[[["self"],["u32"]]]],[11,"shl","","",26,[[["self"],["u64"]],["self"]]],[11,"shr","","",26,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["u64"]]]],[11,"shr_assign","","",26,[[["self"],["u64"]]]],[11,"shl","","",26,[[["self"],["usize"]],["self"]]],[11,"shr","","",26,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["usize"]]]],[11,"shr_assign","","",26,[[["self"],["usize"]]]],[11,"shl","","",26,[[["self"],["i8"]],["self"]]],[11,"shr","","",26,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["i8"]]]],[11,"shr_assign","","",26,[[["self"],["i8"]]]],[11,"shl","","",26,[[["self"],["i16"]],["self"]]],[11,"shr","","",26,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["i16"]]]],[11,"shr_assign","","",26,[[["self"],["i16"]]]],[11,"shl","","",26,[[["self"],["i32"]],["self"]]],[11,"shr","","",26,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["i32"]]]],[11,"shr_assign","","",26,[[["self"],["i32"]]]],[11,"shl","","",26,[[["self"],["i64"]],["self"]]],[11,"shr","","",26,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["i64"]]]],[11,"shr_assign","","",26,[[["self"],["i64"]]]],[11,"shl","","",26,[[["self"],["isize"]],["self"]]],[11,"shr","","",26,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["isize"]]]],[11,"shr_assign","","",26,[[["self"],["isize"]]]],[11,"shl","","",26,[[["self"],["self"]],["self"]]],[11,"shr","","",26,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",26,[[["self"],["self"]]]],[11,"shr_assign","","",26,[[["self"],["self"]]]],[11,"fmt","","",26,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",26,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",26,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",26,[[["self"],["formatter"]],["result"]]],[11,"eq","","",26,[[["self"],["self"]],["bool"]]],[11,"ne","","",26,[[["self"],["self"]],["bool"]]],[11,"default","","",26,[[],["self"]]],[11,"min","","Minimum of two vectors.",26,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",26,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",26,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",26,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",26,[[["self"]],["self"]]],[11,"clone","","",27,[[["self"]],["u32x8"]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",27,[[["self"],["u32x8"]],["option",["ordering"]]]],[11,"lt","","",27,[[["self"],["u32x8"]],["bool"]]],[11,"le","","",27,[[["self"],["u32x8"]],["bool"]]],[11,"gt","","",27,[[["self"],["u32x8"]],["bool"]]],[11,"ge","","",27,[[["self"],["u32x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",27,[[["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",27,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",27,[[["u32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",27,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",27,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",27,[[["self"],["usize"],["u32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",27,[[["self"],["usize"],["u32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",27,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",27,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",27,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",27,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"eq","","Lane-wise equality comparison.",27,[[["self"],["u32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",27,[[["self"],["u32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",27,[[["self"],["u32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",27,[[["self"],["u32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",27,[[["self"],["u32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",27,[[["self"],["u32x8"]],["m32x8"]]],[11,"hash","","",27,[[["self"],["h"]]]],[11,"add","","",27,[[["self"],["self"]],["self"]]],[11,"sub","","",27,[[["self"],["self"]],["self"]]],[11,"mul","","",27,[[["self"],["self"]],["self"]]],[11,"div","","",27,[[["self"],["self"]],["self"]]],[11,"rem","","",27,[[["self"],["self"]],["self"]]],[11,"add_assign","","",27,[[["self"],["self"]]]],[11,"sub_assign","","",27,[[["self"],["self"]]]],[11,"mul_assign","","",27,[[["self"],["self"]]]],[11,"div_assign","","",27,[[["self"],["self"]]]],[11,"rem_assign","","",27,[[["self"],["self"]]]],[11,"add","","",27,[[["self"],["u32"]],["self"]]],[11,"sub","","",27,[[["self"],["u32"]],["self"]]],[11,"mul","","",27,[[["self"],["u32"]],["self"]]],[11,"div","","",27,[[["self"],["u32"]],["self"]]],[11,"rem","","",27,[[["self"],["u32"]],["self"]]],[11,"add_assign","","",27,[[["self"],["u32"]]]],[11,"sub_assign","","",27,[[["self"],["u32"]]]],[11,"mul_assign","","",27,[[["self"],["u32"]]]],[11,"div_assign","","",27,[[["self"],["u32"]]]],[11,"rem_assign","","",27,[[["self"],["u32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",27,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",27,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",27,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",27,[[["self"]],["u32"]]],[11,"bitxor","","",27,[[["self"],["u32"]],["self"]]],[11,"bitand","","",27,[[["self"],["u32"]],["self"]]],[11,"bitor","","",27,[[["self"],["u32"]],["self"]]],[11,"bitand_assign","","",27,[[["self"],["u32"]]]],[11,"bitor_assign","","",27,[[["self"],["u32"]]]],[11,"bitxor_assign","","",27,[[["self"],["u32"]]]],[11,"not","","",27,[[["self"]],["self"]]],[11,"bitxor","","",27,[[["self"],["self"]],["self"]]],[11,"bitand","","",27,[[["self"],["self"]],["self"]]],[11,"bitor","","",27,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",27,[[["self"],["self"]]]],[11,"bitor_assign","","",27,[[["self"],["self"]]]],[11,"bitxor_assign","","",27,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",27,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",27,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",27,[[["self"]],["u32"]]],[11,"shl","","",27,[[["self"],["u8"]],["self"]]],[11,"shr","","",27,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["u8"]]]],[11,"shr_assign","","",27,[[["self"],["u8"]]]],[11,"shl","","",27,[[["self"],["u16"]],["self"]]],[11,"shr","","",27,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["u16"]]]],[11,"shr_assign","","",27,[[["self"],["u16"]]]],[11,"shl","","",27,[[["self"],["u32"]],["self"]]],[11,"shr","","",27,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["u32"]]]],[11,"shr_assign","","",27,[[["self"],["u32"]]]],[11,"shl","","",27,[[["self"],["u64"]],["self"]]],[11,"shr","","",27,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["u64"]]]],[11,"shr_assign","","",27,[[["self"],["u64"]]]],[11,"shl","","",27,[[["self"],["usize"]],["self"]]],[11,"shr","","",27,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["usize"]]]],[11,"shr_assign","","",27,[[["self"],["usize"]]]],[11,"shl","","",27,[[["self"],["i8"]],["self"]]],[11,"shr","","",27,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["i8"]]]],[11,"shr_assign","","",27,[[["self"],["i8"]]]],[11,"shl","","",27,[[["self"],["i16"]],["self"]]],[11,"shr","","",27,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["i16"]]]],[11,"shr_assign","","",27,[[["self"],["i16"]]]],[11,"shl","","",27,[[["self"],["i32"]],["self"]]],[11,"shr","","",27,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["i32"]]]],[11,"shr_assign","","",27,[[["self"],["i32"]]]],[11,"shl","","",27,[[["self"],["i64"]],["self"]]],[11,"shr","","",27,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["i64"]]]],[11,"shr_assign","","",27,[[["self"],["i64"]]]],[11,"shl","","",27,[[["self"],["isize"]],["self"]]],[11,"shr","","",27,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["isize"]]]],[11,"shr_assign","","",27,[[["self"],["isize"]]]],[11,"shl","","",27,[[["self"],["self"]],["self"]]],[11,"shr","","",27,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",27,[[["self"],["self"]]]],[11,"shr_assign","","",27,[[["self"],["self"]]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result"]]],[11,"eq","","",27,[[["self"],["self"]],["bool"]]],[11,"ne","","",27,[[["self"],["self"]],["bool"]]],[11,"default","","",27,[[],["self"]]],[11,"min","","Minimum of two vectors.",27,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",27,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",27,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",27,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",27,[[["self"]],["self"]]],[11,"clone","","",28,[[["self"]],["f32x8"]]],[11,"fmt","","",28,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",28,[[["self"],["f32x8"]],["option",["ordering"]]]],[11,"lt","","",28,[[["self"],["f32x8"]],["bool"]]],[11,"le","","",28,[[["self"],["f32x8"]],["bool"]]],[11,"gt","","",28,[[["self"],["f32x8"]],["bool"]]],[11,"ge","","",28,[[["self"],["f32x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",28,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",28,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",28,[[["f32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",28,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",28,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",28,[[["self"],["usize"],["f32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",28,[[["self"],["usize"],["f32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",28,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",28,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",28,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",28,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",28,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",28,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",28,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",28,N],[11,"eq","","Lane-wise equality comparison.",28,[[["self"],["f32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",28,[[["self"],["f32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",28,[[["self"],["f32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",28,[[["self"],["f32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",28,[[["self"],["f32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",28,[[["self"],["f32x8"]],["m32x8"]]],[11,"add","","",28,[[["self"],["self"]],["self"]]],[11,"sub","","",28,[[["self"],["self"]],["self"]]],[11,"mul","","",28,[[["self"],["self"]],["self"]]],[11,"div","","",28,[[["self"],["self"]],["self"]]],[11,"rem","","",28,[[["self"],["self"]],["self"]]],[11,"add_assign","","",28,[[["self"],["self"]]]],[11,"sub_assign","","",28,[[["self"],["self"]]]],[11,"mul_assign","","",28,[[["self"],["self"]]]],[11,"div_assign","","",28,[[["self"],["self"]]]],[11,"rem_assign","","",28,[[["self"],["self"]]]],[11,"add","","",28,[[["self"],["f32"]],["self"]]],[11,"sub","","",28,[[["self"],["f32"]],["self"]]],[11,"mul","","",28,[[["self"],["f32"]],["self"]]],[11,"div","","",28,[[["self"],["f32"]],["self"]]],[11,"rem","","",28,[[["self"],["f32"]],["self"]]],[11,"add_assign","","",28,[[["self"],["f32"]]]],[11,"sub_assign","","",28,[[["self"],["f32"]]]],[11,"mul_assign","","",28,[[["self"],["f32"]]]],[11,"div_assign","","",28,[[["self"],["f32"]]]],[11,"rem_assign","","",28,[[["self"],["f32"]]]],[11,"sum","","Horizontal sum of the vector elements.",28,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",28,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",28,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",28,[[["self"]],["f32"]]],[11,"neg","","",28,[[["self"]],["self"]]],[11,"eq","","",28,[[["self"],["self"]],["bool"]]],[11,"ne","","",28,[[["self"],["self"]],["bool"]]],[11,"default","","",28,[[],["self"]]],[11,"min","","Minimum of two vectors.",28,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",28,[[["self"],["self"]],["self"]]],[11,"abs","","Absolute-value",28,[[["self"]],["self"]]],[11,"sqrt","","Square-root",28,[[["self"]],["self"]]],[11,"sqrte","","Square-root estimate",28,[[["self"]],["self"]]],[11,"rsqrte","","Reciprocal square-root estimate",28,[[["self"]],["self"]]],[11,"fma","","Fused multiply add: `self * y + z`",28,[[["self"],["self"],["self"]],["self"]]],[11,"sin","","Sin",28,[[["self"]],["self"]]],[11,"cos","","Cos",28,[[["self"]],["self"]]],[11,"clone","","",29,[[["self"]],["m32x8"]]],[11,"fmt","","",29,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",29,[[["self"],["m32x8"]],["option",["ordering"]]]],[11,"lt","","",29,[[["self"],["m32x8"]],["bool"]]],[11,"le","","",29,[[["self"],["m32x8"]],["bool"]]],[11,"gt","","",29,[[["self"],["m32x8"]],["bool"]]],[11,"ge","","",29,[[["self"],["m32x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",29,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",29,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",29,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",29,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",29,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",29,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",29,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",29,[[["self"]],["self"]]],[11,"bitxor","","",29,[[["self"],["self"]],["self"]]],[11,"bitand","","",29,[[["self"],["self"]],["self"]]],[11,"bitor","","",29,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",29,[[["self"],["self"]]]],[11,"bitor_assign","","",29,[[["self"],["self"]]]],[11,"bitxor_assign","","",29,[[["self"],["self"]]]],[11,"bitxor","","",29,[[["self"],["bool"]],["self"]]],[11,"bitand","","",29,[[["self"],["bool"]],["self"]]],[11,"bitor","","",29,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",29,[[["self"],["bool"]]]],[11,"bitor_assign","","",29,[[["self"],["bool"]]]],[11,"bitxor_assign","","",29,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",29,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",29,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",29,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",29,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",29,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",29,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",29,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",29,[[["self"],["m32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",29,[[["self"],["m32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",29,[[["self"],["m32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",29,[[["self"],["m32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",29,[[["self"],["m32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",29,[[["self"],["m32x8"]],["m32x8"]]],[11,"eq","","",29,[[["self"],["self"]],["bool"]]],[11,"ne","","",29,[[["self"],["self"]],["bool"]]],[11,"default","","",29,[[],["self"]]],[11,"clone","","",30,[[["self"]],["i64x4"]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",30,[[["self"],["i64x4"]],["option",["ordering"]]]],[11,"lt","","",30,[[["self"],["i64x4"]],["bool"]]],[11,"le","","",30,[[["self"],["i64x4"]],["bool"]]],[11,"gt","","",30,[[["self"],["i64x4"]],["bool"]]],[11,"ge","","",30,[[["self"],["i64x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",30,[[["i64"],["i64"],["i64"],["i64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",30,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",30,[[["i64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",30,[[["self"],["usize"]],["i64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",30,[[["self"],["usize"]],["i64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",30,[[["self"],["usize"],["i64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",30,[[["self"],["usize"],["i64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",30,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",30,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",30,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",30,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"eq","","Lane-wise equality comparison.",30,[[["self"],["i64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",30,[[["self"],["i64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",30,[[["self"],["i64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",30,[[["self"],["i64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",30,[[["self"],["i64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",30,[[["self"],["i64x4"]],["m64x4"]]],[11,"hash","","",30,[[["self"],["h"]]]],[11,"add","","",30,[[["self"],["self"]],["self"]]],[11,"sub","","",30,[[["self"],["self"]],["self"]]],[11,"mul","","",30,[[["self"],["self"]],["self"]]],[11,"div","","",30,[[["self"],["self"]],["self"]]],[11,"rem","","",30,[[["self"],["self"]],["self"]]],[11,"add_assign","","",30,[[["self"],["self"]]]],[11,"sub_assign","","",30,[[["self"],["self"]]]],[11,"mul_assign","","",30,[[["self"],["self"]]]],[11,"div_assign","","",30,[[["self"],["self"]]]],[11,"rem_assign","","",30,[[["self"],["self"]]]],[11,"add","","",30,[[["self"],["i64"]],["self"]]],[11,"sub","","",30,[[["self"],["i64"]],["self"]]],[11,"mul","","",30,[[["self"],["i64"]],["self"]]],[11,"div","","",30,[[["self"],["i64"]],["self"]]],[11,"rem","","",30,[[["self"],["i64"]],["self"]]],[11,"add_assign","","",30,[[["self"],["i64"]]]],[11,"sub_assign","","",30,[[["self"],["i64"]]]],[11,"mul_assign","","",30,[[["self"],["i64"]]]],[11,"div_assign","","",30,[[["self"],["i64"]]]],[11,"rem_assign","","",30,[[["self"],["i64"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",30,[[["self"]],["i64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",30,[[["self"]],["i64"]]],[11,"max_element","","Largest vector element value.",30,[[["self"]],["i64"]]],[11,"min_element","","Smallest vector element value.",30,[[["self"]],["i64"]]],[11,"neg","","",30,[[["self"]],["self"]]],[11,"not","","",30,[[["self"]],["self"]]],[11,"bitxor","","",30,[[["self"],["self"]],["self"]]],[11,"bitand","","",30,[[["self"],["self"]],["self"]]],[11,"bitor","","",30,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",30,[[["self"],["self"]]]],[11,"bitor_assign","","",30,[[["self"],["self"]]]],[11,"bitxor_assign","","",30,[[["self"],["self"]]]],[11,"bitxor","","",30,[[["self"],["i64"]],["self"]]],[11,"bitand","","",30,[[["self"],["i64"]],["self"]]],[11,"bitor","","",30,[[["self"],["i64"]],["self"]]],[11,"bitand_assign","","",30,[[["self"],["i64"]]]],[11,"bitor_assign","","",30,[[["self"],["i64"]]]],[11,"bitxor_assign","","",30,[[["self"],["i64"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",30,[[["self"]],["i64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",30,[[["self"]],["i64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",30,[[["self"]],["i64"]]],[11,"shl","","",30,[[["self"],["u8"]],["self"]]],[11,"shr","","",30,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["u8"]]]],[11,"shr_assign","","",30,[[["self"],["u8"]]]],[11,"shl","","",30,[[["self"],["u16"]],["self"]]],[11,"shr","","",30,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["u16"]]]],[11,"shr_assign","","",30,[[["self"],["u16"]]]],[11,"shl","","",30,[[["self"],["u32"]],["self"]]],[11,"shr","","",30,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["u32"]]]],[11,"shr_assign","","",30,[[["self"],["u32"]]]],[11,"shl","","",30,[[["self"],["u64"]],["self"]]],[11,"shr","","",30,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["u64"]]]],[11,"shr_assign","","",30,[[["self"],["u64"]]]],[11,"shl","","",30,[[["self"],["usize"]],["self"]]],[11,"shr","","",30,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["usize"]]]],[11,"shr_assign","","",30,[[["self"],["usize"]]]],[11,"shl","","",30,[[["self"],["i8"]],["self"]]],[11,"shr","","",30,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["i8"]]]],[11,"shr_assign","","",30,[[["self"],["i8"]]]],[11,"shl","","",30,[[["self"],["i16"]],["self"]]],[11,"shr","","",30,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["i16"]]]],[11,"shr_assign","","",30,[[["self"],["i16"]]]],[11,"shl","","",30,[[["self"],["i32"]],["self"]]],[11,"shr","","",30,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["i32"]]]],[11,"shr_assign","","",30,[[["self"],["i32"]]]],[11,"shl","","",30,[[["self"],["i64"]],["self"]]],[11,"shr","","",30,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["i64"]]]],[11,"shr_assign","","",30,[[["self"],["i64"]]]],[11,"shl","","",30,[[["self"],["isize"]],["self"]]],[11,"shr","","",30,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["isize"]]]],[11,"shr_assign","","",30,[[["self"],["isize"]]]],[11,"shl","","",30,[[["self"],["self"]],["self"]]],[11,"shr","","",30,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",30,[[["self"],["self"]]]],[11,"shr_assign","","",30,[[["self"],["self"]]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result"]]],[11,"eq","","",30,[[["self"],["self"]],["bool"]]],[11,"ne","","",30,[[["self"],["self"]],["bool"]]],[11,"default","","",30,[[],["self"]]],[11,"min","","Minimum of two vectors.",30,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",30,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",30,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",30,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",30,[[["self"]],["self"]]],[11,"clone","","",31,[[["self"]],["u64x4"]]],[11,"fmt","","",31,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",31,[[["self"],["u64x4"]],["option",["ordering"]]]],[11,"lt","","",31,[[["self"],["u64x4"]],["bool"]]],[11,"le","","",31,[[["self"],["u64x4"]],["bool"]]],[11,"gt","","",31,[[["self"],["u64x4"]],["bool"]]],[11,"ge","","",31,[[["self"],["u64x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",31,[[["u64"],["u64"],["u64"],["u64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",31,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",31,[[["u64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",31,[[["self"],["usize"]],["u64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",31,[[["self"],["usize"]],["u64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",31,[[["self"],["usize"],["u64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",31,[[["self"],["usize"],["u64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",31,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",31,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",31,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",31,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",31,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",31,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",31,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",31,N],[11,"eq","","Lane-wise equality comparison.",31,[[["self"],["u64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",31,[[["self"],["u64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",31,[[["self"],["u64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",31,[[["self"],["u64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",31,[[["self"],["u64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",31,[[["self"],["u64x4"]],["m64x4"]]],[11,"hash","","",31,[[["self"],["h"]]]],[11,"add","","",31,[[["self"],["self"]],["self"]]],[11,"sub","","",31,[[["self"],["self"]],["self"]]],[11,"mul","","",31,[[["self"],["self"]],["self"]]],[11,"div","","",31,[[["self"],["self"]],["self"]]],[11,"rem","","",31,[[["self"],["self"]],["self"]]],[11,"add_assign","","",31,[[["self"],["self"]]]],[11,"sub_assign","","",31,[[["self"],["self"]]]],[11,"mul_assign","","",31,[[["self"],["self"]]]],[11,"div_assign","","",31,[[["self"],["self"]]]],[11,"rem_assign","","",31,[[["self"],["self"]]]],[11,"add","","",31,[[["self"],["u64"]],["self"]]],[11,"sub","","",31,[[["self"],["u64"]],["self"]]],[11,"mul","","",31,[[["self"],["u64"]],["self"]]],[11,"div","","",31,[[["self"],["u64"]],["self"]]],[11,"rem","","",31,[[["self"],["u64"]],["self"]]],[11,"add_assign","","",31,[[["self"],["u64"]]]],[11,"sub_assign","","",31,[[["self"],["u64"]]]],[11,"mul_assign","","",31,[[["self"],["u64"]]]],[11,"div_assign","","",31,[[["self"],["u64"]]]],[11,"rem_assign","","",31,[[["self"],["u64"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",31,[[["self"]],["u64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",31,[[["self"]],["u64"]]],[11,"max_element","","Largest vector element value.",31,[[["self"]],["u64"]]],[11,"min_element","","Smallest vector element value.",31,[[["self"]],["u64"]]],[11,"bitxor","","",31,[[["self"],["u64"]],["self"]]],[11,"bitand","","",31,[[["self"],["u64"]],["self"]]],[11,"bitor","","",31,[[["self"],["u64"]],["self"]]],[11,"bitand_assign","","",31,[[["self"],["u64"]]]],[11,"bitor_assign","","",31,[[["self"],["u64"]]]],[11,"bitxor_assign","","",31,[[["self"],["u64"]]]],[11,"not","","",31,[[["self"]],["self"]]],[11,"bitxor","","",31,[[["self"],["self"]],["self"]]],[11,"bitand","","",31,[[["self"],["self"]],["self"]]],[11,"bitor","","",31,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",31,[[["self"],["self"]]]],[11,"bitor_assign","","",31,[[["self"],["self"]]]],[11,"bitxor_assign","","",31,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",31,[[["self"]],["u64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",31,[[["self"]],["u64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",31,[[["self"]],["u64"]]],[11,"shl","","",31,[[["self"],["u8"]],["self"]]],[11,"shr","","",31,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["u8"]]]],[11,"shr_assign","","",31,[[["self"],["u8"]]]],[11,"shl","","",31,[[["self"],["u16"]],["self"]]],[11,"shr","","",31,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["u16"]]]],[11,"shr_assign","","",31,[[["self"],["u16"]]]],[11,"shl","","",31,[[["self"],["u32"]],["self"]]],[11,"shr","","",31,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["u32"]]]],[11,"shr_assign","","",31,[[["self"],["u32"]]]],[11,"shl","","",31,[[["self"],["u64"]],["self"]]],[11,"shr","","",31,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["u64"]]]],[11,"shr_assign","","",31,[[["self"],["u64"]]]],[11,"shl","","",31,[[["self"],["usize"]],["self"]]],[11,"shr","","",31,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["usize"]]]],[11,"shr_assign","","",31,[[["self"],["usize"]]]],[11,"shl","","",31,[[["self"],["i8"]],["self"]]],[11,"shr","","",31,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["i8"]]]],[11,"shr_assign","","",31,[[["self"],["i8"]]]],[11,"shl","","",31,[[["self"],["i16"]],["self"]]],[11,"shr","","",31,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["i16"]]]],[11,"shr_assign","","",31,[[["self"],["i16"]]]],[11,"shl","","",31,[[["self"],["i32"]],["self"]]],[11,"shr","","",31,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["i32"]]]],[11,"shr_assign","","",31,[[["self"],["i32"]]]],[11,"shl","","",31,[[["self"],["i64"]],["self"]]],[11,"shr","","",31,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["i64"]]]],[11,"shr_assign","","",31,[[["self"],["i64"]]]],[11,"shl","","",31,[[["self"],["isize"]],["self"]]],[11,"shr","","",31,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["isize"]]]],[11,"shr_assign","","",31,[[["self"],["isize"]]]],[11,"shl","","",31,[[["self"],["self"]],["self"]]],[11,"shr","","",31,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",31,[[["self"],["self"]]]],[11,"shr_assign","","",31,[[["self"],["self"]]]],[11,"fmt","","",31,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",31,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",31,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",31,[[["self"],["formatter"]],["result"]]],[11,"eq","","",31,[[["self"],["self"]],["bool"]]],[11,"ne","","",31,[[["self"],["self"]],["bool"]]],[11,"default","","",31,[[],["self"]]],[11,"min","","Minimum of two vectors.",31,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",31,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",31,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",31,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",31,[[["self"]],["self"]]],[11,"clone","","",32,[[["self"]],["f64x4"]]],[11,"fmt","","",32,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",32,[[["self"],["f64x4"]],["option",["ordering"]]]],[11,"lt","","",32,[[["self"],["f64x4"]],["bool"]]],[11,"le","","",32,[[["self"],["f64x4"]],["bool"]]],[11,"gt","","",32,[[["self"],["f64x4"]],["bool"]]],[11,"ge","","",32,[[["self"],["f64x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",32,[[["f64"],["f64"],["f64"],["f64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",32,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",32,[[["f64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",32,[[["self"],["usize"]],["f64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",32,[[["self"],["usize"]],["f64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",32,[[["self"],["usize"],["f64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",32,[[["self"],["usize"],["f64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",32,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",32,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",32,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",32,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",32,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",32,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",32,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",32,N],[11,"eq","","Lane-wise equality comparison.",32,[[["self"],["f64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",32,[[["self"],["f64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",32,[[["self"],["f64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",32,[[["self"],["f64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",32,[[["self"],["f64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",32,[[["self"],["f64x4"]],["m64x4"]]],[11,"add","","",32,[[["self"],["self"]],["self"]]],[11,"sub","","",32,[[["self"],["self"]],["self"]]],[11,"mul","","",32,[[["self"],["self"]],["self"]]],[11,"div","","",32,[[["self"],["self"]],["self"]]],[11,"rem","","",32,[[["self"],["self"]],["self"]]],[11,"add_assign","","",32,[[["self"],["self"]]]],[11,"sub_assign","","",32,[[["self"],["self"]]]],[11,"mul_assign","","",32,[[["self"],["self"]]]],[11,"div_assign","","",32,[[["self"],["self"]]]],[11,"rem_assign","","",32,[[["self"],["self"]]]],[11,"add","","",32,[[["self"],["f64"]],["self"]]],[11,"sub","","",32,[[["self"],["f64"]],["self"]]],[11,"mul","","",32,[[["self"],["f64"]],["self"]]],[11,"div","","",32,[[["self"],["f64"]],["self"]]],[11,"rem","","",32,[[["self"],["f64"]],["self"]]],[11,"add_assign","","",32,[[["self"],["f64"]]]],[11,"sub_assign","","",32,[[["self"],["f64"]]]],[11,"mul_assign","","",32,[[["self"],["f64"]]]],[11,"div_assign","","",32,[[["self"],["f64"]]]],[11,"rem_assign","","",32,[[["self"],["f64"]]]],[11,"sum","","Horizontal sum of the vector elements.",32,[[["self"]],["f64"]]],[11,"product","","Horizontal product of the vector elements.",32,[[["self"]],["f64"]]],[11,"max_element","","Largest vector element value.",32,[[["self"]],["f64"]]],[11,"min_element","","Smallest vector element value.",32,[[["self"]],["f64"]]],[11,"neg","","",32,[[["self"]],["self"]]],[11,"eq","","",32,[[["self"],["self"]],["bool"]]],[11,"ne","","",32,[[["self"],["self"]],["bool"]]],[11,"default","","",32,[[],["self"]]],[11,"min","","Minimum of two vectors.",32,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",32,[[["self"],["self"]],["self"]]],[11,"abs","","Absolute-value",32,[[["self"]],["self"]]],[11,"sqrt","","Square-root",32,[[["self"]],["self"]]],[11,"sqrte","","Square-root estimate",32,[[["self"]],["self"]]],[11,"rsqrte","","Reciprocal square-root estimate",32,[[["self"]],["self"]]],[11,"fma","","Fused multiply add: `self * y + z`",32,[[["self"],["self"],["self"]],["self"]]],[11,"sin","","Sin",32,[[["self"]],["self"]]],[11,"cos","","Cos",32,[[["self"]],["self"]]],[11,"clone","","",33,[[["self"]],["m64x4"]]],[11,"fmt","","",33,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",33,[[["self"],["m64x4"]],["option",["ordering"]]]],[11,"lt","","",33,[[["self"],["m64x4"]],["bool"]]],[11,"le","","",33,[[["self"],["m64x4"]],["bool"]]],[11,"gt","","",33,[[["self"],["m64x4"]],["bool"]]],[11,"ge","","",33,[[["self"],["m64x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",33,[[["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",33,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",33,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",33,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",33,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",33,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",33,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",33,[[["self"]],["self"]]],[11,"bitxor","","",33,[[["self"],["self"]],["self"]]],[11,"bitand","","",33,[[["self"],["self"]],["self"]]],[11,"bitor","","",33,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",33,[[["self"],["self"]]]],[11,"bitor_assign","","",33,[[["self"],["self"]]]],[11,"bitxor_assign","","",33,[[["self"],["self"]]]],[11,"bitxor","","",33,[[["self"],["bool"]],["self"]]],[11,"bitand","","",33,[[["self"],["bool"]],["self"]]],[11,"bitor","","",33,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",33,[[["self"],["bool"]]]],[11,"bitor_assign","","",33,[[["self"],["bool"]]]],[11,"bitxor_assign","","",33,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",33,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",33,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",33,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",33,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",33,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",33,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",33,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",33,[[["self"],["m64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",33,[[["self"],["m64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",33,[[["self"],["m64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",33,[[["self"],["m64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",33,[[["self"],["m64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",33,[[["self"],["m64x4"]],["m64x4"]]],[11,"eq","","",33,[[["self"],["self"]],["bool"]]],[11,"ne","","",33,[[["self"],["self"]],["bool"]]],[11,"default","","",33,[[],["self"]]],[11,"from_bits","","",20,[[["u64x4"]],["i8x32"]]],[11,"from_bits","","",20,[[["i64x4"]],["i8x32"]]],[11,"from_bits","","",20,[[["f64x4"]],["i8x32"]]],[11,"from_bits","","",20,[[["m64x4"]],["i8x32"]]],[11,"from_bits","","",20,[[["u32x8"]],["i8x32"]]],[11,"from_bits","","",20,[[["i32x8"]],["i8x32"]]],[11,"from_bits","","",20,[[["f32x8"]],["i8x32"]]],[11,"from_bits","","",20,[[["m32x8"]],["i8x32"]]],[11,"from_bits","","",20,[[["u16x16"]],["i8x32"]]],[11,"from_bits","","",20,[[["i16x16"]],["i8x32"]]],[11,"from_bits","","",20,[[["m16x16"]],["i8x32"]]],[11,"from_bits","","",20,[[["u8x32"]],["i8x32"]]],[11,"from_bits","","",20,[[["m8x32"]],["i8x32"]]],[11,"from_bits","","",20,[[["__m256"]],["i8x32"]]],[11,"from_bits","","",20,[[["__m256i"]],["i8x32"]]],[11,"from_bits","","",20,[[["__m256d"]],["i8x32"]]],[11,"from_bits","","",21,[[["u64x4"]],["u8x32"]]],[11,"from_bits","","",21,[[["i64x4"]],["u8x32"]]],[11,"from_bits","","",21,[[["f64x4"]],["u8x32"]]],[11,"from_bits","","",21,[[["m64x4"]],["u8x32"]]],[11,"from_bits","","",21,[[["u32x8"]],["u8x32"]]],[11,"from_bits","","",21,[[["i32x8"]],["u8x32"]]],[11,"from_bits","","",21,[[["f32x8"]],["u8x32"]]],[11,"from_bits","","",21,[[["m32x8"]],["u8x32"]]],[11,"from_bits","","",21,[[["u16x16"]],["u8x32"]]],[11,"from_bits","","",21,[[["i16x16"]],["u8x32"]]],[11,"from_bits","","",21,[[["m16x16"]],["u8x32"]]],[11,"from_bits","","",21,[[["i8x32"]],["u8x32"]]],[11,"from_bits","","",21,[[["m8x32"]],["u8x32"]]],[11,"from_bits","","",21,[[["__m256"]],["u8x32"]]],[11,"from_bits","","",21,[[["__m256i"]],["u8x32"]]],[11,"from_bits","","",21,[[["__m256d"]],["u8x32"]]],[11,"from_bits","","",23,[[["u64x4"]],["i16x16"]]],[11,"from_bits","","",23,[[["i64x4"]],["i16x16"]]],[11,"from_bits","","",23,[[["f64x4"]],["i16x16"]]],[11,"from_bits","","",23,[[["m64x4"]],["i16x16"]]],[11,"from_bits","","",23,[[["u32x8"]],["i16x16"]]],[11,"from_bits","","",23,[[["i32x8"]],["i16x16"]]],[11,"from_bits","","",23,[[["f32x8"]],["i16x16"]]],[11,"from_bits","","",23,[[["m32x8"]],["i16x16"]]],[11,"from_bits","","",23,[[["u16x16"]],["i16x16"]]],[11,"from_bits","","",23,[[["m16x16"]],["i16x16"]]],[11,"from_bits","","",23,[[["u8x32"]],["i16x16"]]],[11,"from_bits","","",23,[[["i8x32"]],["i16x16"]]],[11,"from_bits","","",23,[[["m8x32"]],["i16x16"]]],[11,"from_bits","","",23,[[["__m256"]],["i16x16"]]],[11,"from_bits","","",23,[[["__m256i"]],["i16x16"]]],[11,"from_bits","","",23,[[["__m256d"]],["i16x16"]]],[11,"from_bits","","",24,[[["u64x4"]],["u16x16"]]],[11,"from_bits","","",24,[[["i64x4"]],["u16x16"]]],[11,"from_bits","","",24,[[["f64x4"]],["u16x16"]]],[11,"from_bits","","",24,[[["m64x4"]],["u16x16"]]],[11,"from_bits","","",24,[[["u32x8"]],["u16x16"]]],[11,"from_bits","","",24,[[["i32x8"]],["u16x16"]]],[11,"from_bits","","",24,[[["f32x8"]],["u16x16"]]],[11,"from_bits","","",24,[[["m32x8"]],["u16x16"]]],[11,"from_bits","","",24,[[["i16x16"]],["u16x16"]]],[11,"from_bits","","",24,[[["m16x16"]],["u16x16"]]],[11,"from_bits","","",24,[[["u8x32"]],["u16x16"]]],[11,"from_bits","","",24,[[["i8x32"]],["u16x16"]]],[11,"from_bits","","",24,[[["m8x32"]],["u16x16"]]],[11,"from_bits","","",24,[[["__m256"]],["u16x16"]]],[11,"from_bits","","",24,[[["__m256i"]],["u16x16"]]],[11,"from_bits","","",24,[[["__m256d"]],["u16x16"]]],[11,"from_bits","","",26,[[["u64x4"]],["i32x8"]]],[11,"from_bits","","",26,[[["i64x4"]],["i32x8"]]],[11,"from_bits","","",26,[[["f64x4"]],["i32x8"]]],[11,"from_bits","","",26,[[["m64x4"]],["i32x8"]]],[11,"from_bits","","",26,[[["u32x8"]],["i32x8"]]],[11,"from_bits","","",26,[[["f32x8"]],["i32x8"]]],[11,"from_bits","","",26,[[["m32x8"]],["i32x8"]]],[11,"from_bits","","",26,[[["u16x16"]],["i32x8"]]],[11,"from_bits","","",26,[[["i16x16"]],["i32x8"]]],[11,"from_bits","","",26,[[["m16x16"]],["i32x8"]]],[11,"from_bits","","",26,[[["u8x32"]],["i32x8"]]],[11,"from_bits","","",26,[[["i8x32"]],["i32x8"]]],[11,"from_bits","","",26,[[["m8x32"]],["i32x8"]]],[11,"from_bits","","",26,[[["__m256"]],["i32x8"]]],[11,"from_bits","","",26,[[["__m256i"]],["i32x8"]]],[11,"from_bits","","",26,[[["__m256d"]],["i32x8"]]],[11,"from_bits","","",27,[[["u64x4"]],["u32x8"]]],[11,"from_bits","","",27,[[["i64x4"]],["u32x8"]]],[11,"from_bits","","",27,[[["f64x4"]],["u32x8"]]],[11,"from_bits","","",27,[[["m64x4"]],["u32x8"]]],[11,"from_bits","","",27,[[["i32x8"]],["u32x8"]]],[11,"from_bits","","",27,[[["f32x8"]],["u32x8"]]],[11,"from_bits","","",27,[[["m32x8"]],["u32x8"]]],[11,"from_bits","","",27,[[["u16x16"]],["u32x8"]]],[11,"from_bits","","",27,[[["i16x16"]],["u32x8"]]],[11,"from_bits","","",27,[[["m16x16"]],["u32x8"]]],[11,"from_bits","","",27,[[["u8x32"]],["u32x8"]]],[11,"from_bits","","",27,[[["i8x32"]],["u32x8"]]],[11,"from_bits","","",27,[[["m8x32"]],["u32x8"]]],[11,"from_bits","","",27,[[["__m256"]],["u32x8"]]],[11,"from_bits","","",27,[[["__m256i"]],["u32x8"]]],[11,"from_bits","","",27,[[["__m256d"]],["u32x8"]]],[11,"from_bits","","",28,[[["u64x4"]],["f32x8"]]],[11,"from_bits","","",28,[[["i64x4"]],["f32x8"]]],[11,"from_bits","","",28,[[["f64x4"]],["f32x8"]]],[11,"from_bits","","",28,[[["m64x4"]],["f32x8"]]],[11,"from_bits","","",28,[[["i32x8"]],["f32x8"]]],[11,"from_bits","","",28,[[["u32x8"]],["f32x8"]]],[11,"from_bits","","",28,[[["m32x8"]],["f32x8"]]],[11,"from_bits","","",28,[[["u16x16"]],["f32x8"]]],[11,"from_bits","","",28,[[["i16x16"]],["f32x8"]]],[11,"from_bits","","",28,[[["m16x16"]],["f32x8"]]],[11,"from_bits","","",28,[[["u8x32"]],["f32x8"]]],[11,"from_bits","","",28,[[["i8x32"]],["f32x8"]]],[11,"from_bits","","",28,[[["m8x32"]],["f32x8"]]],[11,"from_bits","","",28,[[["__m256"]],["f32x8"]]],[11,"from_bits","","",28,[[["__m256i"]],["f32x8"]]],[11,"from_bits","","",28,[[["__m256d"]],["f32x8"]]],[11,"from_bits","","",30,[[["u64x4"]],["i64x4"]]],[11,"from_bits","","",30,[[["f64x4"]],["i64x4"]]],[11,"from_bits","","",30,[[["m64x4"]],["i64x4"]]],[11,"from_bits","","",30,[[["i32x8"]],["i64x4"]]],[11,"from_bits","","",30,[[["u32x8"]],["i64x4"]]],[11,"from_bits","","",30,[[["f32x8"]],["i64x4"]]],[11,"from_bits","","",30,[[["m32x8"]],["i64x4"]]],[11,"from_bits","","",30,[[["u16x16"]],["i64x4"]]],[11,"from_bits","","",30,[[["i16x16"]],["i64x4"]]],[11,"from_bits","","",30,[[["m16x16"]],["i64x4"]]],[11,"from_bits","","",30,[[["u8x32"]],["i64x4"]]],[11,"from_bits","","",30,[[["i8x32"]],["i64x4"]]],[11,"from_bits","","",30,[[["m8x32"]],["i64x4"]]],[11,"from_bits","","",30,[[["__m256"]],["i64x4"]]],[11,"from_bits","","",30,[[["__m256i"]],["i64x4"]]],[11,"from_bits","","",30,[[["__m256d"]],["i64x4"]]],[11,"from_bits","","",31,[[["i64x4"]],["u64x4"]]],[11,"from_bits","","",31,[[["f64x4"]],["u64x4"]]],[11,"from_bits","","",31,[[["m64x4"]],["u64x4"]]],[11,"from_bits","","",31,[[["i32x8"]],["u64x4"]]],[11,"from_bits","","",31,[[["u32x8"]],["u64x4"]]],[11,"from_bits","","",31,[[["f32x8"]],["u64x4"]]],[11,"from_bits","","",31,[[["m32x8"]],["u64x4"]]],[11,"from_bits","","",31,[[["u16x16"]],["u64x4"]]],[11,"from_bits","","",31,[[["i16x16"]],["u64x4"]]],[11,"from_bits","","",31,[[["m16x16"]],["u64x4"]]],[11,"from_bits","","",31,[[["u8x32"]],["u64x4"]]],[11,"from_bits","","",31,[[["i8x32"]],["u64x4"]]],[11,"from_bits","","",31,[[["m8x32"]],["u64x4"]]],[11,"from_bits","","",31,[[["__m256"]],["u64x4"]]],[11,"from_bits","","",31,[[["__m256i"]],["u64x4"]]],[11,"from_bits","","",31,[[["__m256d"]],["u64x4"]]],[11,"from_bits","","",32,[[["i64x4"]],["f64x4"]]],[11,"from_bits","","",32,[[["u64x4"]],["f64x4"]]],[11,"from_bits","","",32,[[["m64x4"]],["f64x4"]]],[11,"from_bits","","",32,[[["i32x8"]],["f64x4"]]],[11,"from_bits","","",32,[[["u32x8"]],["f64x4"]]],[11,"from_bits","","",32,[[["f32x8"]],["f64x4"]]],[11,"from_bits","","",32,[[["m32x8"]],["f64x4"]]],[11,"from_bits","","",32,[[["u16x16"]],["f64x4"]]],[11,"from_bits","","",32,[[["i16x16"]],["f64x4"]]],[11,"from_bits","","",32,[[["m16x16"]],["f64x4"]]],[11,"from_bits","","",32,[[["u8x32"]],["f64x4"]]],[11,"from_bits","","",32,[[["i8x32"]],["f64x4"]]],[11,"from_bits","","",32,[[["m8x32"]],["f64x4"]]],[11,"from_bits","","",32,[[["__m256"]],["f64x4"]]],[11,"from_bits","","",32,[[["__m256i"]],["f64x4"]]],[11,"from_bits","","",32,[[["__m256d"]],["f64x4"]]],[11,"from","","",32,[[["u64x4"]],["f64x4"]]],[11,"from","","",32,[[["i64x4"]],["f64x4"]]],[11,"from","","",32,[[["m64x4"]],["f64x4"]]],[11,"from","","",32,[[["u32x4"]],["f64x4"]]],[11,"from","","",32,[[["i32x4"]],["f64x4"]]],[11,"from","","",32,[[["f32x4"]],["f64x4"]]],[11,"from","","",32,[[["m32x4"]],["f64x4"]]],[11,"from","","",32,[[["u16x4"]],["f64x4"]]],[11,"from","","",32,[[["i16x4"]],["f64x4"]]],[11,"from","","",32,[[["m16x4"]],["f64x4"]]],[11,"from","","",32,[[["u8x4"]],["f64x4"]]],[11,"from","","",32,[[["i8x4"]],["f64x4"]]],[11,"from","","",32,[[["m8x4"]],["f64x4"]]],[11,"from","","",30,[[["u64x4"]],["i64x4"]]],[11,"from","","",30,[[["f64x4"]],["i64x4"]]],[11,"from","","",30,[[["m64x4"]],["i64x4"]]],[11,"from","","",30,[[["u32x4"]],["i64x4"]]],[11,"from","","",30,[[["i32x4"]],["i64x4"]]],[11,"from","","",30,[[["f32x4"]],["i64x4"]]],[11,"from","","",30,[[["m32x4"]],["i64x4"]]],[11,"from","","",30,[[["u16x4"]],["i64x4"]]],[11,"from","","",30,[[["i16x4"]],["i64x4"]]],[11,"from","","",30,[[["m16x4"]],["i64x4"]]],[11,"from","","",30,[[["u8x4"]],["i64x4"]]],[11,"from","","",30,[[["i8x4"]],["i64x4"]]],[11,"from","","",30,[[["m8x4"]],["i64x4"]]],[11,"from","","",31,[[["i64x4"]],["u64x4"]]],[11,"from","","",31,[[["f64x4"]],["u64x4"]]],[11,"from","","",31,[[["m64x4"]],["u64x4"]]],[11,"from","","",31,[[["u32x4"]],["u64x4"]]],[11,"from","","",31,[[["i32x4"]],["u64x4"]]],[11,"from","","",31,[[["f32x4"]],["u64x4"]]],[11,"from","","",31,[[["m32x4"]],["u64x4"]]],[11,"from","","",31,[[["u16x4"]],["u64x4"]]],[11,"from","","",31,[[["i16x4"]],["u64x4"]]],[11,"from","","",31,[[["m16x4"]],["u64x4"]]],[11,"from","","",31,[[["u8x4"]],["u64x4"]]],[11,"from","","",31,[[["i8x4"]],["u64x4"]]],[11,"from","","",31,[[["m8x4"]],["u64x4"]]],[11,"from","","",28,[[["u64x8"]],["f32x8"]]],[11,"from","","",28,[[["i64x8"]],["f32x8"]]],[11,"from","","",28,[[["f64x8"]],["f32x8"]]],[11,"from","","",28,[[["m1x8"]],["f32x8"]]],[11,"from","","",28,[[["u32x8"]],["f32x8"]]],[11,"from","","",28,[[["i32x8"]],["f32x8"]]],[11,"from","","",28,[[["m32x8"]],["f32x8"]]],[11,"from","","",28,[[["u16x8"]],["f32x8"]]],[11,"from","","",28,[[["i16x8"]],["f32x8"]]],[11,"from","","",28,[[["m16x8"]],["f32x8"]]],[11,"from","","",28,[[["u8x8"]],["f32x8"]]],[11,"from","","",28,[[["i8x8"]],["f32x8"]]],[11,"from","","",28,[[["m8x8"]],["f32x8"]]],[11,"from","","",26,[[["u64x8"]],["i32x8"]]],[11,"from","","",26,[[["i64x8"]],["i32x8"]]],[11,"from","","",26,[[["f64x8"]],["i32x8"]]],[11,"from","","",26,[[["m1x8"]],["i32x8"]]],[11,"from","","",26,[[["u32x8"]],["i32x8"]]],[11,"from","","",26,[[["f32x8"]],["i32x8"]]],[11,"from","","",26,[[["m32x8"]],["i32x8"]]],[11,"from","","",26,[[["u16x8"]],["i32x8"]]],[11,"from","","",26,[[["i16x8"]],["i32x8"]]],[11,"from","","",26,[[["m16x8"]],["i32x8"]]],[11,"from","","",26,[[["u8x8"]],["i32x8"]]],[11,"from","","",26,[[["i8x8"]],["i32x8"]]],[11,"from","","",26,[[["m8x8"]],["i32x8"]]],[11,"from","","",27,[[["u64x8"]],["u32x8"]]],[11,"from","","",27,[[["i64x8"]],["u32x8"]]],[11,"from","","",27,[[["f64x8"]],["u32x8"]]],[11,"from","","",27,[[["m1x8"]],["u32x8"]]],[11,"from","","",27,[[["i32x8"]],["u32x8"]]],[11,"from","","",27,[[["f32x8"]],["u32x8"]]],[11,"from","","",27,[[["m32x8"]],["u32x8"]]],[11,"from","","",27,[[["u16x8"]],["u32x8"]]],[11,"from","","",27,[[["i16x8"]],["u32x8"]]],[11,"from","","",27,[[["m16x8"]],["u32x8"]]],[11,"from","","",27,[[["u8x8"]],["u32x8"]]],[11,"from","","",27,[[["i8x8"]],["u32x8"]]],[11,"from","","",27,[[["m8x8"]],["u32x8"]]],[11,"from","","",23,[[["u32x16"]],["i16x16"]]],[11,"from","","",23,[[["i32x16"]],["i16x16"]]],[11,"from","","",23,[[["f32x16"]],["i16x16"]]],[11,"from","","",23,[[["m1x16"]],["i16x16"]]],[11,"from","","",23,[[["u16x16"]],["i16x16"]]],[11,"from","","",23,[[["m16x16"]],["i16x16"]]],[11,"from","","",23,[[["u8x16"]],["i16x16"]]],[11,"from","","",23,[[["i8x16"]],["i16x16"]]],[11,"from","","",23,[[["m8x16"]],["i16x16"]]],[11,"from","","",24,[[["u32x16"]],["u16x16"]]],[11,"from","","",24,[[["i32x16"]],["u16x16"]]],[11,"from","","",24,[[["f32x16"]],["u16x16"]]],[11,"from","","",24,[[["m1x16"]],["u16x16"]]],[11,"from","","",24,[[["i16x16"]],["u16x16"]]],[11,"from","","",24,[[["m16x16"]],["u16x16"]]],[11,"from","","",24,[[["u8x16"]],["u16x16"]]],[11,"from","","",24,[[["i8x16"]],["u16x16"]]],[11,"from","","",24,[[["m8x16"]],["u16x16"]]],[11,"from","","",20,[[["u16x32"]],["i8x32"]]],[11,"from","","",20,[[["i16x32"]],["i8x32"]]],[11,"from","","",20,[[["u8x32"]],["i8x32"]]],[11,"from","","",20,[[["m8x32"]],["i8x32"]]],[11,"from","","",21,[[["u16x32"]],["u8x32"]]],[11,"from","","",21,[[["i16x32"]],["u8x32"]]],[11,"from","","",21,[[["i8x32"]],["u8x32"]]],[11,"from","","",21,[[["m8x32"]],["u8x32"]]],[11,"from","","",22,[[["m1x32"]],["m8x32"]]],[11,"from","","",25,[[["m1x16"]],["m16x16"]]],[11,"from","","",25,[[["m8x16"]],["m16x16"]]],[11,"from","","",29,[[["m1x8"]],["m32x8"]]],[11,"from","","",29,[[["m16x8"]],["m32x8"]]],[11,"from","","",29,[[["m8x8"]],["m32x8"]]],[11,"from","","",33,[[["m32x4"]],["m64x4"]]],[11,"from","","",33,[[["m16x4"]],["m64x4"]]],[11,"from","","",33,[[["m8x4"]],["m64x4"]]],[11,"clone","","",34,[[["self"]],["i16x2"]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",34,[[["self"],["i16x2"]],["option",["ordering"]]]],[11,"lt","","",34,[[["self"],["i16x2"]],["bool"]]],[11,"le","","",34,[[["self"],["i16x2"]],["bool"]]],[11,"gt","","",34,[[["self"],["i16x2"]],["bool"]]],[11,"ge","","",34,[[["self"],["i16x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",34,[[["i16"],["i16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",34,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",34,[[["i16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",34,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",34,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",34,[[["self"],["usize"],["i16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",34,[[["self"],["usize"],["i16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",34,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",34,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",34,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",34,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"eq","","Lane-wise equality comparison.",34,[[["self"],["i16x2"]],["m16x2"]]],[11,"ne","","Lane-wise inequality comparison.",34,[[["self"],["i16x2"]],["m16x2"]]],[11,"lt","","Lane-wise less-than comparison.",34,[[["self"],["i16x2"]],["m16x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",34,[[["self"],["i16x2"]],["m16x2"]]],[11,"gt","","Lane-wise greater-than comparison.",34,[[["self"],["i16x2"]],["m16x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",34,[[["self"],["i16x2"]],["m16x2"]]],[11,"hash","","",34,[[["self"],["h"]]]],[11,"add","","",34,[[["self"],["self"]],["self"]]],[11,"sub","","",34,[[["self"],["self"]],["self"]]],[11,"mul","","",34,[[["self"],["self"]],["self"]]],[11,"div","","",34,[[["self"],["self"]],["self"]]],[11,"rem","","",34,[[["self"],["self"]],["self"]]],[11,"add_assign","","",34,[[["self"],["self"]]]],[11,"sub_assign","","",34,[[["self"],["self"]]]],[11,"mul_assign","","",34,[[["self"],["self"]]]],[11,"div_assign","","",34,[[["self"],["self"]]]],[11,"rem_assign","","",34,[[["self"],["self"]]]],[11,"add","","",34,[[["self"],["i16"]],["self"]]],[11,"sub","","",34,[[["self"],["i16"]],["self"]]],[11,"mul","","",34,[[["self"],["i16"]],["self"]]],[11,"div","","",34,[[["self"],["i16"]],["self"]]],[11,"rem","","",34,[[["self"],["i16"]],["self"]]],[11,"add_assign","","",34,[[["self"],["i16"]]]],[11,"sub_assign","","",34,[[["self"],["i16"]]]],[11,"mul_assign","","",34,[[["self"],["i16"]]]],[11,"div_assign","","",34,[[["self"],["i16"]]]],[11,"rem_assign","","",34,[[["self"],["i16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",34,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",34,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",34,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",34,[[["self"]],["i16"]]],[11,"neg","","",34,[[["self"]],["self"]]],[11,"not","","",34,[[["self"]],["self"]]],[11,"bitxor","","",34,[[["self"],["self"]],["self"]]],[11,"bitand","","",34,[[["self"],["self"]],["self"]]],[11,"bitor","","",34,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",34,[[["self"],["self"]]]],[11,"bitor_assign","","",34,[[["self"],["self"]]]],[11,"bitxor_assign","","",34,[[["self"],["self"]]]],[11,"bitxor","","",34,[[["self"],["i16"]],["self"]]],[11,"bitand","","",34,[[["self"],["i16"]],["self"]]],[11,"bitor","","",34,[[["self"],["i16"]],["self"]]],[11,"bitand_assign","","",34,[[["self"],["i16"]]]],[11,"bitor_assign","","",34,[[["self"],["i16"]]]],[11,"bitxor_assign","","",34,[[["self"],["i16"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",34,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",34,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",34,[[["self"]],["i16"]]],[11,"shl","","",34,[[["self"],["u8"]],["self"]]],[11,"shr","","",34,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["u8"]]]],[11,"shr_assign","","",34,[[["self"],["u8"]]]],[11,"shl","","",34,[[["self"],["u16"]],["self"]]],[11,"shr","","",34,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["u16"]]]],[11,"shr_assign","","",34,[[["self"],["u16"]]]],[11,"shl","","",34,[[["self"],["u32"]],["self"]]],[11,"shr","","",34,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["u32"]]]],[11,"shr_assign","","",34,[[["self"],["u32"]]]],[11,"shl","","",34,[[["self"],["u64"]],["self"]]],[11,"shr","","",34,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["u64"]]]],[11,"shr_assign","","",34,[[["self"],["u64"]]]],[11,"shl","","",34,[[["self"],["usize"]],["self"]]],[11,"shr","","",34,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["usize"]]]],[11,"shr_assign","","",34,[[["self"],["usize"]]]],[11,"shl","","",34,[[["self"],["i8"]],["self"]]],[11,"shr","","",34,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["i8"]]]],[11,"shr_assign","","",34,[[["self"],["i8"]]]],[11,"shl","","",34,[[["self"],["i16"]],["self"]]],[11,"shr","","",34,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["i16"]]]],[11,"shr_assign","","",34,[[["self"],["i16"]]]],[11,"shl","","",34,[[["self"],["i32"]],["self"]]],[11,"shr","","",34,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["i32"]]]],[11,"shr_assign","","",34,[[["self"],["i32"]]]],[11,"shl","","",34,[[["self"],["i64"]],["self"]]],[11,"shr","","",34,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["i64"]]]],[11,"shr_assign","","",34,[[["self"],["i64"]]]],[11,"shl","","",34,[[["self"],["isize"]],["self"]]],[11,"shr","","",34,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["isize"]]]],[11,"shr_assign","","",34,[[["self"],["isize"]]]],[11,"shl","","",34,[[["self"],["self"]],["self"]]],[11,"shr","","",34,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",34,[[["self"],["self"]]]],[11,"shr_assign","","",34,[[["self"],["self"]]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result"]]],[11,"eq","","",34,[[["self"],["self"]],["bool"]]],[11,"ne","","",34,[[["self"],["self"]],["bool"]]],[11,"default","","",34,[[],["self"]]],[11,"min","","Minimum of two vectors.",34,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",34,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",34,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",34,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",34,[[["self"]],["self"]]],[11,"clone","","",35,[[["self"]],["u16x2"]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",35,[[["self"],["u16x2"]],["option",["ordering"]]]],[11,"lt","","",35,[[["self"],["u16x2"]],["bool"]]],[11,"le","","",35,[[["self"],["u16x2"]],["bool"]]],[11,"gt","","",35,[[["self"],["u16x2"]],["bool"]]],[11,"ge","","",35,[[["self"],["u16x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",35,[[["u16"],["u16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",35,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",35,[[["u16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",35,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",35,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",35,[[["self"],["usize"],["u16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",35,[[["self"],["usize"],["u16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",35,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",35,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",35,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",35,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"eq","","Lane-wise equality comparison.",35,[[["self"],["u16x2"]],["m16x2"]]],[11,"ne","","Lane-wise inequality comparison.",35,[[["self"],["u16x2"]],["m16x2"]]],[11,"lt","","Lane-wise less-than comparison.",35,[[["self"],["u16x2"]],["m16x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",35,[[["self"],["u16x2"]],["m16x2"]]],[11,"gt","","Lane-wise greater-than comparison.",35,[[["self"],["u16x2"]],["m16x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",35,[[["self"],["u16x2"]],["m16x2"]]],[11,"hash","","",35,[[["self"],["h"]]]],[11,"add","","",35,[[["self"],["self"]],["self"]]],[11,"sub","","",35,[[["self"],["self"]],["self"]]],[11,"mul","","",35,[[["self"],["self"]],["self"]]],[11,"div","","",35,[[["self"],["self"]],["self"]]],[11,"rem","","",35,[[["self"],["self"]],["self"]]],[11,"add_assign","","",35,[[["self"],["self"]]]],[11,"sub_assign","","",35,[[["self"],["self"]]]],[11,"mul_assign","","",35,[[["self"],["self"]]]],[11,"div_assign","","",35,[[["self"],["self"]]]],[11,"rem_assign","","",35,[[["self"],["self"]]]],[11,"add","","",35,[[["self"],["u16"]],["self"]]],[11,"sub","","",35,[[["self"],["u16"]],["self"]]],[11,"mul","","",35,[[["self"],["u16"]],["self"]]],[11,"div","","",35,[[["self"],["u16"]],["self"]]],[11,"rem","","",35,[[["self"],["u16"]],["self"]]],[11,"add_assign","","",35,[[["self"],["u16"]]]],[11,"sub_assign","","",35,[[["self"],["u16"]]]],[11,"mul_assign","","",35,[[["self"],["u16"]]]],[11,"div_assign","","",35,[[["self"],["u16"]]]],[11,"rem_assign","","",35,[[["self"],["u16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",35,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",35,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",35,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",35,[[["self"]],["u16"]]],[11,"bitxor","","",35,[[["self"],["u16"]],["self"]]],[11,"bitand","","",35,[[["self"],["u16"]],["self"]]],[11,"bitor","","",35,[[["self"],["u16"]],["self"]]],[11,"bitand_assign","","",35,[[["self"],["u16"]]]],[11,"bitor_assign","","",35,[[["self"],["u16"]]]],[11,"bitxor_assign","","",35,[[["self"],["u16"]]]],[11,"not","","",35,[[["self"]],["self"]]],[11,"bitxor","","",35,[[["self"],["self"]],["self"]]],[11,"bitand","","",35,[[["self"],["self"]],["self"]]],[11,"bitor","","",35,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",35,[[["self"],["self"]]]],[11,"bitor_assign","","",35,[[["self"],["self"]]]],[11,"bitxor_assign","","",35,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",35,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",35,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",35,[[["self"]],["u16"]]],[11,"shl","","",35,[[["self"],["u8"]],["self"]]],[11,"shr","","",35,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["u8"]]]],[11,"shr_assign","","",35,[[["self"],["u8"]]]],[11,"shl","","",35,[[["self"],["u16"]],["self"]]],[11,"shr","","",35,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["u16"]]]],[11,"shr_assign","","",35,[[["self"],["u16"]]]],[11,"shl","","",35,[[["self"],["u32"]],["self"]]],[11,"shr","","",35,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["u32"]]]],[11,"shr_assign","","",35,[[["self"],["u32"]]]],[11,"shl","","",35,[[["self"],["u64"]],["self"]]],[11,"shr","","",35,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["u64"]]]],[11,"shr_assign","","",35,[[["self"],["u64"]]]],[11,"shl","","",35,[[["self"],["usize"]],["self"]]],[11,"shr","","",35,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["usize"]]]],[11,"shr_assign","","",35,[[["self"],["usize"]]]],[11,"shl","","",35,[[["self"],["i8"]],["self"]]],[11,"shr","","",35,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["i8"]]]],[11,"shr_assign","","",35,[[["self"],["i8"]]]],[11,"shl","","",35,[[["self"],["i16"]],["self"]]],[11,"shr","","",35,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["i16"]]]],[11,"shr_assign","","",35,[[["self"],["i16"]]]],[11,"shl","","",35,[[["self"],["i32"]],["self"]]],[11,"shr","","",35,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["i32"]]]],[11,"shr_assign","","",35,[[["self"],["i32"]]]],[11,"shl","","",35,[[["self"],["i64"]],["self"]]],[11,"shr","","",35,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["i64"]]]],[11,"shr_assign","","",35,[[["self"],["i64"]]]],[11,"shl","","",35,[[["self"],["isize"]],["self"]]],[11,"shr","","",35,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["isize"]]]],[11,"shr_assign","","",35,[[["self"],["isize"]]]],[11,"shl","","",35,[[["self"],["self"]],["self"]]],[11,"shr","","",35,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",35,[[["self"],["self"]]]],[11,"shr_assign","","",35,[[["self"],["self"]]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result"]]],[11,"eq","","",35,[[["self"],["self"]],["bool"]]],[11,"ne","","",35,[[["self"],["self"]],["bool"]]],[11,"default","","",35,[[],["self"]]],[11,"min","","Minimum of two vectors.",35,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",35,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",35,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",35,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",35,[[["self"]],["self"]]],[11,"clone","","",36,[[["self"]],["m16x2"]]],[11,"fmt","","",36,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",36,[[["self"],["m16x2"]],["option",["ordering"]]]],[11,"lt","","",36,[[["self"],["m16x2"]],["bool"]]],[11,"le","","",36,[[["self"],["m16x2"]],["bool"]]],[11,"gt","","",36,[[["self"],["m16x2"]],["bool"]]],[11,"ge","","",36,[[["self"],["m16x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",36,[[["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",36,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",36,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",36,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",36,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",36,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",36,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",36,[[["self"]],["self"]]],[11,"bitxor","","",36,[[["self"],["self"]],["self"]]],[11,"bitand","","",36,[[["self"],["self"]],["self"]]],[11,"bitor","","",36,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",36,[[["self"],["self"]]]],[11,"bitor_assign","","",36,[[["self"],["self"]]]],[11,"bitxor_assign","","",36,[[["self"],["self"]]]],[11,"bitxor","","",36,[[["self"],["bool"]],["self"]]],[11,"bitand","","",36,[[["self"],["bool"]],["self"]]],[11,"bitor","","",36,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",36,[[["self"],["bool"]]]],[11,"bitor_assign","","",36,[[["self"],["bool"]]]],[11,"bitxor_assign","","",36,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",36,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",36,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",36,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",36,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",36,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",36,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",36,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",36,[[["self"],["m16x2"]],["m16x2"]]],[11,"ne","","Lane-wise inequality comparison.",36,[[["self"],["m16x2"]],["m16x2"]]],[11,"lt","","Lane-wise less-than comparison.",36,[[["self"],["m16x2"]],["m16x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",36,[[["self"],["m16x2"]],["m16x2"]]],[11,"gt","","Lane-wise greater-than comparison.",36,[[["self"],["m16x2"]],["m16x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",36,[[["self"],["m16x2"]],["m16x2"]]],[11,"eq","","",36,[[["self"],["self"]],["bool"]]],[11,"ne","","",36,[[["self"],["self"]],["bool"]]],[11,"default","","",36,[[],["self"]]],[11,"clone","","",37,[[["self"]],["i8x4"]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",37,[[["self"],["i8x4"]],["option",["ordering"]]]],[11,"lt","","",37,[[["self"],["i8x4"]],["bool"]]],[11,"le","","",37,[[["self"],["i8x4"]],["bool"]]],[11,"gt","","",37,[[["self"],["i8x4"]],["bool"]]],[11,"ge","","",37,[[["self"],["i8x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",37,[[["i8"],["i8"],["i8"],["i8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",37,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",37,[[["i8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",37,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",37,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",37,[[["self"],["usize"],["i8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",37,[[["self"],["usize"],["i8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",37,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",37,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",37,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",37,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"eq","","Lane-wise equality comparison.",37,[[["self"],["i8x4"]],["m8x4"]]],[11,"ne","","Lane-wise inequality comparison.",37,[[["self"],["i8x4"]],["m8x4"]]],[11,"lt","","Lane-wise less-than comparison.",37,[[["self"],["i8x4"]],["m8x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",37,[[["self"],["i8x4"]],["m8x4"]]],[11,"gt","","Lane-wise greater-than comparison.",37,[[["self"],["i8x4"]],["m8x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",37,[[["self"],["i8x4"]],["m8x4"]]],[11,"hash","","",37,[[["self"],["h"]]]],[11,"add","","",37,[[["self"],["self"]],["self"]]],[11,"sub","","",37,[[["self"],["self"]],["self"]]],[11,"mul","","",37,[[["self"],["self"]],["self"]]],[11,"div","","",37,[[["self"],["self"]],["self"]]],[11,"rem","","",37,[[["self"],["self"]],["self"]]],[11,"add_assign","","",37,[[["self"],["self"]]]],[11,"sub_assign","","",37,[[["self"],["self"]]]],[11,"mul_assign","","",37,[[["self"],["self"]]]],[11,"div_assign","","",37,[[["self"],["self"]]]],[11,"rem_assign","","",37,[[["self"],["self"]]]],[11,"add","","",37,[[["self"],["i8"]],["self"]]],[11,"sub","","",37,[[["self"],["i8"]],["self"]]],[11,"mul","","",37,[[["self"],["i8"]],["self"]]],[11,"div","","",37,[[["self"],["i8"]],["self"]]],[11,"rem","","",37,[[["self"],["i8"]],["self"]]],[11,"add_assign","","",37,[[["self"],["i8"]]]],[11,"sub_assign","","",37,[[["self"],["i8"]]]],[11,"mul_assign","","",37,[[["self"],["i8"]]]],[11,"div_assign","","",37,[[["self"],["i8"]]]],[11,"rem_assign","","",37,[[["self"],["i8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",37,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",37,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",37,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",37,[[["self"]],["i8"]]],[11,"neg","","",37,[[["self"]],["self"]]],[11,"not","","",37,[[["self"]],["self"]]],[11,"bitxor","","",37,[[["self"],["self"]],["self"]]],[11,"bitand","","",37,[[["self"],["self"]],["self"]]],[11,"bitor","","",37,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",37,[[["self"],["self"]]]],[11,"bitor_assign","","",37,[[["self"],["self"]]]],[11,"bitxor_assign","","",37,[[["self"],["self"]]]],[11,"bitxor","","",37,[[["self"],["i8"]],["self"]]],[11,"bitand","","",37,[[["self"],["i8"]],["self"]]],[11,"bitor","","",37,[[["self"],["i8"]],["self"]]],[11,"bitand_assign","","",37,[[["self"],["i8"]]]],[11,"bitor_assign","","",37,[[["self"],["i8"]]]],[11,"bitxor_assign","","",37,[[["self"],["i8"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",37,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",37,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",37,[[["self"]],["i8"]]],[11,"shl","","",37,[[["self"],["u8"]],["self"]]],[11,"shr","","",37,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["u8"]]]],[11,"shr_assign","","",37,[[["self"],["u8"]]]],[11,"shl","","",37,[[["self"],["u16"]],["self"]]],[11,"shr","","",37,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["u16"]]]],[11,"shr_assign","","",37,[[["self"],["u16"]]]],[11,"shl","","",37,[[["self"],["u32"]],["self"]]],[11,"shr","","",37,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["u32"]]]],[11,"shr_assign","","",37,[[["self"],["u32"]]]],[11,"shl","","",37,[[["self"],["u64"]],["self"]]],[11,"shr","","",37,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["u64"]]]],[11,"shr_assign","","",37,[[["self"],["u64"]]]],[11,"shl","","",37,[[["self"],["usize"]],["self"]]],[11,"shr","","",37,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["usize"]]]],[11,"shr_assign","","",37,[[["self"],["usize"]]]],[11,"shl","","",37,[[["self"],["i8"]],["self"]]],[11,"shr","","",37,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["i8"]]]],[11,"shr_assign","","",37,[[["self"],["i8"]]]],[11,"shl","","",37,[[["self"],["i16"]],["self"]]],[11,"shr","","",37,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["i16"]]]],[11,"shr_assign","","",37,[[["self"],["i16"]]]],[11,"shl","","",37,[[["self"],["i32"]],["self"]]],[11,"shr","","",37,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["i32"]]]],[11,"shr_assign","","",37,[[["self"],["i32"]]]],[11,"shl","","",37,[[["self"],["i64"]],["self"]]],[11,"shr","","",37,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["i64"]]]],[11,"shr_assign","","",37,[[["self"],["i64"]]]],[11,"shl","","",37,[[["self"],["isize"]],["self"]]],[11,"shr","","",37,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["isize"]]]],[11,"shr_assign","","",37,[[["self"],["isize"]]]],[11,"shl","","",37,[[["self"],["self"]],["self"]]],[11,"shr","","",37,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",37,[[["self"],["self"]]]],[11,"shr_assign","","",37,[[["self"],["self"]]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result"]]],[11,"eq","","",37,[[["self"],["self"]],["bool"]]],[11,"ne","","",37,[[["self"],["self"]],["bool"]]],[11,"default","","",37,[[],["self"]]],[11,"min","","Minimum of two vectors.",37,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",37,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",37,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",37,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",37,[[["self"]],["self"]]],[11,"clone","","",38,[[["self"]],["u8x4"]]],[11,"fmt","","",38,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",38,[[["self"],["u8x4"]],["option",["ordering"]]]],[11,"lt","","",38,[[["self"],["u8x4"]],["bool"]]],[11,"le","","",38,[[["self"],["u8x4"]],["bool"]]],[11,"gt","","",38,[[["self"],["u8x4"]],["bool"]]],[11,"ge","","",38,[[["self"],["u8x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",38,[[["u8"],["u8"],["u8"],["u8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",38,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",38,[[["u8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",38,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",38,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",38,[[["self"],["usize"],["u8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",38,[[["self"],["usize"],["u8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",38,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",38,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",38,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",38,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",38,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",38,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",38,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",38,N],[11,"eq","","Lane-wise equality comparison.",38,[[["self"],["u8x4"]],["m8x4"]]],[11,"ne","","Lane-wise inequality comparison.",38,[[["self"],["u8x4"]],["m8x4"]]],[11,"lt","","Lane-wise less-than comparison.",38,[[["self"],["u8x4"]],["m8x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",38,[[["self"],["u8x4"]],["m8x4"]]],[11,"gt","","Lane-wise greater-than comparison.",38,[[["self"],["u8x4"]],["m8x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",38,[[["self"],["u8x4"]],["m8x4"]]],[11,"hash","","",38,[[["self"],["h"]]]],[11,"add","","",38,[[["self"],["self"]],["self"]]],[11,"sub","","",38,[[["self"],["self"]],["self"]]],[11,"mul","","",38,[[["self"],["self"]],["self"]]],[11,"div","","",38,[[["self"],["self"]],["self"]]],[11,"rem","","",38,[[["self"],["self"]],["self"]]],[11,"add_assign","","",38,[[["self"],["self"]]]],[11,"sub_assign","","",38,[[["self"],["self"]]]],[11,"mul_assign","","",38,[[["self"],["self"]]]],[11,"div_assign","","",38,[[["self"],["self"]]]],[11,"rem_assign","","",38,[[["self"],["self"]]]],[11,"add","","",38,[[["self"],["u8"]],["self"]]],[11,"sub","","",38,[[["self"],["u8"]],["self"]]],[11,"mul","","",38,[[["self"],["u8"]],["self"]]],[11,"div","","",38,[[["self"],["u8"]],["self"]]],[11,"rem","","",38,[[["self"],["u8"]],["self"]]],[11,"add_assign","","",38,[[["self"],["u8"]]]],[11,"sub_assign","","",38,[[["self"],["u8"]]]],[11,"mul_assign","","",38,[[["self"],["u8"]]]],[11,"div_assign","","",38,[[["self"],["u8"]]]],[11,"rem_assign","","",38,[[["self"],["u8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",38,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",38,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",38,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",38,[[["self"]],["u8"]]],[11,"bitxor","","",38,[[["self"],["u8"]],["self"]]],[11,"bitand","","",38,[[["self"],["u8"]],["self"]]],[11,"bitor","","",38,[[["self"],["u8"]],["self"]]],[11,"bitand_assign","","",38,[[["self"],["u8"]]]],[11,"bitor_assign","","",38,[[["self"],["u8"]]]],[11,"bitxor_assign","","",38,[[["self"],["u8"]]]],[11,"not","","",38,[[["self"]],["self"]]],[11,"bitxor","","",38,[[["self"],["self"]],["self"]]],[11,"bitand","","",38,[[["self"],["self"]],["self"]]],[11,"bitor","","",38,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",38,[[["self"],["self"]]]],[11,"bitor_assign","","",38,[[["self"],["self"]]]],[11,"bitxor_assign","","",38,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",38,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",38,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",38,[[["self"]],["u8"]]],[11,"shl","","",38,[[["self"],["u8"]],["self"]]],[11,"shr","","",38,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["u8"]]]],[11,"shr_assign","","",38,[[["self"],["u8"]]]],[11,"shl","","",38,[[["self"],["u16"]],["self"]]],[11,"shr","","",38,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["u16"]]]],[11,"shr_assign","","",38,[[["self"],["u16"]]]],[11,"shl","","",38,[[["self"],["u32"]],["self"]]],[11,"shr","","",38,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["u32"]]]],[11,"shr_assign","","",38,[[["self"],["u32"]]]],[11,"shl","","",38,[[["self"],["u64"]],["self"]]],[11,"shr","","",38,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["u64"]]]],[11,"shr_assign","","",38,[[["self"],["u64"]]]],[11,"shl","","",38,[[["self"],["usize"]],["self"]]],[11,"shr","","",38,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["usize"]]]],[11,"shr_assign","","",38,[[["self"],["usize"]]]],[11,"shl","","",38,[[["self"],["i8"]],["self"]]],[11,"shr","","",38,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["i8"]]]],[11,"shr_assign","","",38,[[["self"],["i8"]]]],[11,"shl","","",38,[[["self"],["i16"]],["self"]]],[11,"shr","","",38,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["i16"]]]],[11,"shr_assign","","",38,[[["self"],["i16"]]]],[11,"shl","","",38,[[["self"],["i32"]],["self"]]],[11,"shr","","",38,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["i32"]]]],[11,"shr_assign","","",38,[[["self"],["i32"]]]],[11,"shl","","",38,[[["self"],["i64"]],["self"]]],[11,"shr","","",38,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["i64"]]]],[11,"shr_assign","","",38,[[["self"],["i64"]]]],[11,"shl","","",38,[[["self"],["isize"]],["self"]]],[11,"shr","","",38,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["isize"]]]],[11,"shr_assign","","",38,[[["self"],["isize"]]]],[11,"shl","","",38,[[["self"],["self"]],["self"]]],[11,"shr","","",38,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",38,[[["self"],["self"]]]],[11,"shr_assign","","",38,[[["self"],["self"]]]],[11,"fmt","","",38,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",38,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",38,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",38,[[["self"],["formatter"]],["result"]]],[11,"eq","","",38,[[["self"],["self"]],["bool"]]],[11,"ne","","",38,[[["self"],["self"]],["bool"]]],[11,"default","","",38,[[],["self"]]],[11,"min","","Minimum of two vectors.",38,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",38,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",38,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",38,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",38,[[["self"]],["self"]]],[11,"clone","","",39,[[["self"]],["m8x4"]]],[11,"fmt","","",39,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",39,[[["self"],["m8x4"]],["option",["ordering"]]]],[11,"lt","","",39,[[["self"],["m8x4"]],["bool"]]],[11,"le","","",39,[[["self"],["m8x4"]],["bool"]]],[11,"gt","","",39,[[["self"],["m8x4"]],["bool"]]],[11,"ge","","",39,[[["self"],["m8x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",39,[[["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",39,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",39,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",39,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",39,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",39,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",39,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",39,[[["self"]],["self"]]],[11,"bitxor","","",39,[[["self"],["self"]],["self"]]],[11,"bitand","","",39,[[["self"],["self"]],["self"]]],[11,"bitor","","",39,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",39,[[["self"],["self"]]]],[11,"bitor_assign","","",39,[[["self"],["self"]]]],[11,"bitxor_assign","","",39,[[["self"],["self"]]]],[11,"bitxor","","",39,[[["self"],["bool"]],["self"]]],[11,"bitand","","",39,[[["self"],["bool"]],["self"]]],[11,"bitor","","",39,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",39,[[["self"],["bool"]]]],[11,"bitor_assign","","",39,[[["self"],["bool"]]]],[11,"bitxor_assign","","",39,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",39,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",39,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",39,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",39,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",39,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",39,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",39,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",39,[[["self"],["m8x4"]],["m8x4"]]],[11,"ne","","Lane-wise inequality comparison.",39,[[["self"],["m8x4"]],["m8x4"]]],[11,"lt","","Lane-wise less-than comparison.",39,[[["self"],["m8x4"]],["m8x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",39,[[["self"],["m8x4"]],["m8x4"]]],[11,"gt","","Lane-wise greater-than comparison.",39,[[["self"],["m8x4"]],["m8x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",39,[[["self"],["m8x4"]],["m8x4"]]],[11,"eq","","",39,[[["self"],["self"]],["bool"]]],[11,"ne","","",39,[[["self"],["self"]],["bool"]]],[11,"default","","",39,[[],["self"]]],[11,"from_bits","","",34,[[["u16x2"]],["i16x2"]]],[11,"from_bits","","",34,[[["m16x2"]],["i16x2"]]],[11,"from_bits","","",34,[[["i8x4"]],["i16x2"]]],[11,"from_bits","","",34,[[["u8x4"]],["i16x2"]]],[11,"from_bits","","",34,[[["m8x4"]],["i16x2"]]],[11,"from_bits","","",35,[[["i16x2"]],["u16x2"]]],[11,"from_bits","","",35,[[["m16x2"]],["u16x2"]]],[11,"from_bits","","",35,[[["i8x4"]],["u16x2"]]],[11,"from_bits","","",35,[[["u8x4"]],["u16x2"]]],[11,"from_bits","","",35,[[["m8x4"]],["u16x2"]]],[11,"from_bits","","",37,[[["i16x2"]],["i8x4"]]],[11,"from_bits","","",37,[[["u16x2"]],["i8x4"]]],[11,"from_bits","","",37,[[["m16x2"]],["i8x4"]]],[11,"from_bits","","",37,[[["u8x4"]],["i8x4"]]],[11,"from_bits","","",37,[[["m8x4"]],["i8x4"]]],[11,"from_bits","","",38,[[["i16x2"]],["u8x4"]]],[11,"from_bits","","",38,[[["u16x2"]],["u8x4"]]],[11,"from_bits","","",38,[[["m16x2"]],["u8x4"]]],[11,"from_bits","","",38,[[["i8x4"]],["u8x4"]]],[11,"from_bits","","",38,[[["m8x4"]],["u8x4"]]],[11,"from","","",34,[[["f64x2"]],["i16x2"]]],[11,"from","","",34,[[["u64x2"]],["i16x2"]]],[11,"from","","",34,[[["i64x2"]],["i16x2"]]],[11,"from","","",34,[[["m64x2"]],["i16x2"]]],[11,"from","","",34,[[["f32x2"]],["i16x2"]]],[11,"from","","",34,[[["u32x2"]],["i16x2"]]],[11,"from","","",34,[[["i32x2"]],["i16x2"]]],[11,"from","","",34,[[["m32x2"]],["i16x2"]]],[11,"from","","",34,[[["u16x2"]],["i16x2"]]],[11,"from","","",34,[[["m16x2"]],["i16x2"]]],[11,"from","","",34,[[["u8x2"]],["i16x2"]]],[11,"from","","",34,[[["i8x2"]],["i16x2"]]],[11,"from","","",34,[[["m8x2"]],["i16x2"]]],[11,"from","","",35,[[["f64x2"]],["u16x2"]]],[11,"from","","",35,[[["u64x2"]],["u16x2"]]],[11,"from","","",35,[[["i64x2"]],["u16x2"]]],[11,"from","","",35,[[["m64x2"]],["u16x2"]]],[11,"from","","",35,[[["f32x2"]],["u16x2"]]],[11,"from","","",35,[[["u32x2"]],["u16x2"]]],[11,"from","","",35,[[["i32x2"]],["u16x2"]]],[11,"from","","",35,[[["m32x2"]],["u16x2"]]],[11,"from","","",35,[[["i16x2"]],["u16x2"]]],[11,"from","","",35,[[["m16x2"]],["u16x2"]]],[11,"from","","",35,[[["u8x2"]],["u16x2"]]],[11,"from","","",35,[[["i8x2"]],["u16x2"]]],[11,"from","","",35,[[["m8x2"]],["u16x2"]]],[11,"from","","",37,[[["f64x4"]],["i8x4"]]],[11,"from","","",37,[[["u64x4"]],["i8x4"]]],[11,"from","","",37,[[["i64x4"]],["i8x4"]]],[11,"from","","",37,[[["m64x4"]],["i8x4"]]],[11,"from","","",37,[[["u32x4"]],["i8x4"]]],[11,"from","","",37,[[["i32x4"]],["i8x4"]]],[11,"from","","",37,[[["f32x4"]],["i8x4"]]],[11,"from","","",37,[[["m32x4"]],["i8x4"]]],[11,"from","","",37,[[["u16x4"]],["i8x4"]]],[11,"from","","",37,[[["i16x4"]],["i8x4"]]],[11,"from","","",37,[[["m16x4"]],["i8x4"]]],[11,"from","","",37,[[["u8x4"]],["i8x4"]]],[11,"from","","",37,[[["m8x4"]],["i8x4"]]],[11,"from","","",38,[[["f64x4"]],["u8x4"]]],[11,"from","","",38,[[["u64x4"]],["u8x4"]]],[11,"from","","",38,[[["i64x4"]],["u8x4"]]],[11,"from","","",38,[[["m64x4"]],["u8x4"]]],[11,"from","","",38,[[["u32x4"]],["u8x4"]]],[11,"from","","",38,[[["i32x4"]],["u8x4"]]],[11,"from","","",38,[[["f32x4"]],["u8x4"]]],[11,"from","","",38,[[["m32x4"]],["u8x4"]]],[11,"from","","",38,[[["u16x4"]],["u8x4"]]],[11,"from","","",38,[[["i16x4"]],["u8x4"]]],[11,"from","","",38,[[["m16x4"]],["u8x4"]]],[11,"from","","",38,[[["i8x4"]],["u8x4"]]],[11,"from","","",38,[[["m8x4"]],["u8x4"]]],[11,"from","","",39,[[["m64x4"]],["m8x4"]]],[11,"from","","",39,[[["m32x4"]],["m8x4"]]],[11,"from","","",39,[[["m16x4"]],["m8x4"]]],[11,"from","","",36,[[["m64x2"]],["m16x2"]]],[11,"from","","",36,[[["m32x2"]],["m16x2"]]],[11,"from","","",36,[[["m8x2"]],["m16x2"]]],[11,"clone","","",40,[[["self"]],["i8x64"]]],[11,"fmt","","",40,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",40,[[["self"],["i8x64"]],["option",["ordering"]]]],[11,"lt","","",40,[[["self"],["i8x64"]],["bool"]]],[11,"le","","",40,[[["self"],["i8x64"]],["bool"]]],[11,"gt","","",40,[[["self"],["i8x64"]],["bool"]]],[11,"ge","","",40,[[["self"],["i8x64"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",40,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",40,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",40,[[["i8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",40,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",40,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",40,[[["self"],["usize"],["i8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",40,[[["self"],["usize"],["i8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",40,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",40,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",40,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",40,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",40,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",40,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",40,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",40,N],[11,"eq","","Lane-wise equality comparison.",40,[[["self"],["i8x64"]],["m1x64"]]],[11,"ne","","Lane-wise inequality comparison.",40,[[["self"],["i8x64"]],["m1x64"]]],[11,"lt","","Lane-wise less-than comparison.",40,[[["self"],["i8x64"]],["m1x64"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",40,[[["self"],["i8x64"]],["m1x64"]]],[11,"gt","","Lane-wise greater-than comparison.",40,[[["self"],["i8x64"]],["m1x64"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",40,[[["self"],["i8x64"]],["m1x64"]]],[11,"hash","","",40,[[["self"],["h"]]]],[11,"add","","",40,[[["self"],["self"]],["self"]]],[11,"sub","","",40,[[["self"],["self"]],["self"]]],[11,"mul","","",40,[[["self"],["self"]],["self"]]],[11,"div","","",40,[[["self"],["self"]],["self"]]],[11,"rem","","",40,[[["self"],["self"]],["self"]]],[11,"add_assign","","",40,[[["self"],["self"]]]],[11,"sub_assign","","",40,[[["self"],["self"]]]],[11,"mul_assign","","",40,[[["self"],["self"]]]],[11,"div_assign","","",40,[[["self"],["self"]]]],[11,"rem_assign","","",40,[[["self"],["self"]]]],[11,"add","","",40,[[["self"],["i8"]],["self"]]],[11,"sub","","",40,[[["self"],["i8"]],["self"]]],[11,"mul","","",40,[[["self"],["i8"]],["self"]]],[11,"div","","",40,[[["self"],["i8"]],["self"]]],[11,"rem","","",40,[[["self"],["i8"]],["self"]]],[11,"add_assign","","",40,[[["self"],["i8"]]]],[11,"sub_assign","","",40,[[["self"],["i8"]]]],[11,"mul_assign","","",40,[[["self"],["i8"]]]],[11,"div_assign","","",40,[[["self"],["i8"]]]],[11,"rem_assign","","",40,[[["self"],["i8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",40,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",40,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",40,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",40,[[["self"]],["i8"]]],[11,"neg","","",40,[[["self"]],["self"]]],[11,"not","","",40,[[["self"]],["self"]]],[11,"bitxor","","",40,[[["self"],["self"]],["self"]]],[11,"bitand","","",40,[[["self"],["self"]],["self"]]],[11,"bitor","","",40,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",40,[[["self"],["self"]]]],[11,"bitor_assign","","",40,[[["self"],["self"]]]],[11,"bitxor_assign","","",40,[[["self"],["self"]]]],[11,"bitxor","","",40,[[["self"],["i8"]],["self"]]],[11,"bitand","","",40,[[["self"],["i8"]],["self"]]],[11,"bitor","","",40,[[["self"],["i8"]],["self"]]],[11,"bitand_assign","","",40,[[["self"],["i8"]]]],[11,"bitor_assign","","",40,[[["self"],["i8"]]]],[11,"bitxor_assign","","",40,[[["self"],["i8"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",40,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",40,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",40,[[["self"]],["i8"]]],[11,"shl","","",40,[[["self"],["u8"]],["self"]]],[11,"shr","","",40,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["u8"]]]],[11,"shr_assign","","",40,[[["self"],["u8"]]]],[11,"shl","","",40,[[["self"],["u16"]],["self"]]],[11,"shr","","",40,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["u16"]]]],[11,"shr_assign","","",40,[[["self"],["u16"]]]],[11,"shl","","",40,[[["self"],["u32"]],["self"]]],[11,"shr","","",40,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["u32"]]]],[11,"shr_assign","","",40,[[["self"],["u32"]]]],[11,"shl","","",40,[[["self"],["u64"]],["self"]]],[11,"shr","","",40,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["u64"]]]],[11,"shr_assign","","",40,[[["self"],["u64"]]]],[11,"shl","","",40,[[["self"],["usize"]],["self"]]],[11,"shr","","",40,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["usize"]]]],[11,"shr_assign","","",40,[[["self"],["usize"]]]],[11,"shl","","",40,[[["self"],["i8"]],["self"]]],[11,"shr","","",40,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["i8"]]]],[11,"shr_assign","","",40,[[["self"],["i8"]]]],[11,"shl","","",40,[[["self"],["i16"]],["self"]]],[11,"shr","","",40,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["i16"]]]],[11,"shr_assign","","",40,[[["self"],["i16"]]]],[11,"shl","","",40,[[["self"],["i32"]],["self"]]],[11,"shr","","",40,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["i32"]]]],[11,"shr_assign","","",40,[[["self"],["i32"]]]],[11,"shl","","",40,[[["self"],["i64"]],["self"]]],[11,"shr","","",40,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["i64"]]]],[11,"shr_assign","","",40,[[["self"],["i64"]]]],[11,"shl","","",40,[[["self"],["isize"]],["self"]]],[11,"shr","","",40,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["isize"]]]],[11,"shr_assign","","",40,[[["self"],["isize"]]]],[11,"shl","","",40,[[["self"],["self"]],["self"]]],[11,"shr","","",40,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",40,[[["self"],["self"]]]],[11,"shr_assign","","",40,[[["self"],["self"]]]],[11,"fmt","","",40,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",40,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",40,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",40,[[["self"],["formatter"]],["result"]]],[11,"eq","","",40,[[["self"],["self"]],["bool"]]],[11,"ne","","",40,[[["self"],["self"]],["bool"]]],[11,"default","","",40,[[],["self"]]],[11,"min","","Minimum of two vectors.",40,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",40,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",40,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",40,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",40,[[["self"]],["self"]]],[11,"clone","","",41,[[["self"]],["u8x64"]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",41,[[["self"],["u8x64"]],["option",["ordering"]]]],[11,"lt","","",41,[[["self"],["u8x64"]],["bool"]]],[11,"le","","",41,[[["self"],["u8x64"]],["bool"]]],[11,"gt","","",41,[[["self"],["u8x64"]],["bool"]]],[11,"ge","","",41,[[["self"],["u8x64"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",41,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",41,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",41,[[["u8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",41,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",41,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",41,[[["self"],["usize"],["u8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",41,[[["self"],["usize"],["u8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",41,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",41,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",41,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",41,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"eq","","Lane-wise equality comparison.",41,[[["self"],["u8x64"]],["m1x64"]]],[11,"ne","","Lane-wise inequality comparison.",41,[[["self"],["u8x64"]],["m1x64"]]],[11,"lt","","Lane-wise less-than comparison.",41,[[["self"],["u8x64"]],["m1x64"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",41,[[["self"],["u8x64"]],["m1x64"]]],[11,"gt","","Lane-wise greater-than comparison.",41,[[["self"],["u8x64"]],["m1x64"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",41,[[["self"],["u8x64"]],["m1x64"]]],[11,"hash","","",41,[[["self"],["h"]]]],[11,"add","","",41,[[["self"],["self"]],["self"]]],[11,"sub","","",41,[[["self"],["self"]],["self"]]],[11,"mul","","",41,[[["self"],["self"]],["self"]]],[11,"div","","",41,[[["self"],["self"]],["self"]]],[11,"rem","","",41,[[["self"],["self"]],["self"]]],[11,"add_assign","","",41,[[["self"],["self"]]]],[11,"sub_assign","","",41,[[["self"],["self"]]]],[11,"mul_assign","","",41,[[["self"],["self"]]]],[11,"div_assign","","",41,[[["self"],["self"]]]],[11,"rem_assign","","",41,[[["self"],["self"]]]],[11,"add","","",41,[[["self"],["u8"]],["self"]]],[11,"sub","","",41,[[["self"],["u8"]],["self"]]],[11,"mul","","",41,[[["self"],["u8"]],["self"]]],[11,"div","","",41,[[["self"],["u8"]],["self"]]],[11,"rem","","",41,[[["self"],["u8"]],["self"]]],[11,"add_assign","","",41,[[["self"],["u8"]]]],[11,"sub_assign","","",41,[[["self"],["u8"]]]],[11,"mul_assign","","",41,[[["self"],["u8"]]]],[11,"div_assign","","",41,[[["self"],["u8"]]]],[11,"rem_assign","","",41,[[["self"],["u8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",41,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",41,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",41,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",41,[[["self"]],["u8"]]],[11,"bitxor","","",41,[[["self"],["u8"]],["self"]]],[11,"bitand","","",41,[[["self"],["u8"]],["self"]]],[11,"bitor","","",41,[[["self"],["u8"]],["self"]]],[11,"bitand_assign","","",41,[[["self"],["u8"]]]],[11,"bitor_assign","","",41,[[["self"],["u8"]]]],[11,"bitxor_assign","","",41,[[["self"],["u8"]]]],[11,"not","","",41,[[["self"]],["self"]]],[11,"bitxor","","",41,[[["self"],["self"]],["self"]]],[11,"bitand","","",41,[[["self"],["self"]],["self"]]],[11,"bitor","","",41,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",41,[[["self"],["self"]]]],[11,"bitor_assign","","",41,[[["self"],["self"]]]],[11,"bitxor_assign","","",41,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",41,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",41,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",41,[[["self"]],["u8"]]],[11,"shl","","",41,[[["self"],["u8"]],["self"]]],[11,"shr","","",41,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["u8"]]]],[11,"shr_assign","","",41,[[["self"],["u8"]]]],[11,"shl","","",41,[[["self"],["u16"]],["self"]]],[11,"shr","","",41,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["u16"]]]],[11,"shr_assign","","",41,[[["self"],["u16"]]]],[11,"shl","","",41,[[["self"],["u32"]],["self"]]],[11,"shr","","",41,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["u32"]]]],[11,"shr_assign","","",41,[[["self"],["u32"]]]],[11,"shl","","",41,[[["self"],["u64"]],["self"]]],[11,"shr","","",41,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["u64"]]]],[11,"shr_assign","","",41,[[["self"],["u64"]]]],[11,"shl","","",41,[[["self"],["usize"]],["self"]]],[11,"shr","","",41,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["usize"]]]],[11,"shr_assign","","",41,[[["self"],["usize"]]]],[11,"shl","","",41,[[["self"],["i8"]],["self"]]],[11,"shr","","",41,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["i8"]]]],[11,"shr_assign","","",41,[[["self"],["i8"]]]],[11,"shl","","",41,[[["self"],["i16"]],["self"]]],[11,"shr","","",41,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["i16"]]]],[11,"shr_assign","","",41,[[["self"],["i16"]]]],[11,"shl","","",41,[[["self"],["i32"]],["self"]]],[11,"shr","","",41,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["i32"]]]],[11,"shr_assign","","",41,[[["self"],["i32"]]]],[11,"shl","","",41,[[["self"],["i64"]],["self"]]],[11,"shr","","",41,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["i64"]]]],[11,"shr_assign","","",41,[[["self"],["i64"]]]],[11,"shl","","",41,[[["self"],["isize"]],["self"]]],[11,"shr","","",41,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["isize"]]]],[11,"shr_assign","","",41,[[["self"],["isize"]]]],[11,"shl","","",41,[[["self"],["self"]],["self"]]],[11,"shr","","",41,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",41,[[["self"],["self"]]]],[11,"shr_assign","","",41,[[["self"],["self"]]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result"]]],[11,"eq","","",41,[[["self"],["self"]],["bool"]]],[11,"ne","","",41,[[["self"],["self"]],["bool"]]],[11,"default","","",41,[[],["self"]]],[11,"min","","Minimum of two vectors.",41,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",41,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",41,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",41,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",41,[[["self"]],["self"]]],[11,"clone","","",42,[[["self"]],["m1x64"]]],[11,"fmt","","",42,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",42,[[["self"],["m1x64"]],["option",["ordering"]]]],[11,"lt","","",42,[[["self"],["m1x64"]],["bool"]]],[11,"le","","",42,[[["self"],["m1x64"]],["bool"]]],[11,"gt","","",42,[[["self"],["m1x64"]],["bool"]]],[11,"ge","","",42,[[["self"],["m1x64"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",42,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",42,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",42,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",42,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",42,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",42,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",42,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",42,[[["self"]],["self"]]],[11,"bitxor","","",42,[[["self"],["self"]],["self"]]],[11,"bitand","","",42,[[["self"],["self"]],["self"]]],[11,"bitor","","",42,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",42,[[["self"],["self"]]]],[11,"bitor_assign","","",42,[[["self"],["self"]]]],[11,"bitxor_assign","","",42,[[["self"],["self"]]]],[11,"bitxor","","",42,[[["self"],["bool"]],["self"]]],[11,"bitand","","",42,[[["self"],["bool"]],["self"]]],[11,"bitor","","",42,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",42,[[["self"],["bool"]]]],[11,"bitor_assign","","",42,[[["self"],["bool"]]]],[11,"bitxor_assign","","",42,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",42,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",42,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",42,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",42,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",42,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",42,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",42,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",42,[[["self"],["m1x64"]],["m1x64"]]],[11,"ne","","Lane-wise inequality comparison.",42,[[["self"],["m1x64"]],["m1x64"]]],[11,"lt","","Lane-wise less-than comparison.",42,[[["self"],["m1x64"]],["m1x64"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",42,[[["self"],["m1x64"]],["m1x64"]]],[11,"gt","","Lane-wise greater-than comparison.",42,[[["self"],["m1x64"]],["m1x64"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",42,[[["self"],["m1x64"]],["m1x64"]]],[11,"eq","","",42,[[["self"],["self"]],["bool"]]],[11,"ne","","",42,[[["self"],["self"]],["bool"]]],[11,"default","","",42,[[],["self"]]],[11,"clone","","",43,[[["self"]],["i16x32"]]],[11,"fmt","","",43,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",43,[[["self"],["i16x32"]],["option",["ordering"]]]],[11,"lt","","",43,[[["self"],["i16x32"]],["bool"]]],[11,"le","","",43,[[["self"],["i16x32"]],["bool"]]],[11,"gt","","",43,[[["self"],["i16x32"]],["bool"]]],[11,"ge","","",43,[[["self"],["i16x32"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",43,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",43,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",43,[[["i16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",43,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",43,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",43,[[["self"],["usize"],["i16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",43,[[["self"],["usize"],["i16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",43,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",43,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",43,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",43,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",43,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",43,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",43,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",43,N],[11,"eq","","Lane-wise equality comparison.",43,[[["self"],["i16x32"]],["m1x32"]]],[11,"ne","","Lane-wise inequality comparison.",43,[[["self"],["i16x32"]],["m1x32"]]],[11,"lt","","Lane-wise less-than comparison.",43,[[["self"],["i16x32"]],["m1x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",43,[[["self"],["i16x32"]],["m1x32"]]],[11,"gt","","Lane-wise greater-than comparison.",43,[[["self"],["i16x32"]],["m1x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",43,[[["self"],["i16x32"]],["m1x32"]]],[11,"hash","","",43,[[["self"],["h"]]]],[11,"add","","",43,[[["self"],["self"]],["self"]]],[11,"sub","","",43,[[["self"],["self"]],["self"]]],[11,"mul","","",43,[[["self"],["self"]],["self"]]],[11,"div","","",43,[[["self"],["self"]],["self"]]],[11,"rem","","",43,[[["self"],["self"]],["self"]]],[11,"add_assign","","",43,[[["self"],["self"]]]],[11,"sub_assign","","",43,[[["self"],["self"]]]],[11,"mul_assign","","",43,[[["self"],["self"]]]],[11,"div_assign","","",43,[[["self"],["self"]]]],[11,"rem_assign","","",43,[[["self"],["self"]]]],[11,"add","","",43,[[["self"],["i16"]],["self"]]],[11,"sub","","",43,[[["self"],["i16"]],["self"]]],[11,"mul","","",43,[[["self"],["i16"]],["self"]]],[11,"div","","",43,[[["self"],["i16"]],["self"]]],[11,"rem","","",43,[[["self"],["i16"]],["self"]]],[11,"add_assign","","",43,[[["self"],["i16"]]]],[11,"sub_assign","","",43,[[["self"],["i16"]]]],[11,"mul_assign","","",43,[[["self"],["i16"]]]],[11,"div_assign","","",43,[[["self"],["i16"]]]],[11,"rem_assign","","",43,[[["self"],["i16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",43,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",43,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",43,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",43,[[["self"]],["i16"]]],[11,"neg","","",43,[[["self"]],["self"]]],[11,"not","","",43,[[["self"]],["self"]]],[11,"bitxor","","",43,[[["self"],["self"]],["self"]]],[11,"bitand","","",43,[[["self"],["self"]],["self"]]],[11,"bitor","","",43,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",43,[[["self"],["self"]]]],[11,"bitor_assign","","",43,[[["self"],["self"]]]],[11,"bitxor_assign","","",43,[[["self"],["self"]]]],[11,"bitxor","","",43,[[["self"],["i16"]],["self"]]],[11,"bitand","","",43,[[["self"],["i16"]],["self"]]],[11,"bitor","","",43,[[["self"],["i16"]],["self"]]],[11,"bitand_assign","","",43,[[["self"],["i16"]]]],[11,"bitor_assign","","",43,[[["self"],["i16"]]]],[11,"bitxor_assign","","",43,[[["self"],["i16"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",43,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",43,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",43,[[["self"]],["i16"]]],[11,"shl","","",43,[[["self"],["u8"]],["self"]]],[11,"shr","","",43,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["u8"]]]],[11,"shr_assign","","",43,[[["self"],["u8"]]]],[11,"shl","","",43,[[["self"],["u16"]],["self"]]],[11,"shr","","",43,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["u16"]]]],[11,"shr_assign","","",43,[[["self"],["u16"]]]],[11,"shl","","",43,[[["self"],["u32"]],["self"]]],[11,"shr","","",43,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["u32"]]]],[11,"shr_assign","","",43,[[["self"],["u32"]]]],[11,"shl","","",43,[[["self"],["u64"]],["self"]]],[11,"shr","","",43,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["u64"]]]],[11,"shr_assign","","",43,[[["self"],["u64"]]]],[11,"shl","","",43,[[["self"],["usize"]],["self"]]],[11,"shr","","",43,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["usize"]]]],[11,"shr_assign","","",43,[[["self"],["usize"]]]],[11,"shl","","",43,[[["self"],["i8"]],["self"]]],[11,"shr","","",43,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["i8"]]]],[11,"shr_assign","","",43,[[["self"],["i8"]]]],[11,"shl","","",43,[[["self"],["i16"]],["self"]]],[11,"shr","","",43,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["i16"]]]],[11,"shr_assign","","",43,[[["self"],["i16"]]]],[11,"shl","","",43,[[["self"],["i32"]],["self"]]],[11,"shr","","",43,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["i32"]]]],[11,"shr_assign","","",43,[[["self"],["i32"]]]],[11,"shl","","",43,[[["self"],["i64"]],["self"]]],[11,"shr","","",43,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["i64"]]]],[11,"shr_assign","","",43,[[["self"],["i64"]]]],[11,"shl","","",43,[[["self"],["isize"]],["self"]]],[11,"shr","","",43,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["isize"]]]],[11,"shr_assign","","",43,[[["self"],["isize"]]]],[11,"shl","","",43,[[["self"],["self"]],["self"]]],[11,"shr","","",43,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",43,[[["self"],["self"]]]],[11,"shr_assign","","",43,[[["self"],["self"]]]],[11,"fmt","","",43,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",43,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",43,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",43,[[["self"],["formatter"]],["result"]]],[11,"eq","","",43,[[["self"],["self"]],["bool"]]],[11,"ne","","",43,[[["self"],["self"]],["bool"]]],[11,"default","","",43,[[],["self"]]],[11,"min","","Minimum of two vectors.",43,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",43,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",43,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",43,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",43,[[["self"]],["self"]]],[11,"clone","","",44,[[["self"]],["u16x32"]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",44,[[["self"],["u16x32"]],["option",["ordering"]]]],[11,"lt","","",44,[[["self"],["u16x32"]],["bool"]]],[11,"le","","",44,[[["self"],["u16x32"]],["bool"]]],[11,"gt","","",44,[[["self"],["u16x32"]],["bool"]]],[11,"ge","","",44,[[["self"],["u16x32"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",44,[[["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",44,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",44,[[["u16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",44,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",44,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",44,[[["self"],["usize"],["u16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",44,[[["self"],["usize"],["u16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",44,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",44,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",44,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",44,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"eq","","Lane-wise equality comparison.",44,[[["self"],["u16x32"]],["m1x32"]]],[11,"ne","","Lane-wise inequality comparison.",44,[[["self"],["u16x32"]],["m1x32"]]],[11,"lt","","Lane-wise less-than comparison.",44,[[["self"],["u16x32"]],["m1x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",44,[[["self"],["u16x32"]],["m1x32"]]],[11,"gt","","Lane-wise greater-than comparison.",44,[[["self"],["u16x32"]],["m1x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",44,[[["self"],["u16x32"]],["m1x32"]]],[11,"hash","","",44,[[["self"],["h"]]]],[11,"add","","",44,[[["self"],["self"]],["self"]]],[11,"sub","","",44,[[["self"],["self"]],["self"]]],[11,"mul","","",44,[[["self"],["self"]],["self"]]],[11,"div","","",44,[[["self"],["self"]],["self"]]],[11,"rem","","",44,[[["self"],["self"]],["self"]]],[11,"add_assign","","",44,[[["self"],["self"]]]],[11,"sub_assign","","",44,[[["self"],["self"]]]],[11,"mul_assign","","",44,[[["self"],["self"]]]],[11,"div_assign","","",44,[[["self"],["self"]]]],[11,"rem_assign","","",44,[[["self"],["self"]]]],[11,"add","","",44,[[["self"],["u16"]],["self"]]],[11,"sub","","",44,[[["self"],["u16"]],["self"]]],[11,"mul","","",44,[[["self"],["u16"]],["self"]]],[11,"div","","",44,[[["self"],["u16"]],["self"]]],[11,"rem","","",44,[[["self"],["u16"]],["self"]]],[11,"add_assign","","",44,[[["self"],["u16"]]]],[11,"sub_assign","","",44,[[["self"],["u16"]]]],[11,"mul_assign","","",44,[[["self"],["u16"]]]],[11,"div_assign","","",44,[[["self"],["u16"]]]],[11,"rem_assign","","",44,[[["self"],["u16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",44,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",44,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",44,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",44,[[["self"]],["u16"]]],[11,"bitxor","","",44,[[["self"],["u16"]],["self"]]],[11,"bitand","","",44,[[["self"],["u16"]],["self"]]],[11,"bitor","","",44,[[["self"],["u16"]],["self"]]],[11,"bitand_assign","","",44,[[["self"],["u16"]]]],[11,"bitor_assign","","",44,[[["self"],["u16"]]]],[11,"bitxor_assign","","",44,[[["self"],["u16"]]]],[11,"not","","",44,[[["self"]],["self"]]],[11,"bitxor","","",44,[[["self"],["self"]],["self"]]],[11,"bitand","","",44,[[["self"],["self"]],["self"]]],[11,"bitor","","",44,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",44,[[["self"],["self"]]]],[11,"bitor_assign","","",44,[[["self"],["self"]]]],[11,"bitxor_assign","","",44,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",44,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",44,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",44,[[["self"]],["u16"]]],[11,"shl","","",44,[[["self"],["u8"]],["self"]]],[11,"shr","","",44,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["u8"]]]],[11,"shr_assign","","",44,[[["self"],["u8"]]]],[11,"shl","","",44,[[["self"],["u16"]],["self"]]],[11,"shr","","",44,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["u16"]]]],[11,"shr_assign","","",44,[[["self"],["u16"]]]],[11,"shl","","",44,[[["self"],["u32"]],["self"]]],[11,"shr","","",44,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["u32"]]]],[11,"shr_assign","","",44,[[["self"],["u32"]]]],[11,"shl","","",44,[[["self"],["u64"]],["self"]]],[11,"shr","","",44,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["u64"]]]],[11,"shr_assign","","",44,[[["self"],["u64"]]]],[11,"shl","","",44,[[["self"],["usize"]],["self"]]],[11,"shr","","",44,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["usize"]]]],[11,"shr_assign","","",44,[[["self"],["usize"]]]],[11,"shl","","",44,[[["self"],["i8"]],["self"]]],[11,"shr","","",44,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["i8"]]]],[11,"shr_assign","","",44,[[["self"],["i8"]]]],[11,"shl","","",44,[[["self"],["i16"]],["self"]]],[11,"shr","","",44,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["i16"]]]],[11,"shr_assign","","",44,[[["self"],["i16"]]]],[11,"shl","","",44,[[["self"],["i32"]],["self"]]],[11,"shr","","",44,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["i32"]]]],[11,"shr_assign","","",44,[[["self"],["i32"]]]],[11,"shl","","",44,[[["self"],["i64"]],["self"]]],[11,"shr","","",44,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["i64"]]]],[11,"shr_assign","","",44,[[["self"],["i64"]]]],[11,"shl","","",44,[[["self"],["isize"]],["self"]]],[11,"shr","","",44,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["isize"]]]],[11,"shr_assign","","",44,[[["self"],["isize"]]]],[11,"shl","","",44,[[["self"],["self"]],["self"]]],[11,"shr","","",44,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",44,[[["self"],["self"]]]],[11,"shr_assign","","",44,[[["self"],["self"]]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result"]]],[11,"eq","","",44,[[["self"],["self"]],["bool"]]],[11,"ne","","",44,[[["self"],["self"]],["bool"]]],[11,"default","","",44,[[],["self"]]],[11,"min","","Minimum of two vectors.",44,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",44,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",44,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",44,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",44,[[["self"]],["self"]]],[11,"clone","","",45,[[["self"]],["m1x32"]]],[11,"fmt","","",45,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",45,[[["self"],["m1x32"]],["option",["ordering"]]]],[11,"lt","","",45,[[["self"],["m1x32"]],["bool"]]],[11,"le","","",45,[[["self"],["m1x32"]],["bool"]]],[11,"gt","","",45,[[["self"],["m1x32"]],["bool"]]],[11,"ge","","",45,[[["self"],["m1x32"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",45,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",45,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",45,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",45,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",45,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",45,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",45,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",45,[[["self"]],["self"]]],[11,"bitxor","","",45,[[["self"],["self"]],["self"]]],[11,"bitand","","",45,[[["self"],["self"]],["self"]]],[11,"bitor","","",45,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",45,[[["self"],["self"]]]],[11,"bitor_assign","","",45,[[["self"],["self"]]]],[11,"bitxor_assign","","",45,[[["self"],["self"]]]],[11,"bitxor","","",45,[[["self"],["bool"]],["self"]]],[11,"bitand","","",45,[[["self"],["bool"]],["self"]]],[11,"bitor","","",45,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",45,[[["self"],["bool"]]]],[11,"bitor_assign","","",45,[[["self"],["bool"]]]],[11,"bitxor_assign","","",45,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",45,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",45,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",45,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",45,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",45,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",45,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",45,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",45,[[["self"],["m1x32"]],["m1x32"]]],[11,"ne","","Lane-wise inequality comparison.",45,[[["self"],["m1x32"]],["m1x32"]]],[11,"lt","","Lane-wise less-than comparison.",45,[[["self"],["m1x32"]],["m1x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",45,[[["self"],["m1x32"]],["m1x32"]]],[11,"gt","","Lane-wise greater-than comparison.",45,[[["self"],["m1x32"]],["m1x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",45,[[["self"],["m1x32"]],["m1x32"]]],[11,"eq","","",45,[[["self"],["self"]],["bool"]]],[11,"ne","","",45,[[["self"],["self"]],["bool"]]],[11,"default","","",45,[[],["self"]]],[11,"clone","","",46,[[["self"]],["i32x16"]]],[11,"fmt","","",46,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",46,[[["self"],["i32x16"]],["option",["ordering"]]]],[11,"lt","","",46,[[["self"],["i32x16"]],["bool"]]],[11,"le","","",46,[[["self"],["i32x16"]],["bool"]]],[11,"gt","","",46,[[["self"],["i32x16"]],["bool"]]],[11,"ge","","",46,[[["self"],["i32x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",46,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",46,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",46,[[["i32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",46,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",46,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",46,[[["self"],["usize"],["i32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",46,[[["self"],["usize"],["i32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",46,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",46,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",46,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",46,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",46,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",46,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",46,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",46,N],[11,"eq","","Lane-wise equality comparison.",46,[[["self"],["i32x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",46,[[["self"],["i32x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",46,[[["self"],["i32x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",46,[[["self"],["i32x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",46,[[["self"],["i32x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",46,[[["self"],["i32x16"]],["m1x16"]]],[11,"hash","","",46,[[["self"],["h"]]]],[11,"add","","",46,[[["self"],["self"]],["self"]]],[11,"sub","","",46,[[["self"],["self"]],["self"]]],[11,"mul","","",46,[[["self"],["self"]],["self"]]],[11,"div","","",46,[[["self"],["self"]],["self"]]],[11,"rem","","",46,[[["self"],["self"]],["self"]]],[11,"add_assign","","",46,[[["self"],["self"]]]],[11,"sub_assign","","",46,[[["self"],["self"]]]],[11,"mul_assign","","",46,[[["self"],["self"]]]],[11,"div_assign","","",46,[[["self"],["self"]]]],[11,"rem_assign","","",46,[[["self"],["self"]]]],[11,"add","","",46,[[["self"],["i32"]],["self"]]],[11,"sub","","",46,[[["self"],["i32"]],["self"]]],[11,"mul","","",46,[[["self"],["i32"]],["self"]]],[11,"div","","",46,[[["self"],["i32"]],["self"]]],[11,"rem","","",46,[[["self"],["i32"]],["self"]]],[11,"add_assign","","",46,[[["self"],["i32"]]]],[11,"sub_assign","","",46,[[["self"],["i32"]]]],[11,"mul_assign","","",46,[[["self"],["i32"]]]],[11,"div_assign","","",46,[[["self"],["i32"]]]],[11,"rem_assign","","",46,[[["self"],["i32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",46,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",46,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",46,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",46,[[["self"]],["i32"]]],[11,"neg","","",46,[[["self"]],["self"]]],[11,"not","","",46,[[["self"]],["self"]]],[11,"bitxor","","",46,[[["self"],["self"]],["self"]]],[11,"bitand","","",46,[[["self"],["self"]],["self"]]],[11,"bitor","","",46,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",46,[[["self"],["self"]]]],[11,"bitor_assign","","",46,[[["self"],["self"]]]],[11,"bitxor_assign","","",46,[[["self"],["self"]]]],[11,"bitxor","","",46,[[["self"],["i32"]],["self"]]],[11,"bitand","","",46,[[["self"],["i32"]],["self"]]],[11,"bitor","","",46,[[["self"],["i32"]],["self"]]],[11,"bitand_assign","","",46,[[["self"],["i32"]]]],[11,"bitor_assign","","",46,[[["self"],["i32"]]]],[11,"bitxor_assign","","",46,[[["self"],["i32"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",46,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",46,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",46,[[["self"]],["i32"]]],[11,"shl","","",46,[[["self"],["u8"]],["self"]]],[11,"shr","","",46,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["u8"]]]],[11,"shr_assign","","",46,[[["self"],["u8"]]]],[11,"shl","","",46,[[["self"],["u16"]],["self"]]],[11,"shr","","",46,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["u16"]]]],[11,"shr_assign","","",46,[[["self"],["u16"]]]],[11,"shl","","",46,[[["self"],["u32"]],["self"]]],[11,"shr","","",46,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["u32"]]]],[11,"shr_assign","","",46,[[["self"],["u32"]]]],[11,"shl","","",46,[[["self"],["u64"]],["self"]]],[11,"shr","","",46,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["u64"]]]],[11,"shr_assign","","",46,[[["self"],["u64"]]]],[11,"shl","","",46,[[["self"],["usize"]],["self"]]],[11,"shr","","",46,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["usize"]]]],[11,"shr_assign","","",46,[[["self"],["usize"]]]],[11,"shl","","",46,[[["self"],["i8"]],["self"]]],[11,"shr","","",46,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["i8"]]]],[11,"shr_assign","","",46,[[["self"],["i8"]]]],[11,"shl","","",46,[[["self"],["i16"]],["self"]]],[11,"shr","","",46,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["i16"]]]],[11,"shr_assign","","",46,[[["self"],["i16"]]]],[11,"shl","","",46,[[["self"],["i32"]],["self"]]],[11,"shr","","",46,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["i32"]]]],[11,"shr_assign","","",46,[[["self"],["i32"]]]],[11,"shl","","",46,[[["self"],["i64"]],["self"]]],[11,"shr","","",46,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["i64"]]]],[11,"shr_assign","","",46,[[["self"],["i64"]]]],[11,"shl","","",46,[[["self"],["isize"]],["self"]]],[11,"shr","","",46,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["isize"]]]],[11,"shr_assign","","",46,[[["self"],["isize"]]]],[11,"shl","","",46,[[["self"],["self"]],["self"]]],[11,"shr","","",46,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",46,[[["self"],["self"]]]],[11,"shr_assign","","",46,[[["self"],["self"]]]],[11,"fmt","","",46,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",46,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",46,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",46,[[["self"],["formatter"]],["result"]]],[11,"eq","","",46,[[["self"],["self"]],["bool"]]],[11,"ne","","",46,[[["self"],["self"]],["bool"]]],[11,"default","","",46,[[],["self"]]],[11,"min","","Minimum of two vectors.",46,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",46,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",46,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",46,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",46,[[["self"]],["self"]]],[11,"clone","","",47,[[["self"]],["u32x16"]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",47,[[["self"],["u32x16"]],["option",["ordering"]]]],[11,"lt","","",47,[[["self"],["u32x16"]],["bool"]]],[11,"le","","",47,[[["self"],["u32x16"]],["bool"]]],[11,"gt","","",47,[[["self"],["u32x16"]],["bool"]]],[11,"ge","","",47,[[["self"],["u32x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",47,[[["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",47,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",47,[[["u32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",47,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",47,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",47,[[["self"],["usize"],["u32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",47,[[["self"],["usize"],["u32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",47,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",47,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",47,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",47,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"eq","","Lane-wise equality comparison.",47,[[["self"],["u32x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",47,[[["self"],["u32x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",47,[[["self"],["u32x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",47,[[["self"],["u32x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",47,[[["self"],["u32x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",47,[[["self"],["u32x16"]],["m1x16"]]],[11,"hash","","",47,[[["self"],["h"]]]],[11,"add","","",47,[[["self"],["self"]],["self"]]],[11,"sub","","",47,[[["self"],["self"]],["self"]]],[11,"mul","","",47,[[["self"],["self"]],["self"]]],[11,"div","","",47,[[["self"],["self"]],["self"]]],[11,"rem","","",47,[[["self"],["self"]],["self"]]],[11,"add_assign","","",47,[[["self"],["self"]]]],[11,"sub_assign","","",47,[[["self"],["self"]]]],[11,"mul_assign","","",47,[[["self"],["self"]]]],[11,"div_assign","","",47,[[["self"],["self"]]]],[11,"rem_assign","","",47,[[["self"],["self"]]]],[11,"add","","",47,[[["self"],["u32"]],["self"]]],[11,"sub","","",47,[[["self"],["u32"]],["self"]]],[11,"mul","","",47,[[["self"],["u32"]],["self"]]],[11,"div","","",47,[[["self"],["u32"]],["self"]]],[11,"rem","","",47,[[["self"],["u32"]],["self"]]],[11,"add_assign","","",47,[[["self"],["u32"]]]],[11,"sub_assign","","",47,[[["self"],["u32"]]]],[11,"mul_assign","","",47,[[["self"],["u32"]]]],[11,"div_assign","","",47,[[["self"],["u32"]]]],[11,"rem_assign","","",47,[[["self"],["u32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",47,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",47,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",47,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",47,[[["self"]],["u32"]]],[11,"bitxor","","",47,[[["self"],["u32"]],["self"]]],[11,"bitand","","",47,[[["self"],["u32"]],["self"]]],[11,"bitor","","",47,[[["self"],["u32"]],["self"]]],[11,"bitand_assign","","",47,[[["self"],["u32"]]]],[11,"bitor_assign","","",47,[[["self"],["u32"]]]],[11,"bitxor_assign","","",47,[[["self"],["u32"]]]],[11,"not","","",47,[[["self"]],["self"]]],[11,"bitxor","","",47,[[["self"],["self"]],["self"]]],[11,"bitand","","",47,[[["self"],["self"]],["self"]]],[11,"bitor","","",47,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",47,[[["self"],["self"]]]],[11,"bitor_assign","","",47,[[["self"],["self"]]]],[11,"bitxor_assign","","",47,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",47,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",47,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",47,[[["self"]],["u32"]]],[11,"shl","","",47,[[["self"],["u8"]],["self"]]],[11,"shr","","",47,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["u8"]]]],[11,"shr_assign","","",47,[[["self"],["u8"]]]],[11,"shl","","",47,[[["self"],["u16"]],["self"]]],[11,"shr","","",47,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["u16"]]]],[11,"shr_assign","","",47,[[["self"],["u16"]]]],[11,"shl","","",47,[[["self"],["u32"]],["self"]]],[11,"shr","","",47,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["u32"]]]],[11,"shr_assign","","",47,[[["self"],["u32"]]]],[11,"shl","","",47,[[["self"],["u64"]],["self"]]],[11,"shr","","",47,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["u64"]]]],[11,"shr_assign","","",47,[[["self"],["u64"]]]],[11,"shl","","",47,[[["self"],["usize"]],["self"]]],[11,"shr","","",47,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["usize"]]]],[11,"shr_assign","","",47,[[["self"],["usize"]]]],[11,"shl","","",47,[[["self"],["i8"]],["self"]]],[11,"shr","","",47,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["i8"]]]],[11,"shr_assign","","",47,[[["self"],["i8"]]]],[11,"shl","","",47,[[["self"],["i16"]],["self"]]],[11,"shr","","",47,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["i16"]]]],[11,"shr_assign","","",47,[[["self"],["i16"]]]],[11,"shl","","",47,[[["self"],["i32"]],["self"]]],[11,"shr","","",47,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["i32"]]]],[11,"shr_assign","","",47,[[["self"],["i32"]]]],[11,"shl","","",47,[[["self"],["i64"]],["self"]]],[11,"shr","","",47,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["i64"]]]],[11,"shr_assign","","",47,[[["self"],["i64"]]]],[11,"shl","","",47,[[["self"],["isize"]],["self"]]],[11,"shr","","",47,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["isize"]]]],[11,"shr_assign","","",47,[[["self"],["isize"]]]],[11,"shl","","",47,[[["self"],["self"]],["self"]]],[11,"shr","","",47,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",47,[[["self"],["self"]]]],[11,"shr_assign","","",47,[[["self"],["self"]]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result"]]],[11,"eq","","",47,[[["self"],["self"]],["bool"]]],[11,"ne","","",47,[[["self"],["self"]],["bool"]]],[11,"default","","",47,[[],["self"]]],[11,"min","","Minimum of two vectors.",47,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",47,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",47,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",47,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",47,[[["self"]],["self"]]],[11,"clone","","",48,[[["self"]],["f32x16"]]],[11,"fmt","","",48,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",48,[[["self"],["f32x16"]],["option",["ordering"]]]],[11,"lt","","",48,[[["self"],["f32x16"]],["bool"]]],[11,"le","","",48,[[["self"],["f32x16"]],["bool"]]],[11,"gt","","",48,[[["self"],["f32x16"]],["bool"]]],[11,"ge","","",48,[[["self"],["f32x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",48,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",48,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",48,[[["f32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",48,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",48,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",48,[[["self"],["usize"],["f32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",48,[[["self"],["usize"],["f32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",48,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",48,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",48,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",48,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",48,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",48,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",48,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",48,N],[11,"eq","","Lane-wise equality comparison.",48,[[["self"],["f32x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",48,[[["self"],["f32x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",48,[[["self"],["f32x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",48,[[["self"],["f32x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",48,[[["self"],["f32x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",48,[[["self"],["f32x16"]],["m1x16"]]],[11,"add","","",48,[[["self"],["self"]],["self"]]],[11,"sub","","",48,[[["self"],["self"]],["self"]]],[11,"mul","","",48,[[["self"],["self"]],["self"]]],[11,"div","","",48,[[["self"],["self"]],["self"]]],[11,"rem","","",48,[[["self"],["self"]],["self"]]],[11,"add_assign","","",48,[[["self"],["self"]]]],[11,"sub_assign","","",48,[[["self"],["self"]]]],[11,"mul_assign","","",48,[[["self"],["self"]]]],[11,"div_assign","","",48,[[["self"],["self"]]]],[11,"rem_assign","","",48,[[["self"],["self"]]]],[11,"add","","",48,[[["self"],["f32"]],["self"]]],[11,"sub","","",48,[[["self"],["f32"]],["self"]]],[11,"mul","","",48,[[["self"],["f32"]],["self"]]],[11,"div","","",48,[[["self"],["f32"]],["self"]]],[11,"rem","","",48,[[["self"],["f32"]],["self"]]],[11,"add_assign","","",48,[[["self"],["f32"]]]],[11,"sub_assign","","",48,[[["self"],["f32"]]]],[11,"mul_assign","","",48,[[["self"],["f32"]]]],[11,"div_assign","","",48,[[["self"],["f32"]]]],[11,"rem_assign","","",48,[[["self"],["f32"]]]],[11,"sum","","Horizontal sum of the vector elements.",48,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",48,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",48,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",48,[[["self"]],["f32"]]],[11,"neg","","",48,[[["self"]],["self"]]],[11,"eq","","",48,[[["self"],["self"]],["bool"]]],[11,"ne","","",48,[[["self"],["self"]],["bool"]]],[11,"default","","",48,[[],["self"]]],[11,"min","","Minimum of two vectors.",48,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",48,[[["self"],["self"]],["self"]]],[11,"abs","","Absolute-value",48,[[["self"]],["self"]]],[11,"sqrt","","Square-root",48,[[["self"]],["self"]]],[11,"sqrte","","Square-root estimate",48,[[["self"]],["self"]]],[11,"rsqrte","","Reciprocal square-root estimate",48,[[["self"]],["self"]]],[11,"fma","","Fused multiply add: `self * y + z`",48,[[["self"],["self"],["self"]],["self"]]],[11,"sin","","Sin",48,[[["self"]],["self"]]],[11,"cos","","Cos",48,[[["self"]],["self"]]],[11,"clone","","",49,[[["self"]],["m1x16"]]],[11,"fmt","","",49,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",49,[[["self"],["m1x16"]],["option",["ordering"]]]],[11,"lt","","",49,[[["self"],["m1x16"]],["bool"]]],[11,"le","","",49,[[["self"],["m1x16"]],["bool"]]],[11,"gt","","",49,[[["self"],["m1x16"]],["bool"]]],[11,"ge","","",49,[[["self"],["m1x16"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",49,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",49,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",49,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",49,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",49,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",49,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",49,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",49,[[["self"]],["self"]]],[11,"bitxor","","",49,[[["self"],["self"]],["self"]]],[11,"bitand","","",49,[[["self"],["self"]],["self"]]],[11,"bitor","","",49,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",49,[[["self"],["self"]]]],[11,"bitor_assign","","",49,[[["self"],["self"]]]],[11,"bitxor_assign","","",49,[[["self"],["self"]]]],[11,"bitxor","","",49,[[["self"],["bool"]],["self"]]],[11,"bitand","","",49,[[["self"],["bool"]],["self"]]],[11,"bitor","","",49,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",49,[[["self"],["bool"]]]],[11,"bitor_assign","","",49,[[["self"],["bool"]]]],[11,"bitxor_assign","","",49,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",49,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",49,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",49,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",49,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",49,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",49,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",49,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",49,[[["self"],["m1x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",49,[[["self"],["m1x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",49,[[["self"],["m1x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",49,[[["self"],["m1x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",49,[[["self"],["m1x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",49,[[["self"],["m1x16"]],["m1x16"]]],[11,"eq","","",49,[[["self"],["self"]],["bool"]]],[11,"ne","","",49,[[["self"],["self"]],["bool"]]],[11,"default","","",49,[[],["self"]]],[11,"clone","","",50,[[["self"]],["i64x8"]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",50,[[["self"],["i64x8"]],["option",["ordering"]]]],[11,"lt","","",50,[[["self"],["i64x8"]],["bool"]]],[11,"le","","",50,[[["self"],["i64x8"]],["bool"]]],[11,"gt","","",50,[[["self"],["i64x8"]],["bool"]]],[11,"ge","","",50,[[["self"],["i64x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",50,[[["i64"],["i64"],["i64"],["i64"],["i64"],["i64"],["i64"],["i64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",50,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",50,[[["i64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",50,[[["self"],["usize"]],["i64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",50,[[["self"],["usize"]],["i64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",50,[[["self"],["usize"],["i64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",50,[[["self"],["usize"],["i64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",50,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",50,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",50,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",50,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"eq","","Lane-wise equality comparison.",50,[[["self"],["i64x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",50,[[["self"],["i64x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",50,[[["self"],["i64x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",50,[[["self"],["i64x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",50,[[["self"],["i64x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",50,[[["self"],["i64x8"]],["m1x8"]]],[11,"hash","","",50,[[["self"],["h"]]]],[11,"add","","",50,[[["self"],["self"]],["self"]]],[11,"sub","","",50,[[["self"],["self"]],["self"]]],[11,"mul","","",50,[[["self"],["self"]],["self"]]],[11,"div","","",50,[[["self"],["self"]],["self"]]],[11,"rem","","",50,[[["self"],["self"]],["self"]]],[11,"add_assign","","",50,[[["self"],["self"]]]],[11,"sub_assign","","",50,[[["self"],["self"]]]],[11,"mul_assign","","",50,[[["self"],["self"]]]],[11,"div_assign","","",50,[[["self"],["self"]]]],[11,"rem_assign","","",50,[[["self"],["self"]]]],[11,"add","","",50,[[["self"],["i64"]],["self"]]],[11,"sub","","",50,[[["self"],["i64"]],["self"]]],[11,"mul","","",50,[[["self"],["i64"]],["self"]]],[11,"div","","",50,[[["self"],["i64"]],["self"]]],[11,"rem","","",50,[[["self"],["i64"]],["self"]]],[11,"add_assign","","",50,[[["self"],["i64"]]]],[11,"sub_assign","","",50,[[["self"],["i64"]]]],[11,"mul_assign","","",50,[[["self"],["i64"]]]],[11,"div_assign","","",50,[[["self"],["i64"]]]],[11,"rem_assign","","",50,[[["self"],["i64"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",50,[[["self"]],["i64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",50,[[["self"]],["i64"]]],[11,"max_element","","Largest vector element value.",50,[[["self"]],["i64"]]],[11,"min_element","","Smallest vector element value.",50,[[["self"]],["i64"]]],[11,"neg","","",50,[[["self"]],["self"]]],[11,"not","","",50,[[["self"]],["self"]]],[11,"bitxor","","",50,[[["self"],["self"]],["self"]]],[11,"bitand","","",50,[[["self"],["self"]],["self"]]],[11,"bitor","","",50,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",50,[[["self"],["self"]]]],[11,"bitor_assign","","",50,[[["self"],["self"]]]],[11,"bitxor_assign","","",50,[[["self"],["self"]]]],[11,"bitxor","","",50,[[["self"],["i64"]],["self"]]],[11,"bitand","","",50,[[["self"],["i64"]],["self"]]],[11,"bitor","","",50,[[["self"],["i64"]],["self"]]],[11,"bitand_assign","","",50,[[["self"],["i64"]]]],[11,"bitor_assign","","",50,[[["self"],["i64"]]]],[11,"bitxor_assign","","",50,[[["self"],["i64"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",50,[[["self"]],["i64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",50,[[["self"]],["i64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",50,[[["self"]],["i64"]]],[11,"shl","","",50,[[["self"],["u8"]],["self"]]],[11,"shr","","",50,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["u8"]]]],[11,"shr_assign","","",50,[[["self"],["u8"]]]],[11,"shl","","",50,[[["self"],["u16"]],["self"]]],[11,"shr","","",50,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["u16"]]]],[11,"shr_assign","","",50,[[["self"],["u16"]]]],[11,"shl","","",50,[[["self"],["u32"]],["self"]]],[11,"shr","","",50,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["u32"]]]],[11,"shr_assign","","",50,[[["self"],["u32"]]]],[11,"shl","","",50,[[["self"],["u64"]],["self"]]],[11,"shr","","",50,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["u64"]]]],[11,"shr_assign","","",50,[[["self"],["u64"]]]],[11,"shl","","",50,[[["self"],["usize"]],["self"]]],[11,"shr","","",50,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["usize"]]]],[11,"shr_assign","","",50,[[["self"],["usize"]]]],[11,"shl","","",50,[[["self"],["i8"]],["self"]]],[11,"shr","","",50,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["i8"]]]],[11,"shr_assign","","",50,[[["self"],["i8"]]]],[11,"shl","","",50,[[["self"],["i16"]],["self"]]],[11,"shr","","",50,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["i16"]]]],[11,"shr_assign","","",50,[[["self"],["i16"]]]],[11,"shl","","",50,[[["self"],["i32"]],["self"]]],[11,"shr","","",50,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["i32"]]]],[11,"shr_assign","","",50,[[["self"],["i32"]]]],[11,"shl","","",50,[[["self"],["i64"]],["self"]]],[11,"shr","","",50,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["i64"]]]],[11,"shr_assign","","",50,[[["self"],["i64"]]]],[11,"shl","","",50,[[["self"],["isize"]],["self"]]],[11,"shr","","",50,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["isize"]]]],[11,"shr_assign","","",50,[[["self"],["isize"]]]],[11,"shl","","",50,[[["self"],["self"]],["self"]]],[11,"shr","","",50,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",50,[[["self"],["self"]]]],[11,"shr_assign","","",50,[[["self"],["self"]]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result"]]],[11,"eq","","",50,[[["self"],["self"]],["bool"]]],[11,"ne","","",50,[[["self"],["self"]],["bool"]]],[11,"default","","",50,[[],["self"]]],[11,"min","","Minimum of two vectors.",50,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",50,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",50,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",50,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",50,[[["self"]],["self"]]],[11,"clone","","",51,[[["self"]],["u64x8"]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",51,[[["self"],["u64x8"]],["option",["ordering"]]]],[11,"lt","","",51,[[["self"],["u64x8"]],["bool"]]],[11,"le","","",51,[[["self"],["u64x8"]],["bool"]]],[11,"gt","","",51,[[["self"],["u64x8"]],["bool"]]],[11,"ge","","",51,[[["self"],["u64x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",51,[[["u64"],["u64"],["u64"],["u64"],["u64"],["u64"],["u64"],["u64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",51,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",51,[[["u64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",51,[[["self"],["usize"]],["u64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",51,[[["self"],["usize"]],["u64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",51,[[["self"],["usize"],["u64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",51,[[["self"],["usize"],["u64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",51,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",51,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",51,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",51,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"eq","","Lane-wise equality comparison.",51,[[["self"],["u64x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",51,[[["self"],["u64x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",51,[[["self"],["u64x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",51,[[["self"],["u64x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",51,[[["self"],["u64x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",51,[[["self"],["u64x8"]],["m1x8"]]],[11,"hash","","",51,[[["self"],["h"]]]],[11,"add","","",51,[[["self"],["self"]],["self"]]],[11,"sub","","",51,[[["self"],["self"]],["self"]]],[11,"mul","","",51,[[["self"],["self"]],["self"]]],[11,"div","","",51,[[["self"],["self"]],["self"]]],[11,"rem","","",51,[[["self"],["self"]],["self"]]],[11,"add_assign","","",51,[[["self"],["self"]]]],[11,"sub_assign","","",51,[[["self"],["self"]]]],[11,"mul_assign","","",51,[[["self"],["self"]]]],[11,"div_assign","","",51,[[["self"],["self"]]]],[11,"rem_assign","","",51,[[["self"],["self"]]]],[11,"add","","",51,[[["self"],["u64"]],["self"]]],[11,"sub","","",51,[[["self"],["u64"]],["self"]]],[11,"mul","","",51,[[["self"],["u64"]],["self"]]],[11,"div","","",51,[[["self"],["u64"]],["self"]]],[11,"rem","","",51,[[["self"],["u64"]],["self"]]],[11,"add_assign","","",51,[[["self"],["u64"]]]],[11,"sub_assign","","",51,[[["self"],["u64"]]]],[11,"mul_assign","","",51,[[["self"],["u64"]]]],[11,"div_assign","","",51,[[["self"],["u64"]]]],[11,"rem_assign","","",51,[[["self"],["u64"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",51,[[["self"]],["u64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",51,[[["self"]],["u64"]]],[11,"max_element","","Largest vector element value.",51,[[["self"]],["u64"]]],[11,"min_element","","Smallest vector element value.",51,[[["self"]],["u64"]]],[11,"bitxor","","",51,[[["self"],["u64"]],["self"]]],[11,"bitand","","",51,[[["self"],["u64"]],["self"]]],[11,"bitor","","",51,[[["self"],["u64"]],["self"]]],[11,"bitand_assign","","",51,[[["self"],["u64"]]]],[11,"bitor_assign","","",51,[[["self"],["u64"]]]],[11,"bitxor_assign","","",51,[[["self"],["u64"]]]],[11,"not","","",51,[[["self"]],["self"]]],[11,"bitxor","","",51,[[["self"],["self"]],["self"]]],[11,"bitand","","",51,[[["self"],["self"]],["self"]]],[11,"bitor","","",51,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",51,[[["self"],["self"]]]],[11,"bitor_assign","","",51,[[["self"],["self"]]]],[11,"bitxor_assign","","",51,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",51,[[["self"]],["u64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",51,[[["self"]],["u64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",51,[[["self"]],["u64"]]],[11,"shl","","",51,[[["self"],["u8"]],["self"]]],[11,"shr","","",51,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["u8"]]]],[11,"shr_assign","","",51,[[["self"],["u8"]]]],[11,"shl","","",51,[[["self"],["u16"]],["self"]]],[11,"shr","","",51,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["u16"]]]],[11,"shr_assign","","",51,[[["self"],["u16"]]]],[11,"shl","","",51,[[["self"],["u32"]],["self"]]],[11,"shr","","",51,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["u32"]]]],[11,"shr_assign","","",51,[[["self"],["u32"]]]],[11,"shl","","",51,[[["self"],["u64"]],["self"]]],[11,"shr","","",51,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["u64"]]]],[11,"shr_assign","","",51,[[["self"],["u64"]]]],[11,"shl","","",51,[[["self"],["usize"]],["self"]]],[11,"shr","","",51,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["usize"]]]],[11,"shr_assign","","",51,[[["self"],["usize"]]]],[11,"shl","","",51,[[["self"],["i8"]],["self"]]],[11,"shr","","",51,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["i8"]]]],[11,"shr_assign","","",51,[[["self"],["i8"]]]],[11,"shl","","",51,[[["self"],["i16"]],["self"]]],[11,"shr","","",51,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["i16"]]]],[11,"shr_assign","","",51,[[["self"],["i16"]]]],[11,"shl","","",51,[[["self"],["i32"]],["self"]]],[11,"shr","","",51,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["i32"]]]],[11,"shr_assign","","",51,[[["self"],["i32"]]]],[11,"shl","","",51,[[["self"],["i64"]],["self"]]],[11,"shr","","",51,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["i64"]]]],[11,"shr_assign","","",51,[[["self"],["i64"]]]],[11,"shl","","",51,[[["self"],["isize"]],["self"]]],[11,"shr","","",51,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["isize"]]]],[11,"shr_assign","","",51,[[["self"],["isize"]]]],[11,"shl","","",51,[[["self"],["self"]],["self"]]],[11,"shr","","",51,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",51,[[["self"],["self"]]]],[11,"shr_assign","","",51,[[["self"],["self"]]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result"]]],[11,"eq","","",51,[[["self"],["self"]],["bool"]]],[11,"ne","","",51,[[["self"],["self"]],["bool"]]],[11,"default","","",51,[[],["self"]]],[11,"min","","Minimum of two vectors.",51,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",51,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",51,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",51,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",51,[[["self"]],["self"]]],[11,"clone","","",52,[[["self"]],["f64x8"]]],[11,"fmt","","",52,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",52,[[["self"],["f64x8"]],["option",["ordering"]]]],[11,"lt","","",52,[[["self"],["f64x8"]],["bool"]]],[11,"le","","",52,[[["self"],["f64x8"]],["bool"]]],[11,"gt","","",52,[[["self"],["f64x8"]],["bool"]]],[11,"ge","","",52,[[["self"],["f64x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",52,[[["f64"],["f64"],["f64"],["f64"],["f64"],["f64"],["f64"],["f64"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",52,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",52,[[["f64"]],["self"]]],[11,"extract","","Extracts the value at `index`.",52,[[["self"],["usize"]],["f64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",52,[[["self"],["usize"]],["f64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",52,[[["self"],["usize"],["f64"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",52,[[["self"],["usize"],["f64"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",52,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",52,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",52,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",52,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"eq","","Lane-wise equality comparison.",52,[[["self"],["f64x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",52,[[["self"],["f64x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",52,[[["self"],["f64x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",52,[[["self"],["f64x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",52,[[["self"],["f64x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",52,[[["self"],["f64x8"]],["m1x8"]]],[11,"add","","",52,[[["self"],["self"]],["self"]]],[11,"sub","","",52,[[["self"],["self"]],["self"]]],[11,"mul","","",52,[[["self"],["self"]],["self"]]],[11,"div","","",52,[[["self"],["self"]],["self"]]],[11,"rem","","",52,[[["self"],["self"]],["self"]]],[11,"add_assign","","",52,[[["self"],["self"]]]],[11,"sub_assign","","",52,[[["self"],["self"]]]],[11,"mul_assign","","",52,[[["self"],["self"]]]],[11,"div_assign","","",52,[[["self"],["self"]]]],[11,"rem_assign","","",52,[[["self"],["self"]]]],[11,"add","","",52,[[["self"],["f64"]],["self"]]],[11,"sub","","",52,[[["self"],["f64"]],["self"]]],[11,"mul","","",52,[[["self"],["f64"]],["self"]]],[11,"div","","",52,[[["self"],["f64"]],["self"]]],[11,"rem","","",52,[[["self"],["f64"]],["self"]]],[11,"add_assign","","",52,[[["self"],["f64"]]]],[11,"sub_assign","","",52,[[["self"],["f64"]]]],[11,"mul_assign","","",52,[[["self"],["f64"]]]],[11,"div_assign","","",52,[[["self"],["f64"]]]],[11,"rem_assign","","",52,[[["self"],["f64"]]]],[11,"sum","","Horizontal sum of the vector elements.",52,[[["self"]],["f64"]]],[11,"product","","Horizontal product of the vector elements.",52,[[["self"]],["f64"]]],[11,"max_element","","Largest vector element value.",52,[[["self"]],["f64"]]],[11,"min_element","","Smallest vector element value.",52,[[["self"]],["f64"]]],[11,"neg","","",52,[[["self"]],["self"]]],[11,"eq","","",52,[[["self"],["self"]],["bool"]]],[11,"ne","","",52,[[["self"],["self"]],["bool"]]],[11,"default","","",52,[[],["self"]]],[11,"min","","Minimum of two vectors.",52,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",52,[[["self"],["self"]],["self"]]],[11,"abs","","Absolute-value",52,[[["self"]],["self"]]],[11,"sqrt","","Square-root",52,[[["self"]],["self"]]],[11,"sqrte","","Square-root estimate",52,[[["self"]],["self"]]],[11,"rsqrte","","Reciprocal square-root estimate",52,[[["self"]],["self"]]],[11,"fma","","Fused multiply add: `self * y + z`",52,[[["self"],["self"],["self"]],["self"]]],[11,"sin","","Sin",52,[[["self"]],["self"]]],[11,"cos","","Cos",52,[[["self"]],["self"]]],[11,"clone","","",53,[[["self"]],["m1x8"]]],[11,"fmt","","",53,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",53,[[["self"],["m1x8"]],["option",["ordering"]]]],[11,"lt","","",53,[[["self"],["m1x8"]],["bool"]]],[11,"le","","",53,[[["self"],["m1x8"]],["bool"]]],[11,"gt","","",53,[[["self"],["m1x8"]],["bool"]]],[11,"ge","","",53,[[["self"],["m1x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",53,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",53,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",53,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",53,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",53,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",53,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",53,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",53,[[["self"]],["self"]]],[11,"bitxor","","",53,[[["self"],["self"]],["self"]]],[11,"bitand","","",53,[[["self"],["self"]],["self"]]],[11,"bitor","","",53,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",53,[[["self"],["self"]]]],[11,"bitor_assign","","",53,[[["self"],["self"]]]],[11,"bitxor_assign","","",53,[[["self"],["self"]]]],[11,"bitxor","","",53,[[["self"],["bool"]],["self"]]],[11,"bitand","","",53,[[["self"],["bool"]],["self"]]],[11,"bitor","","",53,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",53,[[["self"],["bool"]]]],[11,"bitor_assign","","",53,[[["self"],["bool"]]]],[11,"bitxor_assign","","",53,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",53,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",53,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",53,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",53,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",53,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",53,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",53,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",53,[[["self"],["m1x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",53,[[["self"],["m1x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",53,[[["self"],["m1x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",53,[[["self"],["m1x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",53,[[["self"],["m1x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",53,[[["self"],["m1x8"]],["m1x8"]]],[11,"eq","","",53,[[["self"],["self"]],["bool"]]],[11,"ne","","",53,[[["self"],["self"]],["bool"]]],[11,"default","","",53,[[],["self"]]],[11,"from_bits","","",40,[[["u64x8"]],["i8x64"]]],[11,"from_bits","","",40,[[["i64x8"]],["i8x64"]]],[11,"from_bits","","",40,[[["f64x8"]],["i8x64"]]],[11,"from_bits","","",40,[[["m1x8"]],["i8x64"]]],[11,"from_bits","","",40,[[["u32x16"]],["i8x64"]]],[11,"from_bits","","",40,[[["i32x16"]],["i8x64"]]],[11,"from_bits","","",40,[[["f32x16"]],["i8x64"]]],[11,"from_bits","","",40,[[["m1x16"]],["i8x64"]]],[11,"from_bits","","",40,[[["u16x32"]],["i8x64"]]],[11,"from_bits","","",40,[[["i16x32"]],["i8x64"]]],[11,"from_bits","","",40,[[["m1x32"]],["i8x64"]]],[11,"from_bits","","",40,[[["u8x64"]],["i8x64"]]],[11,"from_bits","","",40,[[["m1x64"]],["i8x64"]]],[11,"from_bits","","",41,[[["u64x8"]],["u8x64"]]],[11,"from_bits","","",41,[[["i64x8"]],["u8x64"]]],[11,"from_bits","","",41,[[["f64x8"]],["u8x64"]]],[11,"from_bits","","",41,[[["m1x8"]],["u8x64"]]],[11,"from_bits","","",41,[[["u32x16"]],["u8x64"]]],[11,"from_bits","","",41,[[["i32x16"]],["u8x64"]]],[11,"from_bits","","",41,[[["f32x16"]],["u8x64"]]],[11,"from_bits","","",41,[[["m1x16"]],["u8x64"]]],[11,"from_bits","","",41,[[["u16x32"]],["u8x64"]]],[11,"from_bits","","",41,[[["i16x32"]],["u8x64"]]],[11,"from_bits","","",41,[[["m1x32"]],["u8x64"]]],[11,"from_bits","","",41,[[["i8x64"]],["u8x64"]]],[11,"from_bits","","",41,[[["m1x64"]],["u8x64"]]],[11,"from_bits","","",43,[[["u64x8"]],["i16x32"]]],[11,"from_bits","","",43,[[["i64x8"]],["i16x32"]]],[11,"from_bits","","",43,[[["f64x8"]],["i16x32"]]],[11,"from_bits","","",43,[[["m1x8"]],["i16x32"]]],[11,"from_bits","","",43,[[["u32x16"]],["i16x32"]]],[11,"from_bits","","",43,[[["i32x16"]],["i16x32"]]],[11,"from_bits","","",43,[[["f32x16"]],["i16x32"]]],[11,"from_bits","","",43,[[["m1x16"]],["i16x32"]]],[11,"from_bits","","",43,[[["u16x32"]],["i16x32"]]],[11,"from_bits","","",43,[[["m1x32"]],["i16x32"]]],[11,"from_bits","","",43,[[["i8x64"]],["i16x32"]]],[11,"from_bits","","",43,[[["u8x64"]],["i16x32"]]],[11,"from_bits","","",43,[[["m1x64"]],["i16x32"]]],[11,"from_bits","","",44,[[["u64x8"]],["u16x32"]]],[11,"from_bits","","",44,[[["i64x8"]],["u16x32"]]],[11,"from_bits","","",44,[[["f64x8"]],["u16x32"]]],[11,"from_bits","","",44,[[["m1x8"]],["u16x32"]]],[11,"from_bits","","",44,[[["u32x16"]],["u16x32"]]],[11,"from_bits","","",44,[[["i32x16"]],["u16x32"]]],[11,"from_bits","","",44,[[["f32x16"]],["u16x32"]]],[11,"from_bits","","",44,[[["m1x16"]],["u16x32"]]],[11,"from_bits","","",44,[[["i16x32"]],["u16x32"]]],[11,"from_bits","","",44,[[["m1x32"]],["u16x32"]]],[11,"from_bits","","",44,[[["i8x64"]],["u16x32"]]],[11,"from_bits","","",44,[[["u8x64"]],["u16x32"]]],[11,"from_bits","","",44,[[["m1x64"]],["u16x32"]]],[11,"from_bits","","",46,[[["u64x8"]],["i32x16"]]],[11,"from_bits","","",46,[[["i64x8"]],["i32x16"]]],[11,"from_bits","","",46,[[["f64x8"]],["i32x16"]]],[11,"from_bits","","",46,[[["m1x8"]],["i32x16"]]],[11,"from_bits","","",46,[[["u32x16"]],["i32x16"]]],[11,"from_bits","","",46,[[["f32x16"]],["i32x16"]]],[11,"from_bits","","",46,[[["m1x16"]],["i32x16"]]],[11,"from_bits","","",46,[[["u16x32"]],["i32x16"]]],[11,"from_bits","","",46,[[["i16x32"]],["i32x16"]]],[11,"from_bits","","",46,[[["m1x32"]],["i32x16"]]],[11,"from_bits","","",46,[[["i8x64"]],["i32x16"]]],[11,"from_bits","","",46,[[["u8x64"]],["i32x16"]]],[11,"from_bits","","",46,[[["m1x64"]],["i32x16"]]],[11,"from_bits","","",47,[[["u64x8"]],["u32x16"]]],[11,"from_bits","","",47,[[["i64x8"]],["u32x16"]]],[11,"from_bits","","",47,[[["f64x8"]],["u32x16"]]],[11,"from_bits","","",47,[[["m1x8"]],["u32x16"]]],[11,"from_bits","","",47,[[["i32x16"]],["u32x16"]]],[11,"from_bits","","",47,[[["f32x16"]],["u32x16"]]],[11,"from_bits","","",47,[[["m1x16"]],["u32x16"]]],[11,"from_bits","","",47,[[["u16x32"]],["u32x16"]]],[11,"from_bits","","",47,[[["i16x32"]],["u32x16"]]],[11,"from_bits","","",47,[[["m1x32"]],["u32x16"]]],[11,"from_bits","","",47,[[["i8x64"]],["u32x16"]]],[11,"from_bits","","",47,[[["u8x64"]],["u32x16"]]],[11,"from_bits","","",47,[[["m1x64"]],["u32x16"]]],[11,"from_bits","","",48,[[["u64x8"]],["f32x16"]]],[11,"from_bits","","",48,[[["i64x8"]],["f32x16"]]],[11,"from_bits","","",48,[[["f64x8"]],["f32x16"]]],[11,"from_bits","","",48,[[["m1x8"]],["f32x16"]]],[11,"from_bits","","",48,[[["u32x16"]],["f32x16"]]],[11,"from_bits","","",48,[[["i32x16"]],["f32x16"]]],[11,"from_bits","","",48,[[["m1x16"]],["f32x16"]]],[11,"from_bits","","",48,[[["u16x32"]],["f32x16"]]],[11,"from_bits","","",48,[[["i16x32"]],["f32x16"]]],[11,"from_bits","","",48,[[["m1x32"]],["f32x16"]]],[11,"from_bits","","",48,[[["i8x64"]],["f32x16"]]],[11,"from_bits","","",48,[[["u8x64"]],["f32x16"]]],[11,"from_bits","","",48,[[["m1x64"]],["f32x16"]]],[11,"from_bits","","",50,[[["u64x8"]],["i64x8"]]],[11,"from_bits","","",50,[[["f64x8"]],["i64x8"]]],[11,"from_bits","","",50,[[["m1x8"]],["i64x8"]]],[11,"from_bits","","",50,[[["u32x16"]],["i64x8"]]],[11,"from_bits","","",50,[[["i32x16"]],["i64x8"]]],[11,"from_bits","","",50,[[["f32x16"]],["i64x8"]]],[11,"from_bits","","",50,[[["m1x16"]],["i64x8"]]],[11,"from_bits","","",50,[[["u16x32"]],["i64x8"]]],[11,"from_bits","","",50,[[["i16x32"]],["i64x8"]]],[11,"from_bits","","",50,[[["m1x32"]],["i64x8"]]],[11,"from_bits","","",50,[[["i8x64"]],["i64x8"]]],[11,"from_bits","","",50,[[["u8x64"]],["i64x8"]]],[11,"from_bits","","",50,[[["m1x64"]],["i64x8"]]],[11,"from_bits","","",51,[[["i64x8"]],["u64x8"]]],[11,"from_bits","","",51,[[["f64x8"]],["u64x8"]]],[11,"from_bits","","",51,[[["m1x8"]],["u64x8"]]],[11,"from_bits","","",51,[[["u32x16"]],["u64x8"]]],[11,"from_bits","","",51,[[["i32x16"]],["u64x8"]]],[11,"from_bits","","",51,[[["f32x16"]],["u64x8"]]],[11,"from_bits","","",51,[[["m1x16"]],["u64x8"]]],[11,"from_bits","","",51,[[["u16x32"]],["u64x8"]]],[11,"from_bits","","",51,[[["i16x32"]],["u64x8"]]],[11,"from_bits","","",51,[[["m1x32"]],["u64x8"]]],[11,"from_bits","","",51,[[["i8x64"]],["u64x8"]]],[11,"from_bits","","",51,[[["u8x64"]],["u64x8"]]],[11,"from_bits","","",51,[[["m1x64"]],["u64x8"]]],[11,"from_bits","","",52,[[["u64x8"]],["f64x8"]]],[11,"from_bits","","",52,[[["i64x8"]],["f64x8"]]],[11,"from_bits","","",52,[[["m1x8"]],["f64x8"]]],[11,"from_bits","","",52,[[["u32x16"]],["f64x8"]]],[11,"from_bits","","",52,[[["i32x16"]],["f64x8"]]],[11,"from_bits","","",52,[[["f32x16"]],["f64x8"]]],[11,"from_bits","","",52,[[["m1x16"]],["f64x8"]]],[11,"from_bits","","",52,[[["u16x32"]],["f64x8"]]],[11,"from_bits","","",52,[[["i16x32"]],["f64x8"]]],[11,"from_bits","","",52,[[["m1x32"]],["f64x8"]]],[11,"from_bits","","",52,[[["i8x64"]],["f64x8"]]],[11,"from_bits","","",52,[[["u8x64"]],["f64x8"]]],[11,"from_bits","","",52,[[["m1x64"]],["f64x8"]]],[11,"from","","",52,[[["u64x8"]],["f64x8"]]],[11,"from","","",52,[[["i64x8"]],["f64x8"]]],[11,"from","","",52,[[["m1x8"]],["f64x8"]]],[11,"from","","",52,[[["u32x8"]],["f64x8"]]],[11,"from","","",52,[[["i32x8"]],["f64x8"]]],[11,"from","","",52,[[["f32x8"]],["f64x8"]]],[11,"from","","",52,[[["m32x8"]],["f64x8"]]],[11,"from","","",52,[[["u16x8"]],["f64x8"]]],[11,"from","","",52,[[["i16x8"]],["f64x8"]]],[11,"from","","",52,[[["m16x8"]],["f64x8"]]],[11,"from","","",52,[[["u8x8"]],["f64x8"]]],[11,"from","","",52,[[["i8x8"]],["f64x8"]]],[11,"from","","",52,[[["m8x8"]],["f64x8"]]],[11,"from","","",50,[[["u64x8"]],["i64x8"]]],[11,"from","","",50,[[["f64x8"]],["i64x8"]]],[11,"from","","",50,[[["m1x8"]],["i64x8"]]],[11,"from","","",50,[[["u32x8"]],["i64x8"]]],[11,"from","","",50,[[["i32x8"]],["i64x8"]]],[11,"from","","",50,[[["f32x8"]],["i64x8"]]],[11,"from","","",50,[[["m32x8"]],["i64x8"]]],[11,"from","","",50,[[["u16x8"]],["i64x8"]]],[11,"from","","",50,[[["i16x8"]],["i64x8"]]],[11,"from","","",50,[[["m16x8"]],["i64x8"]]],[11,"from","","",50,[[["u8x8"]],["i64x8"]]],[11,"from","","",50,[[["i8x8"]],["i64x8"]]],[11,"from","","",50,[[["m8x8"]],["i64x8"]]],[11,"from","","",51,[[["i64x8"]],["u64x8"]]],[11,"from","","",51,[[["f64x8"]],["u64x8"]]],[11,"from","","",51,[[["m1x8"]],["u64x8"]]],[11,"from","","",51,[[["u32x8"]],["u64x8"]]],[11,"from","","",51,[[["i32x8"]],["u64x8"]]],[11,"from","","",51,[[["f32x8"]],["u64x8"]]],[11,"from","","",51,[[["m32x8"]],["u64x8"]]],[11,"from","","",51,[[["u16x8"]],["u64x8"]]],[11,"from","","",51,[[["i16x8"]],["u64x8"]]],[11,"from","","",51,[[["m16x8"]],["u64x8"]]],[11,"from","","",51,[[["u8x8"]],["u64x8"]]],[11,"from","","",51,[[["i8x8"]],["u64x8"]]],[11,"from","","",51,[[["m8x8"]],["u64x8"]]],[11,"from","","",48,[[["u32x16"]],["f32x16"]]],[11,"from","","",48,[[["i32x16"]],["f32x16"]]],[11,"from","","",48,[[["m1x16"]],["f32x16"]]],[11,"from","","",48,[[["u16x16"]],["f32x16"]]],[11,"from","","",48,[[["i16x16"]],["f32x16"]]],[11,"from","","",48,[[["m16x16"]],["f32x16"]]],[11,"from","","",48,[[["u8x16"]],["f32x16"]]],[11,"from","","",48,[[["i8x16"]],["f32x16"]]],[11,"from","","",48,[[["m8x16"]],["f32x16"]]],[11,"from","","",46,[[["u32x16"]],["i32x16"]]],[11,"from","","",46,[[["f32x16"]],["i32x16"]]],[11,"from","","",46,[[["m1x16"]],["i32x16"]]],[11,"from","","",46,[[["u16x16"]],["i32x16"]]],[11,"from","","",46,[[["i16x16"]],["i32x16"]]],[11,"from","","",46,[[["m16x16"]],["i32x16"]]],[11,"from","","",46,[[["u8x16"]],["i32x16"]]],[11,"from","","",46,[[["i8x16"]],["i32x16"]]],[11,"from","","",46,[[["m8x16"]],["i32x16"]]],[11,"from","","",47,[[["i32x16"]],["u32x16"]]],[11,"from","","",47,[[["f32x16"]],["u32x16"]]],[11,"from","","",47,[[["m1x16"]],["u32x16"]]],[11,"from","","",47,[[["u16x16"]],["u32x16"]]],[11,"from","","",47,[[["i16x16"]],["u32x16"]]],[11,"from","","",47,[[["m16x16"]],["u32x16"]]],[11,"from","","",47,[[["u8x16"]],["u32x16"]]],[11,"from","","",47,[[["i8x16"]],["u32x16"]]],[11,"from","","",47,[[["m8x16"]],["u32x16"]]],[11,"from","","",43,[[["u16x32"]],["i16x32"]]],[11,"from","","",43,[[["u8x32"]],["i16x32"]]],[11,"from","","",43,[[["i8x32"]],["i16x32"]]],[11,"from","","",43,[[["m1x32"]],["i16x32"]]],[11,"from","","",43,[[["m8x32"]],["i16x32"]]],[11,"from","","",44,[[["i16x32"]],["u16x32"]]],[11,"from","","",44,[[["u8x32"]],["u16x32"]]],[11,"from","","",44,[[["i8x32"]],["u16x32"]]],[11,"from","","",44,[[["m1x32"]],["u16x32"]]],[11,"from","","",44,[[["m8x32"]],["u16x32"]]],[11,"from","","",40,[[["u8x64"]],["i8x64"]]],[11,"from","","",40,[[["m1x64"]],["i8x64"]]],[11,"from","","",41,[[["i8x64"]],["u8x64"]]],[11,"from","","",41,[[["m1x64"]],["u8x64"]]],[11,"from","","",45,[[["m8x32"]],["m1x32"]]],[11,"from","","",49,[[["m16x16"]],["m1x16"]]],[11,"from","","",49,[[["m8x16"]],["m1x16"]]],[11,"from","","",53,[[["m32x8"]],["m1x8"]]],[11,"from","","",53,[[["m16x8"]],["m1x8"]]],[11,"from","","",53,[[["m8x8"]],["m1x8"]]],[11,"clone","","",54,[[["self"]],["i8x8"]]],[11,"fmt","","",54,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",54,[[["self"],["i8x8"]],["option",["ordering"]]]],[11,"lt","","",54,[[["self"],["i8x8"]],["bool"]]],[11,"le","","",54,[[["self"],["i8x8"]],["bool"]]],[11,"gt","","",54,[[["self"],["i8x8"]],["bool"]]],[11,"ge","","",54,[[["self"],["i8x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",54,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",54,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",54,[[["i8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",54,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",54,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",54,[[["self"],["usize"],["i8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",54,[[["self"],["usize"],["i8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",54,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",54,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",54,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",54,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",54,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",54,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",54,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",54,N],[11,"eq","","Lane-wise equality comparison.",54,[[["self"],["i8x8"]],["m8x8"]]],[11,"ne","","Lane-wise inequality comparison.",54,[[["self"],["i8x8"]],["m8x8"]]],[11,"lt","","Lane-wise less-than comparison.",54,[[["self"],["i8x8"]],["m8x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",54,[[["self"],["i8x8"]],["m8x8"]]],[11,"gt","","Lane-wise greater-than comparison.",54,[[["self"],["i8x8"]],["m8x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",54,[[["self"],["i8x8"]],["m8x8"]]],[11,"hash","","",54,[[["self"],["h"]]]],[11,"add","","",54,[[["self"],["self"]],["self"]]],[11,"sub","","",54,[[["self"],["self"]],["self"]]],[11,"mul","","",54,[[["self"],["self"]],["self"]]],[11,"div","","",54,[[["self"],["self"]],["self"]]],[11,"rem","","",54,[[["self"],["self"]],["self"]]],[11,"add_assign","","",54,[[["self"],["self"]]]],[11,"sub_assign","","",54,[[["self"],["self"]]]],[11,"mul_assign","","",54,[[["self"],["self"]]]],[11,"div_assign","","",54,[[["self"],["self"]]]],[11,"rem_assign","","",54,[[["self"],["self"]]]],[11,"add","","",54,[[["self"],["i8"]],["self"]]],[11,"sub","","",54,[[["self"],["i8"]],["self"]]],[11,"mul","","",54,[[["self"],["i8"]],["self"]]],[11,"div","","",54,[[["self"],["i8"]],["self"]]],[11,"rem","","",54,[[["self"],["i8"]],["self"]]],[11,"add_assign","","",54,[[["self"],["i8"]]]],[11,"sub_assign","","",54,[[["self"],["i8"]]]],[11,"mul_assign","","",54,[[["self"],["i8"]]]],[11,"div_assign","","",54,[[["self"],["i8"]]]],[11,"rem_assign","","",54,[[["self"],["i8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",54,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",54,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",54,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",54,[[["self"]],["i8"]]],[11,"neg","","",54,[[["self"]],["self"]]],[11,"not","","",54,[[["self"]],["self"]]],[11,"bitxor","","",54,[[["self"],["self"]],["self"]]],[11,"bitand","","",54,[[["self"],["self"]],["self"]]],[11,"bitor","","",54,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",54,[[["self"],["self"]]]],[11,"bitor_assign","","",54,[[["self"],["self"]]]],[11,"bitxor_assign","","",54,[[["self"],["self"]]]],[11,"bitxor","","",54,[[["self"],["i8"]],["self"]]],[11,"bitand","","",54,[[["self"],["i8"]],["self"]]],[11,"bitor","","",54,[[["self"],["i8"]],["self"]]],[11,"bitand_assign","","",54,[[["self"],["i8"]]]],[11,"bitor_assign","","",54,[[["self"],["i8"]]]],[11,"bitxor_assign","","",54,[[["self"],["i8"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",54,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",54,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",54,[[["self"]],["i8"]]],[11,"shl","","",54,[[["self"],["u8"]],["self"]]],[11,"shr","","",54,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["u8"]]]],[11,"shr_assign","","",54,[[["self"],["u8"]]]],[11,"shl","","",54,[[["self"],["u16"]],["self"]]],[11,"shr","","",54,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["u16"]]]],[11,"shr_assign","","",54,[[["self"],["u16"]]]],[11,"shl","","",54,[[["self"],["u32"]],["self"]]],[11,"shr","","",54,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["u32"]]]],[11,"shr_assign","","",54,[[["self"],["u32"]]]],[11,"shl","","",54,[[["self"],["u64"]],["self"]]],[11,"shr","","",54,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["u64"]]]],[11,"shr_assign","","",54,[[["self"],["u64"]]]],[11,"shl","","",54,[[["self"],["usize"]],["self"]]],[11,"shr","","",54,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["usize"]]]],[11,"shr_assign","","",54,[[["self"],["usize"]]]],[11,"shl","","",54,[[["self"],["i8"]],["self"]]],[11,"shr","","",54,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["i8"]]]],[11,"shr_assign","","",54,[[["self"],["i8"]]]],[11,"shl","","",54,[[["self"],["i16"]],["self"]]],[11,"shr","","",54,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["i16"]]]],[11,"shr_assign","","",54,[[["self"],["i16"]]]],[11,"shl","","",54,[[["self"],["i32"]],["self"]]],[11,"shr","","",54,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["i32"]]]],[11,"shr_assign","","",54,[[["self"],["i32"]]]],[11,"shl","","",54,[[["self"],["i64"]],["self"]]],[11,"shr","","",54,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["i64"]]]],[11,"shr_assign","","",54,[[["self"],["i64"]]]],[11,"shl","","",54,[[["self"],["isize"]],["self"]]],[11,"shr","","",54,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["isize"]]]],[11,"shr_assign","","",54,[[["self"],["isize"]]]],[11,"shl","","",54,[[["self"],["self"]],["self"]]],[11,"shr","","",54,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",54,[[["self"],["self"]]]],[11,"shr_assign","","",54,[[["self"],["self"]]]],[11,"fmt","","",54,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",54,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",54,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",54,[[["self"],["formatter"]],["result"]]],[11,"eq","","",54,[[["self"],["self"]],["bool"]]],[11,"ne","","",54,[[["self"],["self"]],["bool"]]],[11,"default","","",54,[[],["self"]]],[11,"min","","Minimum of two vectors.",54,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",54,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",54,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",54,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",54,[[["self"]],["self"]]],[11,"clone","","",55,[[["self"]],["u8x8"]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",55,[[["self"],["u8x8"]],["option",["ordering"]]]],[11,"lt","","",55,[[["self"],["u8x8"]],["bool"]]],[11,"le","","",55,[[["self"],["u8x8"]],["bool"]]],[11,"gt","","",55,[[["self"],["u8x8"]],["bool"]]],[11,"ge","","",55,[[["self"],["u8x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",55,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",55,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",55,[[["u8"]],["self"]]],[11,"extract","","Extracts the value at `index`.",55,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",55,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",55,[[["self"],["usize"],["u8"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",55,[[["self"],["usize"],["u8"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",55,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",55,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",55,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",55,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"eq","","Lane-wise equality comparison.",55,[[["self"],["u8x8"]],["m8x8"]]],[11,"ne","","Lane-wise inequality comparison.",55,[[["self"],["u8x8"]],["m8x8"]]],[11,"lt","","Lane-wise less-than comparison.",55,[[["self"],["u8x8"]],["m8x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",55,[[["self"],["u8x8"]],["m8x8"]]],[11,"gt","","Lane-wise greater-than comparison.",55,[[["self"],["u8x8"]],["m8x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",55,[[["self"],["u8x8"]],["m8x8"]]],[11,"hash","","",55,[[["self"],["h"]]]],[11,"add","","",55,[[["self"],["self"]],["self"]]],[11,"sub","","",55,[[["self"],["self"]],["self"]]],[11,"mul","","",55,[[["self"],["self"]],["self"]]],[11,"div","","",55,[[["self"],["self"]],["self"]]],[11,"rem","","",55,[[["self"],["self"]],["self"]]],[11,"add_assign","","",55,[[["self"],["self"]]]],[11,"sub_assign","","",55,[[["self"],["self"]]]],[11,"mul_assign","","",55,[[["self"],["self"]]]],[11,"div_assign","","",55,[[["self"],["self"]]]],[11,"rem_assign","","",55,[[["self"],["self"]]]],[11,"add","","",55,[[["self"],["u8"]],["self"]]],[11,"sub","","",55,[[["self"],["u8"]],["self"]]],[11,"mul","","",55,[[["self"],["u8"]],["self"]]],[11,"div","","",55,[[["self"],["u8"]],["self"]]],[11,"rem","","",55,[[["self"],["u8"]],["self"]]],[11,"add_assign","","",55,[[["self"],["u8"]]]],[11,"sub_assign","","",55,[[["self"],["u8"]]]],[11,"mul_assign","","",55,[[["self"],["u8"]]]],[11,"div_assign","","",55,[[["self"],["u8"]]]],[11,"rem_assign","","",55,[[["self"],["u8"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",55,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",55,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",55,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",55,[[["self"]],["u8"]]],[11,"bitxor","","",55,[[["self"],["u8"]],["self"]]],[11,"bitand","","",55,[[["self"],["u8"]],["self"]]],[11,"bitor","","",55,[[["self"],["u8"]],["self"]]],[11,"bitand_assign","","",55,[[["self"],["u8"]]]],[11,"bitor_assign","","",55,[[["self"],["u8"]]]],[11,"bitxor_assign","","",55,[[["self"],["u8"]]]],[11,"not","","",55,[[["self"]],["self"]]],[11,"bitxor","","",55,[[["self"],["self"]],["self"]]],[11,"bitand","","",55,[[["self"],["self"]],["self"]]],[11,"bitor","","",55,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",55,[[["self"],["self"]]]],[11,"bitor_assign","","",55,[[["self"],["self"]]]],[11,"bitxor_assign","","",55,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",55,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",55,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",55,[[["self"]],["u8"]]],[11,"shl","","",55,[[["self"],["u8"]],["self"]]],[11,"shr","","",55,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["u8"]]]],[11,"shr_assign","","",55,[[["self"],["u8"]]]],[11,"shl","","",55,[[["self"],["u16"]],["self"]]],[11,"shr","","",55,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["u16"]]]],[11,"shr_assign","","",55,[[["self"],["u16"]]]],[11,"shl","","",55,[[["self"],["u32"]],["self"]]],[11,"shr","","",55,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["u32"]]]],[11,"shr_assign","","",55,[[["self"],["u32"]]]],[11,"shl","","",55,[[["self"],["u64"]],["self"]]],[11,"shr","","",55,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["u64"]]]],[11,"shr_assign","","",55,[[["self"],["u64"]]]],[11,"shl","","",55,[[["self"],["usize"]],["self"]]],[11,"shr","","",55,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["usize"]]]],[11,"shr_assign","","",55,[[["self"],["usize"]]]],[11,"shl","","",55,[[["self"],["i8"]],["self"]]],[11,"shr","","",55,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["i8"]]]],[11,"shr_assign","","",55,[[["self"],["i8"]]]],[11,"shl","","",55,[[["self"],["i16"]],["self"]]],[11,"shr","","",55,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["i16"]]]],[11,"shr_assign","","",55,[[["self"],["i16"]]]],[11,"shl","","",55,[[["self"],["i32"]],["self"]]],[11,"shr","","",55,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["i32"]]]],[11,"shr_assign","","",55,[[["self"],["i32"]]]],[11,"shl","","",55,[[["self"],["i64"]],["self"]]],[11,"shr","","",55,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["i64"]]]],[11,"shr_assign","","",55,[[["self"],["i64"]]]],[11,"shl","","",55,[[["self"],["isize"]],["self"]]],[11,"shr","","",55,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["isize"]]]],[11,"shr_assign","","",55,[[["self"],["isize"]]]],[11,"shl","","",55,[[["self"],["self"]],["self"]]],[11,"shr","","",55,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",55,[[["self"],["self"]]]],[11,"shr_assign","","",55,[[["self"],["self"]]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result"]]],[11,"eq","","",55,[[["self"],["self"]],["bool"]]],[11,"ne","","",55,[[["self"],["self"]],["bool"]]],[11,"default","","",55,[[],["self"]]],[11,"min","","Minimum of two vectors.",55,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",55,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",55,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",55,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",55,[[["self"]],["self"]]],[11,"clone","","",56,[[["self"]],["m8x8"]]],[11,"fmt","","",56,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",56,[[["self"],["m8x8"]],["option",["ordering"]]]],[11,"lt","","",56,[[["self"],["m8x8"]],["bool"]]],[11,"le","","",56,[[["self"],["m8x8"]],["bool"]]],[11,"gt","","",56,[[["self"],["m8x8"]],["bool"]]],[11,"ge","","",56,[[["self"],["m8x8"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",56,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",56,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",56,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",56,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",56,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",56,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",56,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",56,[[["self"]],["self"]]],[11,"bitxor","","",56,[[["self"],["self"]],["self"]]],[11,"bitand","","",56,[[["self"],["self"]],["self"]]],[11,"bitor","","",56,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",56,[[["self"],["self"]]]],[11,"bitor_assign","","",56,[[["self"],["self"]]]],[11,"bitxor_assign","","",56,[[["self"],["self"]]]],[11,"bitxor","","",56,[[["self"],["bool"]],["self"]]],[11,"bitand","","",56,[[["self"],["bool"]],["self"]]],[11,"bitor","","",56,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",56,[[["self"],["bool"]]]],[11,"bitor_assign","","",56,[[["self"],["bool"]]]],[11,"bitxor_assign","","",56,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",56,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",56,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",56,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",56,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",56,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",56,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",56,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",56,[[["self"],["m8x8"]],["m8x8"]]],[11,"ne","","Lane-wise inequality comparison.",56,[[["self"],["m8x8"]],["m8x8"]]],[11,"lt","","Lane-wise less-than comparison.",56,[[["self"],["m8x8"]],["m8x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",56,[[["self"],["m8x8"]],["m8x8"]]],[11,"gt","","Lane-wise greater-than comparison.",56,[[["self"],["m8x8"]],["m8x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",56,[[["self"],["m8x8"]],["m8x8"]]],[11,"eq","","",56,[[["self"],["self"]],["bool"]]],[11,"ne","","",56,[[["self"],["self"]],["bool"]]],[11,"default","","",56,[[],["self"]]],[11,"clone","","",57,[[["self"]],["i16x4"]]],[11,"fmt","","",57,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",57,[[["self"],["i16x4"]],["option",["ordering"]]]],[11,"lt","","",57,[[["self"],["i16x4"]],["bool"]]],[11,"le","","",57,[[["self"],["i16x4"]],["bool"]]],[11,"gt","","",57,[[["self"],["i16x4"]],["bool"]]],[11,"ge","","",57,[[["self"],["i16x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",57,[[["i16"],["i16"],["i16"],["i16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",57,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",57,[[["i16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",57,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",57,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",57,[[["self"],["usize"],["i16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",57,[[["self"],["usize"],["i16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",57,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",57,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",57,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",57,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"eq","","Lane-wise equality comparison.",57,[[["self"],["i16x4"]],["m16x4"]]],[11,"ne","","Lane-wise inequality comparison.",57,[[["self"],["i16x4"]],["m16x4"]]],[11,"lt","","Lane-wise less-than comparison.",57,[[["self"],["i16x4"]],["m16x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",57,[[["self"],["i16x4"]],["m16x4"]]],[11,"gt","","Lane-wise greater-than comparison.",57,[[["self"],["i16x4"]],["m16x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",57,[[["self"],["i16x4"]],["m16x4"]]],[11,"hash","","",57,[[["self"],["h"]]]],[11,"add","","",57,[[["self"],["self"]],["self"]]],[11,"sub","","",57,[[["self"],["self"]],["self"]]],[11,"mul","","",57,[[["self"],["self"]],["self"]]],[11,"div","","",57,[[["self"],["self"]],["self"]]],[11,"rem","","",57,[[["self"],["self"]],["self"]]],[11,"add_assign","","",57,[[["self"],["self"]]]],[11,"sub_assign","","",57,[[["self"],["self"]]]],[11,"mul_assign","","",57,[[["self"],["self"]]]],[11,"div_assign","","",57,[[["self"],["self"]]]],[11,"rem_assign","","",57,[[["self"],["self"]]]],[11,"add","","",57,[[["self"],["i16"]],["self"]]],[11,"sub","","",57,[[["self"],["i16"]],["self"]]],[11,"mul","","",57,[[["self"],["i16"]],["self"]]],[11,"div","","",57,[[["self"],["i16"]],["self"]]],[11,"rem","","",57,[[["self"],["i16"]],["self"]]],[11,"add_assign","","",57,[[["self"],["i16"]]]],[11,"sub_assign","","",57,[[["self"],["i16"]]]],[11,"mul_assign","","",57,[[["self"],["i16"]]]],[11,"div_assign","","",57,[[["self"],["i16"]]]],[11,"rem_assign","","",57,[[["self"],["i16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",57,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",57,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",57,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",57,[[["self"]],["i16"]]],[11,"neg","","",57,[[["self"]],["self"]]],[11,"not","","",57,[[["self"]],["self"]]],[11,"bitxor","","",57,[[["self"],["self"]],["self"]]],[11,"bitand","","",57,[[["self"],["self"]],["self"]]],[11,"bitor","","",57,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",57,[[["self"],["self"]]]],[11,"bitor_assign","","",57,[[["self"],["self"]]]],[11,"bitxor_assign","","",57,[[["self"],["self"]]]],[11,"bitxor","","",57,[[["self"],["i16"]],["self"]]],[11,"bitand","","",57,[[["self"],["i16"]],["self"]]],[11,"bitor","","",57,[[["self"],["i16"]],["self"]]],[11,"bitand_assign","","",57,[[["self"],["i16"]]]],[11,"bitor_assign","","",57,[[["self"],["i16"]]]],[11,"bitxor_assign","","",57,[[["self"],["i16"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",57,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",57,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",57,[[["self"]],["i16"]]],[11,"shl","","",57,[[["self"],["u8"]],["self"]]],[11,"shr","","",57,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["u8"]]]],[11,"shr_assign","","",57,[[["self"],["u8"]]]],[11,"shl","","",57,[[["self"],["u16"]],["self"]]],[11,"shr","","",57,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["u16"]]]],[11,"shr_assign","","",57,[[["self"],["u16"]]]],[11,"shl","","",57,[[["self"],["u32"]],["self"]]],[11,"shr","","",57,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["u32"]]]],[11,"shr_assign","","",57,[[["self"],["u32"]]]],[11,"shl","","",57,[[["self"],["u64"]],["self"]]],[11,"shr","","",57,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["u64"]]]],[11,"shr_assign","","",57,[[["self"],["u64"]]]],[11,"shl","","",57,[[["self"],["usize"]],["self"]]],[11,"shr","","",57,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["usize"]]]],[11,"shr_assign","","",57,[[["self"],["usize"]]]],[11,"shl","","",57,[[["self"],["i8"]],["self"]]],[11,"shr","","",57,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["i8"]]]],[11,"shr_assign","","",57,[[["self"],["i8"]]]],[11,"shl","","",57,[[["self"],["i16"]],["self"]]],[11,"shr","","",57,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["i16"]]]],[11,"shr_assign","","",57,[[["self"],["i16"]]]],[11,"shl","","",57,[[["self"],["i32"]],["self"]]],[11,"shr","","",57,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["i32"]]]],[11,"shr_assign","","",57,[[["self"],["i32"]]]],[11,"shl","","",57,[[["self"],["i64"]],["self"]]],[11,"shr","","",57,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["i64"]]]],[11,"shr_assign","","",57,[[["self"],["i64"]]]],[11,"shl","","",57,[[["self"],["isize"]],["self"]]],[11,"shr","","",57,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["isize"]]]],[11,"shr_assign","","",57,[[["self"],["isize"]]]],[11,"shl","","",57,[[["self"],["self"]],["self"]]],[11,"shr","","",57,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",57,[[["self"],["self"]]]],[11,"shr_assign","","",57,[[["self"],["self"]]]],[11,"fmt","","",57,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",57,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",57,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",57,[[["self"],["formatter"]],["result"]]],[11,"eq","","",57,[[["self"],["self"]],["bool"]]],[11,"ne","","",57,[[["self"],["self"]],["bool"]]],[11,"default","","",57,[[],["self"]]],[11,"min","","Minimum of two vectors.",57,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",57,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",57,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",57,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",57,[[["self"]],["self"]]],[11,"clone","","",58,[[["self"]],["u16x4"]]],[11,"fmt","","",58,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",58,[[["self"],["u16x4"]],["option",["ordering"]]]],[11,"lt","","",58,[[["self"],["u16x4"]],["bool"]]],[11,"le","","",58,[[["self"],["u16x4"]],["bool"]]],[11,"gt","","",58,[[["self"],["u16x4"]],["bool"]]],[11,"ge","","",58,[[["self"],["u16x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",58,[[["u16"],["u16"],["u16"],["u16"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",58,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",58,[[["u16"]],["self"]]],[11,"extract","","Extracts the value at `index`.",58,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",58,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",58,[[["self"],["usize"],["u16"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",58,[[["self"],["usize"],["u16"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",58,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",58,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",58,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",58,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"eq","","Lane-wise equality comparison.",58,[[["self"],["u16x4"]],["m16x4"]]],[11,"ne","","Lane-wise inequality comparison.",58,[[["self"],["u16x4"]],["m16x4"]]],[11,"lt","","Lane-wise less-than comparison.",58,[[["self"],["u16x4"]],["m16x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",58,[[["self"],["u16x4"]],["m16x4"]]],[11,"gt","","Lane-wise greater-than comparison.",58,[[["self"],["u16x4"]],["m16x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",58,[[["self"],["u16x4"]],["m16x4"]]],[11,"hash","","",58,[[["self"],["h"]]]],[11,"add","","",58,[[["self"],["self"]],["self"]]],[11,"sub","","",58,[[["self"],["self"]],["self"]]],[11,"mul","","",58,[[["self"],["self"]],["self"]]],[11,"div","","",58,[[["self"],["self"]],["self"]]],[11,"rem","","",58,[[["self"],["self"]],["self"]]],[11,"add_assign","","",58,[[["self"],["self"]]]],[11,"sub_assign","","",58,[[["self"],["self"]]]],[11,"mul_assign","","",58,[[["self"],["self"]]]],[11,"div_assign","","",58,[[["self"],["self"]]]],[11,"rem_assign","","",58,[[["self"],["self"]]]],[11,"add","","",58,[[["self"],["u16"]],["self"]]],[11,"sub","","",58,[[["self"],["u16"]],["self"]]],[11,"mul","","",58,[[["self"],["u16"]],["self"]]],[11,"div","","",58,[[["self"],["u16"]],["self"]]],[11,"rem","","",58,[[["self"],["u16"]],["self"]]],[11,"add_assign","","",58,[[["self"],["u16"]]]],[11,"sub_assign","","",58,[[["self"],["u16"]]]],[11,"mul_assign","","",58,[[["self"],["u16"]]]],[11,"div_assign","","",58,[[["self"],["u16"]]]],[11,"rem_assign","","",58,[[["self"],["u16"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",58,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",58,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",58,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",58,[[["self"]],["u16"]]],[11,"bitxor","","",58,[[["self"],["u16"]],["self"]]],[11,"bitand","","",58,[[["self"],["u16"]],["self"]]],[11,"bitor","","",58,[[["self"],["u16"]],["self"]]],[11,"bitand_assign","","",58,[[["self"],["u16"]]]],[11,"bitor_assign","","",58,[[["self"],["u16"]]]],[11,"bitxor_assign","","",58,[[["self"],["u16"]]]],[11,"not","","",58,[[["self"]],["self"]]],[11,"bitxor","","",58,[[["self"],["self"]],["self"]]],[11,"bitand","","",58,[[["self"],["self"]],["self"]]],[11,"bitor","","",58,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",58,[[["self"],["self"]]]],[11,"bitor_assign","","",58,[[["self"],["self"]]]],[11,"bitxor_assign","","",58,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",58,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",58,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",58,[[["self"]],["u16"]]],[11,"shl","","",58,[[["self"],["u8"]],["self"]]],[11,"shr","","",58,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["u8"]]]],[11,"shr_assign","","",58,[[["self"],["u8"]]]],[11,"shl","","",58,[[["self"],["u16"]],["self"]]],[11,"shr","","",58,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["u16"]]]],[11,"shr_assign","","",58,[[["self"],["u16"]]]],[11,"shl","","",58,[[["self"],["u32"]],["self"]]],[11,"shr","","",58,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["u32"]]]],[11,"shr_assign","","",58,[[["self"],["u32"]]]],[11,"shl","","",58,[[["self"],["u64"]],["self"]]],[11,"shr","","",58,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["u64"]]]],[11,"shr_assign","","",58,[[["self"],["u64"]]]],[11,"shl","","",58,[[["self"],["usize"]],["self"]]],[11,"shr","","",58,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["usize"]]]],[11,"shr_assign","","",58,[[["self"],["usize"]]]],[11,"shl","","",58,[[["self"],["i8"]],["self"]]],[11,"shr","","",58,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["i8"]]]],[11,"shr_assign","","",58,[[["self"],["i8"]]]],[11,"shl","","",58,[[["self"],["i16"]],["self"]]],[11,"shr","","",58,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["i16"]]]],[11,"shr_assign","","",58,[[["self"],["i16"]]]],[11,"shl","","",58,[[["self"],["i32"]],["self"]]],[11,"shr","","",58,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["i32"]]]],[11,"shr_assign","","",58,[[["self"],["i32"]]]],[11,"shl","","",58,[[["self"],["i64"]],["self"]]],[11,"shr","","",58,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["i64"]]]],[11,"shr_assign","","",58,[[["self"],["i64"]]]],[11,"shl","","",58,[[["self"],["isize"]],["self"]]],[11,"shr","","",58,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["isize"]]]],[11,"shr_assign","","",58,[[["self"],["isize"]]]],[11,"shl","","",58,[[["self"],["self"]],["self"]]],[11,"shr","","",58,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",58,[[["self"],["self"]]]],[11,"shr_assign","","",58,[[["self"],["self"]]]],[11,"fmt","","",58,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",58,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",58,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",58,[[["self"],["formatter"]],["result"]]],[11,"eq","","",58,[[["self"],["self"]],["bool"]]],[11,"ne","","",58,[[["self"],["self"]],["bool"]]],[11,"default","","",58,[[],["self"]]],[11,"min","","Minimum of two vectors.",58,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",58,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",58,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",58,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",58,[[["self"]],["self"]]],[11,"clone","","",59,[[["self"]],["m16x4"]]],[11,"fmt","","",59,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",59,[[["self"],["m16x4"]],["option",["ordering"]]]],[11,"lt","","",59,[[["self"],["m16x4"]],["bool"]]],[11,"le","","",59,[[["self"],["m16x4"]],["bool"]]],[11,"gt","","",59,[[["self"],["m16x4"]],["bool"]]],[11,"ge","","",59,[[["self"],["m16x4"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",59,[[["bool"],["bool"],["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",59,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",59,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",59,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",59,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",59,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",59,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",59,[[["self"]],["self"]]],[11,"bitxor","","",59,[[["self"],["self"]],["self"]]],[11,"bitand","","",59,[[["self"],["self"]],["self"]]],[11,"bitor","","",59,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",59,[[["self"],["self"]]]],[11,"bitor_assign","","",59,[[["self"],["self"]]]],[11,"bitxor_assign","","",59,[[["self"],["self"]]]],[11,"bitxor","","",59,[[["self"],["bool"]],["self"]]],[11,"bitand","","",59,[[["self"],["bool"]],["self"]]],[11,"bitor","","",59,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",59,[[["self"],["bool"]]]],[11,"bitor_assign","","",59,[[["self"],["bool"]]]],[11,"bitxor_assign","","",59,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",59,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",59,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",59,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",59,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",59,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",59,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",59,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",59,[[["self"],["m16x4"]],["m16x4"]]],[11,"ne","","Lane-wise inequality comparison.",59,[[["self"],["m16x4"]],["m16x4"]]],[11,"lt","","Lane-wise less-than comparison.",59,[[["self"],["m16x4"]],["m16x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",59,[[["self"],["m16x4"]],["m16x4"]]],[11,"gt","","Lane-wise greater-than comparison.",59,[[["self"],["m16x4"]],["m16x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",59,[[["self"],["m16x4"]],["m16x4"]]],[11,"eq","","",59,[[["self"],["self"]],["bool"]]],[11,"ne","","",59,[[["self"],["self"]],["bool"]]],[11,"default","","",59,[[],["self"]]],[11,"clone","","",60,[[["self"]],["i32x2"]]],[11,"fmt","","",60,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",60,[[["self"],["i32x2"]],["option",["ordering"]]]],[11,"lt","","",60,[[["self"],["i32x2"]],["bool"]]],[11,"le","","",60,[[["self"],["i32x2"]],["bool"]]],[11,"gt","","",60,[[["self"],["i32x2"]],["bool"]]],[11,"ge","","",60,[[["self"],["i32x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",60,[[["i32"],["i32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",60,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",60,[[["i32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",60,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",60,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",60,[[["self"],["usize"],["i32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",60,[[["self"],["usize"],["i32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",60,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",60,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",60,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",60,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"eq","","Lane-wise equality comparison.",60,[[["self"],["i32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",60,[[["self"],["i32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",60,[[["self"],["i32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",60,[[["self"],["i32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",60,[[["self"],["i32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",60,[[["self"],["i32x2"]],["m32x2"]]],[11,"hash","","",60,[[["self"],["h"]]]],[11,"add","","",60,[[["self"],["self"]],["self"]]],[11,"sub","","",60,[[["self"],["self"]],["self"]]],[11,"mul","","",60,[[["self"],["self"]],["self"]]],[11,"div","","",60,[[["self"],["self"]],["self"]]],[11,"rem","","",60,[[["self"],["self"]],["self"]]],[11,"add_assign","","",60,[[["self"],["self"]]]],[11,"sub_assign","","",60,[[["self"],["self"]]]],[11,"mul_assign","","",60,[[["self"],["self"]]]],[11,"div_assign","","",60,[[["self"],["self"]]]],[11,"rem_assign","","",60,[[["self"],["self"]]]],[11,"add","","",60,[[["self"],["i32"]],["self"]]],[11,"sub","","",60,[[["self"],["i32"]],["self"]]],[11,"mul","","",60,[[["self"],["i32"]],["self"]]],[11,"div","","",60,[[["self"],["i32"]],["self"]]],[11,"rem","","",60,[[["self"],["i32"]],["self"]]],[11,"add_assign","","",60,[[["self"],["i32"]]]],[11,"sub_assign","","",60,[[["self"],["i32"]]]],[11,"mul_assign","","",60,[[["self"],["i32"]]]],[11,"div_assign","","",60,[[["self"],["i32"]]]],[11,"rem_assign","","",60,[[["self"],["i32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",60,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",60,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",60,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",60,[[["self"]],["i32"]]],[11,"neg","","",60,[[["self"]],["self"]]],[11,"not","","",60,[[["self"]],["self"]]],[11,"bitxor","","",60,[[["self"],["self"]],["self"]]],[11,"bitand","","",60,[[["self"],["self"]],["self"]]],[11,"bitor","","",60,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",60,[[["self"],["self"]]]],[11,"bitor_assign","","",60,[[["self"],["self"]]]],[11,"bitxor_assign","","",60,[[["self"],["self"]]]],[11,"bitxor","","",60,[[["self"],["i32"]],["self"]]],[11,"bitand","","",60,[[["self"],["i32"]],["self"]]],[11,"bitor","","",60,[[["self"],["i32"]],["self"]]],[11,"bitand_assign","","",60,[[["self"],["i32"]]]],[11,"bitor_assign","","",60,[[["self"],["i32"]]]],[11,"bitxor_assign","","",60,[[["self"],["i32"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",60,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",60,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",60,[[["self"]],["i32"]]],[11,"shl","","",60,[[["self"],["u8"]],["self"]]],[11,"shr","","",60,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["u8"]]]],[11,"shr_assign","","",60,[[["self"],["u8"]]]],[11,"shl","","",60,[[["self"],["u16"]],["self"]]],[11,"shr","","",60,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["u16"]]]],[11,"shr_assign","","",60,[[["self"],["u16"]]]],[11,"shl","","",60,[[["self"],["u32"]],["self"]]],[11,"shr","","",60,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["u32"]]]],[11,"shr_assign","","",60,[[["self"],["u32"]]]],[11,"shl","","",60,[[["self"],["u64"]],["self"]]],[11,"shr","","",60,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["u64"]]]],[11,"shr_assign","","",60,[[["self"],["u64"]]]],[11,"shl","","",60,[[["self"],["usize"]],["self"]]],[11,"shr","","",60,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["usize"]]]],[11,"shr_assign","","",60,[[["self"],["usize"]]]],[11,"shl","","",60,[[["self"],["i8"]],["self"]]],[11,"shr","","",60,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["i8"]]]],[11,"shr_assign","","",60,[[["self"],["i8"]]]],[11,"shl","","",60,[[["self"],["i16"]],["self"]]],[11,"shr","","",60,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["i16"]]]],[11,"shr_assign","","",60,[[["self"],["i16"]]]],[11,"shl","","",60,[[["self"],["i32"]],["self"]]],[11,"shr","","",60,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["i32"]]]],[11,"shr_assign","","",60,[[["self"],["i32"]]]],[11,"shl","","",60,[[["self"],["i64"]],["self"]]],[11,"shr","","",60,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["i64"]]]],[11,"shr_assign","","",60,[[["self"],["i64"]]]],[11,"shl","","",60,[[["self"],["isize"]],["self"]]],[11,"shr","","",60,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["isize"]]]],[11,"shr_assign","","",60,[[["self"],["isize"]]]],[11,"shl","","",60,[[["self"],["self"]],["self"]]],[11,"shr","","",60,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",60,[[["self"],["self"]]]],[11,"shr_assign","","",60,[[["self"],["self"]]]],[11,"fmt","","",60,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",60,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",60,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",60,[[["self"],["formatter"]],["result"]]],[11,"eq","","",60,[[["self"],["self"]],["bool"]]],[11,"ne","","",60,[[["self"],["self"]],["bool"]]],[11,"default","","",60,[[],["self"]]],[11,"min","","Minimum of two vectors.",60,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",60,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",60,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",60,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",60,[[["self"]],["self"]]],[11,"clone","","",61,[[["self"]],["u32x2"]]],[11,"fmt","","",61,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",61,[[["self"],["u32x2"]],["option",["ordering"]]]],[11,"lt","","",61,[[["self"],["u32x2"]],["bool"]]],[11,"le","","",61,[[["self"],["u32x2"]],["bool"]]],[11,"gt","","",61,[[["self"],["u32x2"]],["bool"]]],[11,"ge","","",61,[[["self"],["u32x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",61,[[["u32"],["u32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",61,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",61,[[["u32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",61,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",61,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",61,[[["self"],["usize"],["u32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",61,[[["self"],["usize"],["u32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",61,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",61,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",61,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",61,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"eq","","Lane-wise equality comparison.",61,[[["self"],["u32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",61,[[["self"],["u32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",61,[[["self"],["u32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",61,[[["self"],["u32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",61,[[["self"],["u32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",61,[[["self"],["u32x2"]],["m32x2"]]],[11,"hash","","",61,[[["self"],["h"]]]],[11,"add","","",61,[[["self"],["self"]],["self"]]],[11,"sub","","",61,[[["self"],["self"]],["self"]]],[11,"mul","","",61,[[["self"],["self"]],["self"]]],[11,"div","","",61,[[["self"],["self"]],["self"]]],[11,"rem","","",61,[[["self"],["self"]],["self"]]],[11,"add_assign","","",61,[[["self"],["self"]]]],[11,"sub_assign","","",61,[[["self"],["self"]]]],[11,"mul_assign","","",61,[[["self"],["self"]]]],[11,"div_assign","","",61,[[["self"],["self"]]]],[11,"rem_assign","","",61,[[["self"],["self"]]]],[11,"add","","",61,[[["self"],["u32"]],["self"]]],[11,"sub","","",61,[[["self"],["u32"]],["self"]]],[11,"mul","","",61,[[["self"],["u32"]],["self"]]],[11,"div","","",61,[[["self"],["u32"]],["self"]]],[11,"rem","","",61,[[["self"],["u32"]],["self"]]],[11,"add_assign","","",61,[[["self"],["u32"]]]],[11,"sub_assign","","",61,[[["self"],["u32"]]]],[11,"mul_assign","","",61,[[["self"],["u32"]]]],[11,"div_assign","","",61,[[["self"],["u32"]]]],[11,"rem_assign","","",61,[[["self"],["u32"]]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",61,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",61,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",61,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",61,[[["self"]],["u32"]]],[11,"bitxor","","",61,[[["self"],["u32"]],["self"]]],[11,"bitand","","",61,[[["self"],["u32"]],["self"]]],[11,"bitor","","",61,[[["self"],["u32"]],["self"]]],[11,"bitand_assign","","",61,[[["self"],["u32"]]]],[11,"bitor_assign","","",61,[[["self"],["u32"]]]],[11,"bitxor_assign","","",61,[[["self"],["u32"]]]],[11,"not","","",61,[[["self"]],["self"]]],[11,"bitxor","","",61,[[["self"],["self"]],["self"]]],[11,"bitand","","",61,[[["self"],["self"]],["self"]]],[11,"bitor","","",61,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",61,[[["self"],["self"]]]],[11,"bitor_assign","","",61,[[["self"],["self"]]]],[11,"bitxor_assign","","",61,[[["self"],["self"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",61,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",61,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",61,[[["self"]],["u32"]]],[11,"shl","","",61,[[["self"],["u8"]],["self"]]],[11,"shr","","",61,[[["self"],["u8"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["u8"]]]],[11,"shr_assign","","",61,[[["self"],["u8"]]]],[11,"shl","","",61,[[["self"],["u16"]],["self"]]],[11,"shr","","",61,[[["self"],["u16"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["u16"]]]],[11,"shr_assign","","",61,[[["self"],["u16"]]]],[11,"shl","","",61,[[["self"],["u32"]],["self"]]],[11,"shr","","",61,[[["self"],["u32"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["u32"]]]],[11,"shr_assign","","",61,[[["self"],["u32"]]]],[11,"shl","","",61,[[["self"],["u64"]],["self"]]],[11,"shr","","",61,[[["self"],["u64"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["u64"]]]],[11,"shr_assign","","",61,[[["self"],["u64"]]]],[11,"shl","","",61,[[["self"],["usize"]],["self"]]],[11,"shr","","",61,[[["self"],["usize"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["usize"]]]],[11,"shr_assign","","",61,[[["self"],["usize"]]]],[11,"shl","","",61,[[["self"],["i8"]],["self"]]],[11,"shr","","",61,[[["self"],["i8"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["i8"]]]],[11,"shr_assign","","",61,[[["self"],["i8"]]]],[11,"shl","","",61,[[["self"],["i16"]],["self"]]],[11,"shr","","",61,[[["self"],["i16"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["i16"]]]],[11,"shr_assign","","",61,[[["self"],["i16"]]]],[11,"shl","","",61,[[["self"],["i32"]],["self"]]],[11,"shr","","",61,[[["self"],["i32"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["i32"]]]],[11,"shr_assign","","",61,[[["self"],["i32"]]]],[11,"shl","","",61,[[["self"],["i64"]],["self"]]],[11,"shr","","",61,[[["self"],["i64"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["i64"]]]],[11,"shr_assign","","",61,[[["self"],["i64"]]]],[11,"shl","","",61,[[["self"],["isize"]],["self"]]],[11,"shr","","",61,[[["self"],["isize"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["isize"]]]],[11,"shr_assign","","",61,[[["self"],["isize"]]]],[11,"shl","","",61,[[["self"],["self"]],["self"]]],[11,"shr","","",61,[[["self"],["self"]],["self"]]],[11,"shl_assign","","",61,[[["self"],["self"]]]],[11,"shr_assign","","",61,[[["self"],["self"]]]],[11,"fmt","","",61,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",61,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",61,[[["self"],["formatter"]],["result"]]],[11,"fmt","","",61,[[["self"],["formatter"]],["result"]]],[11,"eq","","",61,[[["self"],["self"]],["bool"]]],[11,"ne","","",61,[[["self"],["self"]],["bool"]]],[11,"default","","",61,[[],["self"]]],[11,"min","","Minimum of two vectors.",61,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",61,[[["self"],["self"]],["self"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",61,[[["self"]],["self"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",61,[[["self"]],["self"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",61,[[["self"]],["self"]]],[11,"clone","","",62,[[["self"]],["m32x2"]]],[11,"fmt","","",62,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",62,[[["self"],["m32x2"]],["option",["ordering"]]]],[11,"lt","","",62,[[["self"],["m32x2"]],["bool"]]],[11,"le","","",62,[[["self"],["m32x2"]],["bool"]]],[11,"gt","","",62,[[["self"],["m32x2"]],["bool"]]],[11,"ge","","",62,[[["self"],["m32x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",62,[[["bool"],["bool"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",62,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",62,[[["bool"]],["self"]]],[11,"extract","","Extracts the value at `index`.",62,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",62,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",62,[[["self"],["usize"],["bool"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",62,[[["self"],["usize"],["bool"]],["self"]]],[11,"not","","",62,[[["self"]],["self"]]],[11,"bitxor","","",62,[[["self"],["self"]],["self"]]],[11,"bitand","","",62,[[["self"],["self"]],["self"]]],[11,"bitor","","",62,[[["self"],["self"]],["self"]]],[11,"bitand_assign","","",62,[[["self"],["self"]]]],[11,"bitor_assign","","",62,[[["self"],["self"]]]],[11,"bitxor_assign","","",62,[[["self"],["self"]]]],[11,"bitxor","","",62,[[["self"],["bool"]],["self"]]],[11,"bitand","","",62,[[["self"],["bool"]],["self"]]],[11,"bitor","","",62,[[["self"],["bool"]],["self"]]],[11,"bitand_assign","","",62,[[["self"],["bool"]]]],[11,"bitor_assign","","",62,[[["self"],["bool"]]]],[11,"bitxor_assign","","",62,[[["self"],["bool"]]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",62,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",62,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",62,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",62,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",62,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",62,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",62,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",62,[[["self"],["m32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",62,[[["self"],["m32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",62,[[["self"],["m32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",62,[[["self"],["m32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",62,[[["self"],["m32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",62,[[["self"],["m32x2"]],["m32x2"]]],[11,"eq","","",62,[[["self"],["self"]],["bool"]]],[11,"ne","","",62,[[["self"],["self"]],["bool"]]],[11,"default","","",62,[[],["self"]]],[11,"clone","","",63,[[["self"]],["f32x2"]]],[11,"fmt","","",63,[[["self"],["formatter"]],["result"]]],[11,"partial_cmp","","",63,[[["self"],["f32x2"]],["option",["ordering"]]]],[11,"lt","","",63,[[["self"],["f32x2"]],["bool"]]],[11,"le","","",63,[[["self"],["f32x2"]],["bool"]]],[11,"gt","","",63,[[["self"],["f32x2"]],["bool"]]],[11,"ge","","",63,[[["self"],["f32x2"]],["bool"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",63,[[["f32"],["f32"]],["self"]]],[11,"lanes","","Returns the number of vector lanes.",63,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",63,[[["f32"]],["self"]]],[11,"extract","","Extracts the value at `index`.",63,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",63,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",63,[[["self"],["usize"],["f32"]],["self"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",63,[[["self"],["usize"],["f32"]],["self"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",63,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",63,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",63,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",63,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"eq","","Lane-wise equality comparison.",63,[[["self"],["f32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",63,[[["self"],["f32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",63,[[["self"],["f32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",63,[[["self"],["f32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",63,[[["self"],["f32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",63,[[["self"],["f32x2"]],["m32x2"]]],[11,"add","","",63,[[["self"],["self"]],["self"]]],[11,"sub","","",63,[[["self"],["self"]],["self"]]],[11,"mul","","",63,[[["self"],["self"]],["self"]]],[11,"div","","",63,[[["self"],["self"]],["self"]]],[11,"rem","","",63,[[["self"],["self"]],["self"]]],[11,"add_assign","","",63,[[["self"],["self"]]]],[11,"sub_assign","","",63,[[["self"],["self"]]]],[11,"mul_assign","","",63,[[["self"],["self"]]]],[11,"div_assign","","",63,[[["self"],["self"]]]],[11,"rem_assign","","",63,[[["self"],["self"]]]],[11,"add","","",63,[[["self"],["f32"]],["self"]]],[11,"sub","","",63,[[["self"],["f32"]],["self"]]],[11,"mul","","",63,[[["self"],["f32"]],["self"]]],[11,"div","","",63,[[["self"],["f32"]],["self"]]],[11,"rem","","",63,[[["self"],["f32"]],["self"]]],[11,"add_assign","","",63,[[["self"],["f32"]]]],[11,"sub_assign","","",63,[[["self"],["f32"]]]],[11,"mul_assign","","",63,[[["self"],["f32"]]]],[11,"div_assign","","",63,[[["self"],["f32"]]]],[11,"rem_assign","","",63,[[["self"],["f32"]]]],[11,"sum","","Horizontal sum of the vector elements.",63,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",63,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",63,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",63,[[["self"]],["f32"]]],[11,"neg","","",63,[[["self"]],["self"]]],[11,"eq","","",63,[[["self"],["self"]],["bool"]]],[11,"ne","","",63,[[["self"],["self"]],["bool"]]],[11,"default","","",63,[[],["self"]]],[11,"min","","Minimum of two vectors.",63,[[["self"],["self"]],["self"]]],[11,"max","","Maximum of two vectors.",63,[[["self"],["self"]],["self"]]],[11,"abs","","Absolute-value",63,[[["self"]],["self"]]],[11,"sqrt","","Square-root",63,[[["self"]],["self"]]],[11,"sqrte","","Square-root estimate",63,[[["self"]],["self"]]],[11,"rsqrte","","Reciprocal square-root estimate",63,[[["self"]],["self"]]],[11,"fma","","Fused multiply add: `self * y + z`",63,[[["self"],["self"],["self"]],["self"]]],[11,"sin","","Sin",63,[[["self"]],["self"]]],[11,"cos","","Cos",63,[[["self"]],["self"]]],[11,"from_bits","","",61,[[["i32x2"]],["u32x2"]]],[11,"from_bits","","",61,[[["f32x2"]],["u32x2"]]],[11,"from_bits","","",61,[[["m32x2"]],["u32x2"]]],[11,"from_bits","","",61,[[["u16x4"]],["u32x2"]]],[11,"from_bits","","",61,[[["i16x4"]],["u32x2"]]],[11,"from_bits","","",61,[[["m16x4"]],["u32x2"]]],[11,"from_bits","","",61,[[["u8x8"]],["u32x2"]]],[11,"from_bits","","",61,[[["i8x8"]],["u32x2"]]],[11,"from_bits","","",61,[[["m8x8"]],["u32x2"]]],[11,"from_bits","","",61,[[["__m64"]],["u32x2"]]],[11,"from_bits","","",60,[[["u32x2"]],["i32x2"]]],[11,"from_bits","","",60,[[["f32x2"]],["i32x2"]]],[11,"from_bits","","",60,[[["m32x2"]],["i32x2"]]],[11,"from_bits","","",60,[[["u16x4"]],["i32x2"]]],[11,"from_bits","","",60,[[["i16x4"]],["i32x2"]]],[11,"from_bits","","",60,[[["m16x4"]],["i32x2"]]],[11,"from_bits","","",60,[[["u8x8"]],["i32x2"]]],[11,"from_bits","","",60,[[["i8x8"]],["i32x2"]]],[11,"from_bits","","",60,[[["m8x8"]],["i32x2"]]],[11,"from_bits","","",60,[[["__m64"]],["i32x2"]]],[11,"from_bits","","",63,[[["i32x2"]],["f32x2"]]],[11,"from_bits","","",63,[[["u32x2"]],["f32x2"]]],[11,"from_bits","","",63,[[["m32x2"]],["f32x2"]]],[11,"from_bits","","",63,[[["u16x4"]],["f32x2"]]],[11,"from_bits","","",63,[[["i16x4"]],["f32x2"]]],[11,"from_bits","","",63,[[["m16x4"]],["f32x2"]]],[11,"from_bits","","",63,[[["u8x8"]],["f32x2"]]],[11,"from_bits","","",63,[[["i8x8"]],["f32x2"]]],[11,"from_bits","","",63,[[["m8x8"]],["f32x2"]]],[11,"from_bits","","",63,[[["__m64"]],["f32x2"]]],[11,"from_bits","","",58,[[["u32x2"]],["u16x4"]]],[11,"from_bits","","",58,[[["i32x2"]],["u16x4"]]],[11,"from_bits","","",58,[[["m32x2"]],["u16x4"]]],[11,"from_bits","","",58,[[["i16x4"]],["u16x4"]]],[11,"from_bits","","",58,[[["m16x4"]],["u16x4"]]],[11,"from_bits","","",58,[[["u8x8"]],["u16x4"]]],[11,"from_bits","","",58,[[["i8x8"]],["u16x4"]]],[11,"from_bits","","",58,[[["m8x8"]],["u16x4"]]],[11,"from_bits","","",58,[[["__m64"]],["u16x4"]]],[11,"from_bits","","",57,[[["u32x2"]],["i16x4"]]],[11,"from_bits","","",57,[[["i32x2"]],["i16x4"]]],[11,"from_bits","","",57,[[["m32x2"]],["i16x4"]]],[11,"from_bits","","",57,[[["u16x4"]],["i16x4"]]],[11,"from_bits","","",57,[[["m16x4"]],["i16x4"]]],[11,"from_bits","","",57,[[["u8x8"]],["i16x4"]]],[11,"from_bits","","",57,[[["i8x8"]],["i16x4"]]],[11,"from_bits","","",57,[[["m8x8"]],["i16x4"]]],[11,"from_bits","","",57,[[["__m64"]],["i16x4"]]],[11,"from_bits","","",55,[[["u32x2"]],["u8x8"]]],[11,"from_bits","","",55,[[["i32x2"]],["u8x8"]]],[11,"from_bits","","",55,[[["m32x2"]],["u8x8"]]],[11,"from_bits","","",55,[[["u16x4"]],["u8x8"]]],[11,"from_bits","","",55,[[["i16x4"]],["u8x8"]]],[11,"from_bits","","",55,[[["m16x4"]],["u8x8"]]],[11,"from_bits","","",55,[[["i8x8"]],["u8x8"]]],[11,"from_bits","","",55,[[["m8x8"]],["u8x8"]]],[11,"from_bits","","",55,[[["__m64"]],["u8x8"]]],[11,"from_bits","","",54,[[["u32x2"]],["i8x8"]]],[11,"from_bits","","",54,[[["i32x2"]],["i8x8"]]],[11,"from_bits","","",54,[[["m32x2"]],["i8x8"]]],[11,"from_bits","","",54,[[["u16x4"]],["i8x8"]]],[11,"from_bits","","",54,[[["i16x4"]],["i8x8"]]],[11,"from_bits","","",54,[[["m16x4"]],["i8x8"]]],[11,"from_bits","","",54,[[["u8x8"]],["i8x8"]]],[11,"from_bits","","",54,[[["m8x8"]],["i8x8"]]],[11,"from_bits","","",54,[[["__m64"]],["i8x8"]]],[11,"from","","",63,[[["f64x2"]],["f32x2"]]],[11,"from","","",63,[[["u64x2"]],["f32x2"]]],[11,"from","","",63,[[["i64x2"]],["f32x2"]]],[11,"from","","",63,[[["m64x2"]],["f32x2"]]],[11,"from","","",63,[[["u32x2"]],["f32x2"]]],[11,"from","","",63,[[["i32x2"]],["f32x2"]]],[11,"from","","",63,[[["m32x2"]],["f32x2"]]],[11,"from","","",63,[[["u16x2"]],["f32x2"]]],[11,"from","","",63,[[["i16x2"]],["f32x2"]]],[11,"from","","",63,[[["m16x2"]],["f32x2"]]],[11,"from","","",63,[[["u8x2"]],["f32x2"]]],[11,"from","","",63,[[["i8x2"]],["f32x2"]]],[11,"from","","",63,[[["m8x2"]],["f32x2"]]],[11,"from","","",61,[[["f64x2"]],["u32x2"]]],[11,"from","","",61,[[["u64x2"]],["u32x2"]]],[11,"from","","",61,[[["i64x2"]],["u32x2"]]],[11,"from","","",61,[[["m64x2"]],["u32x2"]]],[11,"from","","",61,[[["f32x2"]],["u32x2"]]],[11,"from","","",61,[[["i32x2"]],["u32x2"]]],[11,"from","","",61,[[["m32x2"]],["u32x2"]]],[11,"from","","",61,[[["u16x2"]],["u32x2"]]],[11,"from","","",61,[[["i16x2"]],["u32x2"]]],[11,"from","","",61,[[["m16x2"]],["u32x2"]]],[11,"from","","",61,[[["u8x2"]],["u32x2"]]],[11,"from","","",61,[[["i8x2"]],["u32x2"]]],[11,"from","","",61,[[["m8x2"]],["u32x2"]]],[11,"from","","",60,[[["f64x2"]],["i32x2"]]],[11,"from","","",60,[[["u64x2"]],["i32x2"]]],[11,"from","","",60,[[["i64x2"]],["i32x2"]]],[11,"from","","",60,[[["m64x2"]],["i32x2"]]],[11,"from","","",60,[[["f32x2"]],["i32x2"]]],[11,"from","","",60,[[["u32x2"]],["i32x2"]]],[11,"from","","",60,[[["m32x2"]],["i32x2"]]],[11,"from","","",60,[[["u16x2"]],["i32x2"]]],[11,"from","","",60,[[["i16x2"]],["i32x2"]]],[11,"from","","",60,[[["m16x2"]],["i32x2"]]],[11,"from","","",60,[[["u8x2"]],["i32x2"]]],[11,"from","","",60,[[["i8x2"]],["i32x2"]]],[11,"from","","",60,[[["m8x2"]],["i32x2"]]],[11,"from","","",58,[[["f64x4"]],["u16x4"]]],[11,"from","","",58,[[["u64x4"]],["u16x4"]]],[11,"from","","",58,[[["i64x4"]],["u16x4"]]],[11,"from","","",58,[[["m64x4"]],["u16x4"]]],[11,"from","","",58,[[["f32x4"]],["u16x4"]]],[11,"from","","",58,[[["i32x4"]],["u16x4"]]],[11,"from","","",58,[[["u32x4"]],["u16x4"]]],[11,"from","","",58,[[["m32x4"]],["u16x4"]]],[11,"from","","",58,[[["i16x4"]],["u16x4"]]],[11,"from","","",58,[[["m16x4"]],["u16x4"]]],[11,"from","","",58,[[["u8x4"]],["u16x4"]]],[11,"from","","",58,[[["i8x4"]],["u16x4"]]],[11,"from","","",58,[[["m8x4"]],["u16x4"]]],[11,"from","","",57,[[["f64x4"]],["i16x4"]]],[11,"from","","",57,[[["u64x4"]],["i16x4"]]],[11,"from","","",57,[[["i64x4"]],["i16x4"]]],[11,"from","","",57,[[["m64x4"]],["i16x4"]]],[11,"from","","",57,[[["f32x4"]],["i16x4"]]],[11,"from","","",57,[[["i32x4"]],["i16x4"]]],[11,"from","","",57,[[["u32x4"]],["i16x4"]]],[11,"from","","",57,[[["m32x4"]],["i16x4"]]],[11,"from","","",57,[[["u16x4"]],["i16x4"]]],[11,"from","","",57,[[["m16x4"]],["i16x4"]]],[11,"from","","",57,[[["u8x4"]],["i16x4"]]],[11,"from","","",57,[[["i8x4"]],["i16x4"]]],[11,"from","","",57,[[["m8x4"]],["i16x4"]]],[11,"from","","",54,[[["f64x8"]],["i8x8"]]],[11,"from","","",54,[[["u64x8"]],["i8x8"]]],[11,"from","","",54,[[["i64x8"]],["i8x8"]]],[11,"from","","",54,[[["m1x8"]],["i8x8"]]],[11,"from","","",54,[[["f32x8"]],["i8x8"]]],[11,"from","","",54,[[["u32x8"]],["i8x8"]]],[11,"from","","",54,[[["i32x8"]],["i8x8"]]],[11,"from","","",54,[[["m32x8"]],["i8x8"]]],[11,"from","","",54,[[["i16x8"]],["i8x8"]]],[11,"from","","",54,[[["u16x8"]],["i8x8"]]],[11,"from","","",54,[[["m16x8"]],["i8x8"]]],[11,"from","","",54,[[["u8x8"]],["i8x8"]]],[11,"from","","",54,[[["m8x8"]],["i8x8"]]],[11,"from","","",55,[[["f64x8"]],["u8x8"]]],[11,"from","","",55,[[["u64x8"]],["u8x8"]]],[11,"from","","",55,[[["i64x8"]],["u8x8"]]],[11,"from","","",55,[[["m1x8"]],["u8x8"]]],[11,"from","","",55,[[["f32x8"]],["u8x8"]]],[11,"from","","",55,[[["u32x8"]],["u8x8"]]],[11,"from","","",55,[[["i32x8"]],["u8x8"]]],[11,"from","","",55,[[["m32x8"]],["u8x8"]]],[11,"from","","",55,[[["i16x8"]],["u8x8"]]],[11,"from","","",55,[[["u16x8"]],["u8x8"]]],[11,"from","","",55,[[["m16x8"]],["u8x8"]]],[11,"from","","",55,[[["i8x8"]],["u8x8"]]],[11,"from","","",55,[[["m8x8"]],["u8x8"]]],[11,"from","","",56,[[["m1x8"]],["m8x8"]]],[11,"from","","",56,[[["m32x8"]],["m8x8"]]],[11,"from","","",56,[[["m16x8"]],["m8x8"]]],[11,"from","","",59,[[["m64x4"]],["m16x4"]]],[11,"from","","",59,[[["m32x4"]],["m16x4"]]],[11,"from","","",59,[[["m8x4"]],["m16x4"]]],[11,"from","","",62,[[["m64x2"]],["m32x2"]]],[11,"from","","",62,[[["m16x2"]],["m32x2"]]],[11,"from","","",62,[[["m8x2"]],["m32x2"]]],[11,"clone","coresimd::arch::x86_64","",0,[[["self"]],["cpuidresult"]]],[11,"cmp","","",0,[[["self"],["cpuidresult"]],["ordering"]]],[11,"eq","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"ne","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"partial_cmp","","",0,[[["self"],["cpuidresult"]],["option",["ordering"]]]],[11,"lt","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"le","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"gt","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"ge","","",0,[[["self"],["cpuidresult"]],["bool"]]],[11,"clone","","",64,[[["self"]],["__m64"]]],[11,"fmt","","",64,[[["self"],["formatter"]],["result"]]],[11,"clone","","",65,[[["self"]],["__m128i"]]],[11,"fmt","","",65,[[["self"],["formatter"]],["result"]]],[11,"clone","","",66,[[["self"]],["__m128"]]],[11,"fmt","","",66,[[["self"],["formatter"]],["result"]]],[11,"clone","","",67,[[["self"]],["__m128d"]]],[11,"fmt","","",67,[[["self"],["formatter"]],["result"]]],[11,"clone","","",68,[[["self"]],["__m256i"]]],[11,"fmt","","",68,[[["self"],["formatter"]],["result"]]],[11,"clone","","",69,[[["self"]],["__m256"]]],[11,"fmt","","",69,[[["self"],["formatter"]],["result"]]],[11,"clone","","",70,[[["self"]],["__m256d"]]],[11,"fmt","","",70,[[["self"],["formatter"]],["result"]]],[11,"from_bits","","",64,[[["u32x2"]],["__m64"]]],[11,"from_bits","","",64,[[["i32x2"]],["__m64"]]],[11,"from_bits","","",64,[[["f32x2"]],["__m64"]]],[11,"from_bits","","",64,[[["m32x2"]],["__m64"]]],[11,"from_bits","","",64,[[["u16x4"]],["__m64"]]],[11,"from_bits","","",64,[[["i16x4"]],["__m64"]]],[11,"from_bits","","",64,[[["m16x4"]],["__m64"]]],[11,"from_bits","","",64,[[["u8x8"]],["__m64"]]],[11,"from_bits","","",64,[[["i8x8"]],["__m64"]]],[11,"from_bits","","",64,[[["m8x8"]],["__m64"]]],[11,"from_bits","","",66,[[["u64x2"]],["__m128"]]],[11,"from_bits","","",66,[[["i64x2"]],["__m128"]]],[11,"from_bits","","",66,[[["f64x2"]],["__m128"]]],[11,"from_bits","","",66,[[["m64x2"]],["__m128"]]],[11,"from_bits","","",66,[[["u32x4"]],["__m128"]]],[11,"from_bits","","",66,[[["i32x4"]],["__m128"]]],[11,"from_bits","","",66,[[["f32x4"]],["__m128"]]],[11,"from_bits","","",66,[[["m32x4"]],["__m128"]]],[11,"from_bits","","",66,[[["u16x8"]],["__m128"]]],[11,"from_bits","","",66,[[["i16x8"]],["__m128"]]],[11,"from_bits","","",66,[[["m16x8"]],["__m128"]]],[11,"from_bits","","",66,[[["u8x16"]],["__m128"]]],[11,"from_bits","","",66,[[["i8x16"]],["__m128"]]],[11,"from_bits","","",66,[[["m8x16"]],["__m128"]]],[11,"from_bits","","",65,[[["u64x2"]],["__m128i"]]],[11,"from_bits","","",65,[[["i64x2"]],["__m128i"]]],[11,"from_bits","","",65,[[["f64x2"]],["__m128i"]]],[11,"from_bits","","",65,[[["m64x2"]],["__m128i"]]],[11,"from_bits","","",65,[[["u32x4"]],["__m128i"]]],[11,"from_bits","","",65,[[["i32x4"]],["__m128i"]]],[11,"from_bits","","",65,[[["f32x4"]],["__m128i"]]],[11,"from_bits","","",65,[[["m32x4"]],["__m128i"]]],[11,"from_bits","","",65,[[["u16x8"]],["__m128i"]]],[11,"from_bits","","",65,[[["i16x8"]],["__m128i"]]],[11,"from_bits","","",65,[[["m16x8"]],["__m128i"]]],[11,"from_bits","","",65,[[["u8x16"]],["__m128i"]]],[11,"from_bits","","",65,[[["i8x16"]],["__m128i"]]],[11,"from_bits","","",65,[[["m8x16"]],["__m128i"]]],[11,"from_bits","","",67,[[["u64x2"]],["__m128d"]]],[11,"from_bits","","",67,[[["i64x2"]],["__m128d"]]],[11,"from_bits","","",67,[[["f64x2"]],["__m128d"]]],[11,"from_bits","","",67,[[["m64x2"]],["__m128d"]]],[11,"from_bits","","",67,[[["u32x4"]],["__m128d"]]],[11,"from_bits","","",67,[[["i32x4"]],["__m128d"]]],[11,"from_bits","","",67,[[["f32x4"]],["__m128d"]]],[11,"from_bits","","",67,[[["m32x4"]],["__m128d"]]],[11,"from_bits","","",67,[[["u16x8"]],["__m128d"]]],[11,"from_bits","","",67,[[["i16x8"]],["__m128d"]]],[11,"from_bits","","",67,[[["m16x8"]],["__m128d"]]],[11,"from_bits","","",67,[[["u8x16"]],["__m128d"]]],[11,"from_bits","","",67,[[["i8x16"]],["__m128d"]]],[11,"from_bits","","",67,[[["m8x16"]],["__m128d"]]],[11,"from_bits","","",69,[[["u64x4"]],["__m256"]]],[11,"from_bits","","",69,[[["i64x4"]],["__m256"]]],[11,"from_bits","","",69,[[["f64x4"]],["__m256"]]],[11,"from_bits","","",69,[[["m64x4"]],["__m256"]]],[11,"from_bits","","",69,[[["u32x8"]],["__m256"]]],[11,"from_bits","","",69,[[["i32x8"]],["__m256"]]],[11,"from_bits","","",69,[[["f32x8"]],["__m256"]]],[11,"from_bits","","",69,[[["m32x8"]],["__m256"]]],[11,"from_bits","","",69,[[["u16x16"]],["__m256"]]],[11,"from_bits","","",69,[[["i16x16"]],["__m256"]]],[11,"from_bits","","",69,[[["m16x16"]],["__m256"]]],[11,"from_bits","","",69,[[["u8x32"]],["__m256"]]],[11,"from_bits","","",69,[[["i8x32"]],["__m256"]]],[11,"from_bits","","",69,[[["m8x32"]],["__m256"]]],[11,"from_bits","","",68,[[["u64x4"]],["__m256i"]]],[11,"from_bits","","",68,[[["i64x4"]],["__m256i"]]],[11,"from_bits","","",68,[[["f64x4"]],["__m256i"]]],[11,"from_bits","","",68,[[["m64x4"]],["__m256i"]]],[11,"from_bits","","",68,[[["u32x8"]],["__m256i"]]],[11,"from_bits","","",68,[[["i32x8"]],["__m256i"]]],[11,"from_bits","","",68,[[["f32x8"]],["__m256i"]]],[11,"from_bits","","",68,[[["m32x8"]],["__m256i"]]],[11,"from_bits","","",68,[[["u16x16"]],["__m256i"]]],[11,"from_bits","","",68,[[["i16x16"]],["__m256i"]]],[11,"from_bits","","",68,[[["m16x16"]],["__m256i"]]],[11,"from_bits","","",68,[[["u8x32"]],["__m256i"]]],[11,"from_bits","","",68,[[["i8x32"]],["__m256i"]]],[11,"from_bits","","",68,[[["m8x32"]],["__m256i"]]],[11,"from_bits","","",70,[[["u64x4"]],["__m256d"]]],[11,"from_bits","","",70,[[["i64x4"]],["__m256d"]]],[11,"from_bits","","",70,[[["f64x4"]],["__m256d"]]],[11,"from_bits","","",70,[[["m64x4"]],["__m256d"]]],[11,"from_bits","","",70,[[["u32x8"]],["__m256d"]]],[11,"from_bits","","",70,[[["i32x8"]],["__m256d"]]],[11,"from_bits","","",70,[[["f32x8"]],["__m256d"]]],[11,"from_bits","","",70,[[["m32x8"]],["__m256d"]]],[11,"from_bits","","",70,[[["u16x16"]],["__m256d"]]],[11,"from_bits","","",70,[[["i16x16"]],["__m256d"]]],[11,"from_bits","","",70,[[["m16x16"]],["__m256d"]]],[11,"from_bits","","",70,[[["u8x32"]],["__m256d"]]],[11,"from_bits","","",70,[[["i8x32"]],["__m256d"]]],[11,"from_bits","","",70,[[["m8x32"]],["__m256d"]]]],"paths":[[3,"CpuidResult"],[8,"FromBits"],[8,"IntoBits"],[3,"i8x16"],[3,"u8x16"],[3,"m8x16"],[3,"i16x8"],[3,"u16x8"],[3,"m16x8"],[3,"i32x4"],[3,"u32x4"],[3,"f32x4"],[3,"m32x4"],[3,"i64x2"],[3,"u64x2"],[3,"f64x2"],[3,"m64x2"],[3,"i8x2"],[3,"u8x2"],[3,"m8x2"],[3,"i8x32"],[3,"u8x32"],[3,"m8x32"],[3,"i16x16"],[3,"u16x16"],[3,"m16x16"],[3,"i32x8"],[3,"u32x8"],[3,"f32x8"],[3,"m32x8"],[3,"i64x4"],[3,"u64x4"],[3,"f64x4"],[3,"m64x4"],[3,"i16x2"],[3,"u16x2"],[3,"m16x2"],[3,"i8x4"],[3,"u8x4"],[3,"m8x4"],[3,"i8x64"],[3,"u8x64"],[3,"m1x64"],[3,"i16x32"],[3,"u16x32"],[3,"m1x32"],[3,"i32x16"],[3,"u32x16"],[3,"f32x16"],[3,"m1x16"],[3,"i64x8"],[3,"u64x8"],[3,"f64x8"],[3,"m1x8"],[3,"i8x8"],[3,"u8x8"],[3,"m8x8"],[3,"i16x4"],[3,"u16x4"],[3,"m16x4"],[3,"i32x2"],[3,"u32x2"],[3,"m32x2"],[3,"f32x2"],[3,"__m64"],[3,"__m128i"],[3,"__m128"],[3,"__m128d"],[3,"__m256i"],[3,"__m256"],[3,"__m256d"]]};
searchIndex["stdsimd"]={"doc":"SIMD and vendor intrinsics support library.","items":[[0,"simd","stdsimd","Platform independent SIMD vector types and operations.",N,N],[3,"m32x8","stdsimd::simd","A 256-bit vector mask with 8 lanes.",N,N],[3,"f64x4","","A 256-bit vector with 4 `f64` lanes.",N,N],[3,"f32x8","","A 256-bit vector with 8 `f32` lanes.",N,N],[3,"f64x2","","A 128-bit vector with 2 `f64` lanes.",N,N],[3,"u16x4","","A 64-bit vector with 4 `u16` lanes.",N,N],[3,"u16x32","","A 512-bit vector with 32 `u16` lanes.",N,N],[3,"i16x2","","A 32-bit wide vector with 2 `i16` lanes.",N,N],[3,"i32x4","","A 128-bit vector with 4 `i32` lanes.",N,N],[3,"m8x2","","A 16-bit wide vector mask with 2 lanes.",N,N],[3,"f32x16","","A 512-bit vector with 16 `f32` lanes.",N,N],[8,"IntoBits","","Safe lossless bitwise conversion from `Self` to `T`.",N,N],[10,"into_bits","","Safe lossless bitwise transmute from `self` to `T`.",0,[[["self"]],["t"]]],[3,"i8x4","","A 32-bit wide vector with 4 `i8` lanes.",N,N],[3,"i32x8","","A 256-bit vector with 8 `i32` lanes.",N,N],[3,"u64x2","","A 128-bit vector with 2 `u64` lanes.",N,N],[3,"i64x8","","A 512-bit vector with 8 `i64` lanes.",N,N],[3,"m16x16","","A 256-bit vector mask with 16 lanes.",N,N],[3,"m64x2","","A 128-bit vector mask with 2 lanes.",N,N],[3,"u16x2","","A 32-bit wide vector with 2 `u16` lanes.",N,N],[3,"m8x8","","A 64-bit vector mask with 8 lanes.",N,N],[3,"m64x4","","A 256-bit vector mask with 4 lanes.",N,N],[3,"u32x4","","A 128-bit vector with 4 `u32` lanes.",N,N],[3,"i8x2","","A 16-bit wide vector with 2 `i8` lanes.",N,N],[3,"m8x32","","A 256-bit vector mask with 32 lanes.",N,N],[3,"u32x16","","A 512-bit vector with 16 `u32` lanes.",N,N],[3,"u8x4","","A 32-bit wide vector with 4 `u8` lanes.",N,N],[3,"f32x2","","A 64-bit vector with 2 `f32` lanes.",N,N],[3,"u16x16","","A 256-bit vector with 16 `u16` lanes.",N,N],[3,"i64x2","","A 128-bit vector with 2 `u64` lanes.",N,N],[3,"m16x8","","A 128-bit vector mask with 8 lanes.",N,N],[3,"m1x64","","A 64-bit vector mask with 64 lanes (FIXME: 512-bit wide).",N,N],[3,"i64x4","","A 256-bit vector with 4 `i64` lanes.",N,N],[3,"i8x32","","A 256-bit vector with 32 `i8` lanes.",N,N],[3,"u8x32","","A 256-bit vector with 32 `u8` lanes.",N,N],[3,"i32x16","","A 512-bit vector with 16 `i32` lanes.",N,N],[3,"f32x4","","A 128-bit vector with 4 `f32` lanes.",N,N],[3,"m16x4","","A 64-bit vector mask with 4 lanes.",N,N],[3,"m8x16","","A 128-bit vector mask with 16 lanes.",N,N],[3,"i16x8","","A 128-bit vector with 8 `i16` lanes.",N,N],[3,"m32x2","","A 64-bit vector mask with 2 lanes.",N,N],[3,"i8x8","","A 64-bit vector with 8 `i8` lanes.",N,N],[8,"FromBits","","Safe lossless bitwise conversion from `T` to `Self`.",N,N],[10,"from_bits","","Safe lossless bitwise from `T` to `Self`.",1,[[["t"]],["self"]]],[3,"u8x64","","A 512-bit vector with 64 `u8` lanes.",N,N],[3,"u16x8","","A 128-bit vector with 8 `u16` lanes.",N,N],[3,"u8x2","","A 16-bit wide vector with 2 `u8` lanes.",N,N],[3,"i16x16","","A 256-bit vector with 16 `i16` lanes.",N,N],[3,"u8x16","","A 128-bit vector with 16 `u8` lanes.",N,N],[3,"i8x16","","A 128-bit vector with 16 `i8` lanes.",N,N],[3,"i8x64","","A 512-bit vector with 64 `i8` lanes.",N,N],[3,"u64x8","","A 512-bit vector with 8 `u64` lanes.",N,N],[3,"i32x2","","A 64-bit vector with 2 `i32` lanes.",N,N],[3,"u64x4","","A 256-bit vector with 4 `u64` lanes.",N,N],[3,"u8x8","","A 64-bit vector with 8 `u8` lanes.",N,N],[3,"u32x8","","A 256-bit vector with 8 `u32` lanes.",N,N],[3,"m1x16","","A 16-bit vector mask with 16 lanes (FIXME: 512-bit wide).",N,N],[3,"i16x4","","A 64-bit vector with 4 `i16` lanes.",N,N],[3,"m8x4","","A 32-bit wide vector mask 4 lanes.",N,N],[3,"m1x32","","A 32-bit vector mask with 32 lanes (FIXME: 512-bit wide).",N,N],[3,"m1x8","","A 8-bit vector mask with 8 lanes (FIXME: 512-bit wide).",N,N],[3,"i16x32","","A 512-bit vector with 32 `i16` lanes.",N,N],[3,"f64x8","","A 512-bit vector with 8 `f64` lanes.",N,N],[3,"u32x2","","A 64-bit vector with 2 `u32` lanes.",N,N],[3,"m16x2","","A 32-bit wide vector mask with 2 lanes.",N,N],[3,"m32x4","","A 128-bit vector mask with 4 lanes.",N,N],[0,"arch","stdsimd","SIMD and vendor intrinsics module.",N,N],[0,"x86_64","stdsimd::arch","Platform-specific intrinsics for the `x86_64` platform.",N,N],[5,"_mm256_zeroall","stdsimd::arch::x86_64","Zero the contents of all XMM or YMM registers.",N,N],[5,"_mm_fmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`,  and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_setr_pi16","","Set packed 16-bit integers in dst with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm256_set_epi16","","Set packed 16-bit integers in returned vector with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm_stream_ps","","Stores `a` into the memory at `mem_addr` using a non-temporal memory hint.",N,N],[5,"_mm256_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_hadd_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_blsi_u64","","Extract lowest set isolated bit.",N,[[["u64"]],["u64"]]],[5,"_mm256_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_cmpgt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm256_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_castsi128_ps","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128i"]],["__m128"]]],[5,"_blcmsk_u32","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u32"]],["u32"]]],[5,"_xrstor64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_maskmove_si64","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[5,"_mm256_set_epi64x","","Set packed 64-bit integers in returned vector with the supplied values.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_mm_cmpnle_sd","","Return a new vector with the low element of `a` replaced by the not-less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_srli_si256","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_floor_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_set_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[17,"_CMP_GE_OQ","","Greater-than-or-equal (ordered, non-signaling)",N,N],[5,"_mm_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_load_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_stream_si32","","Stores a 32-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_add_pi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_testnzc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_storeu_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[17,"_CMP_NGE_US","","Not-greater-than-or-equal (unordered, signaling)",N,N],[5,"_mm_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_bswap64","","Return an integer with the reversed byte order of x",N,[[["i64"]],["i64"]]],[5,"_mm256_srl_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_max_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[17,"_CMP_NLT_UQ","","Not-less-than (unordered, non-signaling)",N,N],[5,"_mm_set1_epi64x","","Broadcast 64-bit integer `a` to all elements.",N,[[["i64"]],["__m128i"]]],[5,"_mm256_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cmpgt_sd","","Return a new vector with the low element of `a` replaced by the greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[17,"_MM_EXCEPT_DENORM","","See `_mm_setcsr`",N,N],[5,"_mm_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_cvtss_sd","","Convert the lower single-precision (32-bit) floating-point element in `b` to a double-precision (64-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128d"],["__m128"]],["__m128d"]]],[17,"_CMP_EQ_UQ","","Equal (unordered, non-signaling)",N,N],[5,"_mm_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128"],["__m128i"]],["__m128"]]],[5,"_blcs_u64","","Sets the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_mm256_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_MM_SHUFFLE","","A utility function for creating masks to use with Intel shuffle and permute intrinsics.",N,[[["u32"],["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm256_cvtepu8_epi64","","Zero-extend the lower four unsigned 8-bit integers in `a` to 64-bit integers. The upper twelve elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_bextr2_u64","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm_andnot_si128","","Compute the bitwise NOT of 128 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_movelh_ps","","Combine lower half of `a` and `b`. The lower half of `b` occupies the higher half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_popcnt32","","Counts the bits that are set.",N,[[["i32"]],["i32"]]],[5,"_mm_setr_ps","","Construct a `__m128` from four floating point values lowest to highest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[5,"_mm_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_set_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm_castps_si128","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit integer vector.",N,[[["__m128"]],["__m128i"]]],[17,"_CMP_TRUE_US","","True (unordered, signaling)",N,N],[5,"_mm256_xor_si256","","Compute the bitwise XOR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_setr_epi16","","Set packed 16-bit integers in returned vector with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m256i"]]],[5,"_mm_sha256msg1_epu32","","Perform an intermediate calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_xsaveopt64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_prefetch","","Fetch the cache line that contains address `p` using the given `strategy`.",N,N],[17,"_SIDD_MASKED_NEGATIVE_POLARITY","","Negate results only before the end of the string",N,N],[5,"_mm_set1_epi64","","Initializes both values in a 128-bit vector of `[2 x i64]` with the specified 64-bit value.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_cmpord_pd","","Compare corresponding elements in `a` and `b` to see if neither is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mulx_u32","","Unsigned multiply without affecting flags.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm_avg_pu16","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_store_ss","","Store the lowest 32 bit float of `a` into memory.",N,N],[5,"_mm_cvtepu8_epi64","","Zero extend packed unsigned 8-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_m_maskmovq","","Conditionally copies the values from each 8-bit element in the first 64-bit integer vector operand to the specified memory location, as specified by the most significant bit in the corresponding element in the second 64-bit integer vector operand.",N,N],[5,"_mm_load_ps","","Load four `f32` values from aligned memory into a `__m128`. If the pointer is not aligned to a 128-bit boundary (16 bytes) a general protection fault will be triggered (fatal program crash).",N,N],[5,"_mm_sqrt_sd","","Return a new vector with the low element of `a` replaced by the square root of the lower element `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm_ucomilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_max_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_movemask_pd","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128d"]],["i32"]]],[5,"_mm256_set_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[5,"_mm_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_cmpestrc","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cmpge_sd","","Return a new vector with the low element of `a` replaced by the greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_hsub_pd","","Horizontally subtract adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm256_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_hadd_ps","","Horizontal addition of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_mpsadbw_epu8","","Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in `a` compared to those in `b`, and store the 16-bit results in dst. Eight SADs are performed for each 128-bit lane using one quadruplet from `b` and eight quadruplets from `a`. One quadruplet is selected from `b` starting at on the offset specified in `imm8`. Eight quadruplets are formed from sequential 8-bit integers selected from `a` starting at the offset specified in `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_xsaveopt","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm256_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256d"]],["__m128i"]]],[5,"_mm_cmpneq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_fmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract the lower element in `c` from the intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_andn_u32","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_hsub_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_comilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_blend_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using control mask `imm2`",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cmpnge_ss","","Compare the lowest `f32` of both inputs for not-greater-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_fmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_blendv_pd","","Blend packed double-precision (64-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_cmpgt_pd","","Compare corresponding elements in `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_setr_ps","","Set packed single-precision (32-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["__m256"]]],[5,"_mm_unpackhi_pi8","","Unpacks the upper four elements from two `i8x8` vectors and interleaves them into the result: `[a.4, b.4, a.5, b.5, a.6, b.6, a.7, b.7]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_MASK_MASK","","See `_MM_GET_EXCEPTION_MASK`",N,N],[5,"_mm_setr_pi8","","Set packed 8-bit integers in dst with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_storeu2_m128","","Store the high and low 128-bit halves (each composed of 4 packed single-precision (32-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvtsi128_si64x","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[17,"_MM_HINT_T2","","See `_mm_prefetch`.",N,N],[5,"_mm256_permute4x64_epi64","","Permutes 64-bit integers from `a` using control mask `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_MM_SET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,N],[17,"_CMP_FALSE_OS","","False (ordered, signaling)",N,N],[5,"_mm_setr_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values in reverse order.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_m_pavgw","","Computes the rounded averages of the packed unsigned 16-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_testz_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_permutevar_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `b`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_mm256_bsrli_epi128","","Shift 128-bit lanes in `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cmpistrs","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and returns `1` if any character in `a` was null, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_cmpeq_epi64","","Compare packed 64-bit integers in `a` and `b` for equality",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the result. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpngt_ss","","Compare the lowest `f32` of both inputs for not-greater-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_castpd256_pd128","","Casts vector of type __m256d to type __m128d.",N,[[["__m256d"]],["__m128d"]]],[17,"_MM_ROUND_UP","","See `_mm_setcsr`",N,N],[5,"_mm_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_UNORD_S","","Unordered (signaling)",N,N],[5,"_mm_add_pi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_hadd_pd","","Horizontal addition of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_m_pmaxsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_cvtepu32_epi64","","Zero-extend unsigned 32-bit integers in `a` to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m256d"]]],[5,"_mm_stream_ss","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_mm_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_slli_epi16","","Shift packed 16-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_abs_epi8","","Compute the absolute value of packed 8-bit signed integers in `a` and return the unsigned results.",N,[[["__m128i"]],["__m128i"]]],[5,"_fxsave64","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[17,"_CMP_NLE_US","","Not-less-than-or-equal (unordered, signaling)",N,N],[5,"_mm256_stream_ps","","Moves single-precision floating point values from a 256-bit vector of `[8 x float]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m128i"]],["__m128"]]],[5,"_mm256_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of `a` using the control in `imm8`. The low 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_set1_epi64x","","Broadcast 64-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastq`.",N,[[["i64"]],["__m256i"]]],[5,"_mm_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_MM_TRANSPOSE4_PS","","Transpose the 4x4 matrix formed by 4 rows of __m128 in place.",N,N],[5,"_mm256_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_comigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_cvtepi16_epi64","","Sign-extend 16-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_cmpge_pd","","Compare corresponding elements in `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_stream_si128","","Stores a 128-bit integer vector to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[17,"_MM_FROUND_RINT","","use MXCSR.RC and do not suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[5,"_mm256_round_ps","","Round packed single-precision (32-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256"],["i32"]],["__m256"]]],[5,"_mm_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[17,"_SIDD_NEGATIVE_POLARITY","","Negate results",N,N],[5,"_m_psubusb","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_set1_epi8","","Broadcast 8-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastb`.",N,[[["i8"]],["__m256i"]]],[5,"_mm_xor_ps","","Bitwise exclusive OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_setr_epi32","","Set packed 32-bit integers with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_setzero_pd","","Returns packed double-precision (64-bit) floating-point elements with all zeros.",N,[[],["__m128d"]]],[5,"_mm_rsqrt_ps","","Return the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_set1_pi32","","Broadcast 32-bit integer a to all all elements of dst.",N,[[["i32"]],["__m64"]]],[17,"_SIDD_POSITIVE_POLARITY","","Do not negate results (Default)",N,N],[5,"_mm256_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_store_pd","","Store 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_fnmadd_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_subs_epu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_blsmsk_u32","","Get mask up to lowest set bit.",N,[[["u32"]],["u32"]]],[5,"_mm_sqrt_pd","","Return a new vector with the square root of each of the values in `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_hsub_ps","","Horizontal subtraction of adjacent pairs in the two packed vectors of 8 32-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in locations of indices 0, 1, 4, 5; while sums of elements from `b` are locations 2, 3, 6, 7.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_insert_epi64","","Return a copy of `a` with the 64-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i64"],["i32"]],["__m128i"]]],[5,"_mm_ceil_sd","","Round the lower double-precision (64-bit) floating-point element in `b` up to an integer value, store the result as a double-precision floating-point element in the lower element of the intrisic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mulx_u64","","Unsigned multiply without affecting flags.",N,[[["u64"],["u64"],["u64"]],["u64"]]],[5,"_mm_cmple_sd","","Return a new vector with the low element of `a` replaced by the less-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_loadh_pi","","Set the upper two single-precision floating-point values with 64 bits of data loaded from the address `p`; the lower two values are passed through from `a`.",N,N],[17,"_CMP_ORD_Q","","Ordered (non-signaling)",N,N],[5,"_mm_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the higher half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpngt_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_ceil_pd","","Round packed double-precision (64-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm256_testnzc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256d"],["__m256d"]],["i32"]]],[17,"_CMP_GT_OQ","","Greater-than (ordered, non-signaling)",N,N],[5,"_pdep_u32","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_rsqrt_ss","","Return the approximate reciprocal square root of the fist single-precision (32-bit) floating-point elements in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_storeu_si256","","Store 256-bits of integer data from `a` into memory.    `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_fmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cvtpu16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[3,"__m256","","256-bit wide set of eight `f32` types, x86-specific",N,N],[5,"_mm256_maskstore_epi32","","Store packed 32-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_bsrli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_MM_HINT_NTA","","See `_mm_prefetch`.",N,N],[5,"_mm_hsubs_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_inserti128_si256","","Copy `a` to `dst`, then insert 128 bits (of integer data) from `b` at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[5,"__rdtscp","","Reads the current value of the processor’s time-stamp counter and the `IA32_TSC_AUX MSR`.",N,N],[5,"_mm256_hsubs_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtsi64x_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[5,"_mm256_store_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"__get_cpuid_max","","Returns the highest-supported `leaf` (`EAX`) and sub-leaf (`ECX`) `cpuid` values.",N,N],[5,"_xsave64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm_cmpunord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If either is equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_or_pd","","Compute the bitwise OR packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_hadd_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cvtsi64_ss","","Convert a 64 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i64"]],["__m128"]]],[5,"_mm_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_unpacklo_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_MM_GET_ROUNDING_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_bextr_u64","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u64"],["u32"],["u32"]],["u64"]]],[5,"_mm256_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_bzhi_u64","","Zero higher bits of `a` >= `index`.",N,[[["u64"],["u32"]],["u64"]]],[5,"_mm_cmpnle_ss","","Compare the lowest `f32` of both inputs for not-less-than-or-equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than or equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mul_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_castsi256_pd","","Casts vector of type __m256i to type __m256d.",N,[[["__m256i"]],["__m256d"]]],[5,"_mm_madd_epi16","","Multiply and then horizontally add signed 16 bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using control mask `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm_dp_ps","","Returns the dot product of two __m128 vectors.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_cvtsi32_ss","","Convert a 32 bit integer to a 32 bit float. The result vector is the input vector `a` with the lowest 32 bit float replaced by the converted integer.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_storer_ps","","Store four 32-bit floats into aligned memory in reverse order.",N,N],[5,"_mm_sub_si64","","Subtracts signed or unsigned 64-bit integer values and writes the difference to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ucomige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_cmpistro","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the lower half of `a` and `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_xsavec","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm_loadu_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm256_stream_pd","","Moves double-precision values from a 256-bit vector of `[4 x double]` to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using the mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_shuffle_epi32","","Shuffle 32-bit integers in 128-bit lanes of `a` using the control in `imm8`.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_set1_pi8","","Broadcast 8-bit integer a to all all elements of dst.",N,[[["i8"]],["__m64"]]],[5,"_mm_store_sd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_shuffle_epi32","","Shuffle 32-bit integers in `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_TRUE_UQ","","True (unordered, non-signaling)",N,N],[5,"_mm256_sub_ps","","Subtract packed single-precision (32-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_clflush","","Invalidate and flush the cache line that contains `p` from all levels of the cache hierarchy.",N,N],[5,"_mm_loadr_pd","","Load 2 double-precision (64-bit) floating-point elements from memory into the returned vector in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_hsub_epi16","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvttsd_si64x","","Alias for `_mm_cvttsd_si64`",N,[[["__m128d"]],["i64"]]],[5,"_mm_move_ss","","Return a `__m128` with the first component from `b` and the remaining components from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpestrs","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in a was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_max_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed maximum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_and_pd","","Compute the bitwise AND of a packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_or_ps","","Compute the bitwise OR packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_testc_si128","","Tests whether the specified bits in a 128-bit integer vector are all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[17,"_MM_ROUND_NEAREST","","See `_mm_setcsr`",N,N],[5,"_mm_mul_ss","","Multiplies the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cvtepi32_epi64","","Sign extend packed 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_adds_epi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_ucomieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_testz_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_min_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_add_epi16","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_stream_si256","","Moves integer data from a 256-bit integer vector to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)",N,N],[5,"_mm256_cvtepu8_epi16","","Zero-extend unsigned 8-bit integers in `a` to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_abs_pi16","","Compute the absolute value of packed 8-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_div_ss","","Divides the first component of `b` by `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_ucomineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_cvttpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`. If the result of either conversion is inexact, the result is truncated (rounded towards zero) regardless of the current MXCSR setting.",N,[[["__m128d"]],["__m64"]]],[5,"_mm_load_pd1","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[5,"_mm_insert_si64","","Inserts the `[length:0]` bits of `y` into `x` at `index`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_add_epi64","","Add packed 64-bit integers in `a` and \"b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_castsi128_pd","","Casts a 128-bit integer vector into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128i"]],["__m128d"]]],[5,"_fxrstor64","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm_set_pi8","","Set packed 8-bit integers in dst with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m64"]]],[5,"_mm_round_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed single-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm256_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_round_pd","","Round packed double-precision (64-bit) floating point elements in `a` according to the flag `b`. The value of `b` may be as follows:",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_load1_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of returned vector.",N,N],[17,"_MM_FROUND_CUR_DIRECTION","","use MXCSR.RC; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[5,"_m_psubd","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ucomineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_storeh_pi","","Store the upper half of `a` (64 bits) into memory.",N,N],[5,"_mm_cmpunord_pd","","Compare corresponding elements in `a` and `b` to see if either is `NaN`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_undefined_pd","","Return vector of type __m128d with undefined elements.",N,[[],["__m128d"]]],[5,"_mm_srai_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_NEQ_OS","","Not-equal (ordered, signaling)",N,N],[5,"_bzhi_u32","","Zero higher bits of `a` >= `index`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_m_psubusw","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm256_set_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_mm_cvtpi16_ps","","Converts a 64-bit vector of `i16`s into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm256_and_ps","","Compute the bitwise AND of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[17,"_MM_MASK_UNDERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_tzcnt_u32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_mm256_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_storel_epi64","","Store the lower 64-bit integer `a` to a memory location.",N,N],[5,"_mm_cmpistrz","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if any character in `b` was null. and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_mask_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_permute2f128_pd","","Shuffle 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_blsic_u32","","Clears least significant bit and sets all other bits.",N,[[["u32"]],["u32"]]],[5,"_mm_srav_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in sign bits.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `mask`",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[17,"_CMP_LE_OQ","","Less-than-or-equal (ordered, non-signaling)",N,N],[5,"_mm_setr_pi32","","Set packed 32-bit integers in dst with the supplied values in reverse order.",N,[[["i32"],["i32"]],["__m64"]]],[5,"_mm256_hsub_epi16","","Horizontally subtract adjacent pairs of 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_movemask_epi8","","Create mask from the most significant bit of each 8-bit element in `a`, return the result.",N,[[["__m256i"]],["i32"]]],[5,"_mm256_zeroupper","","Zero the upper 128 bits of all YMM registers; the lower 128-bits of the registers are unmodified.",N,N],[5,"_mm_fnmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_bslli_epi128","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_hsub_pd","","Horizontal subtraction of adjacent pairs in the two packed vectors of 4 64-bit floating points `a` and `b`. In the result, sums of elements from `a` are returned in even locations, while sums of elements from `b` are returned in odd locations.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvtepi32_pd","","Convert the lower two packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m128d"]]],[5,"_blci_u32","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u32"]],["u32"]]],[5,"_mm_xor_si128","","Compute the bitwise XOR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_cvtepi32_ps","","Convert packed 32-bit integers in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256i"]],["__m256"]]],[5,"_mm_extract_epi32","","Extract an 32-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm256_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_setzero_si256","","Return vector of type __m256i with all elements set to zero.",N,[[],["__m256i"]]],[5,"_mm_ceil_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` up to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_mm_cmplt_ss","","Compare the lowest `f32` of both inputs for less than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_MM_SET_EXCEPTION_MASK","","See `_mm_setcsr`",N,N],[5,"_mm_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_subs_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_avg_pu8","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_setr_epi16","","Set packed 16-bit integers with the supplied values in reverse order.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm_cvtps_pi16","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 16-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm256_loadu_si256","","Load 256-bits of integer data from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_slli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_tzcnt_32","","Counts the number of trailing least significant zero bits.",N,[[["u32"]],["i32"]]],[17,"_SIDD_CMP_EQUAL_ORDERED","","Search for the defined substring in the target",N,N],[5,"_mm_sub_ps","","Subtracts __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_insert_epi16","","Copy `a` to result, and insert the 16-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i16"],["i32"]],["__m256i"]]],[5,"_mm_subs_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_min_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"__cpuid_count","","Returns the result of the `cpuid` instruction for a given `leaf` (`EAX`) and `sub_leaf` (`ECX`).",N,[[["u32"],["u32"]],["cpuidresult"]]],[5,"_mm256_testc_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm_aesenc_si128","","Perform one round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_HINT_T0","","See `_mm_prefetch`.",N,N],[5,"_mm_rcp_ps","","Return the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cvtsi128_si64","","Return the lowest element of `a`.",N,[[["__m128i"]],["i64"]]],[5,"_mm256_fmsubadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_cvtsi256_si32","","Returns the first element of the input vector of `[8 x i32]`.",N,[[["__m256i"]],["i32"]]],[5,"_mm_setzero_si128","","Returns a vector with all elements set to zero.",N,[[],["__m128i"]]],[5,"_mm256_broadcast_pd","","Broadcast 128 bits from memory (composed of 2 packed double-precision (64-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm_cmpestrm","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm_min_pi16","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtepi8_epi16","","Sign extend packed 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_fmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_cmpgt_epi8","","Compare packed 8-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_comineq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are not equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cvtpd_pi32","","Converts the two double-precision floating-point elements of a 128-bit vector of `[2 x double]` into two signed 32-bit integer values, returned in a 64-bit vector of `[2 x i32]`.",N,[[["__m128d"]],["__m64"]]],[5,"_mm_set_epi16","","Set packed 16-bit integers with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["__m128i"]]],[5,"_mm_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_fxrstor","","Restores the `XMM`, `MMX`, `MXCSR`, and `x87` FPU registers from the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm_hadds_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_mulhi_epu16","","Multiply the packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_storel_pd","","Stores the lower 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_set_pi16","","Set packed 16-bit integers in dst with the supplied values.",N,[[["i16"],["i16"],["i16"],["i16"]],["__m64"]]],[5,"_mm256_cvtepi32_epi64","","Sign-extend 32-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_sha1msg2_epu32","","Perform the final calculation for the next four SHA1 message values (unsigned 32-bit integers) using the intermediate result in `a` and the previous message values in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_loadh_pd","","Loads a double-precision value into the high-order bits of a 128-bit vector of `[2 x double]`. The low-order bits are copied from the low-order bits of the first operand.",N,N],[5,"_mm_cvttps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[5,"_mm_sub_epi64","","Subtract packed 64-bit integers in `b` from packed 64-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpgt_pi16","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_dp_pd","","Returns the dot product of two __m128d vectors.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cmpestra","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm256_mask_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 256-bit returned value",N,[[["__m128i"]],["__m256i"]]],[17,"_MM_MASK_DIV_ZERO","","See `_mm_setcsr`",N,N],[5,"_mm256_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`.",N,[[["__m256i"],["__m256i"],["__m256i"]],["__m256i"]]],[17,"_CMP_GT_OS","","Greater-than (ordered, signaling)",N,N],[5,"_mm_cvtpu8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[17,"_MM_FROUND_TO_POS_INF","","round up",N,N],[5,"_mm_cvtepi16_epi64","","Sign extend packed 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_extract_epi64","","Extract an 64-bit integer from `a` selected with `imm8`",N,[[["__m128i"],["i32"]],["i64"]]],[17,"_CMP_NGT_UQ","","Not-greater-than (unordered, non-signaling)",N,N],[5,"_m_psubsw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pavgb","","Computes the rounded averages of the packed unsigned 8-bit integer values and writes the averages to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_broadcast_ps","","Broadcast 128 bits from memory (composed of 4 packed single-precision (32-bit) floating-point elements) to all elements of the returned vector.",N,[[["__m128"]],["__m256"]]],[5,"_mm_aesenclast_si128","","Perform the last round of an AES encryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_andnot_si256","","Compute the bitwise NOT of 256 bits (representing integer data) in `a` and then AND with `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sllv_epi32","","Shift packed 32-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_loadu2_m128d","","Load two 128-bit values (composed of 2 packed double-precision (64-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm256_fmsubadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively subtract and add packed elements in `c` from/to the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[17,"_MM_MASK_DENORM","","See `_mm_setcsr`",N,N],[5,"_mm_insert_epi16","","Return a new vector where the `imm8` element of `a` is replaced with `i`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm256_broadcast_sd","","Broadcast a double-precision (64-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm_srlv_epi64","","Shift packed 64-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sign_epi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_castps256_ps128","","Casts vector of type __m256 to type __m128.",N,[[["__m256"]],["__m128"]]],[5,"_mm256_hadds_epi16","","Horizontally add adjacent pairs of 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_store_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_m_psubsb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_m_pminub","","Compares the packed 8-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_unpackhi_epi64","","Unpack and interleave 64-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_insert_epi32","","Return a copy of `a` with the 32-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[17,"_CMP_UNORD_Q","","Unordered (non-signaling)",N,N],[5,"_mm_ucomigt_sd","","Compare the lower element of `a` and `b` for greater-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_bextr_u32","","Extracts bits in range [`start`, `start` + `length`) from `a` into the least significant bits of the result.",N,[[["u32"],["u32"],["u32"]],["u32"]]],[5,"_mm256_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers, and store the results in dst.",N,[[["__m128i"]],["__m256i"]]],[5,"_xrstors","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed maximum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_sllv_epi64","","Shift packed 64-bit integers in `a` left by the amount specified by the corresponding element in `count` while shifting in zeros, and return the result.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_load_si256","","Load 256-bits of integer data from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_avg_epu8","","Average packed unsigned 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_movehdup_ps","","Duplicate odd-indexed single-precision (32-bit) floating-point elements from `a`.",N,[[["__m128"]],["__m128"]]],[5,"_lzcnt_u64","","Counts the leading most significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_blci_u64","","Sets all bits of `x` to 1 except for the least significant zero bit.",N,[[["u64"]],["u64"]]],[5,"_mm256_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_and_ps","","Bitwise AND of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_hsub_epi32","","Horizontally subtract adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_move_sd","","Constructs a 128-bit floating-point vector of `[2 x double]`. The lower 64 bits are set to the lower 64 bits of the second parameter. The upper 64 bits are set to the upper 64 bits of the first parameter.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[17,"_MM_FROUND_FLOOR","","round down and do not suppress exceptions",N,N],[5,"_mm_cmple_ss","","Compare the lowest `f32` of both inputs for less than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is less than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_sad_epu8","","Compute the absolute differences of packed unsigned 8-bit integers in `a` and `b`, then horizontally sum each consecutive 8 differences to produce four unsigned 16-bit integers, and pack these unsigned 16-bit integers in the low 16 bits of the 64-bit return value",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_rcp_ss","","Return the approximate reciprocal of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[5,"_mm_store_ps","","Store four 32-bit floats into aligned memory.",N,N],[5,"_mm256_loadu2_m128","","Load two 128-bit values (composed of 4 packed single-precision (32-bit) floating-point elements) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvttsd_si64","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 64-bit integer with truncation.",N,[[["__m128d"]],["i64"]]],[5,"_MM_GET_FLUSH_ZERO_MODE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_mm256_packus_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpneq_pd","","Compare corresponding elements in `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_m_pmovmskb","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_mm256_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_MM_GET_EXCEPTION_STATE","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_mm_unpackhi_pi16","","Unpacks the upper two elements from two `i16x4` vectors and interleaves them into the result: `[a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_FROUND_NINT","","round to nearest and do not suppress exceptions",N,N],[5,"_mm_cvt_si2ss","","Alias for `_mm_cvtsi32_ss`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_testnzc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_xor_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_testz_pd","","Compute the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256d"],["__m256d"]],["i32"]]],[5,"_mm256_alignr_epi8","","Concatenate pairs of 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cvtt_ps2pi","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m64"]]],[17,"_MM_EXCEPT_INEXACT","","See `_mm_setcsr`",N,N],[5,"_mm_cmpneq_sd","","Return a new vector with the low element of `a` replaced by the not-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cvtsi64_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i64"]],["__m128i"]]],[17,"_SIDD_CMP_RANGES","","For each character in `a`, determine if `b[0] <= c <= b[1] or b[1] <= c <= b[2]...`",N,N],[5,"_mm_cmpord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are ordered (i.e., neither of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mul_su32","","Multiplies 32-bit unsigned integer values contained in the lower bits of the two 64-bit integer vectors and returns the 64-bit unsigned product.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_tzmsk_u32","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_mm_cmpeq_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input elements were equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_or_pd","","Compute the bitwise OR of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_aesdec_si128","","Perform one round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_MM_SET_EXCEPTION_STATE","","See `_mm_setcsr`",N,N],[5,"_mm_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_comige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_blcfill_u64","","Clears all bits below the least significant zero bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_mm_stream_pd","","Stores a 128-bit floating point vector of `[2 x double]` to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_stream_si64","","Stores a 64-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).",N,N],[5,"_mm_div_sd","","Return a new vector with the low element of `a` replaced by the result of diving the lower element of `a` by the lower element of `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_movemask_epi8","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128i"]],["i32"]]],[5,"_mm256_sqrt_pd","","Return the square root of packed double-precision (64-bit) floating point elements in `a`.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm_sign_pi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpnle_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_srli_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_movemask_pi8","","Takes the most significant bit from each 8-bit element in a 64-bit integer vector to create a 16-bit mask value. Zero-extends the value to 32-bit integer and writes it to the destination.",N,[[["__m64"]],["i32"]]],[5,"_mm_round_sd","","Round the lower double-precision (64-bit) floating-point element in `b` using the `rounding` parameter, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_cmpgt_epi32","","Compare packed 32-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_blcic_u32","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u32"]],["u32"]]],[5,"_mm_lfence","","Perform a serializing operation on all load-from-memory instructions that were issued prior to this instruction.",N,N],[17,"_MM_FROUND_RAISE_EXC","","do not suppress exceptions",N,N],[5,"_mm256_permutevar8x32_ps","","Shuffle eight 32-bit foating-point elements in `a` across lanes using the corresponding 32-bit integer index in `idx`.",N,[[["__m256"],["__m256i"]],["__m256"]]],[5,"_mm_floor_ss","","Round the lower single-precision (32-bit) floating-point element in `b` down to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmplt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_max_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_cvtps_pi32","","Convert the two lower packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m64"]]],[5,"_mm256_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_mask_i64gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_shuffle_pi16","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_mm_cvtepi16_epi32","","Sign extend packed 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_load_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_setzero_si64","","Constructs a 64-bit integer vector initialized to zero.",N,[[],["__m64"]]],[5,"_mm_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_EXCEPT_MASK","","See `_MM_GET_EXCEPTION_STATE`",N,N],[5,"_mm256_addsub_ps","","Alternatively add and subtract packed single-precision (32-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_zextps128_ps256","","Constructs a 256-bit floating-point vector of `[8 x float]` from a 128-bit floating-point vector of `[4 x float]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128"]],["__m256"]]],[5,"_mm_set_sd","","Copy double-precision (64-bit) floating-point element `a` to the lower element of the packed 64-bit return value.",N,[[["f64"]],["__m128d"]]],[17,"_SIDD_CMP_EQUAL_EACH","","The strings defined by `a` and `b` are equal",N,N],[5,"_mm256_extract_epi32","","Extract a 32-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i32"]]],[5,"_mm_mul_ps","","Multiplies __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mullo_pi16","","Multiplies packed 16-bit integer values and writes the low-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_aesdeclast_si128","","Perform the last round of an AES decryption flow on data (state) in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_andnot_pd","","Compute the bitwise NOT of packed double-precision (64-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_insert_epi8","","Return a copy of `a` with the 8-bit integer from `i` inserted at a location specified by `imm8`.",N,[[["__m128i"],["i32"],["i32"]],["__m128i"]]],[5,"_mm256_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_hadd_pi16","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpistri","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpestri`] with the exception that [`_mm_cmpestri`] requires the lengths of `a` and `b` to be explicitly specified.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm256_castpd_si256","","Casts vector of type __m256d to type __m256i.",N,[[["__m256d"]],["__m256i"]]],[5,"_mm_loaddup_pd","","Load a double-precision (64-bit) floating-point element from memory into both elements of return vector.",N,N],[5,"_mm_getcsr","","Get the unsigned 32-bit value of the MXCSR control and status register.",N,[[],["u32"]]],[5,"_mm_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`, and return the signed 64-bit result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_ucomilt_sd","","Compare the lower element of `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["i32"]]],[17,"_CMP_EQ_OQ","","Equal (ordered, non-signaling)",N,N],[5,"_mm_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Elements in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_castpd_si128","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit integer vector.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_maddubs_epi16","","Multiply corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, add pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_loadu_ps","","Load 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_unpackhi_pi32","","Unpacks the upper element from two `i32x2` vectors and interleaves them into the result: `[a.1, b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_ceil_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` up to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_ucomigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_m_pinsrw","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_mm_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than, return the results.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_SIDD_UNIT_MASK","","Mask only: return the byte mask",N,N],[5,"_mm256_subs_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_mulhi_epi16","","Multiply the packed 16-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_xgetbv","","Reads the contents of the extended control register `XCR` specified in `xcr_no`.",N,[[["u32"]],["u64"]]],[5,"_mm256_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_insert_epi32","","Copy `a` to result, and insert the 32-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i32"],["i32"]],["__m256i"]]],[5,"_mm_storeu_si128","","Store 128-bits of integer data from `a` into memory.",N,N],[5,"_mm256_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_i32gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_set_pi32","","Set packed 32-bit integers in dst with the supplied values.",N,[[["i32"],["i32"]],["__m64"]]],[17,"_CMP_NEQ_UQ","","Not-equal (unordered, non-signaling)",N,N],[5,"_bextr2_u32","","Extracts bits of `a` specified by `control` into the least significant bits of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm256_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtepu8_epi16","","Zero extend packed unsigned 8-bit integers in `a` to packed 16-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_broadcastw_epi16","","Broadcast the low packed 16-bit integer from a to all elements of the 128-bit returned value",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_mul_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cvtepi8_epi32","","Sign extend packed 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_loadu_ps","","Load four `f32` values from memory into a `__m128`. There are no restrictions on memory alignment. For aligned memory `_mm_load_ps` may be faster.",N,N],[5,"_mm256_hadd_epi32","","Horizontally add adjacent pairs of 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_dp_ps","","Conditionally multiply the packed single-precision (32-bit) floating-point elements in `a` and `b` using the high 4 bits in `imm8`, sum the four products, and conditionally return the sum  using the low 4 bits of `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm_min_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_testz_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"__cpuid","","See `__cpuid_count`.",N,[[["u32"]],["cpuidresult"]]],[5,"_mm_load_ps1","","Alias for `_mm_load1_ps`",N,N],[5,"_mm_minpos_epu16","","Finds the minimum unsigned 16-bit element in the 128-bit __m128i vector, returning a vector containing its value in its first position, and its index in its second position; all other elements are set to zero.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_cvtsd_f64","","Returns the first element of the input vector of `[4 x double]`.",N,[[["__m256d"]],["f64"]]],[5,"_tzmsk_u64","","Sets all bits below the least significant one of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm_cmpestro","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return bit `0` of the resulting bit mask.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm256_andnot_ps","","Compute the bitwise NOT of packed single-precision (32-bit) floating-point elements in `a` and then AND with `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_fnmsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_add_epi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_rdtsc","","Reads the current value of the processor’s time-stamp counter.",N,[[],["i64"]]],[5,"_mm256_unpacklo_epi16","","Unpack and interleave 16-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_setr_epi8","","Set packed 8-bit integers with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_mm_cmpnge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmpunord_ss","","Check if the lowest `f32` of both inputs are unordered. The lowest 32 bits of the result will be `0xffffffff` if any of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_abs_pi8","","Compute the absolute value of packed 8-bit integers in `a` and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_blcmsk_u64","","Sets the least significant zero bit of `x` and clears all bits above that bit.",N,[[["u64"]],["u64"]]],[5,"_mm_set_ps1","","Alias for `_mm_set1_ps`",N,[[["f32"]],["__m128"]]],[5,"_mm_cmpge_ss","","Compare the lowest `f32` of both inputs for greater than or equal. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than or equal `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_ucomile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_hadd_pd","","Horizontally add adjacent pairs of double-precision (64-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_stream_sd","","Non-temporal store of `a.0` into `p`.",N,N],[5,"_mm256_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_testc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm_cvtsd_ss","","Convert the lower double-precision (64-bit) floating-point element in `b` to a single-precision (32-bit) floating-point element, store the result in the lower element of the return value, and copy the upper element from `a` to the upper element the return value.",N,[[["__m128"],["__m128d"]],["__m128"]]],[5,"_mm_cmpngt_pd","","Compare corresponding elements in `a` and `b` for not-greater-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_round_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` using the `rounding` parameter, and store the results as packed double-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_cvtepu16_epi64","","Zero extend packed unsigned 16-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_xsave","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm_test_all_ones","","Tests whether the specified bits in `a` 128-bit integer vector are all ones.",N,[[["__m128i"]],["i32"]]],[17,"_MM_FLUSH_ZERO_OFF","","See `_mm_setcsr`",N,N],[5,"_mm_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_insertf128_si256","","Copy `a` to result, then insert 128 bits from `b` into result at the location specified by `imm8`.",N,[[["__m256i"],["__m128i"],["i32"]],["__m256i"]]],[5,"_mm_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_adds_pu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_FROUND_TO_ZERO","","truncate",N,N],[5,"_mm256_srlv_epi32","","Shift packed 32-bit integers in `a` right by the amount specified by the corresponding element in `count` while shifting in zeros,",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_m_pshufw","","Shuffles the 4 16-bit integers from a 64-bit integer vector to the destination, as specified by the immediate value operand.",N,[[["__m64"],["i32"]],["__m64"]]],[5,"_mm_set_ps","","Construct a `__m128` from four floating point values highest to lowest.",N,[[["f32"],["f32"],["f32"],["f32"]],["__m128"]]],[5,"_mm256_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 128-bit returned value.",N,[[["__m128"]],["__m128"]]],[5,"_mm_mpsadbw_epu8","","Subtracts 8-bit unsigned integer values and computes the absolute values of the differences to the corresponding bits in the destination. Then sums of the absolute differences are returned according to the bit fields in the immediate operand.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_GE_OS","","Greater-than-or-equal (ordered, signaling)",N,N],[5,"_mm256_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_cvtt_ss2si","","Alias for `_mm_cvttss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm256_div_pd","","Compute the division of each of the 4 packed 64-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_testc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[3,"__m256i","","256-bit wide integer vector type, x86-specific",N,N],[5,"_mm_set_pd1","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[17,"_CMP_NGE_UQ","","Not-greater-than-or-equal (unordered, non-signaling)",N,N],[17,"_MM_FROUND_NO_EXC","","suppress exceptions",N,N],[5,"_mm_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating-point elements in `a`.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_mul_epu32","","Multiply the low unsigned 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_subs_pu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mullo_epi32","","Multiply the packed 32-bit integers in `a` and `b`, producing intermediate 64-bit integers, and returns the lowest 32-bit, whatever they might be, reinterpreted as a signed integer. While `pmulld __m128i::splat(2), __m128i::splat(2)` returns the obvious `__m128i::splat(4)`, due to wrapping arithmetic `pmulld __m128i::splat(i32::MAX), __m128i::splat(2)` would return a negative number.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_m_pmulhuw","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_addsub_pd","","Alternatively add and subtract packed double-precision (64-bit) floating-point elements in `a` to/from packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_set1_pd","","Broadcast double-precision (64-bit) floating-point value `a` to all elements of returned vector.",N,[[["f64"]],["__m256d"]]],[5,"_mm_clmulepi64_si128","","Perform a carry-less multiplication of two 64-bit polynomials over the finite field GF(2^k).",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[17,"_CMP_LT_OQ","","Less-than (ordered, non-signaling)",N,N],[5,"_xsetbv","","Copy 64-bits from `val` to the extended control register (`XCR`) specified by `a`.",N,N],[5,"_mm_sub_ss","","Subtracts the first component of `b` from `a`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_cvtepi16_epi32","","Sign-extend 16-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_shuffle_pi8","","Shuffle packed 8-bit integers in `a` according to shuffle control mask in the corresponding 8-bit element of `b`, and return the results",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_max_epi32","","Compare packed 32-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_MASK_INVALID","","See `_mm_setcsr`",N,N],[5,"_mm256_broadcastss_ps","","Broadcast the low single-precision (32-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128"]],["__m256"]]],[5,"_mm256_cvtss_f32","","Returns the first element of the input vector of `[8 x float]`.",N,[[["__m256"]],["f32"]]],[5,"_mm_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm_cmple_pd","","Compare corresponding elements in `a` and `b` for less-than-or-equal",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm_mfence","","Perform a serializing operation on all load-from-memory and store-to-memory instructions that were issued prior to this instruction.",N,N],[5,"_mm256_insert_epi64","","Copy `a` to result, and insert the 64-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i64"],["i32"]],["__m256i"]]],[5,"_mm_castps_pd","","Casts a 128-bit floating-point vector of `[4 x float]` into a 128-bit floating-point vector of `[2 x double]`.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_cvtsd_si64x","","Alias for `_mm_cvtsd_si64`",N,[[["__m128d"]],["i64"]]],[5,"_mm_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding minimum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_or_si256","","Compute the bitwise OR of 256 bits (representing integer data) in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_crc32_u32","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 32-bit integer `v`.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m128"]]],[5,"_mm_min_epi32","","Compare packed 32-bit integers in `a` and `b`, and return packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_storeh_pd","","Stores the upper 64 bits of a 128-bit vector of `[2 x double]` to a memory location.",N,N],[5,"_mm_mul_sd","","Return a new vector with the low element of `a` replaced by multiplying the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_unpackhi_pd","","Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_fnmadd_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to the lower element in `c`. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cvtss_f32","","Extract the lowest 32 bit float from the input vector.",N,[[["__m128"]],["f32"]]],[5,"_mm256_permute4x64_pd","","Shuffle 64-bit floating-point elements in `a` across lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_unpacklo_pi16","","Unpacks the lower two elements from two `i16x4` vectors and interleaves them into the result: `[a.0 b.0 a.1 b.1]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_testnzc_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm256_storeu_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[17,"_CMP_LT_OS","","Less-than (ordered, signaling)",N,N],[5,"_mm_set1_epi32","","Broadcast 32-bit integer `a` to all elements.",N,[[["i32"]],["__m128i"]]],[5,"_mm_andnot_pd","","Compute the bitwise NOT of `a` and then AND with `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_loadr_ps","","Load four `f32` values from aligned memory into a `__m128` in reverse order.",N,N],[5,"_mm256_adds_epu16","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_loadu2_m128i","","Load two 128-bit values (composed of integer data) from memory, and combine them into a 256-bit value. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[17,"_MM_MASK_OVERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm_add_ps","","Adds __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_set1_epi8","","Broadcast 8-bit integer `a` to all elements.",N,[[["i8"]],["__m128i"]]],[5,"_mm256_extractf128_pd","","Extract 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256d"],["i32"]],["__m128d"]]],[5,"_mm_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cmpngt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not greater than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_set_epi64","","Initializes both 64-bit values in a 128-bit vector of `[2 x i64]` with the specified 64-bit integer values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_andn_u64","","Bitwise logical `AND` of inverted `a` with `b`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm256_extract_epi64","","Extract a 64-bit integer from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["i64"]]],[3,"__m64","","64-bit wide integer vector type, x86-specific",N,N],[5,"_mm256_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_tzcnt_64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["i64"]]],[5,"_t1mskc_u32","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u32"]],["u32"]]],[17,"_CMP_NLT_US","","Not-less-than (unordered, signaling)",N,N],[5,"_mm_set1_pi16","","Broadcast 16-bit integer a to all all elements of dst.",N,[[["i16"]],["__m64"]]],[5,"_mm_add_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_blend_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using mask `imm4`",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_maskload_epi32","","Load packed 32-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_mm_cvtsi32_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i32"]],["__m128d"]]],[5,"_blcic_u64","","Sets the least significant zero bit of `x` and clears all other bits.",N,[[["u64"]],["u64"]]],[17,"_SIDD_LEAST_SIGNIFICANT","","Index only: return the least significant bit (Default)",N,N],[5,"_mm_cvtepu16_epi32","","Zero extend packed unsigned 16-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"has_cpuid","","Does the host support the `cpuid` instruction?",N,[[],["bool"]]],[5,"_mm_castpd_ps","","Casts a 128-bit floating-point vector of `[2 x double]` into a 128-bit floating-point vector of `[4 x float]`.",N,[[["__m128d"]],["__m128"]]],[5,"_mm256_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed single-precision (32-bit) floating-point elements.",N,[[["__m256d"]],["__m128"]]],[3,"__m128","","128-bit wide set of four `f32` types, x86-specific",N,N],[5,"_mm256_storeu_pd","","Store 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from `a` into memory. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_ucomile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_i64gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_store_pd1","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[17,"_SIDD_SBYTE_OPS","","String contains signed 8-bit characters",N,N],[5,"_mm_unpackhi_epi8","","Unpack and interleave 8-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_adds_pi8","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_FROUND_TO_NEG_INF","","round down",N,N],[5,"_mm256_avg_epu16","","Average packed unsigned 16-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return the corresponding maximum values.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_loadu_pd","","Load 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. `mem_addr` does not need to be aligned on any particular boundary.",N,N],[5,"_mm_sad_epu8","","Sum the absolute differences of packed unsigned 8-bit integers.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_broadcastd_epi32","","Broadcast the low packed 32-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_loadl_pd","","Loads a double-precision value into the low-order bits of a 128-bit vector of `[2 x double]`. The high-order bits are copied from the high-order bits of the first operand.",N,N],[17,"_CMP_FALSE_OQ","","False (ordered, non-signaling)",N,N],[5,"_mm_cvtpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_mulhi_pu16","","Multiplies packed 16-bit unsigned integer values and writes the high-order 16 bits of each 32-bit product to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_set1_epi16","","Broadcast 16-bit integer `a` to all elements.",N,[[["i16"]],["__m128i"]]],[5,"_mm_store_ps1","","Alias for `_mm_store1_ps`",N,N],[5,"_mm256_sub_epi8","","Subtract packed 8-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_mulhrs_pi16","","Multiplies packed 16-bit signed integer values, truncates the 32-bit products to the 18 most significant bits by right-shifting, rounds the truncated value by adding 1, and writes bits `[16:1]` to the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_test_mix_ones_zeros","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_MM_GET_EXCEPTION_MASK","","See `_mm_setcsr`",N,[[],["u32"]]],[5,"_mm256_abs_epi16","","Computes the absolute values of packed 16-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm_set_pd","","Set packed double-precision (64-bit) floating-point elements in the return value with the supplied values.",N,[[["f64"],["f64"]],["__m128d"]]],[5,"_mm_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_maskmoveu_si128","","Conditionally store 8-bit integer elements from `a` into memory using `mask`.",N,N],[5,"_mm_permute_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` using the control in `imm8`.",N,[[["__m128"],["i32"]],["__m128"]]],[5,"_mm_load1_ps","","Construct a `__m128` by duplicating the value read from `p` into all elements.",N,N],[5,"_mm256_zextpd128_pd256","","Constructs a 256-bit floating-point vector of `[4 x double]` from a 128-bit floating-point vector of `[2 x double]`. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128d"]],["__m256d"]]],[5,"_mm_add_sd","","Return a new vector with the low element of `a` replaced by the sum of the low elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sub_epi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_max_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_insert_ps","","Select a single value in `a` to store at some position in `b`, Then zero elements according to `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_movemask_ps","","Return a mask of the most significant bit of each element in `a`.",N,[[["__m128"]],["i32"]]],[5,"_mm256_slli_si256","","Shift 128-bit lanes in `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cmpnlt_ss","","Compare the lowest `f32` of both inputs for not-less-than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not less than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_castsi256_ps","","Casts vector of type __m256i to type __m256.",N,[[["__m256i"]],["__m256"]]],[5,"_mm_fmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_movedup_pd","","Duplicate the low double-precision (64-bit) floating-point element from `a`.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm256_permute2x128_si256","","Shuffle 128-bits of integer data selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` using the control in `b`.",N,[[["__m128d"],["__m128i"]],["__m128d"]]],[5,"_mm_add_si64","","Adds two signed or unsigned 64-bit integer values, returning the lower 64 bits of the sum.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_t1mskc_u64","","Clears all bits below the least significant zero of `x` and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_popcnt64","","Counts the bits that are set.",N,[[["i64"]],["i32"]]],[5,"_mm_crc32_u64","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 64-bit integer `v`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_rdseed16_step","","Read a 16-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_mm256_cvtepu16_epi64","","Zero-extend the lower four unsigned 16-bit integers in `a` to 64-bit integers. The upper four elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m256"]],["__m256i"]]],[5,"_mm_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_hadd_epi32","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sad_pu8","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_comieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_sha1nexte_epu32","","Calculate SHA1 state variable E after four rounds of operation from the current SHA1 state variable `a`, add that value to the scheduled values (unsigned 32-bit integers) in `b`, and returns the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_srl_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_FLUSH_ZERO_MASK","","See `_MM_GET_FLUSH_ZERO_MODE`",N,N],[5,"_mm_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128"]],["__m128i"]]],[5,"_m_pextrw","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_mm_comigt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_testc_ps","","Compute the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cmpnlt_sd","","Return a new vector with the low element of `a` replaced by the not-less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_add_epi8","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_shuffle_ps","","Shuffle single-precision (32-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm_broadcastb_epi8","","Broadcast the low packed 8-bit integer from `a` to all elements of the 128-bit returned value.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_setr_m128","","Set packed __m256 returned vector with the supplied values.",N,[[["__m128"],["__m128"]],["__m256"]]],[5,"_mm256_mul_pd","","Add packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_load_ss","","Construct a `__m128` with the lowest element read from `p` and the other elements set to zero.",N,N],[5,"_mm256_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[17,"_MM_ROUND_MASK","","See `_MM_GET_ROUNDING_MODE`",N,N],[5,"_mm_test_all_zeros","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_m_paddsb","","Add packed 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_setr_epi64x","","Set packed 64-bit integers in returned vector with the supplied values in reverse order.",N,[[["i64"],["i64"],["i64"],["i64"]],["__m256i"]]],[5,"_blsic_u64","","Clears least significant bit and sets all other bits.",N,[[["u64"]],["u64"]]],[5,"_mm_maskstore_epi64","","Store packed 64-bit integers from `a` into memory pointed by `mem_addr` using `mask` (elements are not stored when the highest bit is not set in the corresponding element).",N,N],[5,"_mm256_add_epi64","","Add packed 64-bit integers in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_lddqu_si256","","Load 256-bits of integer data from unaligned memory into result. This intrinsic may perform better than `_mm256_loadu_si256` when the data crosses a cache line boundary.",N,N],[5,"_mm256_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mul_epi32","","Multiply the low 32-bit integers from each packed 64-bit element in `a` and `b`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cmpgt_epi64","","Compare packed 64-bit integers in `a` and `b` for greater-than.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_blsmsk_u64","","Get mask up to lowest set bit.",N,[[["u64"]],["u64"]]],[5,"_mm_cvtsi128_si32","","Return the lowest element of `a`.",N,[[["__m128i"]],["i32"]]],[5,"_mm_cmpord_ss","","Check if the lowest `f32` of both inputs are ordered. The lowest 32 bits of the result will be `0xffffffff` if neither of `a.extract(0)` or `b.extract(0)` is a NaN, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_hadds_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_mask_i64gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_cvtsd_f64","","Return the lower double-precision (64-bit) floating-point element of \"a\".",N,[[["__m128d"]],["f64"]]],[5,"_mm_floor_sd","","Round the lower double-precision (64-bit) floating-point element in `b` down to an integer value, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copy the upper element from `a` to the upper element of the intrinsic result.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_floor_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward negative infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm_abs_pi32","","Compute the absolute value of packed 32-bit integers in `a`, and return the unsigned results.",N,[[["__m64"]],["__m64"]]],[5,"_mm_abs_epi32","","Compute the absolute value of each of the packed 32-bit signed integers in `a` and return the 32-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_mulhrs_epi16","","Multiply packed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and return bits `[16:1]`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_mask_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_unpacklo_pi32","","Unpacks the lower element from two `i32x2` vectors and interleaves them into the result: `[a.0, b.0]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_rdseed32_step","","Read a 32-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[17,"_XCR_XFEATURE_ENABLED_MASK","","`XFEATURE_ENABLED_MASK` for `XCR`",N,N],[5,"_mm256_maddubs_epi16","","Vertically multiply each unsigned 8-bit integer from `a` with the corresponding signed 8-bit integer from `b`, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_storeu2_m128i","","Store the high and low 128-bit halves (each composed of integer data) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_cmpnge_sd","","Return a new vector with the low element of `a` replaced by the not-greater-than-or-equal comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[3,"CpuidResult","","Result of the `cpuid` instruction.",N,N],[12,"eax","","EAX register.",2,N],[12,"ebx","","EBX register.",2,N],[12,"ecx","","ECX register.",2,N],[12,"edx","","EDX register.",2,N],[5,"_mm_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_castsi128_si256","","Casts vector of type __m128i to type __m256i; the upper 128 bits of the result are undefined.",N,[[["__m128i"]],["__m256i"]]],[5,"_m_paddusw","","Add packed unsigned 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_subs_epi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_storeu_ps","","Store four 32-bit floats into memory. There are no restrictions on memory alignment. For aligned memory `_mm_store_ps` may be faster.",N,N],[5,"_mm256_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_max_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the maximum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[17,"_SIDD_BIT_MASK","","Mask only: return the bit mask",N,N],[5,"_mm_cvttss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer with truncation.",N,[[["__m128"]],["i32"]]],[5,"_mm_packs_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_cvt_pi2ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm256_broadcastsi128_si256","","Broadcast 128 bits of integer data from a to all 128-bit lanes in the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[17,"_SIDD_UBYTE_OPS","","String contains unsigned 8-bit characters (Default)",N,N],[5,"_m_psadbw","","Subtracts the corresponding 8-bit unsigned integer values of the two 64-bit vector operands and computes the absolute value for each of the difference. Then sum of the 8 absolute differences is written to the bits `[15:0]` of the destination; the remaining bits `[63:16]` are cleared.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_ROUND_DOWN","","See `_mm_setcsr`",N,N],[5,"_mm_sign_pi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpeq_sd","","Return a new vector with the low element of `a` replaced by the equality comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_sub_sd","","Return a new vector with the low element of `a` replaced by subtracting the low element by `b` from the low element of `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_add_ps","","Add packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_mask_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_cvtss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer.",N,[[["__m128"]],["i64"]]],[17,"_SIDD_MOST_SIGNIFICANT","","Index only: return the most significant bit",N,N],[5,"_mm_div_ps","","Divides __m128 vectors.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_min_epi16","","Compare packed 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[17,"_CMP_EQ_OS","","Equal (ordered, signaling)",N,N],[5,"_mm_bslli_si128","","Shift `a` left by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[17,"_MM_EXCEPT_DIV_ZERO","","See `_mm_setcsr`",N,N],[5,"_m_pminsw","","Compares the packed 16-bit signed integers of `a` and `b` writing the smallest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_alignr_pi8","","Concatenates the two 64-bit integer vector operands, and right-shifts the result by the number of bytes specified in the immediate operand.",N,[[["__m64"],["__m64"],["i32"]],["__m64"]]],[5,"_mm256_and_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_rsqrt_ps","","Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[17,"_CMP_LE_OS","","Less-than-or-equal (ordered, signaling)",N,N],[5,"_mm_cvtpi32_pd","","Converts the two signed 32-bit integer elements of a 64-bit vector of `[2 x i32]` into two double-precision floating-point values, returned in a 128-bit vector of `[2 x double]`.",N,[[["__m64"]],["__m128d"]]],[5,"_mm_set1_pd","","Broadcast double-precision (64-bit) floating-point value a to all elements of the return value.",N,[[["f64"]],["__m128d"]]],[5,"_mm256_zextsi128_si256","","Constructs a 256-bit integer vector from a 128-bit integer vector. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_cvttss_si64","","Convert the lowest 32 bit float in the input vector to a 64 bit integer with truncation.",N,[[["__m128"]],["i64"]]],[5,"_mm_floor_ps","","Round the packed single-precision (32-bit) floating-point elements in `a` down to an integer value, and store the results as packed single-precision floating-point elements.",N,[[["__m128"]],["__m128"]]],[5,"_mm256_cvtepi8_epi16","","Sign-extend 8-bit integers to 16-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_unpacklo_pd","","The resulting `__m128d` element is composed by the high-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_castps_pd","","Cast vector of type __m256 to type __m256d.",N,[[["__m256"]],["__m256d"]]],[5,"_mm_sign_pi8","","Negate packed 8-bit integers in `a` when the corresponding signed 8-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_min_epi8","","Compare packed 8-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_hsub_epi32","","Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of `[4 x i32]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_madd_epi16","","Multiply packed signed 16-bit integers in `a` and `b`, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_maskload_pd","","Load packed double-precision (64-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_cmpnge_pd","","Compare corresponding elements in `a` and `b` for not-greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cvtepu32_epi64","","Zero extend packed unsigned 32-bit integers in `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm256_div_ps","","Compute the division of each of the 8 packed 32-bit floating-point elements in `a` by the corresponding packed elements in `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_sign_epi32","","Negate packed 32-bit integers in `a` when the corresponding signed 32-bit integer in `b` is negative, and return the results. Element in result are zeroed out when the corresponding element in `b` is zero.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sll_epi32","","Shift packed 32-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_sub_pi16","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_comile_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than or equal to the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_extract_si64","","Extracts the bit range specified by `y` from the lower 64 bits of `x`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_max_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed maximum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cmpeq_ss","","Compare the lowest `f32` of both inputs for equality. The lowest 32 bits of the result will be `0xffffffff` if the two inputs are equal, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_broadcast_ss","","Broadcast a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm_ucomige_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is greater than or equal to the one from `b`, or `0` otherwise. This instruction will not signal an exception if either argument is a quiet NaN.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_maddubs_pi16","","Multiplies corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, adds pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_min_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_fnmsub_ss","","Multiply the lower single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from `a` to the upper elements of the result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm_min_ss","","Compare the first single-precision (32-bit) floating-point element of `a` and `b`, and return the minimum value in the first element of the return value, the other elements are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed minimum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sub_pi8","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_blsr_u32","","Resets the lowest set bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_rdseed64_step","","Read a 64-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[5,"_xsaves","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[5,"_mm_set_epi32","","Set packed 32-bit integers with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"]],["__m128i"]]],[5,"_mm256_permute_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["i32"]],["__m256d"]]],[5,"_mm_max_epu32","","Compare packed unsigned 32-bit integers in `a` and `b`, and return packed maximum values.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_max_pd","","Return a new vector with the maximum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_cvtepu8_epi32","","Zero-extend the lower eight unsigned 8-bit integers in `a` to 32-bit integers. The upper eight elements of `a` are unused.",N,[[["__m128i"]],["__m256i"]]],[5,"_m_paddb","","Add packed 8-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_pdep_u64","","Scatter contiguous low order bits of `a` to the result at the positions specified by the `mask`.",N,[[["u64"],["u64"]],["u64"]]],[5,"_mm_unpackhi_pd","","The resulting `__m128d` element is composed by the low-order values of the two `__m128d` interleaved input elements, i.e.:",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_undefined_pd","","Return vector of type `__m256d` with undefined elements.",N,[[],["__m256d"]]],[5,"_mm_cmpistra","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if `b` did not contain a null character and the resulting mask was zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm_movehl_ps","","Combine higher half of `a` and `b`. The highwe half of `b` occupies the lower half of result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mulhrs_epi16","","Multiply packed 16-bit signed integer values, truncate the 32-bit product to the 18 most significant bits by right-shifting, round the truncated value by adding 1, and write bits `[16:1]` to the destination.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_unpackhi_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_movedup_pd","","Duplicate even-indexed double-precision (64-bit) floating-point elements from \"a\", and return the results.",N,[[["__m256d"]],["__m256d"]]],[5,"_mm_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_set1_ps","","Construct a `__m128` with all element set to `a`.",N,[[["f32"]],["__m128"]]],[5,"_mm_cvtps_pd","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128"]],["__m128d"]]],[5,"_mm_movepi64_pi64","","Returns the lower 64 bits of a 128-bit integer vector as a 64-bit integer.",N,[[["__m128i"]],["__m64"]]],[5,"_mm_cmpnle_pd","","Compare corresponding elements in `a` and `b` for not-less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_xrstor","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_hadd_epi16","","Horizontally add the adjacent pairs of values contained in 2 packed 128-bit vectors of `[8 x i16]`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm_sha256rnds2_epu32","","Perform 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from `a`, an initial SHA256 state (A,B,E,F) from `b`, and a pre-computed sum of the next 2 round message values (unsigned 32-bit integers) and the corresponding round constants from `k`, and store the updated SHA256 state (A,B,E,F) in dst.",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_castpd128_pd256","","Casts vector of type __m128d to type __m256d; the upper 128 bits of the result are undefined.",N,[[["__m128d"]],["__m256d"]]],[5,"_m_paddsw","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_undefined_si128","","Return vector of type __m128i with undefined elements.",N,[[],["__m128i"]]],[5,"_pext_u32","","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u32"],["u32"]],["u32"]]],[5,"_mm_abs_epi16","","Compute the absolute value of each of the packed 16-bit signed integers in `a` and return the 16-bit unsigned integer",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_packs_epi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_fnmsub_sd","","Multiply the lower double-precision (64-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result. Store the result in the lower element of the returned value, and copy the upper element from `a` to the upper elements of the result.",N,[[["__m128d"],["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cvtsi64_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[17,"_CMP_NEQ_OQ","","Not-equal (ordered, non-signaling)",N,N],[17,"_MM_FROUND_TO_NEAREST_INT","","round to nearest",N,N],[5,"_mm_cmpnlt_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is not less than the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_add_ss","","Adds the first component of `a` and `b`, the other components are copied from `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_blend_epi16","","Blend packed 16-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_insert_epi8","","Copy `a` to result, and insert the 8-bit integer `i` into result at the location specified by `index`.",N,[[["__m256i"],["i8"],["i32"]],["__m256i"]]],[5,"_m_psubw","","Subtract packed 16-bit integers in `b` from packed 16-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_blsfill_u64","","Sets all bits of `x` below the least significant one.",N,[[["u64"]],["u64"]]],[5,"_mm_cmplt_pd","","Compare corresponding elements in `a` and `b` for less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_setzero_pd","","Return vector of type __m256d with all elements set to zero.",N,[[],["__m256d"]]],[5,"_rdrand32_step","","Read a hardware generated 32-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u32"]],["i32"]]],[5,"_mm_cmpestrz","","Compare packed strings in `a` and `b` with lengths `la` and `lb` using the control in `imm8`, and return `1` if any character in `b` was null, and `0` otherwise.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm_cvtepi8_epi64","","Sign extend packed 8-bit integers in the low 8 bytes of `a` to packed 64-bit integers",N,[[["__m128i"]],["__m128i"]]],[17,"_CMP_NLE_UQ","","Not-less-than-or-equal (unordered, non-signaling)",N,N],[5,"_mm256_set1_ps","","Broadcast single-precision (32-bit) floating-point value `a` to all elements of returned vector.",N,[[["f32"]],["__m256"]]],[5,"_mm_testnzc_si128","","Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_round_ss","","Round the lower single-precision (32-bit) floating-point element in `b` using the `rounding` parameter, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the instrinsic result. Rounding is done according to the rounding parameter, which can be one of:",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_pext_u64","","Gathers the bits of `x` specified by the `mask` into the contiguous low order bit positions of the result.",N,[[["u64"],["u64"]],["u64"]]],[5,"_m_psubb","","Subtract packed 8-bit integers in `b` from packed 8-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_extractf128_si256","","Extract 128 bits (composed of integer data) from `a`, selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"_mm_min_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return packed minimum.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_srai_epi32","","Shift packed 32-bit integers in `a` right by `imm8` while shifting in sign bits.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_min_pd","","Return a new vector with the minimum values from corresponding elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_setcsr","","Set the MXCSR register with the 32-bit unsigned integer value.",N,N],[5,"_mm256_set1_epi16","","Broadcast 16-bit integer `a` to all all elements of returned vector. This intrinsic may generate the `vpbroadcastw`.",N,[[["i16"]],["__m256i"]]],[5,"_mm_or_si128","","Compute the bitwise OR of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_cvtepi32_pd","","Convert packed 32-bit integers in `a` to packed double-precision (64-bit) floating-point elements.",N,[[["__m128i"]],["__m256d"]]],[5,"_mm256_fmaddsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cvtps_pi8","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 8-bit integers, and returns theem in the lower 4 elements of the result.",N,[[["__m128"]],["__m64"]]],[5,"_mm256_xor_ps","","Compute the bitwise XOR of packed single-precision (32-bit) floating-point elements in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm_cmplt_epi32","","Compare packed 32-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_blcfill_u32","","Clears all bits below the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_mm_cmpneq_ss","","Compare the lowest `f32` of both inputs for inequality. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is not equal to `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_fmadd_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and add the intermediate result to packed elements in `c`.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_set_epi32","","Set packed 32-bit integers in returned vector with the supplied values.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm_sha256msg2_epu32","","Perform the final calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and return the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_blsfill_u32","","Sets all bits of `x` below the least significant one.",N,[[["u32"]],["u32"]]],[5,"_mm_cmp_ps","","Compare packed single-precision (32-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_cmpgt_pi32","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[17,"_MM_FROUND_NEARBYINT","","use MXCSR.RC and suppress exceptions; see `vendor::_MM_SET_ROUNDING_MODE`",N,N],[5,"_mm_cmpeq_pd","","Compare corresponding elements in `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cvtsd_si64","","Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer.",N,[[["__m128d"]],["i64"]]],[17,"_CMP_EQ_US","","Equal (unordered, signaling)",N,N],[17,"_MM_EXCEPT_OVERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm256_unpackhi_epi32","","Unpack and interleave 32-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvt_ss2si","","Alias for `_mm_cvtss_si32`.",N,[[["__m128"]],["i32"]]],[5,"_mm256_permutevar8x32_epi32","","Permutes packed 32-bit integers from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sub_epi32","","Subtract packed 32-bit integers in `b` from packed 16-bit integers in `a`",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sha1msg1_epu32","","Perform an intermediate calculation for the next four SHA1 message values (unsigned 32-bit integers) using previous message values from `a` and `b`, and returning the result.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_aeskeygenassist_si128","","Assist in expanding the AES cipher key.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_storer_pd","","Store 2 double-precision (64-bit) floating-point elements from `a` into memory in reverse order. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_cvttsd_si32","","Convert the lower double-precision (64-bit) floating-point element in `a` to a 32-bit integer with truncation.",N,[[["__m128d"]],["i32"]]],[5,"_mm_cmpgt_pi8","","Compares whether each element of `a` is greater than the corresponding element of `b` returning `0` for `false` and `-1` for `true`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_adds_pu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_fnmadd_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and add the negated intermediate result to packed elements in `c`.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[17,"_MM_ROUND_TOWARD_ZERO","","See `_mm_setcsr`",N,N],[5,"_bswap","","Return an integer with the reversed byte order of x",N,[[["i32"]],["i32"]]],[5,"_mm_load_sd","","Loads a 64-bit double-precision value to the low element of a 128-bit integer vector and clears the upper element.",N,N],[5,"_mm_cmpistrm","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return the generated mask.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_max_pu8","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_permute2f128_si256","","Shuffle 258-bits (composed of integer data) selected by `imm8` from `a` and `b`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_srli_epi64","","Shift packed 64-bit integers in `a` right by `imm8` while shifting in zeros",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_and_pd","","Compute the bitwise AND of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_adds_epu8","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[17,"_SIDD_SWORD_OPS","","String contains unsigned 16-bit characters",N,N],[5,"_mm_cvtpi8_ps","","Converts the lower 4 8-bit values of `a` into a 128-bit vector of 4 `f32`s.",N,[[["__m64"]],["__m128"]]],[5,"_mm_lddqu_si128","","Load 128-bits of integer data from unaligned memory. This intrinsic may perform better than `_mm_loadu_si128` when the data crosses a cache line boundary.",N,N],[5,"_mm256_insertf128_pd","","Copy `a` to result, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256d"],["__m128d"],["i32"]],["__m256d"]]],[5,"_mm_loadu_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_mm_adds_pi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_undefined_ps","","Return vector of type `__m256` with undefined elements.",N,[[],["__m256"]]],[5,"_mm_loadl_pi","","Load two floats from `p` into the lower half of a `__m128`. The upper half is copied from the upper half of `a`.",N,N],[5,"_mm_comieq_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if they are equal, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm256_rcp_ps","","Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in `a`, and return the results. The maximum relative error for this approximation is less than 1.5*2^-12.",N,[[["__m256"]],["__m256"]]],[5,"_mm_i32gather_pd","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_sub_pi32","","Subtract packed 32-bit integers in `b` from packed 32-bit integers in `a`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_comineq_sd","","Compare the lower element of `a` and `b` for not-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_and_si128","","Compute the bitwise AND of 128 bits (representing integer data) in `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_fmaddsub_pd","","Multiply packed double-precision (64-bit) floating-point elements in `a` and `b`, and alternatively add and subtract packed elements in `c` to/from the intermediate result.",N,[[["__m256d"],["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_cvtpd_ps","","Convert packed double-precision (64-bit) floating-point elements in \"a\" to packed single-precision (32-bit) floating-point elements",N,[[["__m128d"]],["__m128"]]],[5,"_mm_movpi64_epi64","","Moves the 64-bit operand to a 128-bit integer vector, zeroing the upper bits.",N,[[["__m64"]],["__m128i"]]],[5,"_mm_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_xsavec64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`.",N,N],[5,"_mm256_unpacklo_epi64","","Unpack and interleave 64-bit integers from the low half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_cvtepi8_epi64","","Sign-extend 8-bit integers to 64-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_setr_epi8","","Set packed 8-bit integers in returned vector with the supplied values in reverse order.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m256i"]]],[5,"_mm_sha1rnds4_epu32","","Perform four rounds of SHA1 operation using an initial SHA1 state (A,B,C,D) from `a` and some pre-computed sum of the next 4 round message values (unsigned 32-bit integers), and state variable E from `b`, and return the updated SHA1 state (A,B,C,D). `func` contains the logic functions and round constants.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_undefined_si256","","Return vector of type __m256i with undefined elements.",N,[[],["__m256i"]]],[5,"_mm_srli_epi16","","Shift packed 16-bit integers in `a` right by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_shuffle_ps","","Shuffle packed single-precision (32-bit) floating-point elements in `a` and `b` using `mask`.",N,[[["__m128"],["__m128"],["u32"]],["__m128"]]],[5,"_mm256_abs_epi32","","Computes the absolute values of packed 32-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_blendv_ps","","Blend packed single-precision (32-bit) floating-point elements from `a` and `b` using `c` as a mask.",N,[[["__m256"],["__m256"],["__m256"]],["__m256"]]],[17,"_MM_FROUND_CEIL","","round up and do not suppress exceptions",N,N],[5,"_mm_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_maskload_ps","","Load packed single-precision (32-bit) floating-point elements from memory into result using `mask` (elements are zeroed out when the high bit of the corresponding element is not set).",N,N],[5,"_mm_packs_pi16","","Convert packed 16-bit integers from `a` and `b` to packed 8-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cvtepu8_epi32","","Zero extend packed unsigned 8-bit integers in `a` to packed 32-bit integers",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_slli_epi64","","Shift packed 64-bit integers in `a` left by `imm8` while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_blendv_epi8","","Blend packed 8-bit integers from `a` and `b` using `mask`",N,[[["__m128i"],["__m128i"],["__m128i"]],["__m128i"]]],[17,"_SIDD_UWORD_OPS","","String contains unsigned 16-bit characters",N,N],[5,"_mm256_setr_epi32","","Set packed 32-bit integers in returned vector with the supplied values in reverse order.",N,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["__m256i"]]],[5,"_mm256_insertf128_ps","","Copy `a` to result, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `b` into result at the location specified by `imm8`.",N,[[["__m256"],["__m128"],["i32"]],["__m256"]]],[5,"_m_paddw","","Add packed 16-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_floor_pd","","Round the packed double-precision (64-bit) floating-point elements in `a` down to an integer value, and store the results as packed double-precision floating-point elements.",N,[[["__m128d"]],["__m128d"]]],[5,"_mm_cmpunord_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. Returns four floats that have one of two possible bit patterns. The element in the output vector will be `0xffffffff` if the input elements in `a` and `b` are unordered (i.e., at least on of them is a NaN), or 0 otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_insert_pi16","","Copies data from the 64-bit vector of `[4 x i16]` to the destination, and inserts the lower 16-bits of an integer operand at the 16-bit offset specified by the immediate operand `n`.",N,[[["__m64"],["i32"],["i32"]],["__m64"]]],[5,"_mm256_mullo_epi16","","Multiply the packed 16-bit integers in `a` and `b`, producing intermediate 32-bit integers, and return the low 16 bits of the intermediate integers",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_movemask_ps","","Set each bit of the returned mask based on the most significant bit of the corresponding packed single-precision (32-bit) floating-point element in `a`.",N,[[["__m256"]],["i32"]]],[5,"_mm256_store_ps","","Store 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_rdrand16_step","","Read a hardware generated 16-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u16"]],["i32"]]],[5,"_mm_set_epi8","","Set packed 8-bit integers with the supplied values.",N,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["__m128i"]]],[5,"_mm256_srl_epi64","","Shift packed 64-bit integers in `a` right by `count` while shifting in zeros.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm256_broadcastq_epi64","","Broadcast the low packed 64-bit integer from `a` to all elements of the 256-bit returned value.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm256_abs_epi8","","Computes the absolute values of packed 8-bit integers in `a`.",N,[[["__m256i"]],["__m256i"]]],[5,"_mm256_setr_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[17,"_CMP_NGT_US","","Not-greater-than (unordered, signaling)",N,N],[5,"_blsi_u32","","Extract lowest set isolated bit.",N,[[["u32"]],["u32"]]],[5,"_mm_hsubs_pi16","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[4 x i16]`. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_max_epu8","","Compare packed unsigned 8-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_loadl_epi64","","Load 64-bit integer from memory into first element of returned vector.",N,N],[5,"_mm_testc_pd","","Compute the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in `a` and `b`, producing an intermediate 128-bit value, and set `ZF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `CF` value.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_store1_ps","","Store the lowest 32 bit float of `a` repeated four times into aligned memory.",N,N],[5,"_mm_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_setr_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[17,"_MM_FLUSH_ZERO_ON","","See `_mm_setcsr`",N,N],[17,"_SIDD_CMP_EQUAL_ANY","","For each character in `a`, find if it is in `b` (Default)",N,N],[5,"_mm_unpacklo_pi8","","Unpacks the lower four elements from two `i8x8` vectors and interleaves them into the result: `[a.0, b.0, a.1, b.1, a.2, b.2, a.3, b.3]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_extract_epi8","","Extract an 8-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i8"]]],[5,"_m_paddusb","","Add packed unsigned 8-bit integers in `a` and `b` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_lzcnt_u32","","Counts the leading most significant zero bits.",N,[[["u32"]],["u32"]]],[5,"_blcs_u32","","Sets the least significant zero bit of `x`.",N,[[["u32"]],["u32"]]],[5,"_mm_min_sd","","Return a new vector with the low element of `a` replaced by the minimum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[17,"_CMP_NEQ_US","","Not-equal (unordered, signaling)",N,N],[5,"_m_pmaxub","","Compares the packed 8-bit signed integers of `a` and `b` writing the greatest value into the result.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_cmpge_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is greater than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_hsub_pi32","","Horizontally subtracts the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_slli_epi32","","Shift packed 32-bit integers in `a` left by `imm8` while shifting in zeros, return the results;",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cmpistrc","","Compare packed strings with implicit lengths in `a` and `b` using the control in `imm8`, and return `1` if the resulting mask was non-zero, and `0` otherwise.",N,[[["__m128i"],["__m128i"],["i32"]],["i32"]]],[5,"_mm256_castps_si256","","Casts vector of type __m256 to type __m256i.",N,[[["__m256"]],["__m256i"]]],[5,"_mm_cvtsd_si32","","Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer.",N,[[["__m128d"]],["i32"]]],[5,"_mm_cmpnlt_pd","","Compare corresponding elements in `a` and `b` for not-less-than.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_extracti128_si256","","Extract 128 bits (of integer data) from `a` selected with `imm8`.",N,[[["__m256i"],["i32"]],["__m128i"]]],[5,"_mm256_cmpeq_epi32","","Compare packed 32-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm256_sra_epi32","","Shift packed 32-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_maskstore_ps","","Store packed single-precision (32-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_mm256_permutevar_pd","","Shuffle double-precision (64-bit) floating-point elements in `a` within 256-bit lanes using the control in `b`.",N,[[["__m256d"],["__m256i"]],["__m256d"]]],[5,"_mm_set_epi64x","","Set packed 64-bit integers with the supplied values, from highest to lowest.",N,[[["i64"],["i64"]],["__m128i"]]],[5,"_mm_extract_ps","","Extract a single-precision (32-bit) floating-point element from `a`, selected with `imm8`",N,[[["__m128"],["i32"]],["i32"]]],[5,"_mm256_set1_epi32","","Broadcast 32-bit integer `a` to all elements of returned vector. This intrinsic may generate the `vpbroadcastd`.",N,[[["i32"]],["__m256i"]]],[5,"_mm256_setr_pd","","Set packed double-precision (64-bit) floating-point elements in returned vector with the supplied values in reverse order.",N,[[["f64"],["f64"],["f64"],["f64"]],["__m256d"]]],[5,"_mm256_store_si256","","Store 256-bits of integer data from `a` into memory. `mem_addr` must be aligned on a 32-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm_extract_epi16","","Return the `imm8` element of `a`.",N,[[["__m128i"],["i32"]],["i32"]]],[5,"_mm256_sqrt_ps","","Return the square root of packed single-precision (32-bit) floating point elements in `a`.",N,[[["__m256"]],["__m256"]]],[5,"_mm_cmplt_epi8","","Compare packed 8-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_extractf128_ps","","Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from `a`, selected with `imm8`.",N,[[["__m256"],["i32"]],["__m128"]]],[3,"__m128d","","128-bit wide set of two `f64` types, x86-specific",N,N],[5,"_mm_comile_sd","","Compare the lower element of `a` and `b` for less-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_i32gather_epi64","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm256_cmp_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b` based on the comparison operand specified by `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[5,"_MM_SET_ROUNDING_MODE","","See `_mm_setcsr`",N,N],[17,"_SIDD_MASKED_POSITIVE_POLARITY","","Do not negate results before the end of the string",N,N],[5,"_mm_subs_pu16","","Subtract packed unsigned 16-bit integers in `b` from packed unsigned 16-bit integers in `a` using saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_cmpeq_epi8","","Compare packed 8-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_load_pd","","Load 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[17,"_MM_EXCEPT_INVALID","","See `_mm_setcsr`",N,N],[5,"_mm256_packus_epi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using unsigned saturation",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cmplt_sd","","Return a new vector with the low element of `a` replaced by the less-than comparison of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_aesimc_si128","","Perform the `InvMixColumns` transformation on `a`.",N,[[["__m128i"]],["__m128i"]]],[5,"_mm_mask_i32gather_epi32","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_castps128_ps256","","Casts vector of type __m128 to type __m256; the upper 128 bits of the result are undefined.",N,[[["__m128"]],["__m256"]]],[5,"_mm_add_pi32","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_crc32_u16","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 16-bit integer `v`.",N,[[["u32"],["u16"]],["u32"]]],[5,"_mm256_min_pd","","Compare packed double-precision (64-bit) floating-point elements in `a` and `b`, and return packed minimum values",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm256_storeu2_m128d","","Store the high and low 128-bit halves (each composed of 2 packed double-precision (64-bit) floating-point elements) from `a` into memory two different 128-bit locations. `hiaddr` and `loaddr` do not need to be aligned on any particular boundary.",N,N],[5,"_mm_cvtsi64x_sd","","Return `a` with its lower element replaced by `b` after converting it to an `f64`.",N,[[["__m128d"],["i64"]],["__m128d"]]],[5,"_fxsave","","Saves the `x87` FPU, `MMX` technology, `XMM`, and `MXCSR` registers to the 512-byte-long 16-byte-aligned memory region `mem_addr`.",N,N],[5,"_mm256_extract_epi16","","Extract a 16-bit integer from `a`, selected with `imm8`. Returns a 32-bit integer containing the zero-extended integer data.",N,[[["__m256i"],["i32"]],["i16"]]],[5,"_mm256_set_m128d","","Set packed __m256d returned vector with the supplied values.",N,[[["__m128d"],["__m128d"]],["__m256d"]]],[5,"_rdrand64_step","","Read a hardware generated 64-bit random value and store the result in val. Return 1 if a random value was generated, and 0 otherwise.",N,[[["u64"]],["i32"]]],[5,"_mm_comige_sd","","Compare the lower element of `a` and `b` for greater-than-or-equal.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm_stream_pi","","Store 64-bits of integer data from a into memory using a non-temporal memory hint.",N,N],[5,"_mm_undefined_ps","","Return vector of type __m128 with undefined elements.",N,[[],["__m128"]]],[3,"__m256d","","256-bit wide set of four `f64` types, x86-specific",N,N],[5,"_mm_hadd_pi32","","Horizontally add the adjacent pairs of values contained in 2 packed 64-bit vectors of `[2 x i32]`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_sll_epi64","","Shift packed 64-bit integers in `a` left by `count` while shifting in zeros, and return the result",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[17,"_MM_EXCEPT_UNDERFLOW","","See `_mm_setcsr`",N,N],[5,"_mm_ceil_ss","","Round the lower single-precision (32-bit) floating-point element in `b` up to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copy the upper 3 packed elements from `a` to the upper elements of the intrinsic result.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_setzero_ps","","Construct a `__m128` with all elements initialized to zero.",N,[[],["__m128"]]],[5,"_mm256_unpackhi_epi16","","Unpack and interleave 16-bit integers from the high half of each 128-bit lane of `a` and `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_tzcnt_u64","","Counts the number of trailing least significant zero bits.",N,[[["u64"]],["u64"]]],[5,"_mm_hsub_ps","","Horizontally add adjacent pairs of single-precision (32-bit) floating-point elements in `a` and `b`, and pack the results.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_cvttps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m256"]],["__m256i"]]],[5,"_mm_cmpgt_ss","","Compare the lowest `f32` of both inputs for greater than. The lowest 32 bits of the result will be `0xffffffff` if `a.extract(0)` is greater than `b.extract(0)`, or `0` otherwise. The upper 96 bits of the result are the upper 96 bits of `a`.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_max_sd","","Return a new vector with the low element of `a` replaced by the maximum of the lower elements of `a` and `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_cmpeq_epi16","","Compare packed 16-bit integers in `a` and `b` for equality.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtsi32_si128","","Return a vector whose lowest element is `a` and all higher elements are `0`.",N,[[["i32"]],["__m128i"]]],[5,"_mm_ucomieq_sd","","Compare the lower element of `a` and `b` for equality.",N,[[["__m128d"],["__m128d"]],["i32"]]],[5,"_mm256_movemask_pd","","Set each bit of the returned mask based on the most significant bit of the corresponding packed double-precision (64-bit) floating-point element in `a`.",N,[[["__m256d"]],["i32"]]],[5,"_mm_sfence","","Perform a serializing operation on all store-to-memory instructions that were issued prior to this instruction.",N,N],[5,"_mm256_cvtepi8_epi32","","Sign-extend 8-bit integers to 32-bit integers.",N,[[["__m128i"]],["__m256i"]]],[5,"_mm_setr_epi64","","Constructs a 128-bit integer vector, initialized in reverse order with the specified 64-bit integral values.",N,[[["__m64"],["__m64"]],["__m128i"]]],[5,"_blsr_u64","","Resets the lowest set bit of `x`.",N,[[["u64"]],["u64"]]],[5,"_mm256_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8.",N,N],[5,"_mm_cmpgt_epi16","","Compare packed 16-bit integers in `a` and `b` for greater-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm256_moveldup_ps","","Duplicate even-indexed single-precision (32-bit) floating-point elements from `a`, and return the results.",N,[[["__m256"]],["__m256"]]],[5,"_mm_unpacklo_epi32","","Unpack and interleave 32-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_packs_pi32","","Convert packed 32-bit integers from `a` and `b` to packed 16-bit integers using signed saturation.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm_set_ss","","Construct a `__m128` with the lowest element set to `a` and the rest set to zero.",N,[[["f32"]],["__m128"]]],[5,"_mm256_xor_pd","","Compute the bitwise XOR of packed double-precision (64-bit) floating-point elements in `a` and `b`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_cmplt_epi16","","Compare packed 16-bit integers in `a` and `b` for less-than.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_pause","","Provide a hint to the processor that the code sequence is a spin-wait loop.",N,N],[5,"_mm256_shuffle_epi8","","Shuffle bytes from `a` according to the content of `b`.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtpi32x2_ps","","Converts the two 32-bit signed integer values from each 64-bit vector operand of `[2 x i32]` into a 128-bit vector of `[4 x float]`.",N,[[["__m64"],["__m64"]],["__m128"]]],[5,"_mm_cmp_ss","","Compare the lower single-precision (32-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper 3 packed elements from `a` to the upper elements of returned vector.",N,[[["__m128"],["__m128"],["i32"]],["__m128"]]],[5,"_mm_store1_pd","","Store the lower double-precision (64-bit) floating-point element from `a` into 2 contiguous elements in memory. `mem_addr` must be aligned on a 16-byte boundary or a general-protection exception may be generated.",N,N],[5,"_mm256_shuffle_pd","","Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in `imm8`.",N,[[["__m256d"],["__m256d"],["i32"]],["__m256d"]]],[17,"_MM_HINT_T1","","See `_mm_prefetch`.",N,N],[5,"_mm_alignr_epi8","","Concatenate 16-byte blocks in `a` and `b` into a 32-byte temporary result, shift the result right by `n` bytes, and return the low 16 bytes.",N,[[["__m128i"],["__m128i"],["i32"]],["__m128i"]]],[5,"_mm_or_ps","","Bitwise OR of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_mask_i64gather_ps","","Return values from `slice` at offsets determined by `offsets * scale`, where `scale` is between 1 and 8. If mask is set, load the value from `src` in that position instead.",N,N],[5,"_mm256_setzero_ps","","Return vector of type __m256 with all elements set to zero.",N,[[],["__m256"]]],[5,"_mm_crc32_u8","","Starting with the initial value in `crc`, return the accumulated CRC32 value for unsigned 8-bit integer `v`.",N,[[["u32"],["u8"]],["u32"]]],[5,"_mm_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from `a`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm256_broadcastsd_pd","","Broadcast the low double-precision (64-bit) floating-point element from `a` to all elements of the 256-bit returned value.",N,[[["__m128d"]],["__m256d"]]],[17,"_CMP_ORD_S","","Ordered (signaling)",N,N],[17,"_MM_MASK_INEXACT","","See `_mm_setcsr`",N,N],[5,"_mm_testz_si128","","Tests whether the specified bits in a 128-bit integer vector are all zeros.",N,[[["__m128i"],["__m128i"]],["i32"]]],[5,"_mm_move_epi64","","Return a vector where the low element is extracted from `a` and its upper element is zero.",N,[[["__m128i"]],["__m128i"]]],[3,"__m128i","","128-bit wide integer vector type, x86-specific",N,N],[5,"_mm_subs_epu8","","Subtract packed unsigned 8-bit integers in `b` from packed unsigned 8-bit integers in `a` using saturation.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_extract_pi16","","Extracts 16-bit element from a 64-bit vector of `[4 x i16]` and returns it, as specified by the immediate integer operand.",N,[[["__m64"],["i32"]],["i32"]]],[5,"_mm256_unpacklo_ps","","Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in `a` and `b`.",N,[[["__m256"],["__m256"]],["__m256"]]],[5,"_mm256_set_m128i","","Set packed __m256i returned vector with the supplied values.",N,[[["__m128i"],["__m128i"]],["__m256i"]]],[5,"_mm_div_pd","","Divide packed double-precision (64-bit) floating-point elements in `a` by packed elements in `b`.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_comilt_ss","","Compare two 32-bit floats from the low-order bits of `a` and `b`. Returns `1` if the value from `a` is less than the one from `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["i32"]]],[5,"_mm_cmpestri","","Compare packed strings `a` and `b` with lengths `la` and `lb` using the control in `imm8` and return the generated index. Similar to [`_mm_cmpistri`] with the exception that [`_mm_cmpistri`] implicitly determines the length of `a` and `b`.",N,[[["__m128i"],["i32"],["__m128i"],["i32"],["i32"]],["i32"]]],[5,"_mm256_shufflelo_epi16","","Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of `a` using the control in `imm8`. The high 64 bits of 128-bit lanes of `a` are copied to the output.",N,[[["__m256i"],["i32"]],["__m256i"]]],[5,"_mm256_castsi256_si128","","Casts vector of type __m256i to type __m128i.",N,[[["__m256i"]],["__m128i"]]],[5,"_mm_cvttpd_epi32","","Convert packed double-precision (64-bit) floating-point elements in `a` to packed 32-bit integers with truncation.",N,[[["__m128d"]],["__m128i"]]],[5,"_mm_cvtpi32_ps","","Converts two elements of a 64-bit vector of `[2 x i32]` into two floating point values and writes them to the lower 64-bits of the destination. The remaining higher order elements of the destination are copied from the corresponding elements in the first operand.",N,[[["__m128"],["__m64"]],["__m128"]]],[5,"_mm256_sra_epi16","","Shift packed 16-bit integers in `a` right by `count` while shifting in sign bits.",N,[[["__m256i"],["__m128i"]],["__m256i"]]],[5,"_mm_maskload_epi64","","Load packed 64-bit integers from memory pointed by `mem_addr` using `mask` (elements are zeroed out when the highest bit is not set in the corresponding element).",N,N],[5,"_xrstors64","","Perform a full or partial restore of the enabled processor states using the state information stored in memory at `mem_addr`.",N,N],[5,"_mm_cmple_ps","","Compare each of the four floats in `a` to the corresponding element in `b`. The result in the output vector will be `0xffffffff` if the input element in `a` is less than or equal to the corresponding element in `b`, or `0` otherwise.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_max_epu16","","Compare packed unsigned 16-bit integers in `a` and `b`, and return the packed maximum values.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_andnot_ps","","Bitwise AND-NOT of packed single-precision (32-bit) floating-point elements.",N,[[["__m128"],["__m128"]],["__m128"]]],[5,"_mm_unpacklo_epi8","","Unpack and interleave 8-bit integers from the low half of `a` and `b`.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_fmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm256_castpd_ps","","Cast vector of type __m256d to type __m256.",N,[[["__m256d"]],["__m256"]]],[5,"_mm_storel_pi","","Store the lower half of `a` (64 bits) into memory.",N,N],[5,"_mm_shuffle_pd","","Constructs a 128-bit floating-point vector of `[2 x double]` from two 128-bit vector parameters of `[2 x double]`, using the immediate-value parameter as a specifier.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_maskstore_pd","","Store packed double-precision (64-bit) floating-point elements from `a` into memory using `mask`.",N,N],[5,"_xsaves64","","Perform a full or partial save of the enabled processor states to memory at `mem_addr`",N,N],[5,"_mm256_blend_epi32","","Blend packed 32-bit integers from `a` and `b` using control mask `imm8`.",N,[[["__m256i"],["__m256i"],["i32"]],["__m256i"]]],[5,"_mm_cmp_sd","","Compare the lower double-precision (64-bit) floating-point element in `a` and `b` based on the comparison operand specified by `imm8`, store the result in the lower element of returned vector, and copy the upper element from `a` to the upper element of returned vector.",N,[[["__m128d"],["__m128d"],["i32"]],["__m128d"]]],[5,"_mm256_sign_epi16","","Negate packed 16-bit integers in `a` when the corresponding signed 16-bit integer in `b` is negative, and return the results. Results are zeroed out when the corresponding element in `b` is zero.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_cvtss_si32","","Convert the lowest 32 bit float in the input vector to a 32 bit integer.",N,[[["__m128"]],["i32"]]],[5,"_mm_shufflehi_epi16","","Shuffle 16-bit integers in the high 64 bits of `a` using the control in `imm8`.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_ceil_ps","","Round packed single-precision (32-bit) floating point elements in `a` toward positive infinity.",N,[[["__m256"]],["__m256"]]],[5,"_mm_fnmsub_ps","","Multiply packed single-precision (32-bit) floating-point elements in `a` and `b`, and subtract packed elements in `c` from the negated intermediate result.",N,[[["__m128"],["__m128"],["__m128"]],["__m128"]]],[5,"_mm_sll_epi16","","Shift packed 16-bit integers in `a` left by `count` while shifting in zeros.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[17,"_MM_FROUND_TRUNC","","truncate and do not suppress exceptions",N,N],[5,"_mm256_sub_pd","","Subtract packed double-precision (64-bit) floating-point elements in `b` from packed elements in `a`.",N,[[["__m256d"],["__m256d"]],["__m256d"]]],[5,"_mm_srli_si128","","Shift `a` right by `imm8` bytes while shifting in zeros.",N,[[["__m128i"],["i32"]],["__m128i"]]],[5,"_mm256_testz_ps","","Compute the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in `a` and `b`, producing an intermediate 256-bit value, and set `ZF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, producing an intermediate value, and set `CF` to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set `CF` to 0. Return the `ZF` value.",N,[[["__m256"],["__m256"]],["i32"]]],[5,"_mm_cmpord_sd","","Return a new vector with the low element of `a` replaced by the result of comparing both of the lower elements of `a` and `b` to `NaN`. If neither are equal to `NaN` then `0xFFFFFFFFFFFFFFFF` is used and `0` otherwise.",N,[[["__m128d"],["__m128d"]],["__m128d"]]],[5,"_mm_cvtps_epi32","","Convert packed single-precision (32-bit) floating-point elements in `a` to packed 32-bit integers.",N,[[["__m128"]],["__m128i"]]],[5,"_mm_min_epi8","","Compare packed 8-bit integers in `a` and `b` and return packed minimum values in dst.",N,[[["__m128i"],["__m128i"]],["__m128i"]]],[5,"_mm_load_si128","","Load 128-bits of integer data from memory into a new vector.",N,N],[5,"_m_paddd","","Add packed 32-bit integers in `a` and `b`.",N,[[["__m64"],["__m64"]],["__m64"]]],[5,"_mm256_permute2f128_ps","","Shuffle 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) selected by `imm8` from `a` and `b`.",N,[[["__m256"],["__m256"],["i32"]],["__m256"]]],[5,"_mm256_testnzc_si256","","Compute the bitwise AND of 256 bits (representing integer data) in `a` and `b`, and set `ZF` to 1 if the result is zero, otherwise set `ZF` to 0. Compute the bitwise NOT of `a` and then AND with `b`, and set `CF` to 1 if the result is zero, otherwise set `CF` to 0. Return 1 if both the `ZF` and `CF` values are zero, otherwise return 0.",N,[[["__m256i"],["__m256i"]],["i32"]]],[5,"_mm256_adds_epi16","","Add packed 16-bit integers in `a` and `b` using saturation.",N,[[["__m256i"],["__m256i"]],["__m256i"]]],[5,"_mm_sqrt_ss","","Return the square root of the first single-precision (32-bit) floating-point element in `a`, the other elements are unchanged.",N,[[["__m128"]],["__m128"]]],[14,"is_arm_feature_detected","stdsimd","",N,N],[14,"is_aarch64_feature_detected","","",N,N],[14,"is_powerpc_feature_detected","","",N,N],[14,"is_powerpc64_feature_detected","","",N,N],[14,"is_mips_feature_detected","","",N,N],[14,"is_mips64_feature_detected","","",N,N],[14,"is_x86_feature_detected","","A macro to test at runtime whether a CPU feature is available on x86/x86-64 platforms.",N,N],[11,"new","stdsimd::simd","Creates a new instance with each vector elements initialized with the provided values.",3,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m32x8"]]],[11,"lanes","","Returns the number of vector lanes.",3,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",3,[[["bool"]],["m32x8"]]],[11,"extract","","Extracts the value at `index`.",3,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",3,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",3,[[["self"],["usize"],["bool"]],["m32x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",3,[[["self"],["usize"],["bool"]],["m32x8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",3,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",3,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",3,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",3,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",3,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",3,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",3,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"bitand_assign","","",4,N],[11,"bitand_assign","","",5,N],[11,"bitand_assign","","",6,N],[11,"bitand_assign","","",7,N],[11,"bitand_assign","","",8,N],[11,"bitand_assign","","",9,N],[11,"bitand_assign","","",10,N],[11,"bitand_assign","","",11,N],[11,"bitand_assign","","",12,N],[11,"bitand_assign","","",13,N],[11,"bitand_assign","","",14,N],[11,"bitand_assign","","",15,N],[11,"bitand_assign","","",16,N],[11,"bitand_assign","","",14,N],[11,"bitand_assign","","",17,N],[11,"bitand_assign","","",18,N],[11,"bitand_assign","","",19,N],[11,"bitand_assign","","",20,N],[11,"bitand_assign","","",21,N],[11,"bitand_assign","","",22,N],[11,"bitand_assign","","",23,N],[11,"bitand_assign","","",24,N],[11,"bitand_assign","","",25,N],[11,"bitand_assign","","",21,N],[11,"bitand_assign","","",26,N],[11,"bitand_assign","","",11,N],[11,"bitand_assign","","",7,N],[11,"bitand_assign","","",27,N],[11,"bitand_assign","","",28,N],[11,"bitand_assign","","",29,N],[11,"bitand_assign","","",30,N],[11,"bitand_assign","","",31,N],[11,"bitand_assign","","",3,N],[11,"bitand_assign","","",32,N],[11,"bitand_assign","","",33,N],[11,"bitand_assign","","",34,N],[11,"bitand_assign","","",20,N],[11,"bitand_assign","","",35,N],[11,"bitand_assign","","",35,N],[11,"bitand_assign","","",36,N],[11,"bitand_assign","","",15,N],[11,"bitand_assign","","",37,N],[11,"bitand_assign","","",37,N],[11,"bitand_assign","","",38,N],[11,"bitand_assign","","",38,N],[11,"bitand_assign","","",39,N],[11,"bitand_assign","","",40,N],[11,"bitand_assign","","",41,N],[11,"bitand_assign","","",16,N],[11,"bitand_assign","","",27,N],[11,"bitand_assign","","",42,N],[11,"bitand_assign","","",43,N],[11,"bitand_assign","","",34,N],[11,"bitand_assign","","",13,N],[11,"bitand_assign","","",4,N],[11,"bitand_assign","","",44,N],[11,"bitand_assign","","",19,N],[11,"bitand_assign","","",41,N],[11,"bitand_assign","","",45,N],[11,"bitand_assign","","",46,N],[11,"bitand_assign","","",12,N],[11,"bitand_assign","","",10,N],[11,"bitand_assign","","",30,N],[11,"bitand_assign","","",23,N],[11,"bitand_assign","","",47,N],[11,"bitand_assign","","",9,N],[11,"bitand_assign","","",48,N],[11,"bitand_assign","","",28,N],[11,"bitand_assign","","",29,N],[11,"bitand_assign","","",6,N],[11,"bitand_assign","","",49,N],[11,"bitand_assign","","",50,N],[11,"bitand_assign","","",31,N],[11,"bitand_assign","","",22,N],[11,"bitand_assign","","",18,N],[11,"bitand_assign","","",46,N],[11,"bitand_assign","","",47,N],[11,"bitand_assign","","",51,N],[11,"bitand_assign","","",44,N],[11,"bitand_assign","","",43,N],[11,"bitand_assign","","",25,N],[11,"bitand_assign","","",50,N],[11,"bitand_assign","","",17,N],[11,"bitand_assign","","",52,N],[11,"bitand_assign","","",53,N],[11,"bitand_assign","","",3,N],[11,"bitand_assign","","",32,N],[11,"bitand_assign","","",54,N],[11,"bitand_assign","","",36,N],[11,"bitand_assign","","",54,N],[11,"bitand_assign","","",8,N],[11,"bitand_assign","","",39,N],[11,"bitand_assign","","",51,N],[11,"bitand_assign","","",40,N],[11,"bitand_assign","","",5,N],[11,"bitand_assign","","",33,N],[11,"bitand_assign","","",53,N],[11,"bitand_assign","","",24,N],[11,"bitand_assign","","",26,N],[11,"bitand_assign","","",49,N],[11,"bitand_assign","","",48,N],[11,"bitand_assign","","",55,N],[11,"bitand_assign","","",42,N],[11,"bitand_assign","","",45,N],[11,"bitand_assign","","",56,N],[11,"bitand_assign","","",56,N],[11,"bitand_assign","","",55,N],[11,"bitand_assign","","",52,N],[11,"fmt","","",49,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",45,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",19,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",39,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",29,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",33,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",36,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",12,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",52,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",16,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",22,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",56,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result",["error"]]]],[11,"add","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"add","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"add","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"add","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"add","","",57,[[["self"],["f32x4"]],["f32x4"]]],[11,"add","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"add","","",58,[[["self"],["f64"]],["f64x8"]]],[11,"add","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"add","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"add","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"add","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"add","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"add","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"add","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"add","","",59,[[["self"],["f32x16"]],["f32x16"]]],[11,"add","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"add","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"add","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"add","","",60,[[["self"],["f64"]],["f64x2"]]],[11,"add","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"add","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"add","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"add","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"add","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"add","","",60,[[["self"],["f64x2"]],["f64x2"]]],[11,"add","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"add","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"add","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"add","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"add","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"add","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"add","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"add","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"add","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"add","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"add","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"add","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"add","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"add","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"add","","",61,[[["self"],["f32x2"]],["f32x2"]]],[11,"add","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"add","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"add","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"add","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"add","","",59,[[["self"],["f32"]],["f32x16"]]],[11,"add","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"add","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"add","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"add","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"add","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"add","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"add","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"add","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"add","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"add","","",62,[[["self"],["f64"]],["f64x4"]]],[11,"add","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"add","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"add","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"add","","",58,[[["self"],["f64x8"]],["f64x8"]]],[11,"add","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"add","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"add","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"add","","",57,[[["self"],["f32"]],["f32x4"]]],[11,"add","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"add","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"add","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"add","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"add","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"add","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"add","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"add","","",61,[[["self"],["f32"]],["f32x2"]]],[11,"add","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"add","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"add","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"add","","",63,[[["self"],["f32"]],["f32x8"]]],[11,"add","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"add","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"add","","",63,[[["self"],["f32x8"]],["f32x8"]]],[11,"add","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"add","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"add","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"add","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"add","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"add","","",62,[[["self"],["f64x4"]],["f64x4"]]],[11,"add","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"add","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"shr_assign","","",51,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",30,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",19,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",13,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",34,N],[11,"shr_assign","","",47,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",16,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",51,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",18,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",44,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",5,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",39,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",21,N],[11,"shr_assign","","",29,N],[11,"shr_assign","","",55,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",14,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",10,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",45,N],[11,"shr_assign","","",49,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",27,N],[11,"shr_assign","","",52,N],[11,"shr_assign","","",9,N],[11,"shr_assign","","",8,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",4,N],[11,"shr_assign","","",23,N],[11,"shr_assign","","",37,N],[11,"shr_assign","","",22,N],[11,"shr_assign","","",24,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",33,N],[11,"shr_assign","","",36,N],[11,"shr_assign","","",50,N],[11,"shr_assign","","",7,N],[11,"shr_assign","","",6,N],[11,"shr_assign","","",56,N],[11,"shr_assign","","",12,N],[11,"shr_assign","","",41,N],[11,"shr_assign","","",35,N],[11,"shr_assign","","",37,N],[11,"default","","",31,[[],["m32x4"]]],[11,"default","","",3,[[],["m32x8"]]],[11,"default","","",52,[[],["i32x4"]]],[11,"default","","",51,[[],["u8x4"]]],[11,"default","","",16,[[],["u16x2"]]],[11,"default","","",35,[[],["i16x2"]]],[11,"default","","",39,[[],["i32x8"]]],[11,"default","","",4,[[],["u64x4"]]],[11,"default","","",55,[[],["i8x4"]]],[11,"default","","",5,[[],["u8x64"]]],[11,"default","","",20,[[],["m8x8"]]],[11,"default","","",46,[[],["m8x4"]]],[11,"default","","",12,[[],["u16x16"]]],[11,"default","","",57,[[],["f32x4"]]],[11,"default","","",27,[[],["i16x4"]]],[11,"default","","",36,[[],["i64x2"]]],[11,"default","","",14,[[],["u16x8"]]],[11,"default","","",29,[[],["i16x32"]]],[11,"default","","",33,[[],["u16x32"]]],[11,"default","","",7,[[],["u32x8"]]],[11,"default","","",23,[[],["u8x32"]]],[11,"default","","",62,[[],["f64x4"]]],[11,"default","","",17,[[],["m8x32"]]],[11,"default","","",63,[[],["f32x8"]]],[11,"default","","",61,[[],["f32x2"]]],[11,"default","","",15,[[],["m1x8"]]],[11,"default","","",37,[[],["i8x64"]]],[11,"default","","",60,[[],["f64x2"]]],[11,"default","","",26,[[],["m1x64"]]],[11,"default","","",30,[[],["u32x16"]]],[11,"default","","",6,[[],["i8x2"]]],[11,"default","","",22,[[],["i64x4"]]],[11,"default","","",8,[[],["u64x8"]]],[11,"default","","",11,[[],["m8x2"]]],[11,"default","","",44,[[],["u8x16"]]],[11,"default","","",48,[[],["m1x32"]]],[11,"default","","",50,[[],["u8x2"]]],[11,"default","","",9,[[],["u32x2"]]],[11,"default","","",32,[[],["m16x16"]]],[11,"default","","",54,[[],["m64x2"]]],[11,"default","","",41,[[],["i32x16"]]],[11,"default","","",25,[[],["m32x2"]]],[11,"default","","",49,[[],["i8x32"]]],[11,"default","","",47,[[],["i64x8"]]],[11,"default","","",38,[[],["m1x16"]]],[11,"default","","",21,[[],["i8x8"]]],[11,"default","","",19,[[],["u32x4"]]],[11,"default","","",13,[[],["i32x2"]]],[11,"default","","",40,[[],["m16x8"]]],[11,"default","","",58,[[],["f64x8"]]],[11,"default","","",10,[[],["i16x16"]]],[11,"default","","",53,[[],["m16x2"]]],[11,"default","","",34,[[],["i8x16"]]],[11,"default","","",59,[[],["f32x16"]]],[11,"default","","",18,[[],["u64x2"]]],[11,"default","","",28,[[],["m64x4"]]],[11,"default","","",56,[[],["i16x8"]]],[11,"default","","",45,[[],["u8x8"]]],[11,"default","","",24,[[],["u16x4"]]],[11,"default","","",43,[[],["m16x4"]]],[11,"default","","",42,[[],["m8x16"]]],[11,"cmp","stdsimd::arch::x86_64","",2,[[["self"],["cpuidresult"]],["ordering"]]],[11,"not","stdsimd::simd","",49,[[["self"]],["i8x32"]]],[11,"not","","",50,[[["self"]],["u8x2"]]],[11,"not","","",16,[[["self"]],["u16x2"]]],[11,"not","","",47,[[["self"]],["i64x8"]]],[11,"not","","",54,[[["self"]],["m64x2"]]],[11,"not","","",55,[[["self"]],["i8x4"]]],[11,"not","","",7,[[["self"]],["u32x8"]]],[11,"not","","",18,[[["self"]],["u64x2"]]],[11,"not","","",21,[[["self"]],["i8x8"]]],[11,"not","","",45,[[["self"]],["u8x8"]]],[11,"not","","",24,[[["self"]],["u16x4"]]],[11,"not","","",28,[[["self"]],["m64x4"]]],[11,"not","","",8,[[["self"]],["u64x8"]]],[11,"not","","",25,[[["self"]],["m32x2"]]],[11,"not","","",17,[[["self"]],["m8x32"]]],[11,"not","","",4,[[["self"]],["u64x4"]]],[11,"not","","",26,[[["self"]],["m1x64"]]],[11,"not","","",42,[[["self"]],["m8x16"]]],[11,"not","","",35,[[["self"]],["i16x2"]]],[11,"not","","",22,[[["self"]],["i64x4"]]],[11,"not","","",44,[[["self"]],["u8x16"]]],[11,"not","","",15,[[["self"]],["m1x8"]]],[11,"not","","",12,[[["self"]],["u16x16"]]],[11,"not","","",31,[[["self"]],["m32x4"]]],[11,"not","","",52,[[["self"]],["i32x4"]]],[11,"not","","",29,[[["self"]],["i16x32"]]],[11,"not","","",10,[[["self"]],["i16x16"]]],[11,"not","","",23,[[["self"]],["u8x32"]]],[11,"not","","",19,[[["self"]],["u32x4"]]],[11,"not","","",56,[[["self"]],["i16x8"]]],[11,"not","","",38,[[["self"]],["m1x16"]]],[11,"not","","",39,[[["self"]],["i32x8"]]],[11,"not","","",53,[[["self"]],["m16x2"]]],[11,"not","","",48,[[["self"]],["m1x32"]]],[11,"not","","",20,[[["self"]],["m8x8"]]],[11,"not","","",34,[[["self"]],["i8x16"]]],[11,"not","","",6,[[["self"]],["i8x2"]]],[11,"not","","",41,[[["self"]],["i32x16"]]],[11,"not","","",5,[[["self"]],["u8x64"]]],[11,"not","","",27,[[["self"]],["i16x4"]]],[11,"not","","",3,[[["self"]],["m32x8"]]],[11,"not","","",37,[[["self"]],["i8x64"]]],[11,"not","","",9,[[["self"]],["u32x2"]]],[11,"not","","",32,[[["self"]],["m16x16"]]],[11,"not","","",14,[[["self"]],["u16x8"]]],[11,"not","","",51,[[["self"]],["u8x4"]]],[11,"not","","",11,[[["self"]],["m8x2"]]],[11,"not","","",40,[[["self"]],["m16x8"]]],[11,"not","","",46,[[["self"]],["m8x4"]]],[11,"not","","",13,[[["self"]],["i32x2"]]],[11,"not","","",36,[[["self"]],["i64x2"]]],[11,"not","","",43,[[["self"]],["m16x4"]]],[11,"not","","",33,[[["self"]],["u16x32"]]],[11,"not","","",30,[[["self"]],["u32x16"]]],[11,"bitxor_assign","","",49,N],[11,"bitxor_assign","","",37,N],[11,"bitxor_assign","","",16,N],[11,"bitxor_assign","","",25,N],[11,"bitxor_assign","","",36,N],[11,"bitxor_assign","","",15,N],[11,"bitxor_assign","","",3,N],[11,"bitxor_assign","","",37,N],[11,"bitxor_assign","","",29,N],[11,"bitxor_assign","","",6,N],[11,"bitxor_assign","","",38,N],[11,"bitxor_assign","","",39,N],[11,"bitxor_assign","","",39,N],[11,"bitxor_assign","","",4,N],[11,"bitxor_assign","","",26,N],[11,"bitxor_assign","","",12,N],[11,"bitxor_assign","","",10,N],[11,"bitxor_assign","","",20,N],[11,"bitxor_assign","","",52,N],[11,"bitxor_assign","","",13,N],[11,"bitxor_assign","","",20,N],[11,"bitxor_assign","","",13,N],[11,"bitxor_assign","","",25,N],[11,"bitxor_assign","","",40,N],[11,"bitxor_assign","","",17,N],[11,"bitxor_assign","","",55,N],[11,"bitxor_assign","","",27,N],[11,"bitxor_assign","","",35,N],[11,"bitxor_assign","","",41,N],[11,"bitxor_assign","","",19,N],[11,"bitxor_assign","","",4,N],[11,"bitxor_assign","","",52,N],[11,"bitxor_assign","","",18,N],[11,"bitxor_assign","","",53,N],[11,"bitxor_assign","","",33,N],[11,"bitxor_assign","","",53,N],[11,"bitxor_assign","","",44,N],[11,"bitxor_assign","","",45,N],[11,"bitxor_assign","","",44,N],[11,"bitxor_assign","","",22,N],[11,"bitxor_assign","","",30,N],[11,"bitxor_assign","","",50,N],[11,"bitxor_assign","","",19,N],[11,"bitxor_assign","","",5,N],[11,"bitxor_assign","","",14,N],[11,"bitxor_assign","","",45,N],[11,"bitxor_assign","","",24,N],[11,"bitxor_assign","","",32,N],[11,"bitxor_assign","","",8,N],[11,"bitxor_assign","","",51,N],[11,"bitxor_assign","","",6,N],[11,"bitxor_assign","","",47,N],[11,"bitxor_assign","","",24,N],[11,"bitxor_assign","","",40,N],[11,"bitxor_assign","","",46,N],[11,"bitxor_assign","","",26,N],[11,"bitxor_assign","","",10,N],[11,"bitxor_assign","","",15,N],[11,"bitxor_assign","","",56,N],[11,"bitxor_assign","","",49,N],[11,"bitxor_assign","","",11,N],[11,"bitxor_assign","","",7,N],[11,"bitxor_assign","","",48,N],[11,"bitxor_assign","","",7,N],[11,"bitxor_assign","","",47,N],[11,"bitxor_assign","","",48,N],[11,"bitxor_assign","","",43,N],[11,"bitxor_assign","","",28,N],[11,"bitxor_assign","","",51,N],[11,"bitxor_assign","","",41,N],[11,"bitxor_assign","","",21,N],[11,"bitxor_assign","","",43,N],[11,"bitxor_assign","","",30,N],[11,"bitxor_assign","","",34,N],[11,"bitxor_assign","","",9,N],[11,"bitxor_assign","","",54,N],[11,"bitxor_assign","","",31,N],[11,"bitxor_assign","","",29,N],[11,"bitxor_assign","","",46,N],[11,"bitxor_assign","","",56,N],[11,"bitxor_assign","","",16,N],[11,"bitxor_assign","","",38,N],[11,"bitxor_assign","","",54,N],[11,"bitxor_assign","","",42,N],[11,"bitxor_assign","","",28,N],[11,"bitxor_assign","","",22,N],[11,"bitxor_assign","","",34,N],[11,"bitxor_assign","","",21,N],[11,"bitxor_assign","","",31,N],[11,"bitxor_assign","","",9,N],[11,"bitxor_assign","","",23,N],[11,"bitxor_assign","","",50,N],[11,"bitxor_assign","","",32,N],[11,"bitxor_assign","","",5,N],[11,"bitxor_assign","","",23,N],[11,"bitxor_assign","","",36,N],[11,"bitxor_assign","","",27,N],[11,"bitxor_assign","","",8,N],[11,"bitxor_assign","","",55,N],[11,"bitxor_assign","","",17,N],[11,"bitxor_assign","","",14,N],[11,"bitxor_assign","","",11,N],[11,"bitxor_assign","","",3,N],[11,"bitxor_assign","","",33,N],[11,"bitxor_assign","","",18,N],[11,"bitxor_assign","","",42,N],[11,"bitxor_assign","","",12,N],[11,"bitxor_assign","","",35,N],[11,"div","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"div","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"div","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"div","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"div","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"div","","",59,[[["self"],["f32x16"]],["f32x16"]]],[11,"div","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"div","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"div","","",58,[[["self"],["f64x8"]],["f64x8"]]],[11,"div","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"div","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"div","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"div","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"div","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"div","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"div","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"div","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"div","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"div","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"div","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"div","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"div","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"div","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"div","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"div","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"div","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"div","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"div","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"div","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"div","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"div","","",59,[[["self"],["f32"]],["f32x16"]]],[11,"div","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"div","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"div","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"div","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"div","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"div","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"div","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"div","","",63,[[["self"],["f32x8"]],["f32x8"]]],[11,"div","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"div","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"div","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"div","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"div","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"div","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"div","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"div","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"div","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"div","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"div","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"div","","",61,[[["self"],["f32x2"]],["f32x2"]]],[11,"div","","",57,[[["self"],["f32"]],["f32x4"]]],[11,"div","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"div","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"div","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"div","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"div","","",62,[[["self"],["f64x4"]],["f64x4"]]],[11,"div","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"div","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"div","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"div","","",57,[[["self"],["f32x4"]],["f32x4"]]],[11,"div","","",60,[[["self"],["f64x2"]],["f64x2"]]],[11,"div","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"div","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"div","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"div","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"div","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"div","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"div","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"div","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"div","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"div","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"div","","",58,[[["self"],["f64"]],["f64x8"]]],[11,"div","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"div","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"div","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"div","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"div","","",62,[[["self"],["f64"]],["f64x4"]]],[11,"div","","",60,[[["self"],["f64"]],["f64x2"]]],[11,"div","","",61,[[["self"],["f32"]],["f32x2"]]],[11,"div","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"div","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"div","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"div","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"div","","",63,[[["self"],["f32"]],["f32x8"]]],[11,"div","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"shl_assign","","",13,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",56,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",10,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",9,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",21,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",36,N],[11,"shl_assign","","",27,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",12,N],[11,"shl_assign","","",47,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",41,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",23,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",16,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",37,N],[11,"shl_assign","","",33,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",52,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",22,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",55,N],[11,"shl_assign","","",8,N],[11,"shl_assign","","",50,N],[11,"shl_assign","","",45,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",30,N],[11,"shl_assign","","",34,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",39,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",18,N],[11,"shl_assign","","",6,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",4,N],[11,"shl_assign","","",51,N],[11,"shl_assign","","",35,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",19,N],[11,"shl_assign","","",7,N],[11,"shl_assign","","",44,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",14,N],[11,"shl_assign","","",29,N],[11,"shl_assign","","",5,N],[11,"shl_assign","","",13,N],[11,"shl_assign","","",49,N],[11,"shl_assign","","",24,N],[11,"shl_assign","","",18,N],[11,"shr","","",37,[[["self"],["i32"]],["i8x64"]]],[11,"shr","","",52,[[["self"],["isize"]],["i32x4"]]],[11,"shr","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"shr","","",8,[[["self"],["i8"]],["u64x8"]]],[11,"shr","","",52,[[["self"],["i8"]],["i32x4"]]],[11,"shr","","",21,[[["self"],["usize"]],["i8x8"]]],[11,"shr","","",24,[[["self"],["i32"]],["u16x4"]]],[11,"shr","","",36,[[["self"],["usize"]],["i64x2"]]],[11,"shr","","",27,[[["self"],["usize"]],["i16x4"]]],[11,"shr","","",18,[[["self"],["i16"]],["u64x2"]]],[11,"shr","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"shr","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"shr","","",21,[[["self"],["i16"]],["i8x8"]]],[11,"shr","","",41,[[["self"],["u64"]],["i32x16"]]],[11,"shr","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"shr","","",21,[[["self"],["u16"]],["i8x8"]]],[11,"shr","","",56,[[["self"],["u64"]],["i16x8"]]],[11,"shr","","",47,[[["self"],["i32"]],["i64x8"]]],[11,"shr","","",29,[[["self"],["u32"]],["i16x32"]]],[11,"shr","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"shr","","",24,[[["self"],["i64"]],["u16x4"]]],[11,"shr","","",27,[[["self"],["u32"]],["i16x4"]]],[11,"shr","","",13,[[["self"],["u8"]],["i32x2"]]],[11,"shr","","",47,[[["self"],["u16"]],["i64x8"]]],[11,"shr","","",44,[[["self"],["u64"]],["u8x16"]]],[11,"shr","","",47,[[["self"],["i16"]],["i64x8"]]],[11,"shr","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"shr","","",9,[[["self"],["usize"]],["u32x2"]]],[11,"shr","","",7,[[["self"],["i16"]],["u32x8"]]],[11,"shr","","",6,[[["self"],["i16"]],["i8x2"]]],[11,"shr","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"shr","","",45,[[["self"],["u32"]],["u8x8"]]],[11,"shr","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"shr","","",35,[[["self"],["u8"]],["i16x2"]]],[11,"shr","","",39,[[["self"],["usize"]],["i32x8"]]],[11,"shr","","",56,[[["self"],["i32"]],["i16x8"]]],[11,"shr","","",12,[[["self"],["u32"]],["u16x16"]]],[11,"shr","","",51,[[["self"],["i64"]],["u8x4"]]],[11,"shr","","",21,[[["self"],["u64"]],["i8x8"]]],[11,"shr","","",37,[[["self"],["u8"]],["i8x64"]]],[11,"shr","","",29,[[["self"],["usize"]],["i16x32"]]],[11,"shr","","",10,[[["self"],["u8"]],["i16x16"]]],[11,"shr","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"shr","","",6,[[["self"],["usize"]],["i8x2"]]],[11,"shr","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"shr","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"shr","","",36,[[["self"],["u32"]],["i64x2"]]],[11,"shr","","",24,[[["self"],["u64"]],["u16x4"]]],[11,"shr","","",29,[[["self"],["i32"]],["i16x32"]]],[11,"shr","","",37,[[["self"],["u32"]],["i8x64"]]],[11,"shr","","",13,[[["self"],["u64"]],["i32x2"]]],[11,"shr","","",34,[[["self"],["u64"]],["i8x16"]]],[11,"shr","","",5,[[["self"],["i8"]],["u8x64"]]],[11,"shr","","",14,[[["self"],["u64"]],["u16x8"]]],[11,"shr","","",52,[[["self"],["u16"]],["i32x4"]]],[11,"shr","","",47,[[["self"],["u64"]],["i64x8"]]],[11,"shr","","",16,[[["self"],["u8"]],["u16x2"]]],[11,"shr","","",22,[[["self"],["isize"]],["i64x4"]]],[11,"shr","","",9,[[["self"],["i32"]],["u32x2"]]],[11,"shr","","",19,[[["self"],["u64"]],["u32x4"]]],[11,"shr","","",18,[[["self"],["u32"]],["u64x2"]]],[11,"shr","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"shr","","",56,[[["self"],["i8"]],["i16x8"]]],[11,"shr","","",5,[[["self"],["u32"]],["u8x64"]]],[11,"shr","","",55,[[["self"],["i64"]],["i8x4"]]],[11,"shr","","",14,[[["self"],["usize"]],["u16x8"]]],[11,"shr","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"shr","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"shr","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"shr","","",34,[[["self"],["u16"]],["i8x16"]]],[11,"shr","","",5,[[["self"],["usize"]],["u8x64"]]],[11,"shr","","",29,[[["self"],["i8"]],["i16x32"]]],[11,"shr","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"shr","","",45,[[["self"],["isize"]],["u8x8"]]],[11,"shr","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"shr","","",50,[[["self"],["i8"]],["u8x2"]]],[11,"shr","","",37,[[["self"],["i64"]],["i8x64"]]],[11,"shr","","",51,[[["self"],["i8"]],["u8x4"]]],[11,"shr","","",4,[[["self"],["i16"]],["u64x4"]]],[11,"shr","","",29,[[["self"],["u64"]],["i16x32"]]],[11,"shr","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"shr","","",41,[[["self"],["i64"]],["i32x16"]]],[11,"shr","","",22,[[["self"],["i32"]],["i64x4"]]],[11,"shr","","",49,[[["self"],["u32"]],["i8x32"]]],[11,"shr","","",30,[[["self"],["u64"]],["u32x16"]]],[11,"shr","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"shr","","",12,[[["self"],["i64"]],["u16x16"]]],[11,"shr","","",22,[[["self"],["i16"]],["i64x4"]]],[11,"shr","","",50,[[["self"],["i16"]],["u8x2"]]],[11,"shr","","",22,[[["self"],["u16"]],["i64x4"]]],[11,"shr","","",24,[[["self"],["u32"]],["u16x4"]]],[11,"shr","","",10,[[["self"],["u16"]],["i16x16"]]],[11,"shr","","",35,[[["self"],["u64"]],["i16x2"]]],[11,"shr","","",19,[[["self"],["u16"]],["u32x4"]]],[11,"shr","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"shr","","",44,[[["self"],["i64"]],["u8x16"]]],[11,"shr","","",12,[[["self"],["isize"]],["u16x16"]]],[11,"shr","","",41,[[["self"],["u16"]],["i32x16"]]],[11,"shr","","",18,[[["self"],["i64"]],["u64x2"]]],[11,"shr","","",14,[[["self"],["i8"]],["u16x8"]]],[11,"shr","","",33,[[["self"],["isize"]],["u16x32"]]],[11,"shr","","",9,[[["self"],["i16"]],["u32x2"]]],[11,"shr","","",22,[[["self"],["usize"]],["i64x4"]]],[11,"shr","","",27,[[["self"],["i64"]],["i16x4"]]],[11,"shr","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"shr","","",10,[[["self"],["i64"]],["i16x16"]]],[11,"shr","","",44,[[["self"],["usize"]],["u8x16"]]],[11,"shr","","",55,[[["self"],["usize"]],["i8x4"]]],[11,"shr","","",36,[[["self"],["u8"]],["i64x2"]]],[11,"shr","","",5,[[["self"],["i16"]],["u8x64"]]],[11,"shr","","",45,[[["self"],["i32"]],["u8x8"]]],[11,"shr","","",33,[[["self"],["i32"]],["u16x32"]]],[11,"shr","","",52,[[["self"],["i16"]],["i32x4"]]],[11,"shr","","",36,[[["self"],["i16"]],["i64x2"]]],[11,"shr","","",41,[[["self"],["usize"]],["i32x16"]]],[11,"shr","","",4,[[["self"],["u16"]],["u64x4"]]],[11,"shr","","",19,[[["self"],["i64"]],["u32x4"]]],[11,"shr","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"shr","","",39,[[["self"],["i16"]],["i32x8"]]],[11,"shr","","",37,[[["self"],["u16"]],["i8x64"]]],[11,"shr","","",49,[[["self"],["isize"]],["i8x32"]]],[11,"shr","","",55,[[["self"],["u8"]],["i8x4"]]],[11,"shr","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"shr","","",18,[[["self"],["u8"]],["u64x2"]]],[11,"shr","","",23,[[["self"],["i32"]],["u8x32"]]],[11,"shr","","",18,[[["self"],["isize"]],["u64x2"]]],[11,"shr","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"shr","","",56,[[["self"],["u16"]],["i16x8"]]],[11,"shr","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"shr","","",23,[[["self"],["usize"]],["u8x32"]]],[11,"shr","","",6,[[["self"],["isize"]],["i8x2"]]],[11,"shr","","",30,[[["self"],["i32"]],["u32x16"]]],[11,"shr","","",51,[[["self"],["u32"]],["u8x4"]]],[11,"shr","","",21,[[["self"],["u8"]],["i8x8"]]],[11,"shr","","",33,[[["self"],["u64"]],["u16x32"]]],[11,"shr","","",30,[[["self"],["i16"]],["u32x16"]]],[11,"shr","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"shr","","",39,[[["self"],["u64"]],["i32x8"]]],[11,"shr","","",22,[[["self"],["u64"]],["i64x4"]]],[11,"shr","","",13,[[["self"],["isize"]],["i32x2"]]],[11,"shr","","",30,[[["self"],["usize"]],["u32x16"]]],[11,"shr","","",8,[[["self"],["u16"]],["u64x8"]]],[11,"shr","","",37,[[["self"],["i16"]],["i8x64"]]],[11,"shr","","",14,[[["self"],["u8"]],["u16x8"]]],[11,"shr","","",16,[[["self"],["i16"]],["u16x2"]]],[11,"shr","","",19,[[["self"],["isize"]],["u32x4"]]],[11,"shr","","",56,[[["self"],["isize"]],["i16x8"]]],[11,"shr","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"shr","","",4,[[["self"],["i64"]],["u64x4"]]],[11,"shr","","",47,[[["self"],["isize"]],["i64x8"]]],[11,"shr","","",52,[[["self"],["u64"]],["i32x4"]]],[11,"shr","","",44,[[["self"],["i16"]],["u8x16"]]],[11,"shr","","",45,[[["self"],["i16"]],["u8x8"]]],[11,"shr","","",8,[[["self"],["usize"]],["u64x8"]]],[11,"shr","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"shr","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"shr","","",45,[[["self"],["i8"]],["u8x8"]]],[11,"shr","","",55,[[["self"],["i32"]],["i8x4"]]],[11,"shr","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"shr","","",39,[[["self"],["u8"]],["i32x8"]]],[11,"shr","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"shr","","",4,[[["self"],["u8"]],["u64x4"]]],[11,"shr","","",36,[[["self"],["isize"]],["i64x2"]]],[11,"shr","","",39,[[["self"],["u32"]],["i32x8"]]],[11,"shr","","",12,[[["self"],["u8"]],["u16x16"]]],[11,"shr","","",50,[[["self"],["isize"]],["u8x2"]]],[11,"shr","","",30,[[["self"],["i8"]],["u32x16"]]],[11,"shr","","",7,[[["self"],["isize"]],["u32x8"]]],[11,"shr","","",34,[[["self"],["i64"]],["i8x16"]]],[11,"shr","","",49,[[["self"],["u64"]],["i8x32"]]],[11,"shr","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"shr","","",56,[[["self"],["usize"]],["i16x8"]]],[11,"shr","","",27,[[["self"],["u8"]],["i16x4"]]],[11,"shr","","",9,[[["self"],["u8"]],["u32x2"]]],[11,"shr","","",13,[[["self"],["i16"]],["i32x2"]]],[11,"shr","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"shr","","",22,[[["self"],["u8"]],["i64x4"]]],[11,"shr","","",16,[[["self"],["i64"]],["u16x2"]]],[11,"shr","","",23,[[["self"],["i16"]],["u8x32"]]],[11,"shr","","",33,[[["self"],["u32"]],["u16x32"]]],[11,"shr","","",41,[[["self"],["u8"]],["i32x16"]]],[11,"shr","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"shr","","",19,[[["self"],["usize"]],["u32x4"]]],[11,"shr","","",24,[[["self"],["usize"]],["u16x4"]]],[11,"shr","","",44,[[["self"],["u32"]],["u8x16"]]],[11,"shr","","",7,[[["self"],["u16"]],["u32x8"]]],[11,"shr","","",29,[[["self"],["i64"]],["i16x32"]]],[11,"shr","","",10,[[["self"],["i32"]],["i16x16"]]],[11,"shr","","",19,[[["self"],["i32"]],["u32x4"]]],[11,"shr","","",34,[[["self"],["u8"]],["i8x16"]]],[11,"shr","","",19,[[["self"],["i16"]],["u32x4"]]],[11,"shr","","",8,[[["self"],["u8"]],["u64x8"]]],[11,"shr","","",23,[[["self"],["u64"]],["u8x32"]]],[11,"shr","","",24,[[["self"],["u8"]],["u16x4"]]],[11,"shr","","",49,[[["self"],["i64"]],["i8x32"]]],[11,"shr","","",7,[[["self"],["u8"]],["u32x8"]]],[11,"shr","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"shr","","",45,[[["self"],["u16"]],["u8x8"]]],[11,"shr","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"shr","","",4,[[["self"],["isize"]],["u64x4"]]],[11,"shr","","",35,[[["self"],["u16"]],["i16x2"]]],[11,"shr","","",5,[[["self"],["i32"]],["u8x64"]]],[11,"shr","","",44,[[["self"],["i32"]],["u8x16"]]],[11,"shr","","",6,[[["self"],["u16"]],["i8x2"]]],[11,"shr","","",12,[[["self"],["u64"]],["u16x16"]]],[11,"shr","","",4,[[["self"],["i8"]],["u64x4"]]],[11,"shr","","",44,[[["self"],["i8"]],["u8x16"]]],[11,"shr","","",49,[[["self"],["i32"]],["i8x32"]]],[11,"shr","","",37,[[["self"],["u64"]],["i8x64"]]],[11,"shr","","",35,[[["self"],["i32"]],["i16x2"]]],[11,"shr","","",14,[[["self"],["isize"]],["u16x8"]]],[11,"shr","","",47,[[["self"],["u8"]],["i64x8"]]],[11,"shr","","",39,[[["self"],["i64"]],["i32x8"]]],[11,"shr","","",9,[[["self"],["i8"]],["u32x2"]]],[11,"shr","","",13,[[["self"],["u32"]],["i32x2"]]],[11,"shr","","",36,[[["self"],["u64"]],["i64x2"]]],[11,"shr","","",56,[[["self"],["u8"]],["i16x8"]]],[11,"shr","","",24,[[["self"],["isize"]],["u16x4"]]],[11,"shr","","",24,[[["self"],["i8"]],["u16x4"]]],[11,"shr","","",33,[[["self"],["i8"]],["u16x32"]]],[11,"shr","","",19,[[["self"],["i8"]],["u32x4"]]],[11,"shr","","",56,[[["self"],["i64"]],["i16x8"]]],[11,"shr","","",7,[[["self"],["i32"]],["u32x8"]]],[11,"shr","","",52,[[["self"],["i64"]],["i32x4"]]],[11,"shr","","",37,[[["self"],["isize"]],["i8x64"]]],[11,"shr","","",33,[[["self"],["usize"]],["u16x32"]]],[11,"shr","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"shr","","",29,[[["self"],["u8"]],["i16x32"]]],[11,"shr","","",55,[[["self"],["isize"]],["i8x4"]]],[11,"shr","","",47,[[["self"],["usize"]],["i64x8"]]],[11,"shr","","",14,[[["self"],["i16"]],["u16x8"]]],[11,"shr","","",51,[[["self"],["u64"]],["u8x4"]]],[11,"shr","","",6,[[["self"],["u64"]],["i8x2"]]],[11,"shr","","",16,[[["self"],["usize"]],["u16x2"]]],[11,"shr","","",13,[[["self"],["u16"]],["i32x2"]]],[11,"shr","","",52,[[["self"],["usize"]],["i32x4"]]],[11,"shr","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"shr","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"shr","","",45,[[["self"],["u64"]],["u8x8"]]],[11,"shr","","",12,[[["self"],["i16"]],["u16x16"]]],[11,"shr","","",29,[[["self"],["u16"]],["i16x32"]]],[11,"shr","","",41,[[["self"],["u32"]],["i32x16"]]],[11,"shr","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"shr","","",30,[[["self"],["isize"]],["u32x16"]]],[11,"shr","","",55,[[["self"],["u16"]],["i8x4"]]],[11,"shr","","",44,[[["self"],["u16"]],["u8x16"]]],[11,"shr","","",50,[[["self"],["u64"]],["u8x2"]]],[11,"shr","","",16,[[["self"],["u32"]],["u16x2"]]],[11,"shr","","",18,[[["self"],["i8"]],["u64x2"]]],[11,"shr","","",8,[[["self"],["i32"]],["u64x8"]]],[11,"shr","","",56,[[["self"],["u32"]],["i16x8"]]],[11,"shr","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"shr","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"shr","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"shr","","",18,[[["self"],["usize"]],["u64x2"]]],[11,"shr","","",18,[[["self"],["u16"]],["u64x2"]]],[11,"shr","","",5,[[["self"],["i64"]],["u8x64"]]],[11,"shr","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"shr","","",9,[[["self"],["u16"]],["u32x2"]]],[11,"shr","","",50,[[["self"],["i32"]],["u8x2"]]],[11,"shr","","",13,[[["self"],["i8"]],["i32x2"]]],[11,"shr","","",5,[[["self"],["isize"]],["u8x64"]]],[11,"shr","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"shr","","",9,[[["self"],["isize"]],["u32x2"]]],[11,"shr","","",8,[[["self"],["isize"]],["u64x8"]]],[11,"shr","","",52,[[["self"],["u8"]],["i32x4"]]],[11,"shr","","",8,[[["self"],["i64"]],["u64x8"]]],[11,"shr","","",45,[[["self"],["usize"]],["u8x8"]]],[11,"shr","","",5,[[["self"],["u16"]],["u8x64"]]],[11,"shr","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"shr","","",4,[[["self"],["usize"]],["u64x4"]]],[11,"shr","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"shr","","",52,[[["self"],["u32"]],["i32x4"]]],[11,"shr","","",10,[[["self"],["usize"]],["i16x16"]]],[11,"shr","","",27,[[["self"],["u64"]],["i16x4"]]],[11,"shr","","",51,[[["self"],["i16"]],["u8x4"]]],[11,"shr","","",44,[[["self"],["isize"]],["u8x16"]]],[11,"shr","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"shr","","",4,[[["self"],["u32"]],["u64x4"]]],[11,"shr","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"shr","","",30,[[["self"],["i64"]],["u32x16"]]],[11,"shr","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"shr","","",4,[[["self"],["i32"]],["u64x4"]]],[11,"shr","","",16,[[["self"],["i32"]],["u16x2"]]],[11,"shr","","",6,[[["self"],["i32"]],["i8x2"]]],[11,"shr","","",30,[[["self"],["u16"]],["u32x16"]]],[11,"shr","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"shr","","",55,[[["self"],["u64"]],["i8x4"]]],[11,"shr","","",8,[[["self"],["u32"]],["u64x8"]]],[11,"shr","","",10,[[["self"],["isize"]],["i16x16"]]],[11,"shr","","",5,[[["self"],["u64"]],["u8x64"]]],[11,"shr","","",49,[[["self"],["i16"]],["i8x32"]]],[11,"shr","","",30,[[["self"],["u8"]],["u32x16"]]],[11,"shr","","",16,[[["self"],["i8"]],["u16x2"]]],[11,"shr","","",16,[[["self"],["u64"]],["u16x2"]]],[11,"shr","","",23,[[["self"],["u32"]],["u8x32"]]],[11,"shr","","",23,[[["self"],["u16"]],["u8x32"]]],[11,"shr","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"shr","","",27,[[["self"],["u16"]],["i16x4"]]],[11,"shr","","",23,[[["self"],["isize"]],["u8x32"]]],[11,"shr","","",21,[[["self"],["isize"]],["i8x8"]]],[11,"shr","","",14,[[["self"],["i32"]],["u16x8"]]],[11,"shr","","",47,[[["self"],["i8"]],["i64x8"]]],[11,"shr","","",19,[[["self"],["u8"]],["u32x4"]]],[11,"shr","","",33,[[["self"],["i64"]],["u16x32"]]],[11,"shr","","",22,[[["self"],["u32"]],["i64x4"]]],[11,"shr","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"shr","","",7,[[["self"],["usize"]],["u32x8"]]],[11,"shr","","",36,[[["self"],["i8"]],["i64x2"]]],[11,"shr","","",55,[[["self"],["u32"]],["i8x4"]]],[11,"shr","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"shr","","",41,[[["self"],["isize"]],["i32x16"]]],[11,"shr","","",14,[[["self"],["u32"]],["u16x8"]]],[11,"shr","","",21,[[["self"],["u32"]],["i8x8"]]],[11,"shr","","",39,[[["self"],["isize"]],["i32x8"]]],[11,"shr","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"shr","","",50,[[["self"],["i64"]],["u8x2"]]],[11,"shr","","",35,[[["self"],["i8"]],["i16x2"]]],[11,"shr","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"shr","","",10,[[["self"],["u64"]],["i16x16"]]],[11,"shr","","",7,[[["self"],["i64"]],["u32x8"]]],[11,"shr","","",50,[[["self"],["usize"]],["u8x2"]]],[11,"shr","","",16,[[["self"],["isize"]],["u16x2"]]],[11,"shr","","",29,[[["self"],["isize"]],["i16x32"]]],[11,"shr","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"shr","","",41,[[["self"],["i16"]],["i32x16"]]],[11,"shr","","",35,[[["self"],["usize"]],["i16x2"]]],[11,"shr","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"shr","","",33,[[["self"],["u8"]],["u16x32"]]],[11,"shr","","",49,[[["self"],["u8"]],["i8x32"]]],[11,"shr","","",55,[[["self"],["i16"]],["i8x4"]]],[11,"shr","","",51,[[["self"],["i32"]],["u8x4"]]],[11,"shr","","",10,[[["self"],["u32"]],["i16x16"]]],[11,"shr","","",51,[[["self"],["isize"]],["u8x4"]]],[11,"shr","","",27,[[["self"],["i8"]],["i16x4"]]],[11,"shr","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"shr","","",39,[[["self"],["i8"]],["i32x8"]]],[11,"shr","","",10,[[["self"],["i8"]],["i16x16"]]],[11,"shr","","",23,[[["self"],["i8"]],["u8x32"]]],[11,"shr","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"shr","","",24,[[["self"],["i16"]],["u16x4"]]],[11,"shr","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"shr","","",6,[[["self"],["u32"]],["i8x2"]]],[11,"shr","","",13,[[["self"],["usize"]],["i32x2"]]],[11,"shr","","",13,[[["self"],["i64"]],["i32x2"]]],[11,"shr","","",12,[[["self"],["i32"]],["u16x16"]]],[11,"shr","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"shr","","",34,[[["self"],["usize"]],["i8x16"]]],[11,"shr","","",37,[[["self"],["usize"]],["i8x64"]]],[11,"shr","","",12,[[["self"],["i8"]],["u16x16"]]],[11,"shr","","",6,[[["self"],["i64"]],["i8x2"]]],[11,"shr","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"shr","","",27,[[["self"],["isize"]],["i16x4"]]],[11,"shr","","",34,[[["self"],["i32"]],["i8x16"]]],[11,"shr","","",50,[[["self"],["u16"]],["u8x2"]]],[11,"shr","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"shr","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"shr","","",36,[[["self"],["i32"]],["i64x2"]]],[11,"shr","","",51,[[["self"],["usize"]],["u8x4"]]],[11,"shr","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"shr","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"shr","","",14,[[["self"],["i64"]],["u16x8"]]],[11,"shr","","",23,[[["self"],["i64"]],["u8x32"]]],[11,"shr","","",34,[[["self"],["i16"]],["i8x16"]]],[11,"shr","","",6,[[["self"],["u8"]],["i8x2"]]],[11,"shr","","",49,[[["self"],["u16"]],["i8x32"]]],[11,"shr","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"shr","","",12,[[["self"],["usize"]],["u16x16"]]],[11,"shr","","",7,[[["self"],["i8"]],["u32x8"]]],[11,"shr","","",39,[[["self"],["u16"]],["i32x8"]]],[11,"shr","","",50,[[["self"],["u32"]],["u8x2"]]],[11,"shr","","",34,[[["self"],["u32"]],["i8x16"]]],[11,"shr","","",45,[[["self"],["i64"]],["u8x8"]]],[11,"shr","","",36,[[["self"],["u16"]],["i64x2"]]],[11,"shr","","",47,[[["self"],["u32"]],["i64x8"]]],[11,"shr","","",8,[[["self"],["i16"]],["u64x8"]]],[11,"shr","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"shr","","",41,[[["self"],["i8"]],["i32x16"]]],[11,"shr","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"shr","","",49,[[["self"],["usize"]],["i8x32"]]],[11,"shr","","",18,[[["self"],["i32"]],["u64x2"]]],[11,"shr","","",27,[[["self"],["i32"]],["i16x4"]]],[11,"shr","","",35,[[["self"],["i64"]],["i16x2"]]],[11,"shr","","",35,[[["self"],["isize"]],["i16x2"]]],[11,"shr","","",22,[[["self"],["i8"]],["i64x4"]]],[11,"shr","","",9,[[["self"],["u64"]],["u32x2"]]],[11,"shr","","",9,[[["self"],["i64"]],["u32x2"]]],[11,"shr","","",34,[[["self"],["isize"]],["i8x16"]]],[11,"shr","","",21,[[["self"],["i64"]],["i8x8"]]],[11,"shr","","",51,[[["self"],["u16"]],["u8x4"]]],[11,"shr","","",35,[[["self"],["u32"]],["i16x2"]]],[11,"shr","","",21,[[["self"],["i32"]],["i8x8"]]],[11,"shr","","",33,[[["self"],["i16"]],["u16x32"]]],[11,"shr","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"shr","","",7,[[["self"],["u64"]],["u32x8"]]],[11,"shr","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"clone","","",21,[[["self"]],["i8x8"]]],[11,"clone","","",23,[[["self"]],["u8x32"]]],[11,"clone","","",15,[[["self"]],["m1x8"]]],[11,"clone","","",53,[[["self"]],["m16x2"]]],[11,"clone","stdsimd::arch::x86_64","",64,[[["self"]],["__m64"]]],[11,"clone","stdsimd::simd","",56,[[["self"]],["i16x8"]]],[11,"clone","","",27,[[["self"]],["i16x4"]]],[11,"clone","","",60,[[["self"]],["f64x2"]]],[11,"clone","","",61,[[["self"]],["f32x2"]]],[11,"clone","","",3,[[["self"]],["m32x8"]]],[11,"clone","","",52,[[["self"]],["i32x4"]]],[11,"clone","","",10,[[["self"]],["i16x16"]]],[11,"clone","stdsimd::arch::x86_64","",65,[[["self"]],["__m256d"]]],[11,"clone","stdsimd::simd","",62,[[["self"]],["f64x4"]]],[11,"clone","","",35,[[["self"]],["i16x2"]]],[11,"clone","","",29,[[["self"]],["i16x32"]]],[11,"clone","","",32,[[["self"]],["m16x16"]]],[11,"clone","","",24,[[["self"]],["u16x4"]]],[11,"clone","stdsimd::arch::x86_64","",66,[[["self"]],["__m128d"]]],[11,"clone","stdsimd::simd","",34,[[["self"]],["i8x16"]]],[11,"clone","","",51,[[["self"]],["u8x4"]]],[11,"clone","","",43,[[["self"]],["m16x4"]]],[11,"clone","","",20,[[["self"]],["m8x8"]]],[11,"clone","","",59,[[["self"]],["f32x16"]]],[11,"clone","","",55,[[["self"]],["i8x4"]]],[11,"clone","","",11,[[["self"]],["m8x2"]]],[11,"clone","","",48,[[["self"]],["m1x32"]]],[11,"clone","","",57,[[["self"]],["f32x4"]]],[11,"clone","stdsimd::arch::x86_64","",67,[[["self"]],["__m128"]]],[11,"clone","","",2,[[["self"]],["cpuidresult"]]],[11,"clone","stdsimd::simd","",25,[[["self"]],["m32x2"]]],[11,"clone","","",13,[[["self"]],["i32x2"]]],[11,"clone","","",19,[[["self"]],["u32x4"]]],[11,"clone","","",8,[[["self"]],["u64x8"]]],[11,"clone","","",5,[[["self"]],["u8x64"]]],[11,"clone","","",39,[[["self"]],["i32x8"]]],[11,"clone","","",9,[[["self"]],["u32x2"]]],[11,"clone","stdsimd::arch::x86_64","",68,[[["self"]],["__m128i"]]],[11,"clone","stdsimd::simd","",47,[[["self"]],["i64x8"]]],[11,"clone","","",22,[[["self"]],["i64x4"]]],[11,"clone","stdsimd::arch::x86_64","",69,[[["self"]],["__m256"]]],[11,"clone","stdsimd::simd","",49,[[["self"]],["i8x32"]]],[11,"clone","","",58,[[["self"]],["f64x8"]]],[11,"clone","","",6,[[["self"]],["i8x2"]]],[11,"clone","","",14,[[["self"]],["u16x8"]]],[11,"clone","","",16,[[["self"]],["u16x2"]]],[11,"clone","stdsimd::arch::x86_64","",70,[[["self"]],["__m256i"]]],[11,"clone","stdsimd::simd","",38,[[["self"]],["m1x16"]]],[11,"clone","","",40,[[["self"]],["m16x8"]]],[11,"clone","","",45,[[["self"]],["u8x8"]]],[11,"clone","","",30,[[["self"]],["u32x16"]]],[11,"clone","","",54,[[["self"]],["m64x2"]]],[11,"clone","","",63,[[["self"]],["f32x8"]]],[11,"clone","","",36,[[["self"]],["i64x2"]]],[11,"clone","","",31,[[["self"]],["m32x4"]]],[11,"clone","","",18,[[["self"]],["u64x2"]]],[11,"clone","","",46,[[["self"]],["m8x4"]]],[11,"clone","","",7,[[["self"]],["u32x8"]]],[11,"clone","","",17,[[["self"]],["m8x32"]]],[11,"clone","","",4,[[["self"]],["u64x4"]]],[11,"clone","","",33,[[["self"]],["u16x32"]]],[11,"clone","","",41,[[["self"]],["i32x16"]]],[11,"clone","","",42,[[["self"]],["m8x16"]]],[11,"clone","","",37,[[["self"]],["i8x64"]]],[11,"clone","","",26,[[["self"]],["m1x64"]]],[11,"clone","","",28,[[["self"]],["m64x4"]]],[11,"clone","","",12,[[["self"]],["u16x16"]]],[11,"clone","","",44,[[["self"]],["u8x16"]]],[11,"clone","","",50,[[["self"]],["u8x2"]]],[11,"rem_assign","","",29,N],[11,"rem_assign","","",44,N],[11,"rem_assign","","",27,N],[11,"rem_assign","","",50,N],[11,"rem_assign","","",14,N],[11,"rem_assign","","",8,N],[11,"rem_assign","","",14,N],[11,"rem_assign","","",39,N],[11,"rem_assign","","",51,N],[11,"rem_assign","","",62,N],[11,"rem_assign","","",62,N],[11,"rem_assign","","",18,N],[11,"rem_assign","","",4,N],[11,"rem_assign","","",55,N],[11,"rem_assign","","",18,N],[11,"rem_assign","","",21,N],[11,"rem_assign","","",59,N],[11,"rem_assign","","",33,N],[11,"rem_assign","","",9,N],[11,"rem_assign","","",57,N],[11,"rem_assign","","",30,N],[11,"rem_assign","","",60,N],[11,"rem_assign","","",56,N],[11,"rem_assign","","",50,N],[11,"rem_assign","","",52,N],[11,"rem_assign","","",24,N],[11,"rem_assign","","",52,N],[11,"rem_assign","","",47,N],[11,"rem_assign","","",60,N],[11,"rem_assign","","",7,N],[11,"rem_assign","","",41,N],[11,"rem_assign","","",23,N],[11,"rem_assign","","",24,N],[11,"rem_assign","","",61,N],[11,"rem_assign","","",4,N],[11,"rem_assign","","",27,N],[11,"rem_assign","","",9,N],[11,"rem_assign","","",36,N],[11,"rem_assign","","",58,N],[11,"rem_assign","","",63,N],[11,"rem_assign","","",12,N],[11,"rem_assign","","",16,N],[11,"rem_assign","","",34,N],[11,"rem_assign","","",16,N],[11,"rem_assign","","",6,N],[11,"rem_assign","","",33,N],[11,"rem_assign","","",13,N],[11,"rem_assign","","",45,N],[11,"rem_assign","","",51,N],[11,"rem_assign","","",5,N],[11,"rem_assign","","",59,N],[11,"rem_assign","","",22,N],[11,"rem_assign","","",29,N],[11,"rem_assign","","",21,N],[11,"rem_assign","","",5,N],[11,"rem_assign","","",10,N],[11,"rem_assign","","",35,N],[11,"rem_assign","","",41,N],[11,"rem_assign","","",39,N],[11,"rem_assign","","",19,N],[11,"rem_assign","","",58,N],[11,"rem_assign","","",10,N],[11,"rem_assign","","",30,N],[11,"rem_assign","","",36,N],[11,"rem_assign","","",49,N],[11,"rem_assign","","",49,N],[11,"rem_assign","","",37,N],[11,"rem_assign","","",56,N],[11,"rem_assign","","",6,N],[11,"rem_assign","","",13,N],[11,"rem_assign","","",44,N],[11,"rem_assign","","",61,N],[11,"rem_assign","","",37,N],[11,"rem_assign","","",57,N],[11,"rem_assign","","",47,N],[11,"rem_assign","","",55,N],[11,"rem_assign","","",63,N],[11,"rem_assign","","",23,N],[11,"rem_assign","","",8,N],[11,"rem_assign","","",34,N],[11,"rem_assign","","",7,N],[11,"rem_assign","","",45,N],[11,"rem_assign","","",22,N],[11,"rem_assign","","",19,N],[11,"rem_assign","","",12,N],[11,"rem_assign","","",35,N],[11,"mul","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"mul","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"mul","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"mul","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"mul","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"mul","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"mul","","",57,[[["self"],["f32x4"]],["f32x4"]]],[11,"mul","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"mul","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"mul","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"mul","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"mul","","",60,[[["self"],["f64x2"]],["f64x2"]]],[11,"mul","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"mul","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"mul","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"mul","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"mul","","",59,[[["self"],["f32"]],["f32x16"]]],[11,"mul","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"mul","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"mul","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"mul","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"mul","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"mul","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"mul","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"mul","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"mul","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"mul","","",62,[[["self"],["f64"]],["f64x4"]]],[11,"mul","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"mul","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"mul","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"mul","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"mul","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"mul","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"mul","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"mul","","",61,[[["self"],["f32"]],["f32x2"]]],[11,"mul","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"mul","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"mul","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"mul","","",61,[[["self"],["f32x2"]],["f32x2"]]],[11,"mul","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"mul","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"mul","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"mul","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"mul","","",60,[[["self"],["f64"]],["f64x2"]]],[11,"mul","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"mul","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"mul","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"mul","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"mul","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"mul","","",58,[[["self"],["f64x8"]],["f64x8"]]],[11,"mul","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"mul","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"mul","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"mul","","",58,[[["self"],["f64"]],["f64x8"]]],[11,"mul","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"mul","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"mul","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"mul","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"mul","","",59,[[["self"],["f32x16"]],["f32x16"]]],[11,"mul","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"mul","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"mul","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"mul","","",63,[[["self"],["f32x8"]],["f32x8"]]],[11,"mul","","",57,[[["self"],["f32"]],["f32x4"]]],[11,"mul","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"mul","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"mul","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"mul","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"mul","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"mul","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"mul","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"mul","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"mul","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"mul","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"mul","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"mul","","",62,[[["self"],["f64x4"]],["f64x4"]]],[11,"mul","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"mul","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"mul","","",63,[[["self"],["f32"]],["f32x8"]]],[11,"mul","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"mul","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"mul","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"mul","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"mul","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"mul","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"mul","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"bitor","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"bitor","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"bitor","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"bitor","","",11,[[["self"],["bool"]],["m8x2"]]],[11,"bitor","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"bitor","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"bitor","","",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"bitor","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"bitor","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"bitor","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"bitor","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"bitor","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"bitor","","",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"bitor","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"bitor","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"bitor","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"bitor","","",43,[[["self"],["bool"]],["m16x4"]]],[11,"bitor","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"bitor","","",15,[[["self"],["bool"]],["m1x8"]]],[11,"bitor","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"bitor","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"bitor","","",31,[[["self"],["bool"]],["m32x4"]]],[11,"bitor","","",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"bitor","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"bitor","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"bitor","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"bitor","","",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"bitor","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"bitor","","",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"bitor","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"bitor","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"bitor","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"bitor","","",54,[[["self"],["bool"]],["m64x2"]]],[11,"bitor","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"bitor","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"bitor","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"bitor","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"bitor","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"bitor","","",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"bitor","","",32,[[["self"],["bool"]],["m16x16"]]],[11,"bitor","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"bitor","","",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"bitor","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"bitor","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"bitor","","",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"bitor","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"bitor","","",25,[[["self"],["bool"]],["m32x2"]]],[11,"bitor","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"bitor","","",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"bitor","","",42,[[["self"],["bool"]],["m8x16"]]],[11,"bitor","","",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"bitor","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"bitor","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"bitor","","",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"bitor","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"bitor","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"bitor","","",28,[[["self"],["bool"]],["m64x4"]]],[11,"bitor","","",38,[[["self"],["bool"]],["m1x16"]]],[11,"bitor","","",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"bitor","","",20,[[["self"],["bool"]],["m8x8"]]],[11,"bitor","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"bitor","","",17,[[["self"],["bool"]],["m8x32"]]],[11,"bitor","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"bitor","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"bitor","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"bitor","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"bitor","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"bitor","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"bitor","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"bitor","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"bitor","","",3,[[["self"],["bool"]],["m32x8"]]],[11,"bitor","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"bitor","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"bitor","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"bitor","","",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"bitor","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"bitor","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"bitor","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"bitor","","",46,[[["self"],["bool"]],["m8x4"]]],[11,"bitor","","",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"bitor","","",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"bitor","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"bitor","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"bitor","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"bitor","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"bitor","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"bitor","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"bitor","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"bitor","","",53,[[["self"],["bool"]],["m16x2"]]],[11,"bitor","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"bitor","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"bitor","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"bitor","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"bitor","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"bitor","","",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"bitor","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"bitor","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"bitor","","",40,[[["self"],["bool"]],["m16x8"]]],[11,"bitor","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"bitor","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"bitor","","",26,[[["self"],["bool"]],["m1x64"]]],[11,"bitor","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"bitor","","",48,[[["self"],["bool"]],["m1x32"]]],[11,"bitor","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"bitor","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"bitor","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"bitor","","",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"bitor","","",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"neg","","",36,[[["self"]],["i64x2"]]],[11,"neg","","",22,[[["self"]],["i64x4"]]],[11,"neg","","",57,[[["self"]],["f32x4"]]],[11,"neg","","",58,[[["self"]],["f64x8"]]],[11,"neg","","",63,[[["self"]],["f32x8"]]],[11,"neg","","",6,[[["self"]],["i8x2"]]],[11,"neg","","",61,[[["self"]],["f32x2"]]],[11,"neg","","",13,[[["self"]],["i32x2"]]],[11,"neg","","",37,[[["self"]],["i8x64"]]],[11,"neg","","",41,[[["self"]],["i32x16"]]],[11,"neg","","",21,[[["self"]],["i8x8"]]],[11,"neg","","",56,[[["self"]],["i16x8"]]],[11,"neg","","",39,[[["self"]],["i32x8"]]],[11,"neg","","",35,[[["self"]],["i16x2"]]],[11,"neg","","",27,[[["self"]],["i16x4"]]],[11,"neg","","",55,[[["self"]],["i8x4"]]],[11,"neg","","",34,[[["self"]],["i8x16"]]],[11,"neg","","",60,[[["self"]],["f64x2"]]],[11,"neg","","",59,[[["self"]],["f32x16"]]],[11,"neg","","",47,[[["self"]],["i64x8"]]],[11,"neg","","",10,[[["self"]],["i16x16"]]],[11,"neg","","",52,[[["self"]],["i32x4"]]],[11,"neg","","",29,[[["self"]],["i16x32"]]],[11,"neg","","",49,[[["self"]],["i8x32"]]],[11,"neg","","",62,[[["self"]],["f64x4"]]],[11,"bitor_assign","","",4,N],[11,"bitor_assign","","",45,N],[11,"bitor_assign","","",53,N],[11,"bitor_assign","","",34,N],[11,"bitor_assign","","",56,N],[11,"bitor_assign","","",34,N],[11,"bitor_assign","","",7,N],[11,"bitor_assign","","",49,N],[11,"bitor_assign","","",47,N],[11,"bitor_assign","","",3,N],[11,"bitor_assign","","",25,N],[11,"bitor_assign","","",35,N],[11,"bitor_assign","","",36,N],[11,"bitor_assign","","",52,N],[11,"bitor_assign","","",20,N],[11,"bitor_assign","","",27,N],[11,"bitor_assign","","",12,N],[11,"bitor_assign","","",37,N],[11,"bitor_assign","","",11,N],[11,"bitor_assign","","",23,N],[11,"bitor_assign","","",20,N],[11,"bitor_assign","","",32,N],[11,"bitor_assign","","",38,N],[11,"bitor_assign","","",50,N],[11,"bitor_assign","","",30,N],[11,"bitor_assign","","",19,N],[11,"bitor_assign","","",16,N],[11,"bitor_assign","","",28,N],[11,"bitor_assign","","",24,N],[11,"bitor_assign","","",25,N],[11,"bitor_assign","","",33,N],[11,"bitor_assign","","",46,N],[11,"bitor_assign","","",6,N],[11,"bitor_assign","","",29,N],[11,"bitor_assign","","",12,N],[11,"bitor_assign","","",17,N],[11,"bitor_assign","","",15,N],[11,"bitor_assign","","",13,N],[11,"bitor_assign","","",40,N],[11,"bitor_assign","","",41,N],[11,"bitor_assign","","",16,N],[11,"bitor_assign","","",17,N],[11,"bitor_assign","","",51,N],[11,"bitor_assign","","",22,N],[11,"bitor_assign","","",7,N],[11,"bitor_assign","","",49,N],[11,"bitor_assign","","",19,N],[11,"bitor_assign","","",43,N],[11,"bitor_assign","","",44,N],[11,"bitor_assign","","",41,N],[11,"bitor_assign","","",38,N],[11,"bitor_assign","","",35,N],[11,"bitor_assign","","",8,N],[11,"bitor_assign","","",54,N],[11,"bitor_assign","","",14,N],[11,"bitor_assign","","",36,N],[11,"bitor_assign","","",31,N],[11,"bitor_assign","","",3,N],[11,"bitor_assign","","",55,N],[11,"bitor_assign","","",40,N],[11,"bitor_assign","","",14,N],[11,"bitor_assign","","",45,N],[11,"bitor_assign","","",33,N],[11,"bitor_assign","","",6,N],[11,"bitor_assign","","",50,N],[11,"bitor_assign","","",27,N],[11,"bitor_assign","","",5,N],[11,"bitor_assign","","",42,N],[11,"bitor_assign","","",48,N],[11,"bitor_assign","","",30,N],[11,"bitor_assign","","",24,N],[11,"bitor_assign","","",53,N],[11,"bitor_assign","","",10,N],[11,"bitor_assign","","",23,N],[11,"bitor_assign","","",28,N],[11,"bitor_assign","","",26,N],[11,"bitor_assign","","",26,N],[11,"bitor_assign","","",47,N],[11,"bitor_assign","","",9,N],[11,"bitor_assign","","",13,N],[11,"bitor_assign","","",15,N],[11,"bitor_assign","","",22,N],[11,"bitor_assign","","",44,N],[11,"bitor_assign","","",5,N],[11,"bitor_assign","","",18,N],[11,"bitor_assign","","",56,N],[11,"bitor_assign","","",54,N],[11,"bitor_assign","","",37,N],[11,"bitor_assign","","",10,N],[11,"bitor_assign","","",55,N],[11,"bitor_assign","","",9,N],[11,"bitor_assign","","",39,N],[11,"bitor_assign","","",21,N],[11,"bitor_assign","","",39,N],[11,"bitor_assign","","",48,N],[11,"bitor_assign","","",46,N],[11,"bitor_assign","","",29,N],[11,"bitor_assign","","",51,N],[11,"bitor_assign","","",42,N],[11,"bitor_assign","","",52,N],[11,"bitor_assign","","",43,N],[11,"bitor_assign","","",11,N],[11,"bitor_assign","","",32,N],[11,"bitor_assign","","",31,N],[11,"bitor_assign","","",21,N],[11,"bitor_assign","","",8,N],[11,"bitor_assign","","",18,N],[11,"bitor_assign","","",4,N],[11,"bitand","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"bitand","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"bitand","","",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"bitand","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"bitand","","",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"bitand","","",11,[[["self"],["bool"]],["m8x2"]]],[11,"bitand","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"bitand","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"bitand","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"bitand","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"bitand","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"bitand","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"bitand","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"bitand","","",25,[[["self"],["bool"]],["m32x2"]]],[11,"bitand","","",46,[[["self"],["bool"]],["m8x4"]]],[11,"bitand","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"bitand","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"bitand","","",48,[[["self"],["bool"]],["m1x32"]]],[11,"bitand","","",31,[[["self"],["bool"]],["m32x4"]]],[11,"bitand","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"bitand","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"bitand","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"bitand","","",26,[[["self"],["bool"]],["m1x64"]]],[11,"bitand","","",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"bitand","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"bitand","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"bitand","","",3,[[["self"],["bool"]],["m32x8"]]],[11,"bitand","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"bitand","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"bitand","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"bitand","","",42,[[["self"],["bool"]],["m8x16"]]],[11,"bitand","","",20,[[["self"],["bool"]],["m8x8"]]],[11,"bitand","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"bitand","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"bitand","","",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"bitand","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"bitand","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"bitand","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"bitand","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"bitand","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"bitand","","",43,[[["self"],["bool"]],["m16x4"]]],[11,"bitand","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"bitand","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"bitand","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"bitand","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"bitand","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"bitand","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"bitand","","",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"bitand","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"bitand","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"bitand","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"bitand","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"bitand","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"bitand","","",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"bitand","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"bitand","","",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"bitand","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"bitand","","",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"bitand","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"bitand","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"bitand","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"bitand","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"bitand","","",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"bitand","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"bitand","","",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"bitand","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"bitand","","",32,[[["self"],["bool"]],["m16x16"]]],[11,"bitand","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"bitand","","",40,[[["self"],["bool"]],["m16x8"]]],[11,"bitand","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"bitand","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"bitand","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"bitand","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"bitand","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"bitand","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"bitand","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"bitand","","",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"bitand","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"bitand","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"bitand","","",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"bitand","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"bitand","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"bitand","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"bitand","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"bitand","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"bitand","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"bitand","","",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"bitand","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"bitand","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"bitand","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"bitand","","",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"bitand","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"bitand","","",53,[[["self"],["bool"]],["m16x2"]]],[11,"bitand","","",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"bitand","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"bitand","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"bitand","","",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"bitand","","",28,[[["self"],["bool"]],["m64x4"]]],[11,"bitand","","",38,[[["self"],["bool"]],["m1x16"]]],[11,"bitand","","",54,[[["self"],["bool"]],["m64x2"]]],[11,"bitand","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"bitand","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"bitand","","",17,[[["self"],["bool"]],["m8x32"]]],[11,"bitand","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"bitand","","",15,[[["self"],["bool"]],["m1x8"]]],[11,"bitand","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"bitand","","",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"bitand","","",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"eq","","",33,[[["self"],["u16x32"]],["bool"]]],[11,"ne","","",33,[[["self"],["u16x32"]],["bool"]]],[11,"eq","","",4,[[["self"],["u64x4"]],["bool"]]],[11,"ne","","",4,[[["self"],["u64x4"]],["bool"]]],[11,"eq","","",47,[[["self"],["i64x8"]],["bool"]]],[11,"ne","","",47,[[["self"],["i64x8"]],["bool"]]],[11,"eq","","",48,[[["self"],["m1x32"]],["bool"]]],[11,"ne","","",48,[[["self"],["m1x32"]],["bool"]]],[11,"eq","","",46,[[["self"],["m8x4"]],["bool"]]],[11,"ne","","",46,[[["self"],["m8x4"]],["bool"]]],[11,"eq","","",17,[[["self"],["m8x32"]],["bool"]]],[11,"ne","","",17,[[["self"],["m8x32"]],["bool"]]],[11,"eq","","",43,[[["self"],["m16x4"]],["bool"]]],[11,"ne","","",43,[[["self"],["m16x4"]],["bool"]]],[11,"eq","","",6,[[["self"],["i8x2"]],["bool"]]],[11,"ne","","",6,[[["self"],["i8x2"]],["bool"]]],[11,"eq","","",23,[[["self"],["u8x32"]],["bool"]]],[11,"ne","","",23,[[["self"],["u8x32"]],["bool"]]],[11,"eq","","",13,[[["self"],["i32x2"]],["bool"]]],[11,"ne","","",13,[[["self"],["i32x2"]],["bool"]]],[11,"eq","","",36,[[["self"],["i64x2"]],["bool"]]],[11,"ne","","",36,[[["self"],["i64x2"]],["bool"]]],[11,"eq","","",18,[[["self"],["u64x2"]],["bool"]]],[11,"ne","","",18,[[["self"],["u64x2"]],["bool"]]],[11,"eq","","",59,[[["self"],["f32x16"]],["bool"]]],[11,"ne","","",59,[[["self"],["f32x16"]],["bool"]]],[11,"eq","","",16,[[["self"],["u16x2"]],["bool"]]],[11,"ne","","",16,[[["self"],["u16x2"]],["bool"]]],[11,"eq","","",56,[[["self"],["i16x8"]],["bool"]]],[11,"ne","","",56,[[["self"],["i16x8"]],["bool"]]],[11,"eq","","",41,[[["self"],["i32x16"]],["bool"]]],[11,"ne","","",41,[[["self"],["i32x16"]],["bool"]]],[11,"eq","stdsimd::arch::x86_64","",2,[[["self"],["cpuidresult"]],["bool"]]],[11,"ne","","",2,[[["self"],["cpuidresult"]],["bool"]]],[11,"eq","stdsimd::simd","",7,[[["self"],["u32x8"]],["bool"]]],[11,"ne","","",7,[[["self"],["u32x8"]],["bool"]]],[11,"eq","","",27,[[["self"],["i16x4"]],["bool"]]],[11,"ne","","",27,[[["self"],["i16x4"]],["bool"]]],[11,"eq","","",32,[[["self"],["m16x16"]],["bool"]]],[11,"ne","","",32,[[["self"],["m16x16"]],["bool"]]],[11,"eq","","",29,[[["self"],["i16x32"]],["bool"]]],[11,"ne","","",29,[[["self"],["i16x32"]],["bool"]]],[11,"eq","","",8,[[["self"],["u64x8"]],["bool"]]],[11,"ne","","",8,[[["self"],["u64x8"]],["bool"]]],[11,"eq","","",3,[[["self"],["m32x8"]],["bool"]]],[11,"ne","","",3,[[["self"],["m32x8"]],["bool"]]],[11,"eq","","",58,[[["self"],["f64x8"]],["bool"]]],[11,"ne","","",58,[[["self"],["f64x8"]],["bool"]]],[11,"eq","","",14,[[["self"],["u16x8"]],["bool"]]],[11,"ne","","",14,[[["self"],["u16x8"]],["bool"]]],[11,"eq","","",15,[[["self"],["m1x8"]],["bool"]]],[11,"ne","","",15,[[["self"],["m1x8"]],["bool"]]],[11,"eq","","",60,[[["self"],["f64x2"]],["bool"]]],[11,"ne","","",60,[[["self"],["f64x2"]],["bool"]]],[11,"eq","","",40,[[["self"],["m16x8"]],["bool"]]],[11,"ne","","",40,[[["self"],["m16x8"]],["bool"]]],[11,"eq","","",44,[[["self"],["u8x16"]],["bool"]]],[11,"ne","","",44,[[["self"],["u8x16"]],["bool"]]],[11,"eq","","",54,[[["self"],["m64x2"]],["bool"]]],[11,"ne","","",54,[[["self"],["m64x2"]],["bool"]]],[11,"eq","","",51,[[["self"],["u8x4"]],["bool"]]],[11,"ne","","",51,[[["self"],["u8x4"]],["bool"]]],[11,"eq","","",62,[[["self"],["f64x4"]],["bool"]]],[11,"ne","","",62,[[["self"],["f64x4"]],["bool"]]],[11,"eq","","",57,[[["self"],["f32x4"]],["bool"]]],[11,"ne","","",57,[[["self"],["f32x4"]],["bool"]]],[11,"eq","","",35,[[["self"],["i16x2"]],["bool"]]],[11,"ne","","",35,[[["self"],["i16x2"]],["bool"]]],[11,"eq","","",12,[[["self"],["u16x16"]],["bool"]]],[11,"ne","","",12,[[["self"],["u16x16"]],["bool"]]],[11,"eq","","",63,[[["self"],["f32x8"]],["bool"]]],[11,"ne","","",63,[[["self"],["f32x8"]],["bool"]]],[11,"eq","","",50,[[["self"],["u8x2"]],["bool"]]],[11,"ne","","",50,[[["self"],["u8x2"]],["bool"]]],[11,"eq","","",28,[[["self"],["m64x4"]],["bool"]]],[11,"ne","","",28,[[["self"],["m64x4"]],["bool"]]],[11,"eq","","",42,[[["self"],["m8x16"]],["bool"]]],[11,"ne","","",42,[[["self"],["m8x16"]],["bool"]]],[11,"eq","","",22,[[["self"],["i64x4"]],["bool"]]],[11,"ne","","",22,[[["self"],["i64x4"]],["bool"]]],[11,"eq","","",53,[[["self"],["m16x2"]],["bool"]]],[11,"ne","","",53,[[["self"],["m16x2"]],["bool"]]],[11,"eq","","",49,[[["self"],["i8x32"]],["bool"]]],[11,"ne","","",49,[[["self"],["i8x32"]],["bool"]]],[11,"eq","","",45,[[["self"],["u8x8"]],["bool"]]],[11,"ne","","",45,[[["self"],["u8x8"]],["bool"]]],[11,"eq","","",30,[[["self"],["u32x16"]],["bool"]]],[11,"ne","","",30,[[["self"],["u32x16"]],["bool"]]],[11,"eq","","",31,[[["self"],["m32x4"]],["bool"]]],[11,"ne","","",31,[[["self"],["m32x4"]],["bool"]]],[11,"eq","","",37,[[["self"],["i8x64"]],["bool"]]],[11,"ne","","",37,[[["self"],["i8x64"]],["bool"]]],[11,"eq","","",52,[[["self"],["i32x4"]],["bool"]]],[11,"ne","","",52,[[["self"],["i32x4"]],["bool"]]],[11,"eq","","",19,[[["self"],["u32x4"]],["bool"]]],[11,"ne","","",19,[[["self"],["u32x4"]],["bool"]]],[11,"eq","","",10,[[["self"],["i16x16"]],["bool"]]],[11,"ne","","",10,[[["self"],["i16x16"]],["bool"]]],[11,"eq","","",24,[[["self"],["u16x4"]],["bool"]]],[11,"ne","","",24,[[["self"],["u16x4"]],["bool"]]],[11,"eq","","",5,[[["self"],["u8x64"]],["bool"]]],[11,"ne","","",5,[[["self"],["u8x64"]],["bool"]]],[11,"eq","","",21,[[["self"],["i8x8"]],["bool"]]],[11,"ne","","",21,[[["self"],["i8x8"]],["bool"]]],[11,"eq","","",20,[[["self"],["m8x8"]],["bool"]]],[11,"ne","","",20,[[["self"],["m8x8"]],["bool"]]],[11,"eq","","",61,[[["self"],["f32x2"]],["bool"]]],[11,"ne","","",61,[[["self"],["f32x2"]],["bool"]]],[11,"eq","","",34,[[["self"],["i8x16"]],["bool"]]],[11,"ne","","",34,[[["self"],["i8x16"]],["bool"]]],[11,"eq","","",11,[[["self"],["m8x2"]],["bool"]]],[11,"ne","","",11,[[["self"],["m8x2"]],["bool"]]],[11,"eq","","",55,[[["self"],["i8x4"]],["bool"]]],[11,"ne","","",55,[[["self"],["i8x4"]],["bool"]]],[11,"eq","","",39,[[["self"],["i32x8"]],["bool"]]],[11,"ne","","",39,[[["self"],["i32x8"]],["bool"]]],[11,"eq","","",9,[[["self"],["u32x2"]],["bool"]]],[11,"ne","","",9,[[["self"],["u32x2"]],["bool"]]],[11,"eq","","",26,[[["self"],["m1x64"]],["bool"]]],[11,"ne","","",26,[[["self"],["m1x64"]],["bool"]]],[11,"eq","","",25,[[["self"],["m32x2"]],["bool"]]],[11,"ne","","",25,[[["self"],["m32x2"]],["bool"]]],[11,"eq","","",38,[[["self"],["m1x16"]],["bool"]]],[11,"ne","","",38,[[["self"],["m1x16"]],["bool"]]],[11,"mul_assign","","",33,N],[11,"mul_assign","","",37,N],[11,"mul_assign","","",51,N],[11,"mul_assign","","",55,N],[11,"mul_assign","","",45,N],[11,"mul_assign","","",61,N],[11,"mul_assign","","",34,N],[11,"mul_assign","","",59,N],[11,"mul_assign","","",63,N],[11,"mul_assign","","",49,N],[11,"mul_assign","","",35,N],[11,"mul_assign","","",47,N],[11,"mul_assign","","",14,N],[11,"mul_assign","","",37,N],[11,"mul_assign","","",10,N],[11,"mul_assign","","",60,N],[11,"mul_assign","","",18,N],[11,"mul_assign","","",47,N],[11,"mul_assign","","",60,N],[11,"mul_assign","","",59,N],[11,"mul_assign","","",8,N],[11,"mul_assign","","",19,N],[11,"mul_assign","","",5,N],[11,"mul_assign","","",22,N],[11,"mul_assign","","",9,N],[11,"mul_assign","","",52,N],[11,"mul_assign","","",44,N],[11,"mul_assign","","",57,N],[11,"mul_assign","","",41,N],[11,"mul_assign","","",10,N],[11,"mul_assign","","",29,N],[11,"mul_assign","","",6,N],[11,"mul_assign","","",36,N],[11,"mul_assign","","",61,N],[11,"mul_assign","","",16,N],[11,"mul_assign","","",16,N],[11,"mul_assign","","",9,N],[11,"mul_assign","","",55,N],[11,"mul_assign","","",12,N],[11,"mul_assign","","",30,N],[11,"mul_assign","","",58,N],[11,"mul_assign","","",19,N],[11,"mul_assign","","",7,N],[11,"mul_assign","","",27,N],[11,"mul_assign","","",50,N],[11,"mul_assign","","",24,N],[11,"mul_assign","","",30,N],[11,"mul_assign","","",56,N],[11,"mul_assign","","",36,N],[11,"mul_assign","","",34,N],[11,"mul_assign","","",39,N],[11,"mul_assign","","",29,N],[11,"mul_assign","","",63,N],[11,"mul_assign","","",56,N],[11,"mul_assign","","",7,N],[11,"mul_assign","","",24,N],[11,"mul_assign","","",13,N],[11,"mul_assign","","",21,N],[11,"mul_assign","","",33,N],[11,"mul_assign","","",35,N],[11,"mul_assign","","",4,N],[11,"mul_assign","","",5,N],[11,"mul_assign","","",21,N],[11,"mul_assign","","",23,N],[11,"mul_assign","","",14,N],[11,"mul_assign","","",49,N],[11,"mul_assign","","",45,N],[11,"mul_assign","","",57,N],[11,"mul_assign","","",27,N],[11,"mul_assign","","",50,N],[11,"mul_assign","","",23,N],[11,"mul_assign","","",4,N],[11,"mul_assign","","",12,N],[11,"mul_assign","","",6,N],[11,"mul_assign","","",39,N],[11,"mul_assign","","",52,N],[11,"mul_assign","","",22,N],[11,"mul_assign","","",41,N],[11,"mul_assign","","",51,N],[11,"mul_assign","","",44,N],[11,"mul_assign","","",18,N],[11,"mul_assign","","",62,N],[11,"mul_assign","","",58,N],[11,"mul_assign","","",13,N],[11,"mul_assign","","",62,N],[11,"mul_assign","","",8,N],[11,"fmt","","",34,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",33,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",45,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",49,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",19,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",39,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",16,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",36,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",12,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",22,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",52,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",56,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",29,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result",["error"]]]],[11,"hash","","",52,N],[11,"hash","","",35,N],[11,"hash","","",8,N],[11,"hash","","",21,N],[11,"hash","","",56,N],[11,"hash","","",47,N],[11,"hash","","",6,N],[11,"hash","","",16,N],[11,"hash","","",4,N],[11,"hash","","",19,N],[11,"hash","","",10,N],[11,"hash","","",39,N],[11,"hash","","",33,N],[11,"hash","","",24,N],[11,"hash","","",23,N],[11,"hash","","",5,N],[11,"hash","","",7,N],[11,"hash","","",14,N],[11,"hash","","",18,N],[11,"hash","","",12,N],[11,"hash","","",44,N],[11,"hash","","",36,N],[11,"hash","","",55,N],[11,"hash","","",22,N],[11,"hash","","",41,N],[11,"hash","","",30,N],[11,"hash","","",37,N],[11,"hash","","",45,N],[11,"hash","","",9,N],[11,"hash","","",13,N],[11,"hash","","",29,N],[11,"hash","","",50,N],[11,"hash","","",49,N],[11,"hash","","",34,N],[11,"hash","","",27,N],[11,"hash","","",51,N],[11,"div_assign","","",35,N],[11,"div_assign","","",44,N],[11,"div_assign","","",12,N],[11,"div_assign","","",60,N],[11,"div_assign","","",13,N],[11,"div_assign","","",61,N],[11,"div_assign","","",56,N],[11,"div_assign","","",33,N],[11,"div_assign","","",59,N],[11,"div_assign","","",61,N],[11,"div_assign","","",24,N],[11,"div_assign","","",57,N],[11,"div_assign","","",21,N],[11,"div_assign","","",21,N],[11,"div_assign","","",18,N],[11,"div_assign","","",49,N],[11,"div_assign","","",4,N],[11,"div_assign","","",36,N],[11,"div_assign","","",27,N],[11,"div_assign","","",30,N],[11,"div_assign","","",12,N],[11,"div_assign","","",6,N],[11,"div_assign","","",34,N],[11,"div_assign","","",9,N],[11,"div_assign","","",16,N],[11,"div_assign","","",14,N],[11,"div_assign","","",4,N],[11,"div_assign","","",62,N],[11,"div_assign","","",18,N],[11,"div_assign","","",7,N],[11,"div_assign","","",27,N],[11,"div_assign","","",41,N],[11,"div_assign","","",14,N],[11,"div_assign","","",39,N],[11,"div_assign","","",5,N],[11,"div_assign","","",47,N],[11,"div_assign","","",51,N],[11,"div_assign","","",7,N],[11,"div_assign","","",35,N],[11,"div_assign","","",22,N],[11,"div_assign","","",50,N],[11,"div_assign","","",50,N],[11,"div_assign","","",55,N],[11,"div_assign","","",33,N],[11,"div_assign","","",55,N],[11,"div_assign","","",63,N],[11,"div_assign","","",19,N],[11,"div_assign","","",47,N],[11,"div_assign","","",51,N],[11,"div_assign","","",22,N],[11,"div_assign","","",58,N],[11,"div_assign","","",8,N],[11,"div_assign","","",23,N],[11,"div_assign","","",29,N],[11,"div_assign","","",9,N],[11,"div_assign","","",37,N],[11,"div_assign","","",39,N],[11,"div_assign","","",13,N],[11,"div_assign","","",56,N],[11,"div_assign","","",29,N],[11,"div_assign","","",23,N],[11,"div_assign","","",57,N],[11,"div_assign","","",58,N],[11,"div_assign","","",30,N],[11,"div_assign","","",63,N],[11,"div_assign","","",36,N],[11,"div_assign","","",52,N],[11,"div_assign","","",62,N],[11,"div_assign","","",49,N],[11,"div_assign","","",16,N],[11,"div_assign","","",8,N],[11,"div_assign","","",52,N],[11,"div_assign","","",10,N],[11,"div_assign","","",10,N],[11,"div_assign","","",59,N],[11,"div_assign","","",6,N],[11,"div_assign","","",44,N],[11,"div_assign","","",24,N],[11,"div_assign","","",37,N],[11,"div_assign","","",34,N],[11,"div_assign","","",41,N],[11,"div_assign","","",45,N],[11,"div_assign","","",45,N],[11,"div_assign","","",60,N],[11,"div_assign","","",5,N],[11,"div_assign","","",19,N],[11,"shl","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"shl","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"shl","","",24,[[["self"],["i32"]],["u16x4"]]],[11,"shl","","",18,[[["self"],["usize"]],["u64x2"]]],[11,"shl","","",22,[[["self"],["u16"]],["i64x4"]]],[11,"shl","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"shl","","",35,[[["self"],["u16"]],["i16x2"]]],[11,"shl","","",4,[[["self"],["i32"]],["u64x4"]]],[11,"shl","","",7,[[["self"],["i64"]],["u32x8"]]],[11,"shl","","",50,[[["self"],["i8"]],["u8x2"]]],[11,"shl","","",30,[[["self"],["i8"]],["u32x16"]]],[11,"shl","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"shl","","",55,[[["self"],["i32"]],["i8x4"]]],[11,"shl","","",36,[[["self"],["u32"]],["i64x2"]]],[11,"shl","","",55,[[["self"],["usize"]],["i8x4"]]],[11,"shl","","",27,[[["self"],["u8"]],["i16x4"]]],[11,"shl","","",12,[[["self"],["u32"]],["u16x16"]]],[11,"shl","","",50,[[["self"],["usize"]],["u8x2"]]],[11,"shl","","",29,[[["self"],["u8"]],["i16x32"]]],[11,"shl","","",51,[[["self"],["u32"]],["u8x4"]]],[11,"shl","","",6,[[["self"],["i64"]],["i8x2"]]],[11,"shl","","",55,[[["self"],["u64"]],["i8x4"]]],[11,"shl","","",22,[[["self"],["i16"]],["i64x4"]]],[11,"shl","","",12,[[["self"],["i64"]],["u16x16"]]],[11,"shl","","",30,[[["self"],["u64"]],["u32x16"]]],[11,"shl","","",18,[[["self"],["i16"]],["u64x2"]]],[11,"shl","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"shl","","",9,[[["self"],["i8"]],["u32x2"]]],[11,"shl","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"shl","","",49,[[["self"],["u16"]],["i8x32"]]],[11,"shl","","",33,[[["self"],["u64"]],["u16x32"]]],[11,"shl","","",22,[[["self"],["u32"]],["i64x4"]]],[11,"shl","","",8,[[["self"],["i8"]],["u64x8"]]],[11,"shl","","",52,[[["self"],["i64"]],["i32x4"]]],[11,"shl","","",21,[[["self"],["i32"]],["i8x8"]]],[11,"shl","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"shl","","",10,[[["self"],["i8"]],["i16x16"]]],[11,"shl","","",56,[[["self"],["i64"]],["i16x8"]]],[11,"shl","","",37,[[["self"],["u32"]],["i8x64"]]],[11,"shl","","",19,[[["self"],["u16"]],["u32x4"]]],[11,"shl","","",16,[[["self"],["u64"]],["u16x2"]]],[11,"shl","","",6,[[["self"],["u16"]],["i8x2"]]],[11,"shl","","",7,[[["self"],["i16"]],["u32x8"]]],[11,"shl","","",29,[[["self"],["usize"]],["i16x32"]]],[11,"shl","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"shl","","",10,[[["self"],["i64"]],["i16x16"]]],[11,"shl","","",8,[[["self"],["u16"]],["u64x8"]]],[11,"shl","","",36,[[["self"],["i16"]],["i64x2"]]],[11,"shl","","",55,[[["self"],["u32"]],["i8x4"]]],[11,"shl","","",19,[[["self"],["usize"]],["u32x4"]]],[11,"shl","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"shl","","",52,[[["self"],["i16"]],["i32x4"]]],[11,"shl","","",30,[[["self"],["u8"]],["u32x16"]]],[11,"shl","","",51,[[["self"],["i32"]],["u8x4"]]],[11,"shl","","",16,[[["self"],["i32"]],["u16x2"]]],[11,"shl","","",45,[[["self"],["isize"]],["u8x8"]]],[11,"shl","","",52,[[["self"],["i8"]],["i32x4"]]],[11,"shl","","",9,[[["self"],["i32"]],["u32x2"]]],[11,"shl","","",29,[[["self"],["u64"]],["i16x32"]]],[11,"shl","","",14,[[["self"],["i8"]],["u16x8"]]],[11,"shl","","",52,[[["self"],["u64"]],["i32x4"]]],[11,"shl","","",30,[[["self"],["i32"]],["u32x16"]]],[11,"shl","","",5,[[["self"],["isize"]],["u8x64"]]],[11,"shl","","",21,[[["self"],["isize"]],["i8x8"]]],[11,"shl","","",23,[[["self"],["usize"]],["u8x32"]]],[11,"shl","","",47,[[["self"],["u8"]],["i64x8"]]],[11,"shl","","",39,[[["self"],["i16"]],["i32x8"]]],[11,"shl","","",4,[[["self"],["i16"]],["u64x4"]]],[11,"shl","","",51,[[["self"],["i16"]],["u8x4"]]],[11,"shl","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"shl","","",37,[[["self"],["usize"]],["i8x64"]]],[11,"shl","","",6,[[["self"],["u8"]],["i8x2"]]],[11,"shl","","",35,[[["self"],["u8"]],["i16x2"]]],[11,"shl","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"shl","","",4,[[["self"],["u8"]],["u64x4"]]],[11,"shl","","",22,[[["self"],["usize"]],["i64x4"]]],[11,"shl","","",47,[[["self"],["i16"]],["i64x8"]]],[11,"shl","","",5,[[["self"],["u32"]],["u8x64"]]],[11,"shl","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"shl","","",29,[[["self"],["i64"]],["i16x32"]]],[11,"shl","","",50,[[["self"],["isize"]],["u8x2"]]],[11,"shl","","",36,[[["self"],["u8"]],["i64x2"]]],[11,"shl","","",49,[[["self"],["i16"]],["i8x32"]]],[11,"shl","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"shl","","",13,[[["self"],["i8"]],["i32x2"]]],[11,"shl","","",13,[[["self"],["u16"]],["i32x2"]]],[11,"shl","","",44,[[["self"],["u32"]],["u8x16"]]],[11,"shl","","",6,[[["self"],["i32"]],["i8x2"]]],[11,"shl","","",16,[[["self"],["usize"]],["u16x2"]]],[11,"shl","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"shl","","",52,[[["self"],["usize"]],["i32x4"]]],[11,"shl","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"shl","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"shl","","",47,[[["self"],["u64"]],["i64x8"]]],[11,"shl","","",23,[[["self"],["u64"]],["u8x32"]]],[11,"shl","","",39,[[["self"],["u8"]],["i32x8"]]],[11,"shl","","",30,[[["self"],["usize"]],["u32x16"]]],[11,"shl","","",36,[[["self"],["isize"]],["i64x2"]]],[11,"shl","","",37,[[["self"],["u16"]],["i8x64"]]],[11,"shl","","",10,[[["self"],["isize"]],["i16x16"]]],[11,"shl","","",14,[[["self"],["isize"]],["u16x8"]]],[11,"shl","","",22,[[["self"],["i32"]],["i64x4"]]],[11,"shl","","",35,[[["self"],["i8"]],["i16x2"]]],[11,"shl","","",36,[[["self"],["i8"]],["i64x2"]]],[11,"shl","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"shl","","",24,[[["self"],["u32"]],["u16x4"]]],[11,"shl","","",13,[[["self"],["isize"]],["i32x2"]]],[11,"shl","","",19,[[["self"],["i32"]],["u32x4"]]],[11,"shl","","",21,[[["self"],["usize"]],["i8x8"]]],[11,"shl","","",5,[[["self"],["i8"]],["u8x64"]]],[11,"shl","","",21,[[["self"],["u16"]],["i8x8"]]],[11,"shl","","",18,[[["self"],["u32"]],["u64x2"]]],[11,"shl","","",51,[[["self"],["i8"]],["u8x4"]]],[11,"shl","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"shl","","",16,[[["self"],["u32"]],["u16x2"]]],[11,"shl","","",13,[[["self"],["u8"]],["i32x2"]]],[11,"shl","","",16,[[["self"],["i8"]],["u16x2"]]],[11,"shl","","",9,[[["self"],["i16"]],["u32x2"]]],[11,"shl","","",56,[[["self"],["u32"]],["i16x8"]]],[11,"shl","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"shl","","",24,[[["self"],["i8"]],["u16x4"]]],[11,"shl","","",22,[[["self"],["isize"]],["i64x4"]]],[11,"shl","","",34,[[["self"],["i64"]],["i8x16"]]],[11,"shl","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"shl","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"shl","","",49,[[["self"],["isize"]],["i8x32"]]],[11,"shl","","",27,[[["self"],["u16"]],["i16x4"]]],[11,"shl","","",45,[[["self"],["i32"]],["u8x8"]]],[11,"shl","","",36,[[["self"],["usize"]],["i64x2"]]],[11,"shl","","",5,[[["self"],["u64"]],["u8x64"]]],[11,"shl","","",50,[[["self"],["i16"]],["u8x2"]]],[11,"shl","","",19,[[["self"],["isize"]],["u32x4"]]],[11,"shl","","",7,[[["self"],["u8"]],["u32x8"]]],[11,"shl","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"shl","","",10,[[["self"],["usize"]],["i16x16"]]],[11,"shl","","",24,[[["self"],["i16"]],["u16x4"]]],[11,"shl","","",5,[[["self"],["i64"]],["u8x64"]]],[11,"shl","","",7,[[["self"],["isize"]],["u32x8"]]],[11,"shl","","",23,[[["self"],["u16"]],["u8x32"]]],[11,"shl","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"shl","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"shl","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"shl","","",27,[[["self"],["i8"]],["i16x4"]]],[11,"shl","","",37,[[["self"],["isize"]],["i8x64"]]],[11,"shl","","",21,[[["self"],["i64"]],["i8x8"]]],[11,"shl","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"shl","","",52,[[["self"],["u32"]],["i32x4"]]],[11,"shl","","",6,[[["self"],["usize"]],["i8x2"]]],[11,"shl","","",33,[[["self"],["isize"]],["u16x32"]]],[11,"shl","","",56,[[["self"],["u8"]],["i16x8"]]],[11,"shl","","",23,[[["self"],["u32"]],["u8x32"]]],[11,"shl","","",34,[[["self"],["i32"]],["i8x16"]]],[11,"shl","","",24,[[["self"],["i64"]],["u16x4"]]],[11,"shl","","",34,[[["self"],["usize"]],["i8x16"]]],[11,"shl","","",8,[[["self"],["u8"]],["u64x8"]]],[11,"shl","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"shl","","",12,[[["self"],["i32"]],["u16x16"]]],[11,"shl","","",21,[[["self"],["u8"]],["i8x8"]]],[11,"shl","","",51,[[["self"],["u16"]],["u8x4"]]],[11,"shl","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"shl","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"shl","","",7,[[["self"],["i8"]],["u32x8"]]],[11,"shl","","",47,[[["self"],["i8"]],["i64x8"]]],[11,"shl","","",39,[[["self"],["u32"]],["i32x8"]]],[11,"shl","","",41,[[["self"],["i64"]],["i32x16"]]],[11,"shl","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"shl","","",13,[[["self"],["u64"]],["i32x2"]]],[11,"shl","","",56,[[["self"],["isize"]],["i16x8"]]],[11,"shl","","",24,[[["self"],["u8"]],["u16x4"]]],[11,"shl","","",47,[[["self"],["isize"]],["i64x8"]]],[11,"shl","","",44,[[["self"],["i8"]],["u8x16"]]],[11,"shl","","",45,[[["self"],["i64"]],["u8x8"]]],[11,"shl","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"shl","","",29,[[["self"],["u16"]],["i16x32"]]],[11,"shl","","",4,[[["self"],["usize"]],["u64x4"]]],[11,"shl","","",37,[[["self"],["u8"]],["i8x64"]]],[11,"shl","","",56,[[["self"],["i32"]],["i16x8"]]],[11,"shl","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"shl","","",12,[[["self"],["isize"]],["u16x16"]]],[11,"shl","","",41,[[["self"],["i8"]],["i32x16"]]],[11,"shl","","",5,[[["self"],["i32"]],["u8x64"]]],[11,"shl","","",19,[[["self"],["i16"]],["u32x4"]]],[11,"shl","","",14,[[["self"],["usize"]],["u16x8"]]],[11,"shl","","",30,[[["self"],["u16"]],["u32x16"]]],[11,"shl","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"shl","","",8,[[["self"],["i16"]],["u64x8"]]],[11,"shl","","",29,[[["self"],["i8"]],["i16x32"]]],[11,"shl","","",34,[[["self"],["u16"]],["i8x16"]]],[11,"shl","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"shl","","",44,[[["self"],["usize"]],["u8x16"]]],[11,"shl","","",23,[[["self"],["i64"]],["u8x32"]]],[11,"shl","","",16,[[["self"],["i64"]],["u16x2"]]],[11,"shl","","",24,[[["self"],["isize"]],["u16x4"]]],[11,"shl","","",33,[[["self"],["i32"]],["u16x32"]]],[11,"shl","","",5,[[["self"],["usize"]],["u8x64"]]],[11,"shl","","",39,[[["self"],["i64"]],["i32x8"]]],[11,"shl","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"shl","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"shl","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"shl","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"shl","","",24,[[["self"],["u64"]],["u16x4"]]],[11,"shl","","",18,[[["self"],["u8"]],["u64x2"]]],[11,"shl","","",23,[[["self"],["i16"]],["u8x32"]]],[11,"shl","","",7,[[["self"],["usize"]],["u32x8"]]],[11,"shl","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"shl","","",10,[[["self"],["u32"]],["i16x16"]]],[11,"shl","","",9,[[["self"],["i64"]],["u32x2"]]],[11,"shl","","",33,[[["self"],["u32"]],["u16x32"]]],[11,"shl","","",14,[[["self"],["u32"]],["u16x8"]]],[11,"shl","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"shl","","",23,[[["self"],["isize"]],["u8x32"]]],[11,"shl","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"shl","","",36,[[["self"],["u16"]],["i64x2"]]],[11,"shl","","",18,[[["self"],["i8"]],["u64x2"]]],[11,"shl","","",23,[[["self"],["i8"]],["u8x32"]]],[11,"shl","","",21,[[["self"],["u64"]],["i8x8"]]],[11,"shl","","",51,[[["self"],["u64"]],["u8x4"]]],[11,"shl","","",50,[[["self"],["u16"]],["u8x2"]]],[11,"shl","","",44,[[["self"],["u64"]],["u8x16"]]],[11,"shl","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"shl","","",47,[[["self"],["u32"]],["i64x8"]]],[11,"shl","","",44,[[["self"],["u16"]],["u8x16"]]],[11,"shl","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"shl","","",18,[[["self"],["i32"]],["u64x2"]]],[11,"shl","","",41,[[["self"],["isize"]],["i32x16"]]],[11,"shl","","",5,[[["self"],["u16"]],["u8x64"]]],[11,"shl","","",10,[[["self"],["u8"]],["i16x16"]]],[11,"shl","","",35,[[["self"],["u64"]],["i16x2"]]],[11,"shl","","",13,[[["self"],["i16"]],["i32x2"]]],[11,"shl","","",4,[[["self"],["i8"]],["u64x4"]]],[11,"shl","","",9,[[["self"],["u64"]],["u32x2"]]],[11,"shl","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"shl","","",12,[[["self"],["u8"]],["u16x16"]]],[11,"shl","","",47,[[["self"],["u16"]],["i64x8"]]],[11,"shl","","",45,[[["self"],["i8"]],["u8x8"]]],[11,"shl","","",24,[[["self"],["usize"]],["u16x4"]]],[11,"shl","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"shl","","",45,[[["self"],["i16"]],["u8x8"]]],[11,"shl","","",52,[[["self"],["isize"]],["i32x4"]]],[11,"shl","","",8,[[["self"],["u32"]],["u64x8"]]],[11,"shl","","",27,[[["self"],["u64"]],["i16x4"]]],[11,"shl","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"shl","","",55,[[["self"],["u16"]],["i8x4"]]],[11,"shl","","",47,[[["self"],["i32"]],["i64x8"]]],[11,"shl","","",39,[[["self"],["u64"]],["i32x8"]]],[11,"shl","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"shl","","",10,[[["self"],["u64"]],["i16x16"]]],[11,"shl","","",51,[[["self"],["isize"]],["u8x4"]]],[11,"shl","","",37,[[["self"],["i16"]],["i8x64"]]],[11,"shl","","",41,[[["self"],["u64"]],["i32x16"]]],[11,"shl","","",19,[[["self"],["u64"]],["u32x4"]]],[11,"shl","","",41,[[["self"],["usize"]],["i32x16"]]],[11,"shl","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"shl","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"shl","","",44,[[["self"],["i64"]],["u8x16"]]],[11,"shl","","",37,[[["self"],["i32"]],["i8x64"]]],[11,"shl","","",34,[[["self"],["i16"]],["i8x16"]]],[11,"shl","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"shl","","",14,[[["self"],["i16"]],["u16x8"]]],[11,"shl","","",37,[[["self"],["i64"]],["i8x64"]]],[11,"shl","","",13,[[["self"],["usize"]],["i32x2"]]],[11,"shl","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"shl","","",56,[[["self"],["u16"]],["i16x8"]]],[11,"shl","","",8,[[["self"],["isize"]],["u64x8"]]],[11,"shl","","",4,[[["self"],["isize"]],["u64x4"]]],[11,"shl","","",39,[[["self"],["i8"]],["i32x8"]]],[11,"shl","","",18,[[["self"],["i64"]],["u64x2"]]],[11,"shl","","",44,[[["self"],["i32"]],["u8x16"]]],[11,"shl","","",8,[[["self"],["i32"]],["u64x8"]]],[11,"shl","","",14,[[["self"],["i32"]],["u16x8"]]],[11,"shl","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"shl","","",36,[[["self"],["i32"]],["i64x2"]]],[11,"shl","","",5,[[["self"],["i16"]],["u8x64"]]],[11,"shl","","",14,[[["self"],["u64"]],["u16x8"]]],[11,"shl","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"shl","","",13,[[["self"],["i64"]],["i32x2"]]],[11,"shl","","",22,[[["self"],["u8"]],["i64x4"]]],[11,"shl","","",51,[[["self"],["i64"]],["u8x4"]]],[11,"shl","","",36,[[["self"],["u64"]],["i64x2"]]],[11,"shl","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"shl","","",33,[[["self"],["u8"]],["u16x32"]]],[11,"shl","","",27,[[["self"],["i64"]],["i16x4"]]],[11,"shl","","",19,[[["self"],["u8"]],["u32x4"]]],[11,"shl","","",50,[[["self"],["i64"]],["u8x2"]]],[11,"shl","","",18,[[["self"],["u16"]],["u64x2"]]],[11,"shl","","",34,[[["self"],["isize"]],["i8x16"]]],[11,"shl","","",27,[[["self"],["u32"]],["i16x4"]]],[11,"shl","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"shl","","",19,[[["self"],["i8"]],["u32x4"]]],[11,"shl","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"shl","","",39,[[["self"],["u16"]],["i32x8"]]],[11,"shl","","",8,[[["self"],["i64"]],["u64x8"]]],[11,"shl","","",49,[[["self"],["u64"]],["i8x32"]]],[11,"shl","","",30,[[["self"],["i16"]],["u32x16"]]],[11,"shl","","",35,[[["self"],["i64"]],["i16x2"]]],[11,"shl","","",45,[[["self"],["u32"]],["u8x8"]]],[11,"shl","","",6,[[["self"],["isize"]],["i8x2"]]],[11,"shl","","",50,[[["self"],["i32"]],["u8x2"]]],[11,"shl","","",9,[[["self"],["isize"]],["u32x2"]]],[11,"shl","","",10,[[["self"],["i32"]],["i16x16"]]],[11,"shl","","",19,[[["self"],["i64"]],["u32x4"]]],[11,"shl","","",39,[[["self"],["isize"]],["i32x8"]]],[11,"shl","","",16,[[["self"],["isize"]],["u16x2"]]],[11,"shl","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"shl","","",49,[[["self"],["i64"]],["i8x32"]]],[11,"shl","","",6,[[["self"],["u64"]],["i8x2"]]],[11,"shl","","",12,[[["self"],["i8"]],["u16x16"]]],[11,"shl","","",49,[[["self"],["i32"]],["i8x32"]]],[11,"shl","","",50,[[["self"],["u64"]],["u8x2"]]],[11,"shl","","",55,[[["self"],["u8"]],["i8x4"]]],[11,"shl","","",55,[[["self"],["i64"]],["i8x4"]]],[11,"shl","","",12,[[["self"],["u64"]],["u16x16"]]],[11,"shl","","",33,[[["self"],["i64"]],["u16x32"]]],[11,"shl","","",33,[[["self"],["i8"]],["u16x32"]]],[11,"shl","","",45,[[["self"],["u64"]],["u8x8"]]],[11,"shl","","",34,[[["self"],["u8"]],["i8x16"]]],[11,"shl","","",13,[[["self"],["u32"]],["i32x2"]]],[11,"shl","","",7,[[["self"],["u16"]],["u32x8"]]],[11,"shl","","",29,[[["self"],["isize"]],["i16x32"]]],[11,"shl","","",35,[[["self"],["isize"]],["i16x2"]]],[11,"shl","","",41,[[["self"],["u32"]],["i32x16"]]],[11,"shl","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"shl","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"shl","","",22,[[["self"],["u64"]],["i64x4"]]],[11,"shl","","",45,[[["self"],["usize"]],["u8x8"]]],[11,"shl","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"shl","","",45,[[["self"],["u16"]],["u8x8"]]],[11,"shl","","",55,[[["self"],["i16"]],["i8x4"]]],[11,"shl","","",56,[[["self"],["usize"]],["i16x8"]]],[11,"shl","","",27,[[["self"],["isize"]],["i16x4"]]],[11,"shl","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"shl","","",44,[[["self"],["isize"]],["u8x16"]]],[11,"shl","","",52,[[["self"],["u16"]],["i32x4"]]],[11,"shl","","",30,[[["self"],["i64"]],["u32x16"]]],[11,"shl","","",4,[[["self"],["u16"]],["u64x4"]]],[11,"shl","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"shl","","",55,[[["self"],["isize"]],["i8x4"]]],[11,"shl","","",21,[[["self"],["u32"]],["i8x8"]]],[11,"shl","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"shl","","",9,[[["self"],["u16"]],["u32x2"]]],[11,"shl","","",21,[[["self"],["i16"]],["i8x8"]]],[11,"shl","","",22,[[["self"],["i8"]],["i64x4"]]],[11,"shl","","",9,[[["self"],["u8"]],["u32x2"]]],[11,"shl","","",16,[[["self"],["i16"]],["u16x2"]]],[11,"shl","","",10,[[["self"],["u16"]],["i16x16"]]],[11,"shl","","",18,[[["self"],["isize"]],["u64x2"]]],[11,"shl","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"shl","","",49,[[["self"],["u32"]],["i8x32"]]],[11,"shl","","",7,[[["self"],["i32"]],["u32x8"]]],[11,"shl","","",9,[[["self"],["usize"]],["u32x2"]]],[11,"shl","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"shl","","",35,[[["self"],["u32"]],["i16x2"]]],[11,"shl","","",41,[[["self"],["i16"]],["i32x16"]]],[11,"shl","","",56,[[["self"],["u64"]],["i16x8"]]],[11,"shl","","",47,[[["self"],["usize"]],["i64x8"]]],[11,"shl","","",35,[[["self"],["i32"]],["i16x2"]]],[11,"shl","","",34,[[["self"],["u32"]],["i8x16"]]],[11,"shl","","",41,[[["self"],["u8"]],["i32x16"]]],[11,"shl","","",37,[[["self"],["u64"]],["i8x64"]]],[11,"shl","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"shl","","",30,[[["self"],["isize"]],["u32x16"]]],[11,"shl","","",7,[[["self"],["u64"]],["u32x8"]]],[11,"shl","","",6,[[["self"],["u32"]],["i8x2"]]],[11,"shl","","",29,[[["self"],["u32"]],["i16x32"]]],[11,"shl","","",49,[[["self"],["u8"]],["i8x32"]]],[11,"shl","","",4,[[["self"],["u32"]],["u64x4"]]],[11,"shl","","",12,[[["self"],["usize"]],["u16x16"]]],[11,"shl","","",52,[[["self"],["u8"]],["i32x4"]]],[11,"shl","","",44,[[["self"],["i16"]],["u8x16"]]],[11,"shl","","",27,[[["self"],["i32"]],["i16x4"]]],[11,"shl","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"shl","","",14,[[["self"],["u8"]],["u16x8"]]],[11,"shl","","",16,[[["self"],["u8"]],["u16x2"]]],[11,"shl","","",33,[[["self"],["i16"]],["u16x32"]]],[11,"shl","","",27,[[["self"],["usize"]],["i16x4"]]],[11,"shl","","",29,[[["self"],["i32"]],["i16x32"]]],[11,"shl","","",39,[[["self"],["usize"]],["i32x8"]]],[11,"shl","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"shl","","",49,[[["self"],["usize"]],["i8x32"]]],[11,"shl","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"shl","","",51,[[["self"],["usize"]],["u8x4"]]],[11,"shl","","",33,[[["self"],["usize"]],["u16x32"]]],[11,"shl","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"shl","","",4,[[["self"],["i64"]],["u64x4"]]],[11,"shl","","",12,[[["self"],["i16"]],["u16x16"]]],[11,"shl","","",35,[[["self"],["usize"]],["i16x2"]]],[11,"shl","","",14,[[["self"],["i64"]],["u16x8"]]],[11,"shl","","",41,[[["self"],["u16"]],["i32x16"]]],[11,"shl","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"shl","","",8,[[["self"],["usize"]],["u64x8"]]],[11,"shl","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"shl","","",23,[[["self"],["i32"]],["u8x32"]]],[11,"shl","","",56,[[["self"],["i8"]],["i16x8"]]],[11,"shl","","",34,[[["self"],["u64"]],["i8x16"]]],[11,"shl","","",50,[[["self"],["u32"]],["u8x2"]]],[11,"shl","","",6,[[["self"],["i16"]],["i8x2"]]],[11,"fmt","","",56,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",22,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",19,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",36,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",52,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",39,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",29,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",16,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",12,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",33,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",49,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",45,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result",["error"]]]],[11,"add_assign","","",39,N],[11,"add_assign","","",18,N],[11,"add_assign","","",36,N],[11,"add_assign","","",44,N],[11,"add_assign","","",6,N],[11,"add_assign","","",61,N],[11,"add_assign","","",34,N],[11,"add_assign","","",63,N],[11,"add_assign","","",52,N],[11,"add_assign","","",35,N],[11,"add_assign","","",44,N],[11,"add_assign","","",29,N],[11,"add_assign","","",19,N],[11,"add_assign","","",49,N],[11,"add_assign","","",37,N],[11,"add_assign","","",59,N],[11,"add_assign","","",12,N],[11,"add_assign","","",10,N],[11,"add_assign","","",19,N],[11,"add_assign","","",7,N],[11,"add_assign","","",9,N],[11,"add_assign","","",60,N],[11,"add_assign","","",22,N],[11,"add_assign","","",16,N],[11,"add_assign","","",16,N],[11,"add_assign","","",41,N],[11,"add_assign","","",45,N],[11,"add_assign","","",50,N],[11,"add_assign","","",37,N],[11,"add_assign","","",62,N],[11,"add_assign","","",51,N],[11,"add_assign","","",50,N],[11,"add_assign","","",30,N],[11,"add_assign","","",4,N],[11,"add_assign","","",60,N],[11,"add_assign","","",13,N],[11,"add_assign","","",10,N],[11,"add_assign","","",51,N],[11,"add_assign","","",57,N],[11,"add_assign","","",27,N],[11,"add_assign","","",6,N],[11,"add_assign","","",34,N],[11,"add_assign","","",23,N],[11,"add_assign","","",55,N],[11,"add_assign","","",14,N],[11,"add_assign","","",58,N],[11,"add_assign","","",30,N],[11,"add_assign","","",8,N],[11,"add_assign","","",33,N],[11,"add_assign","","",24,N],[11,"add_assign","","",36,N],[11,"add_assign","","",58,N],[11,"add_assign","","",56,N],[11,"add_assign","","",47,N],[11,"add_assign","","",7,N],[11,"add_assign","","",23,N],[11,"add_assign","","",5,N],[11,"add_assign","","",61,N],[11,"add_assign","","",35,N],[11,"add_assign","","",47,N],[11,"add_assign","","",8,N],[11,"add_assign","","",13,N],[11,"add_assign","","",4,N],[11,"add_assign","","",9,N],[11,"add_assign","","",24,N],[11,"add_assign","","",62,N],[11,"add_assign","","",55,N],[11,"add_assign","","",57,N],[11,"add_assign","","",29,N],[11,"add_assign","","",21,N],[11,"add_assign","","",45,N],[11,"add_assign","","",41,N],[11,"add_assign","","",5,N],[11,"add_assign","","",52,N],[11,"add_assign","","",33,N],[11,"add_assign","","",59,N],[11,"add_assign","","",14,N],[11,"add_assign","","",21,N],[11,"add_assign","","",63,N],[11,"add_assign","","",22,N],[11,"add_assign","","",56,N],[11,"add_assign","","",18,N],[11,"add_assign","","",12,N],[11,"add_assign","","",49,N],[11,"add_assign","","",39,N],[11,"add_assign","","",27,N],[11,"from","","",51,[[["m16x4"]],["u8x4"]]],[11,"from","","",42,[[["m1x16"]],["m8x16"]]],[11,"from","","",55,[[["m32x4"]],["i8x4"]]],[11,"from","","",10,[[["u8x16"]],["i16x16"]]],[11,"from","","",58,[[["u8x8"]],["f64x8"]]],[11,"from","","",18,[[["m16x2"]],["u64x2"]]],[11,"from","","",62,[[["m8x4"]],["f64x4"]]],[11,"from","","",13,[[["m16x2"]],["i32x2"]]],[11,"from","","",19,[[["u64x4"]],["u32x4"]]],[11,"from","","",27,[[["i8x4"]],["i16x4"]]],[11,"from","","",62,[[["m32x4"]],["f64x4"]]],[11,"from","","",13,[[["i64x2"]],["i32x2"]]],[11,"from","","",18,[[["u32x2"]],["u64x2"]]],[11,"from","","",63,[[["m1x8"]],["f32x8"]]],[11,"from","","",3,[[["m16x8"]],["m32x8"]]],[11,"from","","",22,[[["f32x4"]],["i64x4"]]],[11,"from","","",50,[[["m8x2"]],["u8x2"]]],[11,"from","","",52,[[["f64x4"]],["i32x4"]]],[11,"from","","",63,[[["u32x8"]],["f32x8"]]],[11,"from","","",28,[[["m8x4"]],["m64x4"]]],[11,"from","","",9,[[["i32x2"]],["u32x2"]]],[11,"from","","",57,[[["u32x4"]],["f32x4"]]],[11,"from","","",30,[[["m1x16"]],["u32x16"]]],[11,"from","","",6,[[["i64x2"]],["i8x2"]]],[11,"from","","",34,[[["m16x16"]],["i8x16"]]],[11,"from","","",55,[[["u64x4"]],["i8x4"]]],[11,"from","","",40,[[["m1x8"]],["m16x8"]]],[11,"from","","",50,[[["i8x2"]],["u8x2"]]],[11,"from","","",27,[[["m64x4"]],["i16x4"]]],[11,"from","","",16,[[["m64x2"]],["u16x2"]]],[11,"from","","",19,[[["m32x4"]],["u32x4"]]],[11,"from","","",58,[[["i32x8"]],["f64x8"]]],[11,"from","","",21,[[["f64x8"]],["i8x8"]]],[11,"from","","",56,[[["f32x8"]],["i16x8"]]],[11,"from","","",3,[[["m8x8"]],["m32x8"]]],[11,"from","","",45,[[["m16x8"]],["u8x8"]]],[11,"from","","",27,[[["f32x4"]],["i16x4"]]],[11,"from","","",47,[[["i8x8"]],["i64x8"]]],[11,"from","","",20,[[["m16x8"]],["m8x8"]]],[11,"from","","",27,[[["f64x4"]],["i16x4"]]],[11,"from","","",27,[[["u64x4"]],["i16x4"]]],[11,"from","","",51,[[["m32x4"]],["u8x4"]]],[11,"from","","",12,[[["f32x16"]],["u16x16"]]],[11,"from","","",59,[[["m16x16"]],["f32x16"]]],[11,"from","","",50,[[["m32x2"]],["u8x2"]]],[11,"from","","",21,[[["u16x8"]],["i8x8"]]],[11,"from","","",15,[[["m32x8"]],["m1x8"]]],[11,"from","","",14,[[["m16x8"]],["u16x8"]]],[11,"from","","",41,[[["m8x16"]],["i32x16"]]],[11,"from","","",14,[[["m32x8"]],["u16x8"]]],[11,"from","","",28,[[["m16x4"]],["m64x4"]]],[11,"from","","",53,[[["m8x2"]],["m16x2"]]],[11,"from","","",24,[[["m16x4"]],["u16x4"]]],[11,"from","","",39,[[["m8x8"]],["i32x8"]]],[11,"from","","",13,[[["m8x2"]],["i32x2"]]],[11,"from","","",57,[[["m64x4"]],["f32x4"]]],[11,"from","","",51,[[["f32x4"]],["u8x4"]]],[11,"from","","",45,[[["f32x8"]],["u8x8"]]],[11,"from","","",45,[[["i64x8"]],["u8x8"]]],[11,"from","","",55,[[["m8x4"]],["i8x4"]]],[11,"from","","",30,[[["f32x16"]],["u32x16"]]],[11,"from","","",36,[[["u8x2"]],["i64x2"]]],[11,"from","","",62,[[["f32x4"]],["f64x4"]]],[11,"from","","",10,[[["m16x16"]],["i16x16"]]],[11,"from","","",51,[[["u64x4"]],["u8x4"]]],[11,"from","","",19,[[["m8x4"]],["u32x4"]]],[11,"from","","",11,[[["m64x2"]],["m8x2"]]],[11,"from","","",41,[[["u16x16"]],["i32x16"]]],[11,"from","","",61,[[["f64x2"]],["f32x2"]]],[11,"from","","",56,[[["m32x8"]],["i16x8"]]],[11,"from","","",18,[[["i32x2"]],["u64x2"]]],[11,"from","","",33,[[["m1x32"]],["u16x32"]]],[11,"from","","",51,[[["u16x4"]],["u8x4"]]],[11,"from","","",51,[[["u32x4"]],["u8x4"]]],[11,"from","","",36,[[["u32x2"]],["i64x2"]]],[11,"from","","",44,[[["u16x16"]],["u8x16"]]],[11,"from","","",39,[[["u8x8"]],["i32x8"]]],[11,"from","","",29,[[["i8x32"]],["i16x32"]]],[11,"from","","",62,[[["i8x4"]],["f64x4"]]],[11,"from","","",7,[[["u16x8"]],["u32x8"]]],[11,"from","","",27,[[["m32x4"]],["i16x4"]]],[11,"from","","",35,[[["m32x2"]],["i16x2"]]],[11,"from","","",39,[[["u64x8"]],["i32x8"]]],[11,"from","","",45,[[["u16x8"]],["u8x8"]]],[11,"from","","",56,[[["m1x8"]],["i16x8"]]],[11,"from","","",21,[[["u64x8"]],["i8x8"]]],[11,"from","","",4,[[["i64x4"]],["u64x4"]]],[11,"from","","",8,[[["m8x8"]],["u64x8"]]],[11,"from","","",52,[[["f32x4"]],["i32x4"]]],[11,"from","","",27,[[["m16x4"]],["i16x4"]]],[11,"from","","",4,[[["m32x4"]],["u64x4"]]],[11,"from","","",35,[[["u8x2"]],["i16x2"]]],[11,"from","","",62,[[["i16x4"]],["f64x4"]]],[11,"from","","",50,[[["i64x2"]],["u8x2"]]],[11,"from","","",14,[[["f64x8"]],["u16x8"]]],[11,"from","","",15,[[["m8x8"]],["m1x8"]]],[11,"from","","",45,[[["m8x8"]],["u8x8"]]],[11,"from","","",7,[[["m16x8"]],["u32x8"]]],[11,"from","","",38,[[["m8x16"]],["m1x16"]]],[11,"from","","",47,[[["m32x8"]],["i64x8"]]],[11,"from","","",52,[[["i64x4"]],["i32x4"]]],[11,"from","","",22,[[["i32x4"]],["i64x4"]]],[11,"from","","",30,[[["i16x16"]],["u32x16"]]],[11,"from","","",7,[[["m1x8"]],["u32x8"]]],[11,"from","","",20,[[["m1x8"]],["m8x8"]]],[11,"from","","",8,[[["f64x8"]],["u64x8"]]],[11,"from","","",51,[[["f64x4"]],["u8x4"]]],[11,"from","","",18,[[["i16x2"]],["u64x2"]]],[11,"from","","",25,[[["m64x2"]],["m32x2"]]],[11,"from","","",35,[[["m8x2"]],["i16x2"]]],[11,"from","","",4,[[["m16x4"]],["u64x4"]]],[11,"from","","",35,[[["f64x2"]],["i16x2"]]],[11,"from","","",13,[[["u8x2"]],["i32x2"]]],[11,"from","","",60,[[["m8x2"]],["f64x2"]]],[11,"from","","",14,[[["m1x8"]],["u16x8"]]],[11,"from","","",19,[[["m64x4"]],["u32x4"]]],[11,"from","","",11,[[["m16x2"]],["m8x2"]]],[11,"from","","",61,[[["m8x2"]],["f32x2"]]],[11,"from","","",50,[[["u64x2"]],["u8x2"]]],[11,"from","","",59,[[["i8x16"]],["f32x16"]]],[11,"from","","",13,[[["u32x2"]],["i32x2"]]],[11,"from","","",63,[[["u16x8"]],["f32x8"]]],[11,"from","","",14,[[["u8x8"]],["u16x8"]]],[11,"from","","",16,[[["i32x2"]],["u16x2"]]],[11,"from","","",39,[[["m1x8"]],["i32x8"]]],[11,"from","","",63,[[["i32x8"]],["f32x8"]]],[11,"from","","",16,[[["i8x2"]],["u16x2"]]],[11,"from","","",4,[[["u32x4"]],["u64x4"]]],[11,"from","","",21,[[["m8x8"]],["i8x8"]]],[11,"from","","",34,[[["i32x16"]],["i8x16"]]],[11,"from","","",4,[[["u8x4"]],["u64x4"]]],[11,"from","","",55,[[["i32x4"]],["i8x4"]]],[11,"from","","",14,[[["f32x8"]],["u16x8"]]],[11,"from","","",62,[[["u32x4"]],["f64x4"]]],[11,"from","","",58,[[["i16x8"]],["f64x8"]]],[11,"from","","",23,[[["u16x32"]],["u8x32"]]],[11,"from","","",24,[[["m8x4"]],["u16x4"]]],[11,"from","","",4,[[["f32x4"]],["u64x4"]]],[11,"from","","",14,[[["i64x8"]],["u16x8"]]],[11,"from","","",12,[[["i32x16"]],["u16x16"]]],[11,"from","","",55,[[["f32x4"]],["i8x4"]]],[11,"from","","",51,[[["m8x4"]],["u8x4"]]],[11,"from","","",59,[[["u32x16"]],["f32x16"]]],[11,"from","","",19,[[["u8x4"]],["u32x4"]]],[11,"from","","",45,[[["i8x8"]],["u8x8"]]],[11,"from","","",55,[[["i64x4"]],["i8x4"]]],[11,"from","","",51,[[["m64x4"]],["u8x4"]]],[11,"from","","",8,[[["u8x8"]],["u64x8"]]],[11,"from","","",25,[[["m16x2"]],["m32x2"]]],[11,"from","","",58,[[["i64x8"]],["f64x8"]]],[11,"from","","",29,[[["m1x32"]],["i16x32"]]],[11,"from","","",62,[[["i32x4"]],["f64x4"]]],[11,"from","","",22,[[["m8x4"]],["i64x4"]]],[11,"from","","",59,[[["u16x16"]],["f32x16"]]],[11,"from","","",60,[[["u32x2"]],["f64x2"]]],[11,"from","","",6,[[["m32x2"]],["i8x2"]]],[11,"from","","",19,[[["f64x4"]],["u32x4"]]],[11,"from","","",54,[[["m16x2"]],["m64x2"]]],[11,"from","","",24,[[["u8x4"]],["u16x4"]]],[11,"from","","",9,[[["i64x2"]],["u32x2"]]],[11,"from","","",41,[[["m16x16"]],["i32x16"]]],[11,"from","","",7,[[["i32x8"]],["u32x8"]]],[11,"from","","",6,[[["u32x2"]],["i8x2"]]],[11,"from","","",36,[[["m8x2"]],["i64x2"]]],[11,"from","","",12,[[["u8x16"]],["u16x16"]]],[11,"from","","",31,[[["m16x4"]],["m32x4"]]],[11,"from","","",19,[[["i32x4"]],["u32x4"]]],[11,"from","","",45,[[["u32x8"]],["u8x8"]]],[11,"from","","",24,[[["i32x4"]],["u16x4"]]],[11,"from","","",34,[[["u8x16"]],["i8x16"]]],[11,"from","","",9,[[["u16x2"]],["u32x2"]]],[11,"from","","",61,[[["i32x2"]],["f32x2"]]],[11,"from","","",38,[[["m16x16"]],["m1x16"]]],[11,"from","","",18,[[["f32x2"]],["u64x2"]]],[11,"from","","",57,[[["u16x4"]],["f32x4"]]],[11,"from","","",58,[[["i8x8"]],["f64x8"]]],[11,"from","","",24,[[["u64x4"]],["u16x4"]]],[11,"from","","",16,[[["m32x2"]],["u16x2"]]],[11,"from","","",60,[[["m64x2"]],["f64x2"]]],[11,"from","","",47,[[["f64x8"]],["i64x8"]]],[11,"from","","",43,[[["m64x4"]],["m16x4"]]],[11,"from","","",6,[[["m8x2"]],["i8x2"]]],[11,"from","","",9,[[["m8x2"]],["u32x2"]]],[11,"from","","",18,[[["u16x2"]],["u64x2"]]],[11,"from","","",21,[[["f32x8"]],["i8x8"]]],[11,"from","","",7,[[["u8x8"]],["u32x8"]]],[11,"from","","",14,[[["i16x8"]],["u16x8"]]],[11,"from","","",49,[[["u16x32"]],["i8x32"]]],[11,"from","","",56,[[["i8x8"]],["i16x8"]]],[11,"from","","",13,[[["f64x2"]],["i32x2"]]],[11,"from","","",61,[[["u8x2"]],["f32x2"]]],[11,"from","","",43,[[["m32x4"]],["m16x4"]]],[11,"from","","",39,[[["f64x8"]],["i32x8"]]],[11,"from","","",58,[[["f32x8"]],["f64x8"]]],[11,"from","","",19,[[["m16x4"]],["u32x4"]]],[11,"from","","",50,[[["m64x2"]],["u8x2"]]],[11,"from","","",21,[[["m1x8"]],["i8x8"]]],[11,"from","","",44,[[["i8x16"]],["u8x16"]]],[11,"from","","",23,[[["i16x32"]],["u8x32"]]],[11,"from","","",52,[[["u8x4"]],["i32x4"]]],[11,"from","","",60,[[["m16x2"]],["f64x2"]]],[11,"from","","",14,[[["i8x8"]],["u16x8"]]],[11,"from","","",34,[[["i16x16"]],["i8x16"]]],[11,"from","","",57,[[["m32x4"]],["f32x4"]]],[11,"from","","",45,[[["i16x8"]],["u8x8"]]],[11,"from","","",9,[[["m32x2"]],["u32x2"]]],[11,"from","","",58,[[["m16x8"]],["f64x8"]]],[11,"from","","",8,[[["f32x8"]],["u64x8"]]],[11,"from","","",57,[[["m8x4"]],["f32x4"]]],[11,"from","","",8,[[["i32x8"]],["u64x8"]]],[11,"from","","",52,[[["u64x4"]],["i32x4"]]],[11,"from","","",55,[[["m16x4"]],["i8x4"]]],[11,"from","","",30,[[["m8x16"]],["u32x16"]]],[11,"from","","",57,[[["u64x4"]],["f32x4"]]],[11,"from","","",55,[[["i16x4"]],["i8x4"]]],[11,"from","","",58,[[["u64x8"]],["f64x8"]]],[11,"from","","",4,[[["i32x4"]],["u64x4"]]],[11,"from","","",62,[[["m16x4"]],["f64x4"]]],[11,"from","","",60,[[["m32x2"]],["f64x2"]]],[11,"from","","",16,[[["f32x2"]],["u16x2"]]],[11,"from","","",62,[[["u64x4"]],["f64x4"]]],[11,"from","","",51,[[["i32x4"]],["u8x4"]]],[11,"from","","",8,[[["i8x8"]],["u64x8"]]],[11,"from","","",60,[[["u16x2"]],["f64x2"]]],[11,"from","","",21,[[["i64x8"]],["i8x8"]]],[11,"from","","",50,[[["i32x2"]],["u8x2"]]],[11,"from","","",9,[[["i8x2"]],["u32x2"]]],[11,"from","","",58,[[["u32x8"]],["f64x8"]]],[11,"from","","",7,[[["i8x8"]],["u32x8"]]],[11,"from","","",44,[[["m1x16"]],["u8x16"]]],[11,"from","","",16,[[["f64x2"]],["u16x2"]]],[11,"from","","",54,[[["m8x2"]],["m64x2"]]],[11,"from","","",36,[[["i16x2"]],["i64x2"]]],[11,"from","","",9,[[["f32x2"]],["u32x2"]]],[11,"from","","",62,[[["u8x4"]],["f64x4"]]],[11,"from","","",35,[[["u16x2"]],["i16x2"]]],[11,"from","","",43,[[["m8x4"]],["m16x4"]]],[11,"from","","",49,[[["m8x32"]],["i8x32"]]],[11,"from","","",39,[[["i8x8"]],["i32x8"]]],[11,"from","","",51,[[["i64x4"]],["u8x4"]]],[11,"from","","",30,[[["i8x16"]],["u32x16"]]],[11,"from","","",24,[[["m32x4"]],["u16x4"]]],[11,"from","","",52,[[["m8x4"]],["i32x4"]]],[11,"from","","",62,[[["m64x4"]],["f64x4"]]],[11,"from","","",60,[[["i64x2"]],["f64x2"]]],[11,"from","","",21,[[["m32x8"]],["i8x8"]]],[11,"from","","",7,[[["m8x8"]],["u32x8"]]],[11,"from","","",41,[[["u8x16"]],["i32x16"]]],[11,"from","","",29,[[["u16x32"]],["i16x32"]]],[11,"from","","",24,[[["f32x4"]],["u16x4"]]],[11,"from","","",50,[[["f64x2"]],["u8x2"]]],[11,"from","","",34,[[["u16x16"]],["i8x16"]]],[11,"from","","",4,[[["i8x4"]],["u64x4"]]],[11,"from","","",57,[[["i8x4"]],["f32x4"]]],[11,"from","","",16,[[["i64x2"]],["u16x2"]]],[11,"from","","",61,[[["m64x2"]],["f32x2"]]],[11,"from","","",52,[[["m32x4"]],["i32x4"]]],[11,"from","","",27,[[["m8x4"]],["i16x4"]]],[11,"from","","",15,[[["m16x8"]],["m1x8"]]],[11,"from","","",19,[[["i8x4"]],["u32x4"]]],[11,"from","","",47,[[["u64x8"]],["i64x8"]]],[11,"from","","",9,[[["m64x2"]],["u32x2"]]],[11,"from","","",61,[[["u32x2"]],["f32x2"]]],[11,"from","","",8,[[["m1x8"]],["u64x8"]]],[11,"from","","",40,[[["m32x8"]],["m16x8"]]],[11,"from","","",6,[[["m64x2"]],["i8x2"]]],[11,"from","","",10,[[["u32x16"]],["i16x16"]]],[11,"from","","",56,[[["m16x8"]],["i16x8"]]],[11,"from","","",35,[[["i64x2"]],["i16x2"]]],[11,"from","","",41,[[["u32x16"]],["i32x16"]]],[11,"from","","",53,[[["m32x2"]],["m16x2"]]],[11,"from","","",13,[[["i16x2"]],["i32x2"]]],[11,"from","","",61,[[["i64x2"]],["f32x2"]]],[11,"from","","",59,[[["i16x16"]],["f32x16"]]],[11,"from","","",58,[[["m32x8"]],["f64x8"]]],[11,"from","","",18,[[["m64x2"]],["u64x2"]]],[11,"from","","",34,[[["m8x16"]],["i8x16"]]],[11,"from","","",12,[[["m16x16"]],["u16x16"]]],[11,"from","","",53,[[["m64x2"]],["m16x2"]]],[11,"from","","",7,[[["f64x8"]],["u32x8"]]],[11,"from","","",61,[[["m32x2"]],["f32x2"]]],[11,"from","","",14,[[["u64x8"]],["u16x8"]]],[11,"from","","",36,[[["f64x2"]],["i64x2"]]],[11,"from","","",19,[[["f32x4"]],["u32x4"]]],[11,"from","","",52,[[["i8x4"]],["i32x4"]]],[11,"from","","",59,[[["m8x16"]],["f32x16"]]],[11,"from","","",24,[[["m64x4"]],["u16x4"]]],[11,"from","","",59,[[["u8x16"]],["f32x16"]]],[11,"from","","",34,[[["u32x16"]],["i8x16"]]],[11,"from","","",36,[[["i32x2"]],["i64x2"]]],[11,"from","","",35,[[["u32x2"]],["i16x2"]]],[11,"from","","",30,[[["u8x16"]],["u32x16"]]],[11,"from","","",21,[[["i16x8"]],["i8x8"]]],[11,"from","","",63,[[["m8x8"]],["f32x8"]]],[11,"from","","",14,[[["u32x8"]],["u16x8"]]],[11,"from","","",24,[[["u32x4"]],["u16x4"]]],[11,"from","","",47,[[["u8x8"]],["i64x8"]]],[11,"from","","",24,[[["i64x4"]],["u16x4"]]],[11,"from","","",52,[[["u32x4"]],["i32x4"]]],[11,"from","","",56,[[["f64x8"]],["i16x8"]]],[11,"from","","",57,[[["i32x4"]],["f32x4"]]],[11,"from","","",27,[[["i64x4"]],["i16x4"]]],[11,"from","","",52,[[["m16x4"]],["i32x4"]]],[11,"from","","",11,[[["m32x2"]],["m8x2"]]],[11,"from","","",13,[[["f32x2"]],["i32x2"]]],[11,"from","","",28,[[["m32x4"]],["m64x4"]]],[11,"from","","",63,[[["u64x8"]],["f32x8"]]],[11,"from","","",21,[[["m16x8"]],["i8x8"]]],[11,"from","","",35,[[["m64x2"]],["i16x2"]]],[11,"from","","",31,[[["m8x4"]],["m32x4"]]],[11,"from","","",7,[[["f32x8"]],["u32x8"]]],[11,"from","","",62,[[["u16x4"]],["f64x4"]]],[11,"from","","",62,[[["i64x4"]],["f64x4"]]],[11,"from","","",16,[[["u64x2"]],["u16x2"]]],[11,"from","","",18,[[["m32x2"]],["u64x2"]]],[11,"from","","",18,[[["m8x2"]],["u64x2"]]],[11,"from","","",30,[[["i32x16"]],["u32x16"]]],[11,"from","","",12,[[["m8x16"]],["u16x16"]]],[11,"from","","",34,[[["m1x16"]],["i8x16"]]],[11,"from","","",36,[[["m32x2"]],["i64x2"]]],[11,"from","","",52,[[["m64x4"]],["i32x4"]]],[11,"from","","",47,[[["f32x8"]],["i64x8"]]],[11,"from","","",20,[[["m32x8"]],["m8x8"]]],[11,"from","","",30,[[["m16x16"]],["u32x16"]]],[11,"from","","",46,[[["m32x4"]],["m8x4"]]],[11,"from","","",22,[[["u64x4"]],["i64x4"]]],[11,"from","","",8,[[["m16x8"]],["u64x8"]]],[11,"from","","",22,[[["u16x4"]],["i64x4"]]],[11,"from","","",4,[[["i16x4"]],["u64x4"]]],[11,"from","","",47,[[["m8x8"]],["i64x8"]]],[11,"from","","",36,[[["f32x2"]],["i64x2"]]],[11,"from","","",50,[[["f32x2"]],["u8x2"]]],[11,"from","","",8,[[["i16x8"]],["u64x8"]]],[11,"from","","",35,[[["u64x2"]],["i16x2"]]],[11,"from","","",59,[[["m1x16"]],["f32x16"]]],[11,"from","","",50,[[["u16x2"]],["u8x2"]]],[11,"from","","",50,[[["m16x2"]],["u8x2"]]],[11,"from","","",56,[[["i64x8"]],["i16x8"]]],[11,"from","","",22,[[["m16x4"]],["i64x4"]]],[11,"from","","",7,[[["i16x8"]],["u32x8"]]],[11,"from","","",57,[[["u8x4"]],["f32x4"]]],[11,"from","","",60,[[["f32x2"]],["f64x2"]]],[11,"from","","",44,[[["u32x16"]],["u8x16"]]],[11,"from","","",61,[[["u64x2"]],["f32x2"]]],[11,"from","","",36,[[["i8x2"]],["i64x2"]]],[11,"from","","",40,[[["m8x8"]],["m16x8"]]],[11,"from","","",10,[[["m1x16"]],["i16x16"]]],[11,"from","","",57,[[["f64x4"]],["f32x4"]]],[11,"from","","",55,[[["u32x4"]],["i8x4"]]],[11,"from","","",29,[[["m8x32"]],["i16x32"]]],[11,"from","","",12,[[["i8x16"]],["u16x16"]]],[11,"from","","",22,[[["m64x4"]],["i64x4"]]],[11,"from","","",10,[[["m8x16"]],["i16x16"]]],[11,"from","","",44,[[["f32x16"]],["u8x16"]]],[11,"from","","",12,[[["i16x16"]],["u16x16"]]],[11,"from","","",4,[[["m64x4"]],["u64x4"]]],[11,"from","","",56,[[["u32x8"]],["i16x8"]]],[11,"from","","",47,[[["i16x8"]],["i64x8"]]],[11,"from","","",61,[[["u16x2"]],["f32x2"]]],[11,"from","","",6,[[["i32x2"]],["i8x2"]]],[11,"from","","",9,[[["i16x2"]],["u32x2"]]],[11,"from","","",44,[[["i32x16"]],["u8x16"]]],[11,"from","","",60,[[["u8x2"]],["f64x2"]]],[11,"from","","",39,[[["m32x8"]],["i32x8"]]],[11,"from","","",27,[[["u32x4"]],["i16x4"]]],[11,"from","","",35,[[["i8x2"]],["i16x2"]]],[11,"from","","",50,[[["u32x2"]],["u8x2"]]],[11,"from","","",55,[[["u16x4"]],["i8x4"]]],[11,"from","","",21,[[["i32x8"]],["i8x8"]]],[11,"from","","",57,[[["i16x4"]],["f32x4"]]],[11,"from","","",36,[[["m64x2"]],["i64x2"]]],[11,"from","","",47,[[["i32x8"]],["i64x8"]]],[11,"from","","",14,[[["m8x8"]],["u16x8"]]],[11,"from","","",27,[[["u8x4"]],["i16x4"]]],[11,"from","","",61,[[["i8x2"]],["f32x2"]]],[11,"from","","",47,[[["u16x8"]],["i64x8"]]],[11,"from","","",5,[[["m1x64"]],["u8x64"]]],[11,"from","","",10,[[["f32x16"]],["i16x16"]]],[11,"from","","",49,[[["i16x32"]],["i8x32"]]],[11,"from","","",33,[[["m8x32"]],["u16x32"]]],[11,"from","","",19,[[["u16x4"]],["u32x4"]]],[11,"from","","",60,[[["u64x2"]],["f64x2"]]],[11,"from","","",36,[[["m16x2"]],["i64x2"]]],[11,"from","","",63,[[["i16x8"]],["f32x8"]]],[11,"from","","",4,[[["u16x4"]],["u64x4"]]],[11,"from","","",56,[[["u16x8"]],["i16x8"]]],[11,"from","","",7,[[["u64x8"]],["u32x8"]]],[11,"from","","",6,[[["u16x2"]],["i8x2"]]],[11,"from","","",9,[[["u8x2"]],["u32x2"]]],[11,"from","","",22,[[["i16x4"]],["i64x4"]]],[11,"from","","",4,[[["f64x4"]],["u64x4"]]],[11,"from","","",4,[[["m8x4"]],["u64x4"]]],[11,"from","","",3,[[["m1x8"]],["m32x8"]]],[11,"from","","",32,[[["m8x16"]],["m16x16"]]],[11,"from","","",12,[[["u32x16"]],["u16x16"]]],[11,"from","","",52,[[["i16x4"]],["i32x4"]]],[11,"from","","",6,[[["m16x2"]],["i8x2"]]],[11,"from","","",47,[[["u32x8"]],["i64x8"]]],[11,"from","","",45,[[["i32x8"]],["u8x8"]]],[11,"from","","",39,[[["f32x8"]],["i32x8"]]],[11,"from","","",29,[[["u8x32"]],["i16x32"]]],[11,"from","","",45,[[["m32x8"]],["u8x8"]]],[11,"from","","",13,[[["m64x2"]],["i32x2"]]],[11,"from","","",24,[[["i8x4"]],["u16x4"]]],[11,"from","","",63,[[["i64x8"]],["f32x8"]]],[11,"from","","",39,[[["i64x8"]],["i32x8"]]],[11,"from","","",36,[[["u64x2"]],["i64x2"]]],[11,"from","","",60,[[["i16x2"]],["f64x2"]]],[11,"from","","",61,[[["m16x2"]],["f32x2"]]],[11,"from","","",23,[[["i8x32"]],["u8x32"]]],[11,"from","","",48,[[["m8x32"]],["m1x32"]]],[11,"from","","",18,[[["f64x2"]],["u64x2"]]],[11,"from","","",27,[[["i32x4"]],["i16x4"]]],[11,"from","","",57,[[["i64x4"]],["f32x4"]]],[11,"from","","",41,[[["i16x16"]],["i32x16"]]],[11,"from","","",33,[[["i8x32"]],["u16x32"]]],[11,"from","","",35,[[["f32x2"]],["i16x2"]]],[11,"from","","",7,[[["m32x8"]],["u32x8"]]],[11,"from","","",22,[[["u8x4"]],["i64x4"]]],[11,"from","","",13,[[["u64x2"]],["i32x2"]]],[11,"from","","",30,[[["u16x16"]],["u32x16"]]],[11,"from","","",33,[[["u8x32"]],["u16x32"]]],[11,"from","","",44,[[["i16x16"]],["u8x16"]]],[11,"from","","",9,[[["f64x2"]],["u32x2"]]],[11,"from","","",8,[[["i64x8"]],["u64x8"]]],[11,"from","","",39,[[["u16x8"]],["i32x8"]]],[11,"from","","",63,[[["f64x8"]],["f32x8"]]],[11,"from","","",32,[[["m1x16"]],["m16x16"]]],[11,"from","","",45,[[["m1x8"]],["u8x8"]]],[11,"from","","",35,[[["m16x2"]],["i16x2"]]],[11,"from","","",44,[[["m8x16"]],["u8x16"]]],[11,"from","","",6,[[["u64x2"]],["i8x2"]]],[11,"from","","",16,[[["u8x2"]],["u16x2"]]],[11,"from","","",56,[[["i32x8"]],["i16x8"]]],[11,"from","","",27,[[["u16x4"]],["i16x4"]]],[11,"from","","",47,[[["m16x8"]],["i64x8"]]],[11,"from","","",63,[[["u8x8"]],["f32x8"]]],[11,"from","","",13,[[["m32x2"]],["i32x2"]]],[11,"from","","",60,[[["i8x2"]],["f64x2"]]],[11,"from","","",10,[[["u16x16"]],["i16x16"]]],[11,"from","","",23,[[["m8x32"]],["u8x32"]]],[11,"from","","",63,[[["m32x8"]],["f32x8"]]],[11,"from","","",16,[[["m8x2"]],["u16x2"]]],[11,"from","","",8,[[["u16x8"]],["u64x8"]]],[11,"from","","",12,[[["m1x16"]],["u16x16"]]],[11,"from","","",59,[[["i32x16"]],["f32x16"]]],[11,"from","","",39,[[["u32x8"]],["i32x8"]]],[11,"from","","",55,[[["u8x4"]],["i8x4"]]],[11,"from","","",56,[[["u64x8"]],["i16x8"]]],[11,"from","","",49,[[["u8x32"]],["i8x32"]]],[11,"from","","",8,[[["m32x8"]],["u64x8"]]],[11,"from","","",37,[[["u8x64"]],["i8x64"]]],[11,"from","","",16,[[["i16x2"]],["u16x2"]]],[11,"from","","",16,[[["u32x2"]],["u16x2"]]],[11,"from","","",34,[[["f32x16"]],["i8x16"]]],[11,"from","","",36,[[["u16x2"]],["i64x2"]]],[11,"from","","",45,[[["f64x8"]],["u8x8"]]],[11,"from","","",24,[[["f64x4"]],["u16x4"]]],[11,"from","","",33,[[["i16x32"]],["u16x32"]]],[11,"from","","",61,[[["i16x2"]],["f32x2"]]],[11,"from","","",10,[[["i32x16"]],["i16x16"]]],[11,"from","","",18,[[["i8x2"]],["u64x2"]]],[11,"from","","",13,[[["i8x2"]],["i32x2"]]],[11,"from","","",21,[[["u32x8"]],["i8x8"]]],[11,"from","","",24,[[["i16x4"]],["u16x4"]]],[11,"from","","",6,[[["u8x2"]],["i8x2"]]],[11,"from","","",46,[[["m64x4"]],["m8x4"]]],[11,"from","","",8,[[["u32x8"]],["u64x8"]]],[11,"from","","",60,[[["i32x2"]],["f64x2"]]],[11,"from","","",17,[[["m1x32"]],["m8x32"]]],[11,"from","","",16,[[["m16x2"]],["u16x2"]]],[11,"from","","",39,[[["m16x8"]],["i32x8"]]],[11,"from","","",58,[[["m8x8"]],["f64x8"]]],[11,"from","","",44,[[["m16x16"]],["u8x16"]]],[11,"from","","",57,[[["m16x4"]],["f32x4"]]],[11,"from","","",18,[[["u8x2"]],["u64x2"]]],[11,"from","","",9,[[["m16x2"]],["u32x2"]]],[11,"from","","",63,[[["i8x8"]],["f32x8"]]],[11,"from","","",31,[[["m64x4"]],["m32x4"]]],[11,"from","","",22,[[["u32x4"]],["i64x4"]]],[11,"from","","",46,[[["m16x4"]],["m8x4"]]],[11,"from","","",39,[[["i16x8"]],["i32x8"]]],[11,"from","","",42,[[["m16x16"]],["m8x16"]]],[11,"from","","",10,[[["i8x16"]],["i16x16"]]],[11,"from","","",25,[[["m8x2"]],["m32x2"]]],[11,"from","","",5,[[["i8x64"]],["u8x64"]]],[11,"from","","",6,[[["f32x2"]],["i8x2"]]],[11,"from","","",19,[[["i16x4"]],["u32x4"]]],[11,"from","","",13,[[["u16x2"]],["i32x2"]]],[11,"from","","",22,[[["i8x4"]],["i64x4"]]],[11,"from","","",58,[[["m1x8"]],["f64x8"]]],[11,"from","","",47,[[["m1x8"]],["i64x8"]]],[11,"from","","",63,[[["m16x8"]],["f32x8"]]],[11,"from","","",7,[[["i64x8"]],["u32x8"]]],[11,"from","","",41,[[["i8x16"]],["i32x16"]]],[11,"from","","",58,[[["u16x8"]],["f64x8"]]],[11,"from","","",41,[[["m1x16"]],["i32x16"]]],[11,"from","","",19,[[["i64x4"]],["u32x4"]]],[11,"from","","",22,[[["m32x4"]],["i64x4"]]],[11,"from","","",41,[[["f32x16"]],["i32x16"]]],[11,"from","","",18,[[["i64x2"]],["u64x2"]]],[11,"from","","",14,[[["i32x8"]],["u16x8"]]],[11,"from","","",51,[[["i16x4"]],["u8x4"]]],[11,"from","","",51,[[["i8x4"]],["u8x4"]]],[11,"from","","",6,[[["f64x2"]],["i8x2"]]],[11,"from","","",45,[[["u64x8"]],["u8x8"]]],[11,"from","","",56,[[["u8x8"]],["i16x8"]]],[11,"from","","",52,[[["u16x4"]],["i32x4"]]],[11,"from","","",9,[[["u64x2"]],["u32x2"]]],[11,"from","","",55,[[["m64x4"]],["i8x4"]]],[11,"from","","",37,[[["m1x64"]],["i8x64"]]],[11,"from","","",22,[[["f64x4"]],["i64x4"]]],[11,"from","","",56,[[["m8x8"]],["i16x8"]]],[11,"from","","",35,[[["i32x2"]],["i16x2"]]],[11,"from","","",21,[[["u8x8"]],["i8x8"]]],[11,"from","","",55,[[["f64x4"]],["i8x4"]]],[11,"from","","",54,[[["m32x2"]],["m64x2"]]],[11,"sub_assign","","",9,N],[11,"sub_assign","","",10,N],[11,"sub_assign","","",19,N],[11,"sub_assign","","",6,N],[11,"sub_assign","","",30,N],[11,"sub_assign","","",62,N],[11,"sub_assign","","",8,N],[11,"sub_assign","","",39,N],[11,"sub_assign","","",47,N],[11,"sub_assign","","",50,N],[11,"sub_assign","","",7,N],[11,"sub_assign","","",36,N],[11,"sub_assign","","",45,N],[11,"sub_assign","","",5,N],[11,"sub_assign","","",22,N],[11,"sub_assign","","",44,N],[11,"sub_assign","","",4,N],[11,"sub_assign","","",58,N],[11,"sub_assign","","",33,N],[11,"sub_assign","","",51,N],[11,"sub_assign","","",37,N],[11,"sub_assign","","",49,N],[11,"sub_assign","","",24,N],[11,"sub_assign","","",9,N],[11,"sub_assign","","",59,N],[11,"sub_assign","","",22,N],[11,"sub_assign","","",41,N],[11,"sub_assign","","",51,N],[11,"sub_assign","","",55,N],[11,"sub_assign","","",62,N],[11,"sub_assign","","",47,N],[11,"sub_assign","","",61,N],[11,"sub_assign","","",21,N],[11,"sub_assign","","",34,N],[11,"sub_assign","","",37,N],[11,"sub_assign","","",34,N],[11,"sub_assign","","",24,N],[11,"sub_assign","","",50,N],[11,"sub_assign","","",12,N],[11,"sub_assign","","",63,N],[11,"sub_assign","","",12,N],[11,"sub_assign","","",30,N],[11,"sub_assign","","",57,N],[11,"sub_assign","","",52,N],[11,"sub_assign","","",36,N],[11,"sub_assign","","",45,N],[11,"sub_assign","","",4,N],[11,"sub_assign","","",55,N],[11,"sub_assign","","",44,N],[11,"sub_assign","","",6,N],[11,"sub_assign","","",16,N],[11,"sub_assign","","",33,N],[11,"sub_assign","","",29,N],[11,"sub_assign","","",19,N],[11,"sub_assign","","",8,N],[11,"sub_assign","","",35,N],[11,"sub_assign","","",61,N],[11,"sub_assign","","",35,N],[11,"sub_assign","","",49,N],[11,"sub_assign","","",60,N],[11,"sub_assign","","",7,N],[11,"sub_assign","","",39,N],[11,"sub_assign","","",23,N],[11,"sub_assign","","",63,N],[11,"sub_assign","","",18,N],[11,"sub_assign","","",13,N],[11,"sub_assign","","",52,N],[11,"sub_assign","","",60,N],[11,"sub_assign","","",18,N],[11,"sub_assign","","",58,N],[11,"sub_assign","","",13,N],[11,"sub_assign","","",41,N],[11,"sub_assign","","",57,N],[11,"sub_assign","","",56,N],[11,"sub_assign","","",56,N],[11,"sub_assign","","",10,N],[11,"sub_assign","","",29,N],[11,"sub_assign","","",5,N],[11,"sub_assign","","",14,N],[11,"sub_assign","","",23,N],[11,"sub_assign","","",21,N],[11,"sub_assign","","",14,N],[11,"sub_assign","","",27,N],[11,"sub_assign","","",27,N],[11,"sub_assign","","",59,N],[11,"sub_assign","","",16,N],[11,"partial_cmp","","",57,[[["self"],["f32x4"]],["option",["ordering"]]]],[11,"lt","","",57,[[["self"],["f32x4"]],["bool"]]],[11,"le","","",57,[[["self"],["f32x4"]],["bool"]]],[11,"gt","","",57,[[["self"],["f32x4"]],["bool"]]],[11,"ge","","",57,[[["self"],["f32x4"]],["bool"]]],[11,"partial_cmp","","",51,[[["self"],["u8x4"]],["option",["ordering"]]]],[11,"lt","","",51,[[["self"],["u8x4"]],["bool"]]],[11,"le","","",51,[[["self"],["u8x4"]],["bool"]]],[11,"gt","","",51,[[["self"],["u8x4"]],["bool"]]],[11,"ge","","",51,[[["self"],["u8x4"]],["bool"]]],[11,"partial_cmp","","",14,[[["self"],["u16x8"]],["option",["ordering"]]]],[11,"lt","","",14,[[["self"],["u16x8"]],["bool"]]],[11,"le","","",14,[[["self"],["u16x8"]],["bool"]]],[11,"gt","","",14,[[["self"],["u16x8"]],["bool"]]],[11,"ge","","",14,[[["self"],["u16x8"]],["bool"]]],[11,"partial_cmp","","",61,[[["self"],["f32x2"]],["option",["ordering"]]]],[11,"lt","","",61,[[["self"],["f32x2"]],["bool"]]],[11,"le","","",61,[[["self"],["f32x2"]],["bool"]]],[11,"gt","","",61,[[["self"],["f32x2"]],["bool"]]],[11,"ge","","",61,[[["self"],["f32x2"]],["bool"]]],[11,"partial_cmp","","",53,[[["self"],["m16x2"]],["option",["ordering"]]]],[11,"lt","","",53,[[["self"],["m16x2"]],["bool"]]],[11,"le","","",53,[[["self"],["m16x2"]],["bool"]]],[11,"gt","","",53,[[["self"],["m16x2"]],["bool"]]],[11,"ge","","",53,[[["self"],["m16x2"]],["bool"]]],[11,"partial_cmp","","",60,[[["self"],["f64x2"]],["option",["ordering"]]]],[11,"lt","","",60,[[["self"],["f64x2"]],["bool"]]],[11,"le","","",60,[[["self"],["f64x2"]],["bool"]]],[11,"gt","","",60,[[["self"],["f64x2"]],["bool"]]],[11,"ge","","",60,[[["self"],["f64x2"]],["bool"]]],[11,"partial_cmp","","",15,[[["self"],["m1x8"]],["option",["ordering"]]]],[11,"lt","","",15,[[["self"],["m1x8"]],["bool"]]],[11,"le","","",15,[[["self"],["m1x8"]],["bool"]]],[11,"gt","","",15,[[["self"],["m1x8"]],["bool"]]],[11,"ge","","",15,[[["self"],["m1x8"]],["bool"]]],[11,"partial_cmp","","",5,[[["self"],["u8x64"]],["option",["ordering"]]]],[11,"lt","","",5,[[["self"],["u8x64"]],["bool"]]],[11,"le","","",5,[[["self"],["u8x64"]],["bool"]]],[11,"gt","","",5,[[["self"],["u8x64"]],["bool"]]],[11,"ge","","",5,[[["self"],["u8x64"]],["bool"]]],[11,"partial_cmp","","",42,[[["self"],["m8x16"]],["option",["ordering"]]]],[11,"lt","","",42,[[["self"],["m8x16"]],["bool"]]],[11,"le","","",42,[[["self"],["m8x16"]],["bool"]]],[11,"gt","","",42,[[["self"],["m8x16"]],["bool"]]],[11,"ge","","",42,[[["self"],["m8x16"]],["bool"]]],[11,"partial_cmp","","",9,[[["self"],["u32x2"]],["option",["ordering"]]]],[11,"lt","","",9,[[["self"],["u32x2"]],["bool"]]],[11,"le","","",9,[[["self"],["u32x2"]],["bool"]]],[11,"gt","","",9,[[["self"],["u32x2"]],["bool"]]],[11,"ge","","",9,[[["self"],["u32x2"]],["bool"]]],[11,"partial_cmp","","",33,[[["self"],["u16x32"]],["option",["ordering"]]]],[11,"lt","","",33,[[["self"],["u16x32"]],["bool"]]],[11,"le","","",33,[[["self"],["u16x32"]],["bool"]]],[11,"gt","","",33,[[["self"],["u16x32"]],["bool"]]],[11,"ge","","",33,[[["self"],["u16x32"]],["bool"]]],[11,"partial_cmp","","",10,[[["self"],["i16x16"]],["option",["ordering"]]]],[11,"lt","","",10,[[["self"],["i16x16"]],["bool"]]],[11,"le","","",10,[[["self"],["i16x16"]],["bool"]]],[11,"gt","","",10,[[["self"],["i16x16"]],["bool"]]],[11,"ge","","",10,[[["self"],["i16x16"]],["bool"]]],[11,"partial_cmp","","",63,[[["self"],["f32x8"]],["option",["ordering"]]]],[11,"lt","","",63,[[["self"],["f32x8"]],["bool"]]],[11,"le","","",63,[[["self"],["f32x8"]],["bool"]]],[11,"gt","","",63,[[["self"],["f32x8"]],["bool"]]],[11,"ge","","",63,[[["self"],["f32x8"]],["bool"]]],[11,"partial_cmp","","",27,[[["self"],["i16x4"]],["option",["ordering"]]]],[11,"lt","","",27,[[["self"],["i16x4"]],["bool"]]],[11,"le","","",27,[[["self"],["i16x4"]],["bool"]]],[11,"gt","","",27,[[["self"],["i16x4"]],["bool"]]],[11,"ge","","",27,[[["self"],["i16x4"]],["bool"]]],[11,"partial_cmp","","",43,[[["self"],["m16x4"]],["option",["ordering"]]]],[11,"lt","","",43,[[["self"],["m16x4"]],["bool"]]],[11,"le","","",43,[[["self"],["m16x4"]],["bool"]]],[11,"gt","","",43,[[["self"],["m16x4"]],["bool"]]],[11,"ge","","",43,[[["self"],["m16x4"]],["bool"]]],[11,"partial_cmp","","",37,[[["self"],["i8x64"]],["option",["ordering"]]]],[11,"lt","","",37,[[["self"],["i8x64"]],["bool"]]],[11,"le","","",37,[[["self"],["i8x64"]],["bool"]]],[11,"gt","","",37,[[["self"],["i8x64"]],["bool"]]],[11,"ge","","",37,[[["self"],["i8x64"]],["bool"]]],[11,"partial_cmp","","",31,[[["self"],["m32x4"]],["option",["ordering"]]]],[11,"lt","","",31,[[["self"],["m32x4"]],["bool"]]],[11,"le","","",31,[[["self"],["m32x4"]],["bool"]]],[11,"gt","","",31,[[["self"],["m32x4"]],["bool"]]],[11,"ge","","",31,[[["self"],["m32x4"]],["bool"]]],[11,"partial_cmp","","",55,[[["self"],["i8x4"]],["option",["ordering"]]]],[11,"lt","","",55,[[["self"],["i8x4"]],["bool"]]],[11,"le","","",55,[[["self"],["i8x4"]],["bool"]]],[11,"gt","","",55,[[["self"],["i8x4"]],["bool"]]],[11,"ge","","",55,[[["self"],["i8x4"]],["bool"]]],[11,"partial_cmp","","",50,[[["self"],["u8x2"]],["option",["ordering"]]]],[11,"lt","","",50,[[["self"],["u8x2"]],["bool"]]],[11,"le","","",50,[[["self"],["u8x2"]],["bool"]]],[11,"gt","","",50,[[["self"],["u8x2"]],["bool"]]],[11,"ge","","",50,[[["self"],["u8x2"]],["bool"]]],[11,"partial_cmp","","",44,[[["self"],["u8x16"]],["option",["ordering"]]]],[11,"lt","","",44,[[["self"],["u8x16"]],["bool"]]],[11,"le","","",44,[[["self"],["u8x16"]],["bool"]]],[11,"gt","","",44,[[["self"],["u8x16"]],["bool"]]],[11,"ge","","",44,[[["self"],["u8x16"]],["bool"]]],[11,"partial_cmp","","",29,[[["self"],["i16x32"]],["option",["ordering"]]]],[11,"lt","","",29,[[["self"],["i16x32"]],["bool"]]],[11,"le","","",29,[[["self"],["i16x32"]],["bool"]]],[11,"gt","","",29,[[["self"],["i16x32"]],["bool"]]],[11,"ge","","",29,[[["self"],["i16x32"]],["bool"]]],[11,"partial_cmp","","",7,[[["self"],["u32x8"]],["option",["ordering"]]]],[11,"lt","","",7,[[["self"],["u32x8"]],["bool"]]],[11,"le","","",7,[[["self"],["u32x8"]],["bool"]]],[11,"gt","","",7,[[["self"],["u32x8"]],["bool"]]],[11,"ge","","",7,[[["self"],["u32x8"]],["bool"]]],[11,"partial_cmp","","",56,[[["self"],["i16x8"]],["option",["ordering"]]]],[11,"lt","","",56,[[["self"],["i16x8"]],["bool"]]],[11,"le","","",56,[[["self"],["i16x8"]],["bool"]]],[11,"gt","","",56,[[["self"],["i16x8"]],["bool"]]],[11,"ge","","",56,[[["self"],["i16x8"]],["bool"]]],[11,"partial_cmp","","",18,[[["self"],["u64x2"]],["option",["ordering"]]]],[11,"lt","","",18,[[["self"],["u64x2"]],["bool"]]],[11,"le","","",18,[[["self"],["u64x2"]],["bool"]]],[11,"gt","","",18,[[["self"],["u64x2"]],["bool"]]],[11,"ge","","",18,[[["self"],["u64x2"]],["bool"]]],[11,"partial_cmp","","",62,[[["self"],["f64x4"]],["option",["ordering"]]]],[11,"lt","","",62,[[["self"],["f64x4"]],["bool"]]],[11,"le","","",62,[[["self"],["f64x4"]],["bool"]]],[11,"gt","","",62,[[["self"],["f64x4"]],["bool"]]],[11,"ge","","",62,[[["self"],["f64x4"]],["bool"]]],[11,"partial_cmp","","",16,[[["self"],["u16x2"]],["option",["ordering"]]]],[11,"lt","","",16,[[["self"],["u16x2"]],["bool"]]],[11,"le","","",16,[[["self"],["u16x2"]],["bool"]]],[11,"gt","","",16,[[["self"],["u16x2"]],["bool"]]],[11,"ge","","",16,[[["self"],["u16x2"]],["bool"]]],[11,"partial_cmp","","",20,[[["self"],["m8x8"]],["option",["ordering"]]]],[11,"lt","","",20,[[["self"],["m8x8"]],["bool"]]],[11,"le","","",20,[[["self"],["m8x8"]],["bool"]]],[11,"gt","","",20,[[["self"],["m8x8"]],["bool"]]],[11,"ge","","",20,[[["self"],["m8x8"]],["bool"]]],[11,"partial_cmp","","",41,[[["self"],["i32x16"]],["option",["ordering"]]]],[11,"lt","","",41,[[["self"],["i32x16"]],["bool"]]],[11,"le","","",41,[[["self"],["i32x16"]],["bool"]]],[11,"gt","","",41,[[["self"],["i32x16"]],["bool"]]],[11,"ge","","",41,[[["self"],["i32x16"]],["bool"]]],[11,"partial_cmp","","",38,[[["self"],["m1x16"]],["option",["ordering"]]]],[11,"lt","","",38,[[["self"],["m1x16"]],["bool"]]],[11,"le","","",38,[[["self"],["m1x16"]],["bool"]]],[11,"gt","","",38,[[["self"],["m1x16"]],["bool"]]],[11,"ge","","",38,[[["self"],["m1x16"]],["bool"]]],[11,"partial_cmp","","",34,[[["self"],["i8x16"]],["option",["ordering"]]]],[11,"lt","","",34,[[["self"],["i8x16"]],["bool"]]],[11,"le","","",34,[[["self"],["i8x16"]],["bool"]]],[11,"gt","","",34,[[["self"],["i8x16"]],["bool"]]],[11,"ge","","",34,[[["self"],["i8x16"]],["bool"]]],[11,"partial_cmp","","",28,[[["self"],["m64x4"]],["option",["ordering"]]]],[11,"lt","","",28,[[["self"],["m64x4"]],["bool"]]],[11,"le","","",28,[[["self"],["m64x4"]],["bool"]]],[11,"gt","","",28,[[["self"],["m64x4"]],["bool"]]],[11,"ge","","",28,[[["self"],["m64x4"]],["bool"]]],[11,"partial_cmp","","",25,[[["self"],["m32x2"]],["option",["ordering"]]]],[11,"lt","","",25,[[["self"],["m32x2"]],["bool"]]],[11,"le","","",25,[[["self"],["m32x2"]],["bool"]]],[11,"gt","","",25,[[["self"],["m32x2"]],["bool"]]],[11,"ge","","",25,[[["self"],["m32x2"]],["bool"]]],[11,"partial_cmp","","",21,[[["self"],["i8x8"]],["option",["ordering"]]]],[11,"lt","","",21,[[["self"],["i8x8"]],["bool"]]],[11,"le","","",21,[[["self"],["i8x8"]],["bool"]]],[11,"gt","","",21,[[["self"],["i8x8"]],["bool"]]],[11,"ge","","",21,[[["self"],["i8x8"]],["bool"]]],[11,"partial_cmp","","",22,[[["self"],["i64x4"]],["option",["ordering"]]]],[11,"lt","","",22,[[["self"],["i64x4"]],["bool"]]],[11,"le","","",22,[[["self"],["i64x4"]],["bool"]]],[11,"gt","","",22,[[["self"],["i64x4"]],["bool"]]],[11,"ge","","",22,[[["self"],["i64x4"]],["bool"]]],[11,"partial_cmp","","",40,[[["self"],["m16x8"]],["option",["ordering"]]]],[11,"lt","","",40,[[["self"],["m16x8"]],["bool"]]],[11,"le","","",40,[[["self"],["m16x8"]],["bool"]]],[11,"gt","","",40,[[["self"],["m16x8"]],["bool"]]],[11,"ge","","",40,[[["self"],["m16x8"]],["bool"]]],[11,"partial_cmp","","",12,[[["self"],["u16x16"]],["option",["ordering"]]]],[11,"lt","","",12,[[["self"],["u16x16"]],["bool"]]],[11,"le","","",12,[[["self"],["u16x16"]],["bool"]]],[11,"gt","","",12,[[["self"],["u16x16"]],["bool"]]],[11,"ge","","",12,[[["self"],["u16x16"]],["bool"]]],[11,"partial_cmp","","",45,[[["self"],["u8x8"]],["option",["ordering"]]]],[11,"lt","","",45,[[["self"],["u8x8"]],["bool"]]],[11,"le","","",45,[[["self"],["u8x8"]],["bool"]]],[11,"gt","","",45,[[["self"],["u8x8"]],["bool"]]],[11,"ge","","",45,[[["self"],["u8x8"]],["bool"]]],[11,"partial_cmp","","",49,[[["self"],["i8x32"]],["option",["ordering"]]]],[11,"lt","","",49,[[["self"],["i8x32"]],["bool"]]],[11,"le","","",49,[[["self"],["i8x32"]],["bool"]]],[11,"gt","","",49,[[["self"],["i8x32"]],["bool"]]],[11,"ge","","",49,[[["self"],["i8x32"]],["bool"]]],[11,"partial_cmp","","",3,[[["self"],["m32x8"]],["option",["ordering"]]]],[11,"lt","","",3,[[["self"],["m32x8"]],["bool"]]],[11,"le","","",3,[[["self"],["m32x8"]],["bool"]]],[11,"gt","","",3,[[["self"],["m32x8"]],["bool"]]],[11,"ge","","",3,[[["self"],["m32x8"]],["bool"]]],[11,"partial_cmp","","",24,[[["self"],["u16x4"]],["option",["ordering"]]]],[11,"lt","","",24,[[["self"],["u16x4"]],["bool"]]],[11,"le","","",24,[[["self"],["u16x4"]],["bool"]]],[11,"gt","","",24,[[["self"],["u16x4"]],["bool"]]],[11,"ge","","",24,[[["self"],["u16x4"]],["bool"]]],[11,"partial_cmp","","",48,[[["self"],["m1x32"]],["option",["ordering"]]]],[11,"lt","","",48,[[["self"],["m1x32"]],["bool"]]],[11,"le","","",48,[[["self"],["m1x32"]],["bool"]]],[11,"gt","","",48,[[["self"],["m1x32"]],["bool"]]],[11,"ge","","",48,[[["self"],["m1x32"]],["bool"]]],[11,"partial_cmp","","",13,[[["self"],["i32x2"]],["option",["ordering"]]]],[11,"lt","","",13,[[["self"],["i32x2"]],["bool"]]],[11,"le","","",13,[[["self"],["i32x2"]],["bool"]]],[11,"gt","","",13,[[["self"],["i32x2"]],["bool"]]],[11,"ge","","",13,[[["self"],["i32x2"]],["bool"]]],[11,"partial_cmp","","",8,[[["self"],["u64x8"]],["option",["ordering"]]]],[11,"lt","","",8,[[["self"],["u64x8"]],["bool"]]],[11,"le","","",8,[[["self"],["u64x8"]],["bool"]]],[11,"gt","","",8,[[["self"],["u64x8"]],["bool"]]],[11,"ge","","",8,[[["self"],["u64x8"]],["bool"]]],[11,"partial_cmp","","",4,[[["self"],["u64x4"]],["option",["ordering"]]]],[11,"lt","","",4,[[["self"],["u64x4"]],["bool"]]],[11,"le","","",4,[[["self"],["u64x4"]],["bool"]]],[11,"gt","","",4,[[["self"],["u64x4"]],["bool"]]],[11,"ge","","",4,[[["self"],["u64x4"]],["bool"]]],[11,"partial_cmp","","",6,[[["self"],["i8x2"]],["option",["ordering"]]]],[11,"lt","","",6,[[["self"],["i8x2"]],["bool"]]],[11,"le","","",6,[[["self"],["i8x2"]],["bool"]]],[11,"gt","","",6,[[["self"],["i8x2"]],["bool"]]],[11,"ge","","",6,[[["self"],["i8x2"]],["bool"]]],[11,"partial_cmp","","",58,[[["self"],["f64x8"]],["option",["ordering"]]]],[11,"lt","","",58,[[["self"],["f64x8"]],["bool"]]],[11,"le","","",58,[[["self"],["f64x8"]],["bool"]]],[11,"gt","","",58,[[["self"],["f64x8"]],["bool"]]],[11,"ge","","",58,[[["self"],["f64x8"]],["bool"]]],[11,"partial_cmp","","",19,[[["self"],["u32x4"]],["option",["ordering"]]]],[11,"lt","","",19,[[["self"],["u32x4"]],["bool"]]],[11,"le","","",19,[[["self"],["u32x4"]],["bool"]]],[11,"gt","","",19,[[["self"],["u32x4"]],["bool"]]],[11,"ge","","",19,[[["self"],["u32x4"]],["bool"]]],[11,"partial_cmp","","",35,[[["self"],["i16x2"]],["option",["ordering"]]]],[11,"lt","","",35,[[["self"],["i16x2"]],["bool"]]],[11,"le","","",35,[[["self"],["i16x2"]],["bool"]]],[11,"gt","","",35,[[["self"],["i16x2"]],["bool"]]],[11,"ge","","",35,[[["self"],["i16x2"]],["bool"]]],[11,"partial_cmp","","",11,[[["self"],["m8x2"]],["option",["ordering"]]]],[11,"lt","","",11,[[["self"],["m8x2"]],["bool"]]],[11,"le","","",11,[[["self"],["m8x2"]],["bool"]]],[11,"gt","","",11,[[["self"],["m8x2"]],["bool"]]],[11,"ge","","",11,[[["self"],["m8x2"]],["bool"]]],[11,"partial_cmp","","",47,[[["self"],["i64x8"]],["option",["ordering"]]]],[11,"lt","","",47,[[["self"],["i64x8"]],["bool"]]],[11,"le","","",47,[[["self"],["i64x8"]],["bool"]]],[11,"gt","","",47,[[["self"],["i64x8"]],["bool"]]],[11,"ge","","",47,[[["self"],["i64x8"]],["bool"]]],[11,"partial_cmp","","",30,[[["self"],["u32x16"]],["option",["ordering"]]]],[11,"lt","","",30,[[["self"],["u32x16"]],["bool"]]],[11,"le","","",30,[[["self"],["u32x16"]],["bool"]]],[11,"gt","","",30,[[["self"],["u32x16"]],["bool"]]],[11,"ge","","",30,[[["self"],["u32x16"]],["bool"]]],[11,"partial_cmp","","",39,[[["self"],["i32x8"]],["option",["ordering"]]]],[11,"lt","","",39,[[["self"],["i32x8"]],["bool"]]],[11,"le","","",39,[[["self"],["i32x8"]],["bool"]]],[11,"gt","","",39,[[["self"],["i32x8"]],["bool"]]],[11,"ge","","",39,[[["self"],["i32x8"]],["bool"]]],[11,"partial_cmp","","",26,[[["self"],["m1x64"]],["option",["ordering"]]]],[11,"lt","","",26,[[["self"],["m1x64"]],["bool"]]],[11,"le","","",26,[[["self"],["m1x64"]],["bool"]]],[11,"gt","","",26,[[["self"],["m1x64"]],["bool"]]],[11,"ge","","",26,[[["self"],["m1x64"]],["bool"]]],[11,"partial_cmp","","",52,[[["self"],["i32x4"]],["option",["ordering"]]]],[11,"lt","","",52,[[["self"],["i32x4"]],["bool"]]],[11,"le","","",52,[[["self"],["i32x4"]],["bool"]]],[11,"gt","","",52,[[["self"],["i32x4"]],["bool"]]],[11,"ge","","",52,[[["self"],["i32x4"]],["bool"]]],[11,"partial_cmp","","",17,[[["self"],["m8x32"]],["option",["ordering"]]]],[11,"lt","","",17,[[["self"],["m8x32"]],["bool"]]],[11,"le","","",17,[[["self"],["m8x32"]],["bool"]]],[11,"gt","","",17,[[["self"],["m8x32"]],["bool"]]],[11,"ge","","",17,[[["self"],["m8x32"]],["bool"]]],[11,"partial_cmp","stdsimd::arch::x86_64","",2,[[["self"],["cpuidresult"]],["option",["ordering"]]]],[11,"lt","","",2,[[["self"],["cpuidresult"]],["bool"]]],[11,"le","","",2,[[["self"],["cpuidresult"]],["bool"]]],[11,"gt","","",2,[[["self"],["cpuidresult"]],["bool"]]],[11,"ge","","",2,[[["self"],["cpuidresult"]],["bool"]]],[11,"partial_cmp","stdsimd::simd","",36,[[["self"],["i64x2"]],["option",["ordering"]]]],[11,"lt","","",36,[[["self"],["i64x2"]],["bool"]]],[11,"le","","",36,[[["self"],["i64x2"]],["bool"]]],[11,"gt","","",36,[[["self"],["i64x2"]],["bool"]]],[11,"ge","","",36,[[["self"],["i64x2"]],["bool"]]],[11,"partial_cmp","","",54,[[["self"],["m64x2"]],["option",["ordering"]]]],[11,"lt","","",54,[[["self"],["m64x2"]],["bool"]]],[11,"le","","",54,[[["self"],["m64x2"]],["bool"]]],[11,"gt","","",54,[[["self"],["m64x2"]],["bool"]]],[11,"ge","","",54,[[["self"],["m64x2"]],["bool"]]],[11,"partial_cmp","","",23,[[["self"],["u8x32"]],["option",["ordering"]]]],[11,"lt","","",23,[[["self"],["u8x32"]],["bool"]]],[11,"le","","",23,[[["self"],["u8x32"]],["bool"]]],[11,"gt","","",23,[[["self"],["u8x32"]],["bool"]]],[11,"ge","","",23,[[["self"],["u8x32"]],["bool"]]],[11,"partial_cmp","","",46,[[["self"],["m8x4"]],["option",["ordering"]]]],[11,"lt","","",46,[[["self"],["m8x4"]],["bool"]]],[11,"le","","",46,[[["self"],["m8x4"]],["bool"]]],[11,"gt","","",46,[[["self"],["m8x4"]],["bool"]]],[11,"ge","","",46,[[["self"],["m8x4"]],["bool"]]],[11,"partial_cmp","","",59,[[["self"],["f32x16"]],["option",["ordering"]]]],[11,"lt","","",59,[[["self"],["f32x16"]],["bool"]]],[11,"le","","",59,[[["self"],["f32x16"]],["bool"]]],[11,"gt","","",59,[[["self"],["f32x16"]],["bool"]]],[11,"ge","","",59,[[["self"],["f32x16"]],["bool"]]],[11,"partial_cmp","","",32,[[["self"],["m16x16"]],["option",["ordering"]]]],[11,"lt","","",32,[[["self"],["m16x16"]],["bool"]]],[11,"le","","",32,[[["self"],["m16x16"]],["bool"]]],[11,"gt","","",32,[[["self"],["m16x16"]],["bool"]]],[11,"ge","","",32,[[["self"],["m16x16"]],["bool"]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",29,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",56,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",52,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",33,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",39,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",36,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",9,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",19,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",45,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",16,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",12,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",49,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",22,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result",["error"]]]],[11,"rem","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"rem","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"rem","","",61,[[["self"],["f32x2"]],["f32x2"]]],[11,"rem","","",61,[[["self"],["f32"]],["f32x2"]]],[11,"rem","","",58,[[["self"],["f64x8"]],["f64x8"]]],[11,"rem","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"rem","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"rem","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"rem","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"rem","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"rem","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"rem","","",63,[[["self"],["f32x8"]],["f32x8"]]],[11,"rem","","",62,[[["self"],["f64"]],["f64x4"]]],[11,"rem","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"rem","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"rem","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"rem","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"rem","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"rem","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"rem","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"rem","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"rem","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"rem","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"rem","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"rem","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"rem","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"rem","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"rem","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"rem","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"rem","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"rem","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"rem","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"rem","","",57,[[["self"],["f32"]],["f32x4"]]],[11,"rem","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"rem","","",58,[[["self"],["f64"]],["f64x8"]]],[11,"rem","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"rem","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"rem","","",62,[[["self"],["f64x4"]],["f64x4"]]],[11,"rem","","",57,[[["self"],["f32x4"]],["f32x4"]]],[11,"rem","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"rem","","",63,[[["self"],["f32"]],["f32x8"]]],[11,"rem","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"rem","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"rem","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"rem","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"rem","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"rem","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"rem","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"rem","","",59,[[["self"],["f32x16"]],["f32x16"]]],[11,"rem","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"rem","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"rem","","",59,[[["self"],["f32"]],["f32x16"]]],[11,"rem","","",60,[[["self"],["f64x2"]],["f64x2"]]],[11,"rem","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"rem","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"rem","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"rem","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"rem","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"rem","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"rem","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"rem","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"rem","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"rem","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"rem","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"rem","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"rem","","",60,[[["self"],["f64"]],["f64x2"]]],[11,"rem","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"rem","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"rem","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"rem","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"rem","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"rem","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"rem","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"rem","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"rem","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"rem","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"rem","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"rem","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"rem","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"rem","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"rem","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"rem","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"rem","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"rem","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"rem","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"rem","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"bitxor","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"bitxor","","",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"bitxor","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"bitxor","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"bitxor","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"bitxor","","",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"bitxor","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"bitxor","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"bitxor","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"bitxor","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"bitxor","","",17,[[["self"],["bool"]],["m8x32"]]],[11,"bitxor","","",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"bitxor","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"bitxor","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"bitxor","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"bitxor","","",28,[[["self"],["bool"]],["m64x4"]]],[11,"bitxor","","",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"bitxor","","",38,[[["self"],["bool"]],["m1x16"]]],[11,"bitxor","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"bitxor","","",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"bitxor","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"bitxor","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"bitxor","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"bitxor","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"bitxor","","",11,[[["self"],["bool"]],["m8x2"]]],[11,"bitxor","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"bitxor","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"bitxor","","",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"bitxor","","",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"bitxor","","",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"bitxor","","",53,[[["self"],["bool"]],["m16x2"]]],[11,"bitxor","","",3,[[["self"],["m32x8"]],["m32x8"]]],[11,"bitxor","","",54,[[["self"],["bool"]],["m64x2"]]],[11,"bitxor","","",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"bitxor","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"bitxor","","",48,[[["self"],["bool"]],["m1x32"]]],[11,"bitxor","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"bitxor","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"bitxor","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"bitxor","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"bitxor","","",31,[[["self"],["bool"]],["m32x4"]]],[11,"bitxor","","",26,[[["self"],["bool"]],["m1x64"]]],[11,"bitxor","","",20,[[["self"],["bool"]],["m8x8"]]],[11,"bitxor","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"bitxor","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"bitxor","","",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"bitxor","","",40,[[["self"],["bool"]],["m16x8"]]],[11,"bitxor","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"bitxor","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"bitxor","","",15,[[["self"],["bool"]],["m1x8"]]],[11,"bitxor","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"bitxor","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"bitxor","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"bitxor","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"bitxor","","",43,[[["self"],["bool"]],["m16x4"]]],[11,"bitxor","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"bitxor","","",46,[[["self"],["bool"]],["m8x4"]]],[11,"bitxor","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"bitxor","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"bitxor","","",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"bitxor","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"bitxor","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"bitxor","","",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"bitxor","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"bitxor","","",32,[[["self"],["bool"]],["m16x16"]]],[11,"bitxor","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"bitxor","","",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"bitxor","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"bitxor","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"bitxor","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"bitxor","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"bitxor","","",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"bitxor","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"bitxor","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"bitxor","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"bitxor","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"bitxor","","",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"bitxor","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"bitxor","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"bitxor","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"bitxor","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"bitxor","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"bitxor","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"bitxor","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"bitxor","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"bitxor","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"bitxor","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"bitxor","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"bitxor","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"bitxor","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"bitxor","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"bitxor","","",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"bitxor","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"bitxor","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"bitxor","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"bitxor","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"bitxor","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"bitxor","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"bitxor","","",25,[[["self"],["bool"]],["m32x2"]]],[11,"bitxor","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"bitxor","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"bitxor","","",3,[[["self"],["bool"]],["m32x8"]]],[11,"bitxor","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"bitxor","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"bitxor","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"bitxor","","",42,[[["self"],["bool"]],["m8x16"]]],[11,"bitxor","","",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"bitxor","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"fmt","","",13,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",59,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",26,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",18,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",52,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",5,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",58,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",60,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",33,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::arch::x86_64","",70,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::simd","",12,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",53,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",51,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",23,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",19,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",10,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",55,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",4,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",34,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",29,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",44,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",37,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",24,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",28,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",6,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",14,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",43,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",46,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",47,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",42,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",20,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",30,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",27,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",22,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",15,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::arch::x86_64","",65,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::simd","",3,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",11,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",39,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",41,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::arch::x86_64","",68,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::simd","",9,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",31,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",45,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",17,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",56,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",38,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",7,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",57,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",63,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",32,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::arch::x86_64","",66,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::simd","",54,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",21,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",35,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",40,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",16,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",25,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",8,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",50,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::arch::x86_64","",67,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::simd","",48,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::arch::x86_64","",69,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::simd","",49,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",36,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",62,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","","",61,[[["self"],["formatter"]],["result",["error"]]]],[11,"fmt","stdsimd::arch::x86_64","",64,[[["self"],["formatter"]],["result",["error"]]]],[11,"from_bits","stdsimd::simd","",60,[[["__m128d"]],["f64x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["u16x16"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",8,[[["u8x64"]],["u64x8"]]],[11,"from_bits","","",13,[[["m16x4"]],["i32x2"]]],[11,"from_bits","","",27,[[["u8x8"]],["i16x4"]]],[11,"from_bits","","",52,[[["u16x8"]],["i32x4"]]],[11,"from_bits","","",47,[[["i16x32"]],["i64x8"]]],[11,"from_bits","","",9,[[["m32x2"]],["u32x2"]]],[11,"from_bits","","",45,[[["__m64"]],["u8x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["u8x16"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",24,[[["__m64"]],["u16x4"]]],[11,"from_bits","","",50,[[["m8x2"]],["u8x2"]]],[11,"from_bits","","",59,[[["i64x8"]],["f32x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["u16x16"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",59,[[["m1x32"]],["f32x16"]]],[11,"from_bits","","",36,[[["i32x4"]],["i64x2"]]],[11,"from_bits","","",21,[[["i16x4"]],["i8x8"]]],[11,"from_bits","","",33,[[["u64x8"]],["u16x32"]]],[11,"from_bits","","",14,[[["__m128"]],["u16x8"]]],[11,"from_bits","","",47,[[["m1x16"]],["i64x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["u8x32"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",29,[[["u64x8"]],["i16x32"]]],[11,"from_bits","","",8,[[["i16x32"]],["u64x8"]]],[11,"from_bits","","",44,[[["m8x16"]],["u8x16"]]],[11,"from_bits","","",22,[[["u8x32"]],["i64x4"]]],[11,"from_bits","","",7,[[["u16x16"]],["u32x8"]]],[11,"from_bits","","",5,[[["m1x64"]],["u8x64"]]],[11,"from_bits","","",39,[[["u8x32"]],["i32x8"]]],[11,"from_bits","","",18,[[["m16x8"]],["u64x2"]]],[11,"from_bits","","",57,[[["__m128i"]],["f32x4"]]],[11,"from_bits","","",57,[[["u8x16"]],["f32x4"]]],[11,"from_bits","","",7,[[["i32x8"]],["u32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["i8x32"]],["__m256d"]]],[11,"from_bits","","",65,[[["m64x4"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",14,[[["u32x4"]],["u16x8"]]],[11,"from_bits","","",59,[[["m1x8"]],["f32x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["u64x4"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",45,[[["m16x4"]],["u8x8"]]],[11,"from_bits","","",9,[[["u8x8"]],["u32x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["u16x8"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",4,[[["i64x4"]],["u64x4"]]],[11,"from_bits","","",62,[[["i64x4"]],["f64x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["i32x4"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",4,[[["m8x32"]],["u64x4"]]],[11,"from_bits","","",9,[[["__m64"]],["u32x2"]]],[11,"from_bits","","",24,[[["i8x8"]],["u16x4"]]],[11,"from_bits","","",5,[[["m1x16"]],["u8x64"]]],[11,"from_bits","","",23,[[["u64x4"]],["u8x32"]]],[11,"from_bits","","",47,[[["u16x32"]],["i64x8"]]],[11,"from_bits","","",24,[[["i16x4"]],["u16x4"]]],[11,"from_bits","","",41,[[["i16x32"]],["i32x16"]]],[11,"from_bits","","",52,[[["m16x8"]],["i32x4"]]],[11,"from_bits","","",18,[[["i32x4"]],["u64x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["f32x4"]],["__m128d"]]],[11,"from_bits","","",69,[[["f64x4"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",29,[[["m1x16"]],["i16x32"]]],[11,"from_bits","","",19,[[["f32x4"]],["u32x4"]]],[11,"from_bits","","",62,[[["m64x4"]],["f64x4"]]],[11,"from_bits","","",30,[[["m1x32"]],["u32x16"]]],[11,"from_bits","","",23,[[["__m256d"]],["u8x32"]]],[11,"from_bits","","",30,[[["i8x64"]],["u32x16"]]],[11,"from_bits","","",12,[[["f32x8"]],["u16x16"]]],[11,"from_bits","","",14,[[["i64x2"]],["u16x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["m64x4"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",27,[[["m16x4"]],["i16x4"]]],[11,"from_bits","","",23,[[["m32x8"]],["u8x32"]]],[11,"from_bits","","",59,[[["i8x64"]],["f32x16"]]],[11,"from_bits","","",47,[[["i32x16"]],["i64x8"]]],[11,"from_bits","","",8,[[["u32x16"]],["u64x8"]]],[11,"from_bits","","",22,[[["f64x4"]],["i64x4"]]],[11,"from_bits","","",62,[[["__m256i"]],["f64x4"]]],[11,"from_bits","","",19,[[["i64x2"]],["u32x4"]]],[11,"from_bits","","",60,[[["__m128i"]],["f64x2"]]],[11,"from_bits","","",49,[[["f32x8"]],["i8x32"]]],[11,"from_bits","","",45,[[["m8x8"]],["u8x8"]]],[11,"from_bits","","",12,[[["__m256i"]],["u16x16"]]],[11,"from_bits","","",58,[[["f32x16"]],["f64x8"]]],[11,"from_bits","","",41,[[["f64x8"]],["i32x16"]]],[11,"from_bits","","",41,[[["m1x16"]],["i32x16"]]],[11,"from_bits","","",4,[[["__m256"]],["u64x4"]]],[11,"from_bits","","",41,[[["m1x64"]],["i32x16"]]],[11,"from_bits","","",56,[[["u32x4"]],["i16x8"]]],[11,"from_bits","","",61,[[["m16x4"]],["f32x2"]]],[11,"from_bits","","",34,[[["i32x4"]],["i8x16"]]],[11,"from_bits","","",10,[[["__m256"]],["i16x16"]]],[11,"from_bits","","",21,[[["m16x4"]],["i8x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["m64x2"]],["__m128"]]],[11,"from_bits","","",68,[[["i8x16"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",22,[[["u16x16"]],["i64x4"]]],[11,"from_bits","","",34,[[["u16x8"]],["i8x16"]]],[11,"from_bits","","",30,[[["i64x8"]],["u32x16"]]],[11,"from_bits","","",21,[[["m8x8"]],["i8x8"]]],[11,"from_bits","","",58,[[["m1x8"]],["f64x8"]]],[11,"from_bits","","",14,[[["u8x16"]],["u16x8"]]],[11,"from_bits","","",9,[[["f32x2"]],["u32x2"]]],[11,"from_bits","","",44,[[["f64x2"]],["u8x16"]]],[11,"from_bits","","",60,[[["m8x16"]],["f64x2"]]],[11,"from_bits","","",7,[[["__m256i"]],["u32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["u8x32"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",36,[[["u8x16"]],["i64x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["u16x16"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",35,[[["m16x2"]],["i16x2"]]],[11,"from_bits","","",56,[[["m16x8"]],["i16x8"]]],[11,"from_bits","","",8,[[["f64x8"]],["u64x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["f64x2"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",37,[[["m1x8"]],["i8x64"]]],[11,"from_bits","","",9,[[["i8x8"]],["u32x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["i16x16"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",62,[[["m32x8"]],["f64x4"]]],[11,"from_bits","","",19,[[["u64x2"]],["u32x4"]]],[11,"from_bits","","",39,[[["u32x8"]],["i32x8"]]],[11,"from_bits","","",37,[[["f64x8"]],["i8x64"]]],[11,"from_bits","","",30,[[["m1x16"]],["u32x16"]]],[11,"from_bits","","",60,[[["u32x4"]],["f64x2"]]],[11,"from_bits","","",37,[[["m1x16"]],["i8x64"]]],[11,"from_bits","","",8,[[["m1x32"]],["u64x8"]]],[11,"from_bits","","",58,[[["u32x16"]],["f64x8"]]],[11,"from_bits","","",44,[[["m16x8"]],["u8x16"]]],[11,"from_bits","","",7,[[["i8x32"]],["u32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["u32x8"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",58,[[["u8x64"]],["f64x8"]]],[11,"from_bits","","",35,[[["i8x4"]],["i16x2"]]],[11,"from_bits","","",62,[[["u8x32"]],["f64x4"]]],[11,"from_bits","","",7,[[["f64x4"]],["u32x8"]]],[11,"from_bits","","",63,[[["i32x8"]],["f32x8"]]],[11,"from_bits","","",10,[[["f32x8"]],["i16x16"]]],[11,"from_bits","","",59,[[["i16x32"]],["f32x16"]]],[11,"from_bits","","",61,[[["m32x2"]],["f32x2"]]],[11,"from_bits","","",12,[[["__m256"]],["u16x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["m8x32"]],["__m256d"]]],[11,"from_bits","","",68,[[["m8x16"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",5,[[["i64x8"]],["u8x64"]]],[11,"from_bits","","",37,[[["i16x32"]],["i8x64"]]],[11,"from_bits","","",19,[[["i16x8"]],["u32x4"]]],[11,"from_bits","","",14,[[["i8x16"]],["u16x8"]]],[11,"from_bits","","",60,[[["i8x16"]],["f64x2"]]],[11,"from_bits","","",59,[[["m1x16"]],["f32x16"]]],[11,"from_bits","","",7,[[["i64x4"]],["u32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["u32x8"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",41,[[["u16x32"]],["i32x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["i32x4"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",52,[[["i64x2"]],["i32x4"]]],[11,"from_bits","","",23,[[["__m256"]],["u8x32"]]],[11,"from_bits","","",14,[[["m64x2"]],["u16x8"]]],[11,"from_bits","","",41,[[["m1x8"]],["i32x16"]]],[11,"from_bits","","",63,[[["f64x4"]],["f32x8"]]],[11,"from_bits","","",57,[[["u32x4"]],["f32x4"]]],[11,"from_bits","","",36,[[["m64x2"]],["i64x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["m32x2"]],["__m64"]]],[11,"from_bits","","",68,[[["u32x4"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",52,[[["u32x4"]],["i32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["f32x2"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",19,[[["__m128"]],["u32x4"]]],[11,"from_bits","","",9,[[["u16x4"]],["u32x2"]]],[11,"from_bits","","",49,[[["f64x4"]],["i8x32"]]],[11,"from_bits","","",23,[[["__m256i"]],["u8x32"]]],[11,"from_bits","","",34,[[["i16x8"]],["i8x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["m16x4"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",22,[[["i32x8"]],["i64x4"]]],[11,"from_bits","","",33,[[["m1x8"]],["u16x32"]]],[11,"from_bits","","",39,[[["m8x32"]],["i32x8"]]],[11,"from_bits","","",34,[[["m8x16"]],["i8x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["m16x16"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",44,[[["u32x4"]],["u8x16"]]],[11,"from_bits","","",49,[[["m16x16"]],["i8x32"]]],[11,"from_bits","","",62,[[["__m256d"]],["f64x4"]]],[11,"from_bits","","",45,[[["u32x2"]],["u8x8"]]],[11,"from_bits","","",10,[[["u16x16"]],["i16x16"]]],[11,"from_bits","","",27,[[["__m64"]],["i16x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["i32x2"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",7,[[["m16x16"]],["u32x8"]]],[11,"from_bits","","",30,[[["m1x64"]],["u32x16"]]],[11,"from_bits","","",62,[[["i8x32"]],["f64x4"]]],[11,"from_bits","","",39,[[["i8x32"]],["i32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["u16x4"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",60,[[["i64x2"]],["f64x2"]]],[11,"from_bits","","",8,[[["u16x32"]],["u64x8"]]],[11,"from_bits","","",49,[[["m64x4"]],["i8x32"]]],[11,"from_bits","","",35,[[["u8x4"]],["i16x2"]]],[11,"from_bits","","",8,[[["i8x64"]],["u64x8"]]],[11,"from_bits","","",6,[[["u8x2"]],["i8x2"]]],[11,"from_bits","","",29,[[["m1x32"]],["i16x32"]]],[11,"from_bits","","",49,[[["m32x8"]],["i8x32"]]],[11,"from_bits","","",33,[[["u8x64"]],["u16x32"]]],[11,"from_bits","","",36,[[["u64x2"]],["i64x2"]]],[11,"from_bits","","",47,[[["u64x8"]],["i64x8"]]],[11,"from_bits","","",47,[[["i8x64"]],["i64x8"]]],[11,"from_bits","","",49,[[["u16x16"]],["i8x32"]]],[11,"from_bits","","",4,[[["u8x32"]],["u64x4"]]],[11,"from_bits","","",45,[[["i16x4"]],["u8x8"]]],[11,"from_bits","","",63,[[["i64x4"]],["f32x8"]]],[11,"from_bits","","",19,[[["m16x8"]],["u32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["m64x2"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",56,[[["__m128d"]],["i16x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["m32x8"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",39,[[["f64x4"]],["i32x8"]]],[11,"from_bits","","",14,[[["i16x8"]],["u16x8"]]],[11,"from_bits","","",36,[[["m16x8"]],["i64x2"]]],[11,"from_bits","","",10,[[["m8x32"]],["i16x16"]]],[11,"from_bits","","",10,[[["f64x4"]],["i16x16"]]],[11,"from_bits","","",56,[[["i32x4"]],["i16x8"]]],[11,"from_bits","","",7,[[["u8x32"]],["u32x8"]]],[11,"from_bits","","",36,[[["m32x4"]],["i64x2"]]],[11,"from_bits","","",52,[[["m64x2"]],["i32x4"]]],[11,"from_bits","","",36,[[["m8x16"]],["i64x2"]]],[11,"from_bits","","",4,[[["i16x16"]],["u64x4"]]],[11,"from_bits","","",47,[[["m1x64"]],["i64x8"]]],[11,"from_bits","","",63,[[["m64x4"]],["f32x8"]]],[11,"from_bits","","",23,[[["f64x4"]],["u8x32"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["i64x2"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",30,[[["u8x64"]],["u32x16"]]],[11,"from_bits","","",27,[[["u16x4"]],["i16x4"]]],[11,"from_bits","","",55,[[["m16x2"]],["i8x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["f64x2"]],["__m128d"]]],[11,"from_bits","","",66,[[["u16x8"]],["__m128d"]]],[11,"from_bits","","",69,[[["m8x32"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",4,[[["u16x16"]],["u64x4"]]],[11,"from_bits","","",61,[[["__m64"]],["f32x2"]]],[11,"from_bits","","",10,[[["u32x8"]],["i16x16"]]],[11,"from_bits","","",14,[[["f64x2"]],["u16x8"]]],[11,"from_bits","","",45,[[["m32x2"]],["u8x8"]]],[11,"from_bits","","",63,[[["u8x32"]],["f32x8"]]],[11,"from_bits","","",18,[[["__m128d"]],["u64x2"]]],[11,"from_bits","","",13,[[["f32x2"]],["i32x2"]]],[11,"from_bits","","",37,[[["f32x16"]],["i8x64"]]],[11,"from_bits","","",41,[[["f32x16"]],["i32x16"]]],[11,"from_bits","","",59,[[["u16x32"]],["f32x16"]]],[11,"from_bits","","",5,[[["m1x8"]],["u8x64"]]],[11,"from_bits","","",19,[[["__m128i"]],["u32x4"]]],[11,"from_bits","","",49,[[["i16x16"]],["i8x32"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["u8x8"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",37,[[["u64x8"]],["i8x64"]]],[11,"from_bits","","",57,[[["u16x8"]],["f32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["i16x16"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",5,[[["i8x64"]],["u8x64"]]],[11,"from_bits","","",7,[[["m64x4"]],["u32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["i64x2"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",39,[[["__m256i"]],["i32x8"]]],[11,"from_bits","","",39,[[["i16x16"]],["i32x8"]]],[11,"from_bits","","",4,[[["__m256i"]],["u64x4"]]],[11,"from_bits","","",62,[[["u32x8"]],["f64x4"]]],[11,"from_bits","","",21,[[["__m64"]],["i8x8"]]],[11,"from_bits","","",39,[[["__m256"]],["i32x8"]]],[11,"from_bits","","",56,[[["i64x2"]],["i16x8"]]],[11,"from_bits","","",62,[[["u64x4"]],["f64x4"]]],[11,"from_bits","","",62,[[["u16x16"]],["f64x4"]]],[11,"from_bits","","",39,[[["m16x16"]],["i32x8"]]],[11,"from_bits","","",51,[[["u16x2"]],["u8x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["f32x8"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",56,[[["f64x2"]],["i16x8"]]],[11,"from_bits","","",34,[[["u32x4"]],["i8x16"]]],[11,"from_bits","","",51,[[["i8x4"]],["u8x4"]]],[11,"from_bits","","",33,[[["i64x8"]],["u16x32"]]],[11,"from_bits","","",24,[[["m16x4"]],["u16x4"]]],[11,"from_bits","","",12,[[["m16x16"]],["u16x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["m16x16"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",45,[[["u16x4"]],["u8x8"]]],[11,"from_bits","","",36,[[["i16x8"]],["i64x2"]]],[11,"from_bits","","",56,[[["f32x4"]],["i16x8"]]],[11,"from_bits","","",36,[[["f64x2"]],["i64x2"]]],[11,"from_bits","","",22,[[["i8x32"]],["i64x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["i16x4"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",49,[[["u64x4"]],["i8x32"]]],[11,"from_bits","","",22,[[["__m256"]],["i64x4"]]],[11,"from_bits","","",37,[[["u32x16"]],["i8x64"]]],[11,"from_bits","","",35,[[["m8x4"]],["i16x2"]]],[11,"from_bits","","",63,[[["m16x16"]],["f32x8"]]],[11,"from_bits","","",49,[[["__m256"]],["i8x32"]]],[11,"from_bits","","",57,[[["m8x16"]],["f32x4"]]],[11,"from_bits","","",14,[[["m32x4"]],["u16x8"]]],[11,"from_bits","","",13,[[["u8x8"]],["i32x2"]]],[11,"from_bits","","",9,[[["m16x4"]],["u32x2"]]],[11,"from_bits","","",4,[[["i32x8"]],["u64x4"]]],[11,"from_bits","","",19,[[["i8x16"]],["u32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["i32x8"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",23,[[["m16x16"]],["u8x32"]]],[11,"from_bits","","",62,[[["__m256"]],["f64x4"]]],[11,"from_bits","","",61,[[["u8x8"]],["f32x2"]]],[11,"from_bits","","",33,[[["m1x32"]],["u16x32"]]],[11,"from_bits","","",59,[[["u64x8"]],["f32x16"]]],[11,"from_bits","","",12,[[["i32x8"]],["u16x16"]]],[11,"from_bits","","",7,[[["u64x4"]],["u32x8"]]],[11,"from_bits","","",23,[[["u16x16"]],["u8x32"]]],[11,"from_bits","","",41,[[["i64x8"]],["i32x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["m8x16"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",61,[[["u16x4"]],["f32x2"]]],[11,"from_bits","","",52,[[["__m128i"]],["i32x4"]]],[11,"from_bits","","",4,[[["m64x4"]],["u64x4"]]],[11,"from_bits","","",10,[[["m32x8"]],["i16x16"]]],[11,"from_bits","","",33,[[["i32x16"]],["u16x32"]]],[11,"from_bits","","",18,[[["u32x4"]],["u64x2"]]],[11,"from_bits","","",45,[[["i32x2"]],["u8x8"]]],[11,"from_bits","","",13,[[["i8x8"]],["i32x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["i64x4"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",47,[[["u32x16"]],["i64x8"]]],[11,"from_bits","","",27,[[["i8x8"]],["i16x4"]]],[11,"from_bits","","",4,[[["m32x8"]],["u64x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["i32x4"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",29,[[["i64x8"]],["i16x32"]]],[11,"from_bits","","",9,[[["i16x4"]],["u32x2"]]],[11,"from_bits","","",22,[[["i16x16"]],["i64x4"]]],[11,"from_bits","","",5,[[["u64x8"]],["u8x64"]]],[11,"from_bits","","",27,[[["m8x8"]],["i16x4"]]],[11,"from_bits","","",34,[[["__m128"]],["i8x16"]]],[11,"from_bits","","",57,[[["f64x2"]],["f32x4"]]],[11,"from_bits","","",18,[[["m64x2"]],["u64x2"]]],[11,"from_bits","","",44,[[["__m128d"]],["u8x16"]]],[11,"from_bits","","",63,[[["__m256"]],["f32x8"]]],[11,"from_bits","","",52,[[["f32x4"]],["i32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["i8x16"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",34,[[["u64x2"]],["i8x16"]]],[11,"from_bits","","",63,[[["u64x4"]],["f32x8"]]],[11,"from_bits","","",39,[[["m64x4"]],["i32x8"]]],[11,"from_bits","","",62,[[["i16x16"]],["f64x4"]]],[11,"from_bits","","",14,[[["u64x2"]],["u16x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["i8x32"]],["__m256i"]]],[11,"from_bits","","",67,[[["m32x4"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",18,[[["m8x16"]],["u64x2"]]],[11,"from_bits","","",35,[[["u16x2"]],["i16x2"]]],[11,"from_bits","","",4,[[["m16x16"]],["u64x4"]]],[11,"from_bits","","",47,[[["u8x64"]],["i64x8"]]],[11,"from_bits","","",37,[[["m1x64"]],["i8x64"]]],[11,"from_bits","","",63,[[["__m256i"]],["f32x8"]]],[11,"from_bits","","",34,[[["m16x8"]],["i8x16"]]],[11,"from_bits","","",52,[[["i8x16"]],["i32x4"]]],[11,"from_bits","","",12,[[["m8x32"]],["u16x16"]]],[11,"from_bits","","",24,[[["m8x8"]],["u16x4"]]],[11,"from_bits","","",13,[[["i16x4"]],["i32x2"]]],[11,"from_bits","","",4,[[["u32x8"]],["u64x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["m16x8"]],["__m128i"]]],[11,"from_bits","","",66,[[["u8x16"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",27,[[["i32x2"]],["i16x4"]]],[11,"from_bits","","",19,[[["u16x8"]],["u32x4"]]],[11,"from_bits","","",24,[[["m32x2"]],["u16x4"]]],[11,"from_bits","","",61,[[["i8x8"]],["f32x2"]]],[11,"from_bits","","",33,[[["u32x16"]],["u16x32"]]],[11,"from_bits","","",6,[[["m8x2"]],["i8x2"]]],[11,"from_bits","","",30,[[["u64x8"]],["u32x16"]]],[11,"from_bits","","",12,[[["u32x8"]],["u16x16"]]],[11,"from_bits","","",57,[[["__m128d"]],["f32x4"]]],[11,"from_bits","","",51,[[["m16x2"]],["u8x4"]]],[11,"from_bits","","",18,[[["i8x16"]],["u64x2"]]],[11,"from_bits","","",44,[[["f32x4"]],["u8x16"]]],[11,"from_bits","","",12,[[["u8x32"]],["u16x16"]]],[11,"from_bits","","",18,[[["i64x2"]],["u64x2"]]],[11,"from_bits","","",61,[[["u32x2"]],["f32x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["i16x16"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",47,[[["f64x8"]],["i64x8"]]],[11,"from_bits","","",23,[[["i8x32"]],["u8x32"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["i16x8"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",57,[[["m16x8"]],["f32x4"]]],[11,"from_bits","","",60,[[["m64x2"]],["f64x2"]]],[11,"from_bits","","",21,[[["u8x8"]],["i8x8"]]],[11,"from_bits","","",29,[[["u8x64"]],["i16x32"]]],[11,"from_bits","","",47,[[["m1x8"]],["i64x8"]]],[11,"from_bits","","",30,[[["i16x32"]],["u32x16"]]],[11,"from_bits","","",56,[[["m64x2"]],["i16x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["f32x8"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",29,[[["m1x64"]],["i16x32"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["i8x16"]],["__m128"]]],[11,"from_bits","","",66,[[["m8x16"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",8,[[["m1x64"]],["u64x8"]]],[11,"from_bits","","",58,[[["i32x16"]],["f64x8"]]],[11,"from_bits","","",8,[[["m1x8"]],["u64x8"]]],[11,"from_bits","","",33,[[["i8x64"]],["u16x32"]]],[11,"from_bits","","",29,[[["f64x8"]],["i16x32"]]],[11,"from_bits","","",13,[[["u16x4"]],["i32x2"]]],[11,"from_bits","","",58,[[["i16x32"]],["f64x8"]]],[11,"from_bits","","",55,[[["u16x2"]],["i8x4"]]],[11,"from_bits","","",19,[[["u8x16"]],["u32x4"]]],[11,"from_bits","","",41,[[["m1x32"]],["i32x16"]]],[11,"from_bits","","",63,[[["i8x32"]],["f32x8"]]],[11,"from_bits","","",58,[[["i64x8"]],["f64x8"]]],[11,"from_bits","","",33,[[["f64x8"]],["u16x32"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["f32x4"]],["__m128i"]]],[11,"from_bits","","",67,[[["u8x16"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",50,[[["i8x2"]],["u8x2"]]],[11,"from_bits","","",60,[[["i16x8"]],["f64x2"]]],[11,"from_bits","","",60,[[["u8x16"]],["f64x2"]]],[11,"from_bits","","",29,[[["i8x64"]],["i16x32"]]],[11,"from_bits","","",59,[[["f64x8"]],["f32x16"]]],[11,"from_bits","","",29,[[["u32x16"]],["i16x32"]]],[11,"from_bits","","",22,[[["m32x8"]],["i64x4"]]],[11,"from_bits","","",5,[[["i32x16"]],["u8x64"]]],[11,"from_bits","","",18,[[["__m128"]],["u64x2"]]],[11,"from_bits","","",8,[[["f32x16"]],["u64x8"]]],[11,"from_bits","","",12,[[["__m256d"]],["u16x16"]]],[11,"from_bits","","",23,[[["f32x8"]],["u8x32"]]],[11,"from_bits","","",24,[[["i32x2"]],["u16x4"]]],[11,"from_bits","","",14,[[["__m128i"]],["u16x8"]]],[11,"from_bits","","",58,[[["m1x16"]],["f64x8"]]],[11,"from_bits","","",47,[[["f32x16"]],["i64x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["u16x8"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",10,[[["__m256i"]],["i16x16"]]],[11,"from_bits","","",36,[[["__m128d"]],["i64x2"]]],[11,"from_bits","","",13,[[["__m64"]],["i32x2"]]],[11,"from_bits","","",41,[[["i8x64"]],["i32x16"]]],[11,"from_bits","","",22,[[["u32x8"]],["i64x4"]]],[11,"from_bits","","",4,[[["f32x8"]],["u64x4"]]],[11,"from_bits","","",7,[[["__m256"]],["u32x8"]]],[11,"from_bits","","",52,[[["__m128"]],["i32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["m32x4"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",4,[[["__m256d"]],["u64x4"]]],[11,"from_bits","","",51,[[["i16x2"]],["u8x4"]]],[11,"from_bits","","",41,[[["u8x64"]],["i32x16"]]],[11,"from_bits","","",59,[[["i32x16"]],["f32x16"]]],[11,"from_bits","","",36,[[["u16x8"]],["i64x2"]]],[11,"from_bits","","",63,[[["i16x16"]],["f32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["i64x4"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",14,[[["__m128d"]],["u16x8"]]],[11,"from_bits","","",56,[[["m8x16"]],["i16x8"]]],[11,"from_bits","","",21,[[["u32x2"]],["i8x8"]]],[11,"from_bits","","",13,[[["m32x2"]],["i32x2"]]],[11,"from_bits","","",23,[[["u32x8"]],["u8x32"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["f64x4"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",30,[[["m1x8"]],["u32x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["m8x32"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",44,[[["__m128i"]],["u8x16"]]],[11,"from_bits","","",22,[[["__m256i"]],["i64x4"]]],[11,"from_bits","","",34,[[["__m128i"]],["i8x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["u32x4"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",34,[[["f32x4"]],["i8x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["i16x8"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",29,[[["i32x16"]],["i16x32"]]],[11,"from_bits","","",49,[[["u8x32"]],["i8x32"]]],[11,"from_bits","","",52,[[["u64x2"]],["i32x4"]]],[11,"from_bits","","",52,[[["__m128d"]],["i32x4"]]],[11,"from_bits","","",22,[[["f32x8"]],["i64x4"]]],[11,"from_bits","","",33,[[["m1x16"]],["u16x32"]]],[11,"from_bits","","",5,[[["i16x32"]],["u8x64"]]],[11,"from_bits","","",14,[[["f32x4"]],["u16x8"]]],[11,"from_bits","","",22,[[["m16x16"]],["i64x4"]]],[11,"from_bits","","",44,[[["i64x2"]],["u8x16"]]],[11,"from_bits","","",14,[[["i32x4"]],["u16x8"]]],[11,"from_bits","","",12,[[["m32x8"]],["u16x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["m16x8"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",10,[[["m64x4"]],["i16x16"]]],[11,"from_bits","","",56,[[["u16x8"]],["i16x8"]]],[11,"from_bits","","",37,[[["m1x32"]],["i8x64"]]],[11,"from_bits","","",9,[[["i32x2"]],["u32x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["i64x2"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",60,[[["f32x4"]],["f64x2"]]],[11,"from_bits","","",44,[[["u16x8"]],["u8x16"]]],[11,"from_bits","","",23,[[["m8x32"]],["u8x32"]]],[11,"from_bits","","",36,[[["i8x16"]],["i64x2"]]],[11,"from_bits","","",63,[[["m8x32"]],["f32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["u32x2"]],["__m64"]]],[11,"from_bits","","",69,[[["i8x32"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",13,[[["u32x2"]],["i32x2"]]],[11,"from_bits","","",23,[[["m64x4"]],["u8x32"]]],[11,"from_bits","","",19,[[["m8x16"]],["u32x4"]]],[11,"from_bits","","",12,[[["f64x4"]],["u16x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["u64x2"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",19,[[["i32x4"]],["u32x4"]]],[11,"from_bits","","",59,[[["u32x16"]],["f32x16"]]],[11,"from_bits","","",18,[[["__m128i"]],["u64x2"]]],[11,"from_bits","","",52,[[["i16x8"]],["i32x4"]]],[11,"from_bits","","",61,[[["i32x2"]],["f32x2"]]],[11,"from_bits","","",44,[[["m32x4"]],["u8x16"]]],[11,"from_bits","","",16,[[["m8x4"]],["u16x2"]]],[11,"from_bits","","",4,[[["f64x4"]],["u64x4"]]],[11,"from_bits","","",16,[[["i8x4"]],["u16x2"]]],[11,"from_bits","","",10,[[["m16x16"]],["i16x16"]]],[11,"from_bits","","",19,[[["f64x2"]],["u32x4"]]],[11,"from_bits","","",29,[[["m1x8"]],["i16x32"]]],[11,"from_bits","","",57,[[["u64x2"]],["f32x4"]]],[11,"from_bits","","",5,[[["u16x32"]],["u8x64"]]],[11,"from_bits","","",33,[[["i16x32"]],["u16x32"]]],[11,"from_bits","","",12,[[["i16x16"]],["u16x16"]]],[11,"from_bits","","",18,[[["u16x8"]],["u64x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["u64x4"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",34,[[["f64x2"]],["i8x16"]]],[11,"from_bits","","",36,[[["__m128"]],["i64x2"]]],[11,"from_bits","","",44,[[["i32x4"]],["u8x16"]]],[11,"from_bits","","",45,[[["i8x8"]],["u8x8"]]],[11,"from_bits","","",30,[[["f64x8"]],["u32x16"]]],[11,"from_bits","","",16,[[["i16x2"]],["u16x2"]]],[11,"from_bits","","",56,[[["__m128"]],["i16x8"]]],[11,"from_bits","","",33,[[["m1x64"]],["u16x32"]]],[11,"from_bits","","",57,[[["i32x4"]],["f32x4"]]],[11,"from_bits","","",57,[[["m32x4"]],["f32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["u64x2"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",33,[[["f32x16"]],["u16x32"]]],[11,"from_bits","","",7,[[["i16x16"]],["u32x8"]]],[11,"from_bits","","",27,[[["m32x2"]],["i16x4"]]],[11,"from_bits","","",18,[[["f32x4"]],["u64x2"]]],[11,"from_bits","","",5,[[["m1x32"]],["u8x64"]]],[11,"from_bits","","",39,[[["u64x4"]],["i32x8"]]],[11,"from_bits","","",5,[[["f64x8"]],["u8x64"]]],[11,"from_bits","","",39,[[["m32x8"]],["i32x8"]]],[11,"from_bits","","",49,[[["__m256d"]],["i8x32"]]],[11,"from_bits","","",13,[[["m8x8"]],["i32x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["i32x8"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",34,[[["u8x16"]],["i8x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["u64x2"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",52,[[["f64x2"]],["i32x4"]]],[11,"from_bits","","",10,[[["i64x4"]],["i16x16"]]],[11,"from_bits","","",49,[[["i32x8"]],["i8x32"]]],[11,"from_bits","","",60,[[["u64x2"]],["f64x2"]]],[11,"from_bits","","",9,[[["m8x8"]],["u32x2"]]],[11,"from_bits","","",44,[[["i16x8"]],["u8x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["i64x4"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",14,[[["m16x8"]],["u16x8"]]],[11,"from_bits","","",37,[[["u8x64"]],["i8x64"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["f64x2"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",49,[[["m8x32"]],["i8x32"]]],[11,"from_bits","","",8,[[["i64x8"]],["u64x8"]]],[11,"from_bits","","",59,[[["u8x64"]],["f32x16"]]],[11,"from_bits","","",60,[[["__m128"]],["f64x2"]]],[11,"from_bits","","",39,[[["u16x16"]],["i32x8"]]],[11,"from_bits","","",62,[[["i32x8"]],["f64x4"]]],[11,"from_bits","","",55,[[["m8x4"]],["i8x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["i32x8"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",7,[[["f32x8"]],["u32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["u32x8"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",29,[[["f32x16"]],["i16x32"]]],[11,"from_bits","","",60,[[["i32x4"]],["f64x2"]]],[11,"from_bits","","",8,[[["m1x16"]],["u64x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["m16x8"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",58,[[["m1x32"]],["f64x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",66,[[["i16x8"]],["__m128d"]]],[11,"from_bits","stdsimd::simd","",58,[[["u64x8"]],["f64x8"]]],[11,"from_bits","","",60,[[["u16x8"]],["f64x2"]]],[11,"from_bits","","",7,[[["m32x8"]],["u32x8"]]],[11,"from_bits","","",55,[[["i16x2"]],["i8x4"]]],[11,"from_bits","","",8,[[["i32x16"]],["u64x8"]]],[11,"from_bits","","",22,[[["m64x4"]],["i64x4"]]],[11,"from_bits","","",12,[[["i8x32"]],["u16x16"]]],[11,"from_bits","","",16,[[["u8x4"]],["u16x2"]]],[11,"from_bits","","",41,[[["u64x8"]],["i32x16"]]],[11,"from_bits","","",36,[[["f32x4"]],["i64x2"]]],[11,"from_bits","","",34,[[["i64x2"]],["i8x16"]]],[11,"from_bits","","",37,[[["u16x32"]],["i8x64"]]],[11,"from_bits","","",16,[[["m16x2"]],["u16x2"]]],[11,"from_bits","","",58,[[["u16x32"]],["f64x8"]]],[11,"from_bits","","",58,[[["m1x64"]],["f64x8"]]],[11,"from_bits","","",10,[[["u64x4"]],["i16x16"]]],[11,"from_bits","","",44,[[["m64x2"]],["u8x16"]]],[11,"from_bits","","",44,[[["u64x2"]],["u8x16"]]],[11,"from_bits","","",61,[[["i16x4"]],["f32x2"]]],[11,"from_bits","","",10,[[["i8x32"]],["i16x16"]]],[11,"from_bits","","",56,[[["__m128i"]],["i16x8"]]],[11,"from_bits","","",61,[[["m8x8"]],["f32x2"]]],[11,"from_bits","","",18,[[["m32x4"]],["u64x2"]]],[11,"from_bits","","",39,[[["i64x4"]],["i32x8"]]],[11,"from_bits","","",62,[[["f32x8"]],["f64x4"]]],[11,"from_bits","","",30,[[["u16x32"]],["u32x16"]]],[11,"from_bits","","",62,[[["m8x32"]],["f64x4"]]],[11,"from_bits","","",24,[[["u8x8"]],["u16x4"]]],[11,"from_bits","","",52,[[["u8x16"]],["i32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["m32x8"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",57,[[["__m128"]],["f32x4"]]],[11,"from_bits","","",52,[[["m8x16"]],["i32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["i8x8"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",21,[[["u16x4"]],["i8x8"]]],[11,"from_bits","","",44,[[["i8x16"]],["u8x16"]]],[11,"from_bits","","",7,[[["m8x32"]],["u32x8"]]],[11,"from_bits","","",60,[[["m32x4"]],["f64x2"]]],[11,"from_bits","","",57,[[["m64x2"]],["f32x4"]]],[11,"from_bits","","",47,[[["m1x32"]],["i64x8"]]],[11,"from_bits","","",22,[[["__m256d"]],["i64x4"]]],[11,"from_bits","","",63,[[["u16x16"]],["f32x8"]]],[11,"from_bits","","",23,[[["i32x8"]],["u8x32"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["u8x32"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",60,[[["m16x8"]],["f64x2"]]],[11,"from_bits","","",27,[[["u32x2"]],["i16x4"]]],[11,"from_bits","","",34,[[["m64x2"]],["i8x16"]]],[11,"from_bits","","",58,[[["i8x64"]],["f64x8"]]],[11,"from_bits","","",56,[[["u64x2"]],["i16x8"]]],[11,"from_bits","","",34,[[["m32x4"]],["i8x16"]]],[11,"from_bits","","",19,[[["__m128d"]],["u32x4"]]],[11,"from_bits","","",63,[[["__m256d"]],["f32x8"]]],[11,"from_bits","","",56,[[["m32x4"]],["i16x8"]]],[11,"from_bits","","",63,[[["m32x8"]],["f32x8"]]],[11,"from_bits","","",34,[[["__m128d"]],["i8x16"]]],[11,"from_bits","","",57,[[["i64x2"]],["f32x4"]]],[11,"from_bits","","",21,[[["m32x2"]],["i8x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["m64x2"]],["__m128i"]]],[11,"from_bits","stdsimd::simd","",23,[[["i16x16"]],["u8x32"]]],[11,"from_bits","","",4,[[["i8x32"]],["u64x4"]]],[11,"from_bits","","",52,[[["m32x4"]],["i32x4"]]],[11,"from_bits","","",5,[[["u32x16"]],["u8x64"]]],[11,"from_bits","","",59,[[["m1x64"]],["f32x16"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["u64x4"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",10,[[["__m256d"]],["i16x16"]]],[11,"from_bits","","",49,[[["u32x8"]],["i8x32"]]],[11,"from_bits","","",51,[[["m8x4"]],["u8x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",64,[[["m8x8"]],["__m64"]]],[11,"from_bits","stdsimd::simd","",18,[[["f64x2"]],["u64x2"]]],[11,"from_bits","","",30,[[["f32x16"]],["u32x16"]]],[11,"from_bits","","",39,[[["f32x8"]],["i32x8"]]],[11,"from_bits","","",49,[[["i64x4"]],["i8x32"]]],[11,"from_bits","","",37,[[["i64x8"]],["i8x64"]]],[11,"from_bits","","",18,[[["u8x16"]],["u64x2"]]],[11,"from_bits","","",21,[[["i32x2"]],["i8x8"]]],[11,"from_bits","","",57,[[["i16x8"]],["f32x4"]]],[11,"from_bits","","",63,[[["u32x8"]],["f32x8"]]],[11,"from_bits","","",10,[[["i32x8"]],["i16x16"]]],[11,"from_bits","","",23,[[["i64x4"]],["u8x32"]]],[11,"from_bits","","",56,[[["u8x16"]],["i16x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["m16x16"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",18,[[["i16x8"]],["u64x2"]]],[11,"from_bits","","",37,[[["i32x16"]],["i8x64"]]],[11,"from_bits","","",12,[[["m64x4"]],["u16x16"]]],[11,"from_bits","","",36,[[["__m128i"]],["i64x2"]]],[11,"from_bits","","",41,[[["u32x16"]],["i32x16"]]],[11,"from_bits","","",22,[[["m8x32"]],["i64x4"]]],[11,"from_bits","","",49,[[["__m256i"]],["i8x32"]]],[11,"from_bits","","",55,[[["u8x4"]],["i8x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["u32x4"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",19,[[["m64x2"]],["u32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",68,[[["m32x4"]],["__m128i"]]],[11,"from_bits","","",70,[[["m32x8"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",22,[[["u64x4"]],["i64x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",65,[[["f32x8"]],["__m256d"]]],[11,"from_bits","stdsimd::simd","",62,[[["m16x16"]],["f64x4"]]],[11,"from_bits","","",29,[[["u16x32"]],["i16x32"]]],[11,"from_bits","","",30,[[["i32x16"]],["u32x16"]]],[11,"from_bits","","",56,[[["i8x16"]],["i16x8"]]],[11,"from_bits","","",10,[[["u8x32"]],["i16x16"]]],[11,"from_bits","","",14,[[["m8x16"]],["u16x8"]]],[11,"from_bits","","",36,[[["u32x4"]],["i64x2"]]],[11,"from_bits","stdsimd::arch::x86_64","",69,[[["m64x4"]],["__m256"]]],[11,"from_bits","stdsimd::simd","",57,[[["i8x16"]],["f32x4"]]],[11,"from_bits","stdsimd::arch::x86_64","",70,[[["f64x4"]],["__m256i"]]],[11,"from_bits","stdsimd::simd","",12,[[["u64x4"]],["u16x16"]]],[11,"from_bits","","",12,[[["i64x4"]],["u16x16"]]],[11,"from_bits","","",44,[[["__m128"]],["u8x16"]]],[11,"from_bits","","",39,[[["__m256d"]],["i32x8"]]],[11,"from_bits","stdsimd::arch::x86_64","",67,[[["f32x4"]],["__m128"]]],[11,"from_bits","stdsimd::simd","",19,[[["m32x4"]],["u32x4"]]],[11,"from_bits","","",5,[[["f32x16"]],["u8x64"]]],[11,"from_bits","","",24,[[["u32x2"]],["u16x4"]]],[11,"from_bits","","",7,[[["__m256d"]],["u32x8"]]],[11,"sub","","",8,[[["self"],["u64"]],["u64x8"]]],[11,"sub","","",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"sub","","",37,[[["self"],["i8"]],["i8x64"]]],[11,"sub","","",7,[[["self"],["u32"]],["u32x8"]]],[11,"sub","","",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"sub","","",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"sub","","",61,[[["self"],["f32"]],["f32x2"]]],[11,"sub","","",52,[[["self"],["i32"]],["i32x4"]]],[11,"sub","","",50,[[["self"],["u8"]],["u8x2"]]],[11,"sub","","",13,[[["self"],["i32"]],["i32x2"]]],[11,"sub","","",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"sub","","",9,[[["self"],["u32"]],["u32x2"]]],[11,"sub","","",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"sub","","",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"sub","","",58,[[["self"],["f64x8"]],["f64x8"]]],[11,"sub","","",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"sub","","",56,[[["self"],["i16"]],["i16x8"]]],[11,"sub","","",60,[[["self"],["f64x2"]],["f64x2"]]],[11,"sub","","",4,[[["self"],["u64"]],["u64x4"]]],[11,"sub","","",30,[[["self"],["u32"]],["u32x16"]]],[11,"sub","","",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"sub","","",61,[[["self"],["f32x2"]],["f32x2"]]],[11,"sub","","",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"sub","","",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"sub","","",62,[[["self"],["f64"]],["f64x4"]]],[11,"sub","","",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"sub","","",51,[[["self"],["u8"]],["u8x4"]]],[11,"sub","","",60,[[["self"],["f64"]],["f64x2"]]],[11,"sub","","",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"sub","","",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"sub","","",44,[[["self"],["u8"]],["u8x16"]]],[11,"sub","","",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"sub","","",22,[[["self"],["i64"]],["i64x4"]]],[11,"sub","","",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"sub","","",41,[[["self"],["i32"]],["i32x16"]]],[11,"sub","","",27,[[["self"],["i16"]],["i16x4"]]],[11,"sub","","",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"sub","","",39,[[["self"],["i32"]],["i32x8"]]],[11,"sub","","",12,[[["self"],["u16"]],["u16x16"]]],[11,"sub","","",47,[[["self"],["i64"]],["i64x8"]]],[11,"sub","","",45,[[["self"],["u8"]],["u8x8"]]],[11,"sub","","",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"sub","","",19,[[["self"],["u32"]],["u32x4"]]],[11,"sub","","",57,[[["self"],["f32"]],["f32x4"]]],[11,"sub","","",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"sub","","",33,[[["self"],["u16"]],["u16x32"]]],[11,"sub","","",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"sub","","",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"sub","","",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"sub","","",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"sub","","",35,[[["self"],["i16"]],["i16x2"]]],[11,"sub","","",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"sub","","",16,[[["self"],["u16"]],["u16x2"]]],[11,"sub","","",58,[[["self"],["f64"]],["f64x8"]]],[11,"sub","","",63,[[["self"],["f32"]],["f32x8"]]],[11,"sub","","",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"sub","","",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"sub","","",5,[[["self"],["u8"]],["u8x64"]]],[11,"sub","","",14,[[["self"],["u16"]],["u16x8"]]],[11,"sub","","",62,[[["self"],["f64x4"]],["f64x4"]]],[11,"sub","","",29,[[["self"],["i16"]],["i16x32"]]],[11,"sub","","",63,[[["self"],["f32x8"]],["f32x8"]]],[11,"sub","","",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"sub","","",6,[[["self"],["i8"]],["i8x2"]]],[11,"sub","","",36,[[["self"],["i64"]],["i64x2"]]],[11,"sub","","",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"sub","","",10,[[["self"],["i16"]],["i16x16"]]],[11,"sub","","",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"sub","","",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"sub","","",21,[[["self"],["i8"]],["i8x8"]]],[11,"sub","","",24,[[["self"],["u16"]],["u16x4"]]],[11,"sub","","",55,[[["self"],["i8"]],["i8x4"]]],[11,"sub","","",59,[[["self"],["f32"]],["f32x16"]]],[11,"sub","","",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"sub","","",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"sub","","",49,[[["self"],["i8"]],["i8x32"]]],[11,"sub","","",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"sub","","",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"sub","","",34,[[["self"],["i8"]],["i8x16"]]],[11,"sub","","",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"sub","","",59,[[["self"],["f32x16"]],["f32x16"]]],[11,"sub","","",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"sub","","",18,[[["self"],["u64"]],["u64x2"]]],[11,"sub","","",23,[[["self"],["u8"]],["u8x32"]]],[11,"sub","","",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"sub","","",57,[[["self"],["f32x4"]],["f32x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",62,[[["f64"],["f64"],["f64"],["f64"]],["f64x4"]]],[11,"lanes","","Returns the number of vector lanes.",62,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",62,[[["f64"]],["f64x4"]]],[11,"extract","","Extracts the value at `index`.",62,[[["self"],["usize"]],["f64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",62,[[["self"],["usize"]],["f64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",62,[[["self"],["usize"],["f64"]],["f64x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",62,[[["self"],["usize"],["f64"]],["f64x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",62,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",62,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",62,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",62,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",62,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",62,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",62,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",62,N],[11,"eq","","Lane-wise equality comparison.",62,[[["self"],["f64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",62,[[["self"],["f64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",62,[[["self"],["f64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",62,[[["self"],["f64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",62,[[["self"],["f64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",62,[[["self"],["f64x4"]],["m64x4"]]],[11,"sum","","Horizontal sum of the vector elements.",62,[[["self"]],["f64"]]],[11,"product","","Horizontal product of the vector elements.",62,[[["self"]],["f64"]]],[11,"max_element","","Largest vector element value.",62,[[["self"]],["f64"]]],[11,"min_element","","Smallest vector element value.",62,[[["self"]],["f64"]]],[11,"min","","Minimum of two vectors.",62,[[["self"],["f64x4"]],["f64x4"]]],[11,"max","","Maximum of two vectors.",62,[[["self"],["f64x4"]],["f64x4"]]],[11,"abs","","Absolute-value",62,[[["self"]],["f64x4"]]],[11,"sqrt","","Square-root",62,[[["self"]],["f64x4"]]],[11,"sqrte","","Square-root estimate",62,[[["self"]],["f64x4"]]],[11,"rsqrte","","Reciprocal square-root estimate",62,[[["self"]],["f64x4"]]],[11,"fma","","Fused multiply add: `self * y + z`",62,[[["self"],["f64x4"],["f64x4"]],["f64x4"]]],[11,"sin","","Sin",62,[[["self"]],["f64x4"]]],[11,"cos","","Cos",62,[[["self"]],["f64x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",63,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["f32x8"]]],[11,"lanes","","Returns the number of vector lanes.",63,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",63,[[["f32"]],["f32x8"]]],[11,"extract","","Extracts the value at `index`.",63,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",63,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",63,[[["self"],["usize"],["f32"]],["f32x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",63,[[["self"],["usize"],["f32"]],["f32x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",63,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",63,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",63,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",63,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",63,N],[11,"eq","","Lane-wise equality comparison.",63,[[["self"],["f32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",63,[[["self"],["f32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",63,[[["self"],["f32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",63,[[["self"],["f32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",63,[[["self"],["f32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",63,[[["self"],["f32x8"]],["m32x8"]]],[11,"sum","","Horizontal sum of the vector elements.",63,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",63,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",63,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",63,[[["self"]],["f32"]]],[11,"min","","Minimum of two vectors.",63,[[["self"],["f32x8"]],["f32x8"]]],[11,"max","","Maximum of two vectors.",63,[[["self"],["f32x8"]],["f32x8"]]],[11,"abs","","Absolute-value",63,[[["self"]],["f32x8"]]],[11,"sqrt","","Square-root",63,[[["self"]],["f32x8"]]],[11,"sqrte","","Square-root estimate",63,[[["self"]],["f32x8"]]],[11,"rsqrte","","Reciprocal square-root estimate",63,[[["self"]],["f32x8"]]],[11,"fma","","Fused multiply add: `self * y + z`",63,[[["self"],["f32x8"],["f32x8"]],["f32x8"]]],[11,"sin","","Sin",63,[[["self"]],["f32x8"]]],[11,"cos","","Cos",63,[[["self"]],["f32x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",60,[[["f64"],["f64"]],["f64x2"]]],[11,"lanes","","Returns the number of vector lanes.",60,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",60,[[["f64"]],["f64x2"]]],[11,"extract","","Extracts the value at `index`.",60,[[["self"],["usize"]],["f64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",60,[[["self"],["usize"]],["f64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",60,[[["self"],["usize"],["f64"]],["f64x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",60,[[["self"],["usize"],["f64"]],["f64x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",60,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",60,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",60,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",60,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",60,N],[11,"eq","","Lane-wise equality comparison.",60,[[["self"],["f64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",60,[[["self"],["f64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",60,[[["self"],["f64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",60,[[["self"],["f64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",60,[[["self"],["f64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",60,[[["self"],["f64x2"]],["m64x2"]]],[11,"sum","","Horizontal sum of the vector elements.",60,[[["self"]],["f64"]]],[11,"product","","Horizontal product of the vector elements.",60,[[["self"]],["f64"]]],[11,"max_element","","Largest vector element value.",60,[[["self"]],["f64"]]],[11,"min_element","","Smallest vector element value.",60,[[["self"]],["f64"]]],[11,"min","","Minimum of two vectors.",60,[[["self"],["f64x2"]],["f64x2"]]],[11,"max","","Maximum of two vectors.",60,[[["self"],["f64x2"]],["f64x2"]]],[11,"abs","","Absolute-value",60,[[["self"]],["f64x2"]]],[11,"sqrt","","Square-root",60,[[["self"]],["f64x2"]]],[11,"sqrte","","Square-root estimate",60,[[["self"]],["f64x2"]]],[11,"rsqrte","","Reciprocal square-root estimate",60,[[["self"]],["f64x2"]]],[11,"fma","","Fused multiply add: `self * y + z`",60,[[["self"],["f64x2"],["f64x2"]],["f64x2"]]],[11,"sin","","Sin",60,[[["self"]],["f64x2"]]],[11,"cos","","Cos",60,[[["self"]],["f64x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",24,[[["u16"],["u16"],["u16"],["u16"]],["u16x4"]]],[11,"lanes","","Returns the number of vector lanes.",24,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",24,[[["u16"]],["u16x4"]]],[11,"extract","","Extracts the value at `index`.",24,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",24,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",24,[[["self"],["usize"],["u16"]],["u16x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",24,[[["self"],["usize"],["u16"]],["u16x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",24,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",24,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",24,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",24,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",24,N],[11,"eq","","Lane-wise equality comparison.",24,[[["self"],["u16x4"]],["m16x4"]]],[11,"ne","","Lane-wise inequality comparison.",24,[[["self"],["u16x4"]],["m16x4"]]],[11,"lt","","Lane-wise less-than comparison.",24,[[["self"],["u16x4"]],["m16x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",24,[[["self"],["u16x4"]],["m16x4"]]],[11,"gt","","Lane-wise greater-than comparison.",24,[[["self"],["u16x4"]],["m16x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",24,[[["self"],["u16x4"]],["m16x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",24,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",24,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",24,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",24,[[["self"]],["u16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",24,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",24,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",24,[[["self"]],["u16"]]],[11,"min","","Minimum of two vectors.",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"max","","Maximum of two vectors.",24,[[["self"],["u16x4"]],["u16x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",24,[[["self"]],["u16x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",24,[[["self"]],["u16x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",24,[[["self"]],["u16x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",33,[[["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"]],["u16x32"]]],[11,"lanes","","Returns the number of vector lanes.",33,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",33,[[["u16"]],["u16x32"]]],[11,"extract","","Extracts the value at `index`.",33,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",33,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",33,[[["self"],["usize"],["u16"]],["u16x32"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",33,[[["self"],["usize"],["u16"]],["u16x32"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",33,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",33,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",33,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",33,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",33,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",33,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",33,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",33,N],[11,"eq","","Lane-wise equality comparison.",33,[[["self"],["u16x32"]],["m1x32"]]],[11,"ne","","Lane-wise inequality comparison.",33,[[["self"],["u16x32"]],["m1x32"]]],[11,"lt","","Lane-wise less-than comparison.",33,[[["self"],["u16x32"]],["m1x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",33,[[["self"],["u16x32"]],["m1x32"]]],[11,"gt","","Lane-wise greater-than comparison.",33,[[["self"],["u16x32"]],["m1x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",33,[[["self"],["u16x32"]],["m1x32"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",33,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",33,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",33,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",33,[[["self"]],["u16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",33,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",33,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",33,[[["self"]],["u16"]]],[11,"min","","Minimum of two vectors.",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"max","","Maximum of two vectors.",33,[[["self"],["u16x32"]],["u16x32"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",33,[[["self"]],["u16x32"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",33,[[["self"]],["u16x32"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",33,[[["self"]],["u16x32"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",35,[[["i16"],["i16"]],["i16x2"]]],[11,"lanes","","Returns the number of vector lanes.",35,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",35,[[["i16"]],["i16x2"]]],[11,"extract","","Extracts the value at `index`.",35,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",35,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",35,[[["self"],["usize"],["i16"]],["i16x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",35,[[["self"],["usize"],["i16"]],["i16x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",35,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",35,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",35,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",35,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",35,N],[11,"eq","","Lane-wise equality comparison.",35,[[["self"],["i16x2"]],["m16x2"]]],[11,"ne","","Lane-wise inequality comparison.",35,[[["self"],["i16x2"]],["m16x2"]]],[11,"lt","","Lane-wise less-than comparison.",35,[[["self"],["i16x2"]],["m16x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",35,[[["self"],["i16x2"]],["m16x2"]]],[11,"gt","","Lane-wise greater-than comparison.",35,[[["self"],["i16x2"]],["m16x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",35,[[["self"],["i16x2"]],["m16x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",35,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",35,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",35,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",35,[[["self"]],["i16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",35,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",35,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",35,[[["self"]],["i16"]]],[11,"min","","Minimum of two vectors.",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"max","","Maximum of two vectors.",35,[[["self"],["i16x2"]],["i16x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",35,[[["self"]],["i16x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",35,[[["self"]],["i16x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",35,[[["self"]],["i16x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",52,[[["i32"],["i32"],["i32"],["i32"]],["i32x4"]]],[11,"lanes","","Returns the number of vector lanes.",52,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",52,[[["i32"]],["i32x4"]]],[11,"extract","","Extracts the value at `index`.",52,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",52,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",52,[[["self"],["usize"],["i32"]],["i32x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",52,[[["self"],["usize"],["i32"]],["i32x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",52,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",52,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",52,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",52,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",52,N],[11,"eq","","Lane-wise equality comparison.",52,[[["self"],["i32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",52,[[["self"],["i32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",52,[[["self"],["i32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",52,[[["self"],["i32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",52,[[["self"],["i32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",52,[[["self"],["i32x4"]],["m32x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",52,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",52,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",52,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",52,[[["self"]],["i32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",52,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",52,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",52,[[["self"]],["i32"]]],[11,"min","","Minimum of two vectors.",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"max","","Maximum of two vectors.",52,[[["self"],["i32x4"]],["i32x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",52,[[["self"]],["i32x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",52,[[["self"]],["i32x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",52,[[["self"]],["i32x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",11,[[["bool"],["bool"]],["m8x2"]]],[11,"lanes","","Returns the number of vector lanes.",11,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",11,[[["bool"]],["m8x2"]]],[11,"extract","","Extracts the value at `index`.",11,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",11,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",11,[[["self"],["usize"],["bool"]],["m8x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",11,[[["self"],["usize"],["bool"]],["m8x2"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",11,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",11,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",11,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",11,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",11,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",11,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",11,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"ne","","Lane-wise inequality comparison.",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"lt","","Lane-wise less-than comparison.",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"gt","","Lane-wise greater-than comparison.",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",11,[[["self"],["m8x2"]],["m8x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",59,[[["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"],["f32"]],["f32x16"]]],[11,"lanes","","Returns the number of vector lanes.",59,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",59,[[["f32"]],["f32x16"]]],[11,"extract","","Extracts the value at `index`.",59,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",59,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",59,[[["self"],["usize"],["f32"]],["f32x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",59,[[["self"],["usize"],["f32"]],["f32x16"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",59,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",59,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",59,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",59,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",59,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",59,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",59,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",59,N],[11,"eq","","Lane-wise equality comparison.",59,[[["self"],["f32x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",59,[[["self"],["f32x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",59,[[["self"],["f32x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",59,[[["self"],["f32x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",59,[[["self"],["f32x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",59,[[["self"],["f32x16"]],["m1x16"]]],[11,"sum","","Horizontal sum of the vector elements.",59,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",59,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",59,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",59,[[["self"]],["f32"]]],[11,"min","","Minimum of two vectors.",59,[[["self"],["f32x16"]],["f32x16"]]],[11,"max","","Maximum of two vectors.",59,[[["self"],["f32x16"]],["f32x16"]]],[11,"abs","","Absolute-value",59,[[["self"]],["f32x16"]]],[11,"sqrt","","Square-root",59,[[["self"]],["f32x16"]]],[11,"sqrte","","Square-root estimate",59,[[["self"]],["f32x16"]]],[11,"rsqrte","","Reciprocal square-root estimate",59,[[["self"]],["f32x16"]]],[11,"fma","","Fused multiply add: `self * y + z`",59,[[["self"],["f32x16"],["f32x16"]],["f32x16"]]],[11,"sin","","Sin",59,[[["self"]],["f32x16"]]],[11,"cos","","Cos",59,[[["self"]],["f32x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",55,[[["i8"],["i8"],["i8"],["i8"]],["i8x4"]]],[11,"lanes","","Returns the number of vector lanes.",55,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",55,[[["i8"]],["i8x4"]]],[11,"extract","","Extracts the value at `index`.",55,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",55,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",55,[[["self"],["usize"],["i8"]],["i8x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",55,[[["self"],["usize"],["i8"]],["i8x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",55,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",55,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",55,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",55,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",55,N],[11,"eq","","Lane-wise equality comparison.",55,[[["self"],["i8x4"]],["m8x4"]]],[11,"ne","","Lane-wise inequality comparison.",55,[[["self"],["i8x4"]],["m8x4"]]],[11,"lt","","Lane-wise less-than comparison.",55,[[["self"],["i8x4"]],["m8x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",55,[[["self"],["i8x4"]],["m8x4"]]],[11,"gt","","Lane-wise greater-than comparison.",55,[[["self"],["i8x4"]],["m8x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",55,[[["self"],["i8x4"]],["m8x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",55,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",55,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",55,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",55,[[["self"]],["i8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",55,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",55,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",55,[[["self"]],["i8"]]],[11,"min","","Minimum of two vectors.",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"max","","Maximum of two vectors.",55,[[["self"],["i8x4"]],["i8x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",55,[[["self"]],["i8x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",55,[[["self"]],["i8x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",55,[[["self"]],["i8x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",39,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["i32x8"]]],[11,"lanes","","Returns the number of vector lanes.",39,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",39,[[["i32"]],["i32x8"]]],[11,"extract","","Extracts the value at `index`.",39,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",39,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",39,[[["self"],["usize"],["i32"]],["i32x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",39,[[["self"],["usize"],["i32"]],["i32x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",39,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",39,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",39,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",39,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",39,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",39,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",39,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",39,N],[11,"eq","","Lane-wise equality comparison.",39,[[["self"],["i32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",39,[[["self"],["i32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",39,[[["self"],["i32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",39,[[["self"],["i32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",39,[[["self"],["i32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",39,[[["self"],["i32x8"]],["m32x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",39,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",39,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",39,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",39,[[["self"]],["i32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",39,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",39,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",39,[[["self"]],["i32"]]],[11,"min","","Minimum of two vectors.",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"max","","Maximum of two vectors.",39,[[["self"],["i32x8"]],["i32x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",39,[[["self"]],["i32x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",39,[[["self"]],["i32x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",39,[[["self"]],["i32x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",18,[[["u64"],["u64"]],["u64x2"]]],[11,"lanes","","Returns the number of vector lanes.",18,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",18,[[["u64"]],["u64x2"]]],[11,"extract","","Extracts the value at `index`.",18,[[["self"],["usize"]],["u64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",18,[[["self"],["usize"]],["u64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",18,[[["self"],["usize"],["u64"]],["u64x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",18,[[["self"],["usize"],["u64"]],["u64x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",18,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",18,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",18,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",18,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",18,N],[11,"eq","","Lane-wise equality comparison.",18,[[["self"],["u64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",18,[[["self"],["u64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",18,[[["self"],["u64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",18,[[["self"],["u64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",18,[[["self"],["u64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",18,[[["self"],["u64x2"]],["m64x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",18,[[["self"]],["u64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",18,[[["self"]],["u64"]]],[11,"max_element","","Largest vector element value.",18,[[["self"]],["u64"]]],[11,"min_element","","Smallest vector element value.",18,[[["self"]],["u64"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",18,[[["self"]],["u64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",18,[[["self"]],["u64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",18,[[["self"]],["u64"]]],[11,"min","","Minimum of two vectors.",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"max","","Maximum of two vectors.",18,[[["self"],["u64x2"]],["u64x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",18,[[["self"]],["u64x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",18,[[["self"]],["u64x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",18,[[["self"]],["u64x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",47,[[["i64"],["i64"],["i64"],["i64"],["i64"],["i64"],["i64"],["i64"]],["i64x8"]]],[11,"lanes","","Returns the number of vector lanes.",47,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",47,[[["i64"]],["i64x8"]]],[11,"extract","","Extracts the value at `index`.",47,[[["self"],["usize"]],["i64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",47,[[["self"],["usize"]],["i64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",47,[[["self"],["usize"],["i64"]],["i64x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",47,[[["self"],["usize"],["i64"]],["i64x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",47,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",47,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",47,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",47,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",47,N],[11,"eq","","Lane-wise equality comparison.",47,[[["self"],["i64x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",47,[[["self"],["i64x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",47,[[["self"],["i64x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",47,[[["self"],["i64x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",47,[[["self"],["i64x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",47,[[["self"],["i64x8"]],["m1x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",47,[[["self"]],["i64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",47,[[["self"]],["i64"]]],[11,"max_element","","Largest vector element value.",47,[[["self"]],["i64"]]],[11,"min_element","","Smallest vector element value.",47,[[["self"]],["i64"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",47,[[["self"]],["i64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",47,[[["self"]],["i64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",47,[[["self"]],["i64"]]],[11,"min","","Minimum of two vectors.",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"max","","Maximum of two vectors.",47,[[["self"],["i64x8"]],["i64x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",47,[[["self"]],["i64x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",47,[[["self"]],["i64x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",47,[[["self"]],["i64x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",32,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m16x16"]]],[11,"lanes","","Returns the number of vector lanes.",32,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",32,[[["bool"]],["m16x16"]]],[11,"extract","","Extracts the value at `index`.",32,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",32,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",32,[[["self"],["usize"],["bool"]],["m16x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",32,[[["self"],["usize"],["bool"]],["m16x16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",32,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",32,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",32,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",32,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",32,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",32,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",32,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"ne","","Lane-wise inequality comparison.",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"lt","","Lane-wise less-than comparison.",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"gt","","Lane-wise greater-than comparison.",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",32,[[["self"],["m16x16"]],["m16x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",54,[[["bool"],["bool"]],["m64x2"]]],[11,"lanes","","Returns the number of vector lanes.",54,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",54,[[["bool"]],["m64x2"]]],[11,"extract","","Extracts the value at `index`.",54,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",54,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",54,[[["self"],["usize"],["bool"]],["m64x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",54,[[["self"],["usize"],["bool"]],["m64x2"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",54,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",54,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",54,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",54,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",54,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",54,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",54,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",54,[[["self"],["m64x2"]],["m64x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",16,[[["u16"],["u16"]],["u16x2"]]],[11,"lanes","","Returns the number of vector lanes.",16,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",16,[[["u16"]],["u16x2"]]],[11,"extract","","Extracts the value at `index`.",16,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",16,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",16,[[["self"],["usize"],["u16"]],["u16x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",16,[[["self"],["usize"],["u16"]],["u16x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",16,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",16,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",16,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",16,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",16,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",16,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",16,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",16,N],[11,"eq","","Lane-wise equality comparison.",16,[[["self"],["u16x2"]],["m16x2"]]],[11,"ne","","Lane-wise inequality comparison.",16,[[["self"],["u16x2"]],["m16x2"]]],[11,"lt","","Lane-wise less-than comparison.",16,[[["self"],["u16x2"]],["m16x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",16,[[["self"],["u16x2"]],["m16x2"]]],[11,"gt","","Lane-wise greater-than comparison.",16,[[["self"],["u16x2"]],["m16x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",16,[[["self"],["u16x2"]],["m16x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",16,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",16,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",16,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",16,[[["self"]],["u16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",16,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",16,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",16,[[["self"]],["u16"]]],[11,"min","","Minimum of two vectors.",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"max","","Maximum of two vectors.",16,[[["self"],["u16x2"]],["u16x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",16,[[["self"]],["u16x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",16,[[["self"]],["u16x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",16,[[["self"]],["u16x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",20,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m8x8"]]],[11,"lanes","","Returns the number of vector lanes.",20,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",20,[[["bool"]],["m8x8"]]],[11,"extract","","Extracts the value at `index`.",20,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",20,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",20,[[["self"],["usize"],["bool"]],["m8x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",20,[[["self"],["usize"],["bool"]],["m8x8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",20,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",20,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",20,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",20,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",20,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",20,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",20,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"ne","","Lane-wise inequality comparison.",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"lt","","Lane-wise less-than comparison.",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"gt","","Lane-wise greater-than comparison.",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",20,[[["self"],["m8x8"]],["m8x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",28,[[["bool"],["bool"],["bool"],["bool"]],["m64x4"]]],[11,"lanes","","Returns the number of vector lanes.",28,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",28,[[["bool"]],["m64x4"]]],[11,"extract","","Extracts the value at `index`.",28,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",28,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",28,[[["self"],["usize"],["bool"]],["m64x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",28,[[["self"],["usize"],["bool"]],["m64x4"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",28,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",28,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",28,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",28,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",28,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",28,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",28,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",28,[[["self"],["m64x4"]],["m64x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",19,[[["u32"],["u32"],["u32"],["u32"]],["u32x4"]]],[11,"lanes","","Returns the number of vector lanes.",19,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",19,[[["u32"]],["u32x4"]]],[11,"extract","","Extracts the value at `index`.",19,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",19,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",19,[[["self"],["usize"],["u32"]],["u32x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",19,[[["self"],["usize"],["u32"]],["u32x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",19,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",19,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",19,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",19,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",19,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",19,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",19,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",19,N],[11,"eq","","Lane-wise equality comparison.",19,[[["self"],["u32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",19,[[["self"],["u32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",19,[[["self"],["u32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",19,[[["self"],["u32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",19,[[["self"],["u32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",19,[[["self"],["u32x4"]],["m32x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",19,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",19,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",19,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",19,[[["self"]],["u32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",19,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",19,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",19,[[["self"]],["u32"]]],[11,"min","","Minimum of two vectors.",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"max","","Maximum of two vectors.",19,[[["self"],["u32x4"]],["u32x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",19,[[["self"]],["u32x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",19,[[["self"]],["u32x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",19,[[["self"]],["u32x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",6,[[["i8"],["i8"]],["i8x2"]]],[11,"lanes","","Returns the number of vector lanes.",6,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",6,[[["i8"]],["i8x2"]]],[11,"extract","","Extracts the value at `index`.",6,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",6,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",6,[[["self"],["usize"],["i8"]],["i8x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",6,[[["self"],["usize"],["i8"]],["i8x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",6,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",6,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",6,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",6,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",6,N],[11,"eq","","Lane-wise equality comparison.",6,[[["self"],["i8x2"]],["m8x2"]]],[11,"ne","","Lane-wise inequality comparison.",6,[[["self"],["i8x2"]],["m8x2"]]],[11,"lt","","Lane-wise less-than comparison.",6,[[["self"],["i8x2"]],["m8x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",6,[[["self"],["i8x2"]],["m8x2"]]],[11,"gt","","Lane-wise greater-than comparison.",6,[[["self"],["i8x2"]],["m8x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",6,[[["self"],["i8x2"]],["m8x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",6,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",6,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",6,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",6,[[["self"]],["i8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",6,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",6,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",6,[[["self"]],["i8"]]],[11,"min","","Minimum of two vectors.",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"max","","Maximum of two vectors.",6,[[["self"],["i8x2"]],["i8x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",6,[[["self"]],["i8x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",6,[[["self"]],["i8x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",6,[[["self"]],["i8x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",17,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m8x32"]]],[11,"lanes","","Returns the number of vector lanes.",17,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",17,[[["bool"]],["m8x32"]]],[11,"extract","","Extracts the value at `index`.",17,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",17,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",17,[[["self"],["usize"],["bool"]],["m8x32"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",17,[[["self"],["usize"],["bool"]],["m8x32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",17,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",17,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",17,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",17,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",17,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",17,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",17,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"ne","","Lane-wise inequality comparison.",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"lt","","Lane-wise less-than comparison.",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"gt","","Lane-wise greater-than comparison.",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",17,[[["self"],["m8x32"]],["m8x32"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",30,[[["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"]],["u32x16"]]],[11,"lanes","","Returns the number of vector lanes.",30,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",30,[[["u32"]],["u32x16"]]],[11,"extract","","Extracts the value at `index`.",30,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",30,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",30,[[["self"],["usize"],["u32"]],["u32x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",30,[[["self"],["usize"],["u32"]],["u32x16"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",30,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",30,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",30,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",30,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",30,N],[11,"eq","","Lane-wise equality comparison.",30,[[["self"],["u32x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",30,[[["self"],["u32x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",30,[[["self"],["u32x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",30,[[["self"],["u32x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",30,[[["self"],["u32x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",30,[[["self"],["u32x16"]],["m1x16"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",30,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",30,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",30,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",30,[[["self"]],["u32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",30,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",30,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",30,[[["self"]],["u32"]]],[11,"min","","Minimum of two vectors.",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"max","","Maximum of two vectors.",30,[[["self"],["u32x16"]],["u32x16"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",30,[[["self"]],["u32x16"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",30,[[["self"]],["u32x16"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",30,[[["self"]],["u32x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",51,[[["u8"],["u8"],["u8"],["u8"]],["u8x4"]]],[11,"lanes","","Returns the number of vector lanes.",51,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",51,[[["u8"]],["u8x4"]]],[11,"extract","","Extracts the value at `index`.",51,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",51,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",51,[[["self"],["usize"],["u8"]],["u8x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",51,[[["self"],["usize"],["u8"]],["u8x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",51,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",51,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",51,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",51,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",51,N],[11,"eq","","Lane-wise equality comparison.",51,[[["self"],["u8x4"]],["m8x4"]]],[11,"ne","","Lane-wise inequality comparison.",51,[[["self"],["u8x4"]],["m8x4"]]],[11,"lt","","Lane-wise less-than comparison.",51,[[["self"],["u8x4"]],["m8x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",51,[[["self"],["u8x4"]],["m8x4"]]],[11,"gt","","Lane-wise greater-than comparison.",51,[[["self"],["u8x4"]],["m8x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",51,[[["self"],["u8x4"]],["m8x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",51,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",51,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",51,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",51,[[["self"]],["u8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",51,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",51,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",51,[[["self"]],["u8"]]],[11,"min","","Minimum of two vectors.",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"max","","Maximum of two vectors.",51,[[["self"],["u8x4"]],["u8x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",51,[[["self"]],["u8x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",51,[[["self"]],["u8x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",51,[[["self"]],["u8x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",61,[[["f32"],["f32"]],["f32x2"]]],[11,"lanes","","Returns the number of vector lanes.",61,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",61,[[["f32"]],["f32x2"]]],[11,"extract","","Extracts the value at `index`.",61,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",61,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",61,[[["self"],["usize"],["f32"]],["f32x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",61,[[["self"],["usize"],["f32"]],["f32x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",61,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",61,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",61,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",61,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",61,N],[11,"eq","","Lane-wise equality comparison.",61,[[["self"],["f32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",61,[[["self"],["f32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",61,[[["self"],["f32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",61,[[["self"],["f32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",61,[[["self"],["f32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",61,[[["self"],["f32x2"]],["m32x2"]]],[11,"sum","","Horizontal sum of the vector elements.",61,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",61,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",61,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",61,[[["self"]],["f32"]]],[11,"min","","Minimum of two vectors.",61,[[["self"],["f32x2"]],["f32x2"]]],[11,"max","","Maximum of two vectors.",61,[[["self"],["f32x2"]],["f32x2"]]],[11,"abs","","Absolute-value",61,[[["self"]],["f32x2"]]],[11,"sqrt","","Square-root",61,[[["self"]],["f32x2"]]],[11,"sqrte","","Square-root estimate",61,[[["self"]],["f32x2"]]],[11,"rsqrte","","Reciprocal square-root estimate",61,[[["self"]],["f32x2"]]],[11,"fma","","Fused multiply add: `self * y + z`",61,[[["self"],["f32x2"],["f32x2"]],["f32x2"]]],[11,"sin","","Sin",61,[[["self"]],["f32x2"]]],[11,"cos","","Cos",61,[[["self"]],["f32x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",12,[[["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"]],["u16x16"]]],[11,"lanes","","Returns the number of vector lanes.",12,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",12,[[["u16"]],["u16x16"]]],[11,"extract","","Extracts the value at `index`.",12,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",12,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",12,[[["self"],["usize"],["u16"]],["u16x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",12,[[["self"],["usize"],["u16"]],["u16x16"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",12,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",12,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",12,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",12,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",12,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",12,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",12,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",12,N],[11,"eq","","Lane-wise equality comparison.",12,[[["self"],["u16x16"]],["m16x16"]]],[11,"ne","","Lane-wise inequality comparison.",12,[[["self"],["u16x16"]],["m16x16"]]],[11,"lt","","Lane-wise less-than comparison.",12,[[["self"],["u16x16"]],["m16x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",12,[[["self"],["u16x16"]],["m16x16"]]],[11,"gt","","Lane-wise greater-than comparison.",12,[[["self"],["u16x16"]],["m16x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",12,[[["self"],["u16x16"]],["m16x16"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",12,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",12,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",12,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",12,[[["self"]],["u16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",12,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",12,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",12,[[["self"]],["u16"]]],[11,"min","","Minimum of two vectors.",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"max","","Maximum of two vectors.",12,[[["self"],["u16x16"]],["u16x16"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",12,[[["self"]],["u16x16"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",12,[[["self"]],["u16x16"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",12,[[["self"]],["u16x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",36,[[["i64"],["i64"]],["i64x2"]]],[11,"lanes","","Returns the number of vector lanes.",36,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",36,[[["i64"]],["i64x2"]]],[11,"extract","","Extracts the value at `index`.",36,[[["self"],["usize"]],["i64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",36,[[["self"],["usize"]],["i64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",36,[[["self"],["usize"],["i64"]],["i64x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",36,[[["self"],["usize"],["i64"]],["i64x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",36,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",36,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",36,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",36,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",36,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",36,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",36,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",36,N],[11,"eq","","Lane-wise equality comparison.",36,[[["self"],["i64x2"]],["m64x2"]]],[11,"ne","","Lane-wise inequality comparison.",36,[[["self"],["i64x2"]],["m64x2"]]],[11,"lt","","Lane-wise less-than comparison.",36,[[["self"],["i64x2"]],["m64x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",36,[[["self"],["i64x2"]],["m64x2"]]],[11,"gt","","Lane-wise greater-than comparison.",36,[[["self"],["i64x2"]],["m64x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",36,[[["self"],["i64x2"]],["m64x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",36,[[["self"]],["i64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",36,[[["self"]],["i64"]]],[11,"max_element","","Largest vector element value.",36,[[["self"]],["i64"]]],[11,"min_element","","Smallest vector element value.",36,[[["self"]],["i64"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",36,[[["self"]],["i64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",36,[[["self"]],["i64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",36,[[["self"]],["i64"]]],[11,"min","","Minimum of two vectors.",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"max","","Maximum of two vectors.",36,[[["self"],["i64x2"]],["i64x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",36,[[["self"]],["i64x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",36,[[["self"]],["i64x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",36,[[["self"]],["i64x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",40,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m16x8"]]],[11,"lanes","","Returns the number of vector lanes.",40,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",40,[[["bool"]],["m16x8"]]],[11,"extract","","Extracts the value at `index`.",40,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",40,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",40,[[["self"],["usize"],["bool"]],["m16x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",40,[[["self"],["usize"],["bool"]],["m16x8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",40,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",40,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",40,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",40,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",40,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",40,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",40,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"ne","","Lane-wise inequality comparison.",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"lt","","Lane-wise less-than comparison.",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"gt","","Lane-wise greater-than comparison.",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",40,[[["self"],["m16x8"]],["m16x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",26,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m1x64"]]],[11,"lanes","","Returns the number of vector lanes.",26,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",26,[[["bool"]],["m1x64"]]],[11,"extract","","Extracts the value at `index`.",26,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",26,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",26,[[["self"],["usize"],["bool"]],["m1x64"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",26,[[["self"],["usize"],["bool"]],["m1x64"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",26,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",26,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",26,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",26,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",26,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",26,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",26,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"ne","","Lane-wise inequality comparison.",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"lt","","Lane-wise less-than comparison.",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"gt","","Lane-wise greater-than comparison.",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",26,[[["self"],["m1x64"]],["m1x64"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",22,[[["i64"],["i64"],["i64"],["i64"]],["i64x4"]]],[11,"lanes","","Returns the number of vector lanes.",22,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",22,[[["i64"]],["i64x4"]]],[11,"extract","","Extracts the value at `index`.",22,[[["self"],["usize"]],["i64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",22,[[["self"],["usize"]],["i64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",22,[[["self"],["usize"],["i64"]],["i64x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",22,[[["self"],["usize"],["i64"]],["i64x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",22,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",22,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",22,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",22,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",22,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",22,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",22,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",22,N],[11,"eq","","Lane-wise equality comparison.",22,[[["self"],["i64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",22,[[["self"],["i64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",22,[[["self"],["i64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",22,[[["self"],["i64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",22,[[["self"],["i64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",22,[[["self"],["i64x4"]],["m64x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",22,[[["self"]],["i64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",22,[[["self"]],["i64"]]],[11,"max_element","","Largest vector element value.",22,[[["self"]],["i64"]]],[11,"min_element","","Smallest vector element value.",22,[[["self"]],["i64"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",22,[[["self"]],["i64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",22,[[["self"]],["i64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",22,[[["self"]],["i64"]]],[11,"min","","Minimum of two vectors.",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"max","","Maximum of two vectors.",22,[[["self"],["i64x4"]],["i64x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",22,[[["self"]],["i64x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",22,[[["self"]],["i64x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",22,[[["self"]],["i64x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",49,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["i8x32"]]],[11,"lanes","","Returns the number of vector lanes.",49,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",49,[[["i8"]],["i8x32"]]],[11,"extract","","Extracts the value at `index`.",49,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",49,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",49,[[["self"],["usize"],["i8"]],["i8x32"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",49,[[["self"],["usize"],["i8"]],["i8x32"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",49,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",49,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",49,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",49,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",49,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",49,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",49,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",49,N],[11,"eq","","Lane-wise equality comparison.",49,[[["self"],["i8x32"]],["m8x32"]]],[11,"ne","","Lane-wise inequality comparison.",49,[[["self"],["i8x32"]],["m8x32"]]],[11,"lt","","Lane-wise less-than comparison.",49,[[["self"],["i8x32"]],["m8x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",49,[[["self"],["i8x32"]],["m8x32"]]],[11,"gt","","Lane-wise greater-than comparison.",49,[[["self"],["i8x32"]],["m8x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",49,[[["self"],["i8x32"]],["m8x32"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",49,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",49,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",49,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",49,[[["self"]],["i8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",49,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",49,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",49,[[["self"]],["i8"]]],[11,"min","","Minimum of two vectors.",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"max","","Maximum of two vectors.",49,[[["self"],["i8x32"]],["i8x32"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",49,[[["self"]],["i8x32"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",49,[[["self"]],["i8x32"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",49,[[["self"]],["i8x32"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",23,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["u8x32"]]],[11,"lanes","","Returns the number of vector lanes.",23,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",23,[[["u8"]],["u8x32"]]],[11,"extract","","Extracts the value at `index`.",23,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",23,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",23,[[["self"],["usize"],["u8"]],["u8x32"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",23,[[["self"],["usize"],["u8"]],["u8x32"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",23,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",23,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",23,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",23,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",23,N],[11,"eq","","Lane-wise equality comparison.",23,[[["self"],["u8x32"]],["m8x32"]]],[11,"ne","","Lane-wise inequality comparison.",23,[[["self"],["u8x32"]],["m8x32"]]],[11,"lt","","Lane-wise less-than comparison.",23,[[["self"],["u8x32"]],["m8x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",23,[[["self"],["u8x32"]],["m8x32"]]],[11,"gt","","Lane-wise greater-than comparison.",23,[[["self"],["u8x32"]],["m8x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",23,[[["self"],["u8x32"]],["m8x32"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",23,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",23,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",23,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",23,[[["self"]],["u8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",23,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",23,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",23,[[["self"]],["u8"]]],[11,"min","","Minimum of two vectors.",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"max","","Maximum of two vectors.",23,[[["self"],["u8x32"]],["u8x32"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",23,[[["self"]],["u8x32"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",23,[[["self"]],["u8x32"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",23,[[["self"]],["u8x32"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",41,[[["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"],["i32"]],["i32x16"]]],[11,"lanes","","Returns the number of vector lanes.",41,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",41,[[["i32"]],["i32x16"]]],[11,"extract","","Extracts the value at `index`.",41,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",41,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",41,[[["self"],["usize"],["i32"]],["i32x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",41,[[["self"],["usize"],["i32"]],["i32x16"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",41,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",41,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",41,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",41,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",41,N],[11,"eq","","Lane-wise equality comparison.",41,[[["self"],["i32x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",41,[[["self"],["i32x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",41,[[["self"],["i32x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",41,[[["self"],["i32x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",41,[[["self"],["i32x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",41,[[["self"],["i32x16"]],["m1x16"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",41,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",41,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",41,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",41,[[["self"]],["i32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",41,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",41,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",41,[[["self"]],["i32"]]],[11,"min","","Minimum of two vectors.",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"max","","Maximum of two vectors.",41,[[["self"],["i32x16"]],["i32x16"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",41,[[["self"]],["i32x16"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",41,[[["self"]],["i32x16"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",41,[[["self"]],["i32x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",57,[[["f32"],["f32"],["f32"],["f32"]],["f32x4"]]],[11,"lanes","","Returns the number of vector lanes.",57,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",57,[[["f32"]],["f32x4"]]],[11,"extract","","Extracts the value at `index`.",57,[[["self"],["usize"]],["f32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",57,[[["self"],["usize"]],["f32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",57,[[["self"],["usize"],["f32"]],["f32x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",57,[[["self"],["usize"],["f32"]],["f32x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",57,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",57,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",57,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",57,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",57,N],[11,"eq","","Lane-wise equality comparison.",57,[[["self"],["f32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",57,[[["self"],["f32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",57,[[["self"],["f32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",57,[[["self"],["f32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",57,[[["self"],["f32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",57,[[["self"],["f32x4"]],["m32x4"]]],[11,"sum","","Horizontal sum of the vector elements.",57,[[["self"]],["f32"]]],[11,"product","","Horizontal product of the vector elements.",57,[[["self"]],["f32"]]],[11,"max_element","","Largest vector element value.",57,[[["self"]],["f32"]]],[11,"min_element","","Smallest vector element value.",57,[[["self"]],["f32"]]],[11,"min","","Minimum of two vectors.",57,[[["self"],["f32x4"]],["f32x4"]]],[11,"max","","Maximum of two vectors.",57,[[["self"],["f32x4"]],["f32x4"]]],[11,"abs","","Absolute-value",57,[[["self"]],["f32x4"]]],[11,"sqrt","","Square-root",57,[[["self"]],["f32x4"]]],[11,"sqrte","","Square-root estimate",57,[[["self"]],["f32x4"]]],[11,"rsqrte","","Reciprocal square-root estimate",57,[[["self"]],["f32x4"]]],[11,"fma","","Fused multiply add: `self * y + z`",57,[[["self"],["f32x4"],["f32x4"]],["f32x4"]]],[11,"sin","","Sin",57,[[["self"]],["f32x4"]]],[11,"cos","","Cos",57,[[["self"]],["f32x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",43,[[["bool"],["bool"],["bool"],["bool"]],["m16x4"]]],[11,"lanes","","Returns the number of vector lanes.",43,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",43,[[["bool"]],["m16x4"]]],[11,"extract","","Extracts the value at `index`.",43,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",43,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",43,[[["self"],["usize"],["bool"]],["m16x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",43,[[["self"],["usize"],["bool"]],["m16x4"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",43,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",43,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",43,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",43,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",43,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",43,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",43,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"ne","","Lane-wise inequality comparison.",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"lt","","Lane-wise less-than comparison.",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"gt","","Lane-wise greater-than comparison.",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",43,[[["self"],["m16x4"]],["m16x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",42,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m8x16"]]],[11,"lanes","","Returns the number of vector lanes.",42,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",42,[[["bool"]],["m8x16"]]],[11,"extract","","Extracts the value at `index`.",42,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",42,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",42,[[["self"],["usize"],["bool"]],["m8x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",42,[[["self"],["usize"],["bool"]],["m8x16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",42,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",42,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",42,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",42,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",42,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",42,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",42,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"ne","","Lane-wise inequality comparison.",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"lt","","Lane-wise less-than comparison.",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"gt","","Lane-wise greater-than comparison.",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",42,[[["self"],["m8x16"]],["m8x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",56,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["i16x8"]]],[11,"lanes","","Returns the number of vector lanes.",56,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",56,[[["i16"]],["i16x8"]]],[11,"extract","","Extracts the value at `index`.",56,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",56,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",56,[[["self"],["usize"],["i16"]],["i16x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",56,[[["self"],["usize"],["i16"]],["i16x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",56,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",56,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",56,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",56,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",56,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",56,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",56,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",56,N],[11,"eq","","Lane-wise equality comparison.",56,[[["self"],["i16x8"]],["m16x8"]]],[11,"ne","","Lane-wise inequality comparison.",56,[[["self"],["i16x8"]],["m16x8"]]],[11,"lt","","Lane-wise less-than comparison.",56,[[["self"],["i16x8"]],["m16x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",56,[[["self"],["i16x8"]],["m16x8"]]],[11,"gt","","Lane-wise greater-than comparison.",56,[[["self"],["i16x8"]],["m16x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",56,[[["self"],["i16x8"]],["m16x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",56,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",56,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",56,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",56,[[["self"]],["i16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",56,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",56,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",56,[[["self"]],["i16"]]],[11,"min","","Minimum of two vectors.",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"max","","Maximum of two vectors.",56,[[["self"],["i16x8"]],["i16x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",56,[[["self"]],["i16x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",56,[[["self"]],["i16x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",56,[[["self"]],["i16x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",25,[[["bool"],["bool"]],["m32x2"]]],[11,"lanes","","Returns the number of vector lanes.",25,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",25,[[["bool"]],["m32x2"]]],[11,"extract","","Extracts the value at `index`.",25,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",25,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",25,[[["self"],["usize"],["bool"]],["m32x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",25,[[["self"],["usize"],["bool"]],["m32x2"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",25,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",25,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",25,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",25,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",25,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",25,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",25,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",25,[[["self"],["m32x2"]],["m32x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",21,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["i8x8"]]],[11,"lanes","","Returns the number of vector lanes.",21,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",21,[[["i8"]],["i8x8"]]],[11,"extract","","Extracts the value at `index`.",21,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",21,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",21,[[["self"],["usize"],["i8"]],["i8x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",21,[[["self"],["usize"],["i8"]],["i8x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",21,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",21,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",21,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",21,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",21,N],[11,"eq","","Lane-wise equality comparison.",21,[[["self"],["i8x8"]],["m8x8"]]],[11,"ne","","Lane-wise inequality comparison.",21,[[["self"],["i8x8"]],["m8x8"]]],[11,"lt","","Lane-wise less-than comparison.",21,[[["self"],["i8x8"]],["m8x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",21,[[["self"],["i8x8"]],["m8x8"]]],[11,"gt","","Lane-wise greater-than comparison.",21,[[["self"],["i8x8"]],["m8x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",21,[[["self"],["i8x8"]],["m8x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",21,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",21,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",21,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",21,[[["self"]],["i8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",21,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",21,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",21,[[["self"]],["i8"]]],[11,"min","","Minimum of two vectors.",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"max","","Maximum of two vectors.",21,[[["self"],["i8x8"]],["i8x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",21,[[["self"]],["i8x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",21,[[["self"]],["i8x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",21,[[["self"]],["i8x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",5,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["u8x64"]]],[11,"lanes","","Returns the number of vector lanes.",5,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",5,[[["u8"]],["u8x64"]]],[11,"extract","","Extracts the value at `index`.",5,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",5,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",5,[[["self"],["usize"],["u8"]],["u8x64"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",5,[[["self"],["usize"],["u8"]],["u8x64"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",5,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",5,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",5,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",5,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",5,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",5,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",5,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",5,N],[11,"eq","","Lane-wise equality comparison.",5,[[["self"],["u8x64"]],["m1x64"]]],[11,"ne","","Lane-wise inequality comparison.",5,[[["self"],["u8x64"]],["m1x64"]]],[11,"lt","","Lane-wise less-than comparison.",5,[[["self"],["u8x64"]],["m1x64"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",5,[[["self"],["u8x64"]],["m1x64"]]],[11,"gt","","Lane-wise greater-than comparison.",5,[[["self"],["u8x64"]],["m1x64"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",5,[[["self"],["u8x64"]],["m1x64"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",5,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",5,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",5,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",5,[[["self"]],["u8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",5,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",5,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",5,[[["self"]],["u8"]]],[11,"min","","Minimum of two vectors.",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"max","","Maximum of two vectors.",5,[[["self"],["u8x64"]],["u8x64"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",5,[[["self"]],["u8x64"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",5,[[["self"]],["u8x64"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",5,[[["self"]],["u8x64"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",14,[[["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"],["u16"]],["u16x8"]]],[11,"lanes","","Returns the number of vector lanes.",14,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",14,[[["u16"]],["u16x8"]]],[11,"extract","","Extracts the value at `index`.",14,[[["self"],["usize"]],["u16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",14,[[["self"],["usize"]],["u16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",14,[[["self"],["usize"],["u16"]],["u16x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",14,[[["self"],["usize"],["u16"]],["u16x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",14,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",14,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",14,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",14,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",14,N],[11,"eq","","Lane-wise equality comparison.",14,[[["self"],["u16x8"]],["m16x8"]]],[11,"ne","","Lane-wise inequality comparison.",14,[[["self"],["u16x8"]],["m16x8"]]],[11,"lt","","Lane-wise less-than comparison.",14,[[["self"],["u16x8"]],["m16x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",14,[[["self"],["u16x8"]],["m16x8"]]],[11,"gt","","Lane-wise greater-than comparison.",14,[[["self"],["u16x8"]],["m16x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",14,[[["self"],["u16x8"]],["m16x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",14,[[["self"]],["u16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",14,[[["self"]],["u16"]]],[11,"max_element","","Largest vector element value.",14,[[["self"]],["u16"]]],[11,"min_element","","Smallest vector element value.",14,[[["self"]],["u16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",14,[[["self"]],["u16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",14,[[["self"]],["u16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",14,[[["self"]],["u16"]]],[11,"min","","Minimum of two vectors.",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"max","","Maximum of two vectors.",14,[[["self"],["u16x8"]],["u16x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",14,[[["self"]],["u16x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",14,[[["self"]],["u16x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",14,[[["self"]],["u16x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",50,[[["u8"],["u8"]],["u8x2"]]],[11,"lanes","","Returns the number of vector lanes.",50,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",50,[[["u8"]],["u8x2"]]],[11,"extract","","Extracts the value at `index`.",50,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",50,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",50,[[["self"],["usize"],["u8"]],["u8x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",50,[[["self"],["usize"],["u8"]],["u8x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",50,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",50,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",50,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",50,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",50,N],[11,"eq","","Lane-wise equality comparison.",50,[[["self"],["u8x2"]],["m8x2"]]],[11,"ne","","Lane-wise inequality comparison.",50,[[["self"],["u8x2"]],["m8x2"]]],[11,"lt","","Lane-wise less-than comparison.",50,[[["self"],["u8x2"]],["m8x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",50,[[["self"],["u8x2"]],["m8x2"]]],[11,"gt","","Lane-wise greater-than comparison.",50,[[["self"],["u8x2"]],["m8x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",50,[[["self"],["u8x2"]],["m8x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",50,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",50,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",50,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",50,[[["self"]],["u8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",50,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",50,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",50,[[["self"]],["u8"]]],[11,"min","","Minimum of two vectors.",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"max","","Maximum of two vectors.",50,[[["self"],["u8x2"]],["u8x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",50,[[["self"]],["u8x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",50,[[["self"]],["u8x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",50,[[["self"]],["u8x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",10,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["i16x16"]]],[11,"lanes","","Returns the number of vector lanes.",10,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",10,[[["i16"]],["i16x16"]]],[11,"extract","","Extracts the value at `index`.",10,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",10,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",10,[[["self"],["usize"],["i16"]],["i16x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",10,[[["self"],["usize"],["i16"]],["i16x16"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",10,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",10,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",10,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",10,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",10,N],[11,"eq","","Lane-wise equality comparison.",10,[[["self"],["i16x16"]],["m16x16"]]],[11,"ne","","Lane-wise inequality comparison.",10,[[["self"],["i16x16"]],["m16x16"]]],[11,"lt","","Lane-wise less-than comparison.",10,[[["self"],["i16x16"]],["m16x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",10,[[["self"],["i16x16"]],["m16x16"]]],[11,"gt","","Lane-wise greater-than comparison.",10,[[["self"],["i16x16"]],["m16x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",10,[[["self"],["i16x16"]],["m16x16"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",10,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",10,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",10,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",10,[[["self"]],["i16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",10,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",10,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",10,[[["self"]],["i16"]]],[11,"min","","Minimum of two vectors.",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"max","","Maximum of two vectors.",10,[[["self"],["i16x16"]],["i16x16"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",10,[[["self"]],["i16x16"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",10,[[["self"]],["i16x16"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",10,[[["self"]],["i16x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",44,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["u8x16"]]],[11,"lanes","","Returns the number of vector lanes.",44,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",44,[[["u8"]],["u8x16"]]],[11,"extract","","Extracts the value at `index`.",44,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",44,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",44,[[["self"],["usize"],["u8"]],["u8x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",44,[[["self"],["usize"],["u8"]],["u8x16"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",44,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",44,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",44,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",44,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",44,N],[11,"eq","","Lane-wise equality comparison.",44,[[["self"],["u8x16"]],["m8x16"]]],[11,"ne","","Lane-wise inequality comparison.",44,[[["self"],["u8x16"]],["m8x16"]]],[11,"lt","","Lane-wise less-than comparison.",44,[[["self"],["u8x16"]],["m8x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",44,[[["self"],["u8x16"]],["m8x16"]]],[11,"gt","","Lane-wise greater-than comparison.",44,[[["self"],["u8x16"]],["m8x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",44,[[["self"],["u8x16"]],["m8x16"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",44,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",44,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",44,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",44,[[["self"]],["u8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",44,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",44,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",44,[[["self"]],["u8"]]],[11,"min","","Minimum of two vectors.",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"max","","Maximum of two vectors.",44,[[["self"],["u8x16"]],["u8x16"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",44,[[["self"]],["u8x16"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",44,[[["self"]],["u8x16"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",44,[[["self"]],["u8x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",34,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["i8x16"]]],[11,"lanes","","Returns the number of vector lanes.",34,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",34,[[["i8"]],["i8x16"]]],[11,"extract","","Extracts the value at `index`.",34,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",34,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",34,[[["self"],["usize"],["i8"]],["i8x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",34,[[["self"],["usize"],["i8"]],["i8x16"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",34,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",34,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",34,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",34,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",34,N],[11,"eq","","Lane-wise equality comparison.",34,[[["self"],["i8x16"]],["m8x16"]]],[11,"ne","","Lane-wise inequality comparison.",34,[[["self"],["i8x16"]],["m8x16"]]],[11,"lt","","Lane-wise less-than comparison.",34,[[["self"],["i8x16"]],["m8x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",34,[[["self"],["i8x16"]],["m8x16"]]],[11,"gt","","Lane-wise greater-than comparison.",34,[[["self"],["i8x16"]],["m8x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",34,[[["self"],["i8x16"]],["m8x16"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",34,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",34,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",34,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",34,[[["self"]],["i8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",34,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",34,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",34,[[["self"]],["i8"]]],[11,"min","","Minimum of two vectors.",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"max","","Maximum of two vectors.",34,[[["self"],["i8x16"]],["i8x16"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",34,[[["self"]],["i8x16"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",34,[[["self"]],["i8x16"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",34,[[["self"]],["i8x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",37,[[["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"],["i8"]],["i8x64"]]],[11,"lanes","","Returns the number of vector lanes.",37,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",37,[[["i8"]],["i8x64"]]],[11,"extract","","Extracts the value at `index`.",37,[[["self"],["usize"]],["i8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",37,[[["self"],["usize"]],["i8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",37,[[["self"],["usize"],["i8"]],["i8x64"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",37,[[["self"],["usize"],["i8"]],["i8x64"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",37,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",37,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",37,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",37,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",37,N],[11,"eq","","Lane-wise equality comparison.",37,[[["self"],["i8x64"]],["m1x64"]]],[11,"ne","","Lane-wise inequality comparison.",37,[[["self"],["i8x64"]],["m1x64"]]],[11,"lt","","Lane-wise less-than comparison.",37,[[["self"],["i8x64"]],["m1x64"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",37,[[["self"],["i8x64"]],["m1x64"]]],[11,"gt","","Lane-wise greater-than comparison.",37,[[["self"],["i8x64"]],["m1x64"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",37,[[["self"],["i8x64"]],["m1x64"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",37,[[["self"]],["i8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",37,[[["self"]],["i8"]]],[11,"max_element","","Largest vector element value.",37,[[["self"]],["i8"]]],[11,"min_element","","Smallest vector element value.",37,[[["self"]],["i8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",37,[[["self"]],["i8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",37,[[["self"]],["i8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",37,[[["self"]],["i8"]]],[11,"min","","Minimum of two vectors.",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"max","","Maximum of two vectors.",37,[[["self"],["i8x64"]],["i8x64"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",37,[[["self"]],["i8x64"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",37,[[["self"]],["i8x64"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",37,[[["self"]],["i8x64"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",8,[[["u64"],["u64"],["u64"],["u64"],["u64"],["u64"],["u64"],["u64"]],["u64x8"]]],[11,"lanes","","Returns the number of vector lanes.",8,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",8,[[["u64"]],["u64x8"]]],[11,"extract","","Extracts the value at `index`.",8,[[["self"],["usize"]],["u64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",8,[[["self"],["usize"]],["u64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",8,[[["self"],["usize"],["u64"]],["u64x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",8,[[["self"],["usize"],["u64"]],["u64x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",8,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",8,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",8,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",8,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",8,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",8,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",8,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",8,N],[11,"eq","","Lane-wise equality comparison.",8,[[["self"],["u64x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",8,[[["self"],["u64x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",8,[[["self"],["u64x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",8,[[["self"],["u64x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",8,[[["self"],["u64x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",8,[[["self"],["u64x8"]],["m1x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",8,[[["self"]],["u64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",8,[[["self"]],["u64"]]],[11,"max_element","","Largest vector element value.",8,[[["self"]],["u64"]]],[11,"min_element","","Smallest vector element value.",8,[[["self"]],["u64"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",8,[[["self"]],["u64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",8,[[["self"]],["u64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",8,[[["self"]],["u64"]]],[11,"min","","Minimum of two vectors.",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"max","","Maximum of two vectors.",8,[[["self"],["u64x8"]],["u64x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",8,[[["self"]],["u64x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",8,[[["self"]],["u64x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",8,[[["self"]],["u64x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",13,[[["i32"],["i32"]],["i32x2"]]],[11,"lanes","","Returns the number of vector lanes.",13,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",13,[[["i32"]],["i32x2"]]],[11,"extract","","Extracts the value at `index`.",13,[[["self"],["usize"]],["i32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",13,[[["self"],["usize"]],["i32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",13,[[["self"],["usize"],["i32"]],["i32x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",13,[[["self"],["usize"],["i32"]],["i32x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",13,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",13,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",13,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",13,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",13,N],[11,"eq","","Lane-wise equality comparison.",13,[[["self"],["i32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",13,[[["self"],["i32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",13,[[["self"],["i32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",13,[[["self"],["i32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",13,[[["self"],["i32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",13,[[["self"],["i32x2"]],["m32x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",13,[[["self"]],["i32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",13,[[["self"]],["i32"]]],[11,"max_element","","Largest vector element value.",13,[[["self"]],["i32"]]],[11,"min_element","","Smallest vector element value.",13,[[["self"]],["i32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",13,[[["self"]],["i32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",13,[[["self"]],["i32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",13,[[["self"]],["i32"]]],[11,"min","","Minimum of two vectors.",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"max","","Maximum of two vectors.",13,[[["self"],["i32x2"]],["i32x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",13,[[["self"]],["i32x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",13,[[["self"]],["i32x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",13,[[["self"]],["i32x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",4,[[["u64"],["u64"],["u64"],["u64"]],["u64x4"]]],[11,"lanes","","Returns the number of vector lanes.",4,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",4,[[["u64"]],["u64x4"]]],[11,"extract","","Extracts the value at `index`.",4,[[["self"],["usize"]],["u64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",4,[[["self"],["usize"]],["u64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",4,[[["self"],["usize"],["u64"]],["u64x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",4,[[["self"],["usize"],["u64"]],["u64x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",4,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",4,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",4,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",4,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",4,N],[11,"eq","","Lane-wise equality comparison.",4,[[["self"],["u64x4"]],["m64x4"]]],[11,"ne","","Lane-wise inequality comparison.",4,[[["self"],["u64x4"]],["m64x4"]]],[11,"lt","","Lane-wise less-than comparison.",4,[[["self"],["u64x4"]],["m64x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",4,[[["self"],["u64x4"]],["m64x4"]]],[11,"gt","","Lane-wise greater-than comparison.",4,[[["self"],["u64x4"]],["m64x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",4,[[["self"],["u64x4"]],["m64x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",4,[[["self"]],["u64"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",4,[[["self"]],["u64"]]],[11,"max_element","","Largest vector element value.",4,[[["self"]],["u64"]]],[11,"min_element","","Smallest vector element value.",4,[[["self"]],["u64"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",4,[[["self"]],["u64"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",4,[[["self"]],["u64"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",4,[[["self"]],["u64"]]],[11,"min","","Minimum of two vectors.",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"max","","Maximum of two vectors.",4,[[["self"],["u64x4"]],["u64x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",4,[[["self"]],["u64x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",4,[[["self"]],["u64x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",4,[[["self"]],["u64x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",45,[[["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"],["u8"]],["u8x8"]]],[11,"lanes","","Returns the number of vector lanes.",45,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",45,[[["u8"]],["u8x8"]]],[11,"extract","","Extracts the value at `index`.",45,[[["self"],["usize"]],["u8"]]],[11,"extract_unchecked","","Extracts the value at `index`.",45,[[["self"],["usize"]],["u8"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",45,[[["self"],["usize"],["u8"]],["u8x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",45,[[["self"],["usize"],["u8"]],["u8x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",45,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",45,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",45,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",45,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",45,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",45,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",45,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",45,N],[11,"eq","","Lane-wise equality comparison.",45,[[["self"],["u8x8"]],["m8x8"]]],[11,"ne","","Lane-wise inequality comparison.",45,[[["self"],["u8x8"]],["m8x8"]]],[11,"lt","","Lane-wise less-than comparison.",45,[[["self"],["u8x8"]],["m8x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",45,[[["self"],["u8x8"]],["m8x8"]]],[11,"gt","","Lane-wise greater-than comparison.",45,[[["self"],["u8x8"]],["m8x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",45,[[["self"],["u8x8"]],["m8x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",45,[[["self"]],["u8"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",45,[[["self"]],["u8"]]],[11,"max_element","","Largest vector element value.",45,[[["self"]],["u8"]]],[11,"min_element","","Smallest vector element value.",45,[[["self"]],["u8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",45,[[["self"]],["u8"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",45,[[["self"]],["u8"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",45,[[["self"]],["u8"]]],[11,"min","","Minimum of two vectors.",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"max","","Maximum of two vectors.",45,[[["self"],["u8x8"]],["u8x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",45,[[["self"]],["u8x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",45,[[["self"]],["u8x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",45,[[["self"]],["u8x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",7,[[["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"],["u32"]],["u32x8"]]],[11,"lanes","","Returns the number of vector lanes.",7,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",7,[[["u32"]],["u32x8"]]],[11,"extract","","Extracts the value at `index`.",7,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",7,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",7,[[["self"],["usize"],["u32"]],["u32x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",7,[[["self"],["usize"],["u32"]],["u32x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",7,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",7,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",7,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",7,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",7,N],[11,"eq","","Lane-wise equality comparison.",7,[[["self"],["u32x8"]],["m32x8"]]],[11,"ne","","Lane-wise inequality comparison.",7,[[["self"],["u32x8"]],["m32x8"]]],[11,"lt","","Lane-wise less-than comparison.",7,[[["self"],["u32x8"]],["m32x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",7,[[["self"],["u32x8"]],["m32x8"]]],[11,"gt","","Lane-wise greater-than comparison.",7,[[["self"],["u32x8"]],["m32x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",7,[[["self"],["u32x8"]],["m32x8"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",7,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",7,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",7,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",7,[[["self"]],["u32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",7,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",7,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",7,[[["self"]],["u32"]]],[11,"min","","Minimum of two vectors.",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"max","","Maximum of two vectors.",7,[[["self"],["u32x8"]],["u32x8"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",7,[[["self"]],["u32x8"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",7,[[["self"]],["u32x8"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",7,[[["self"]],["u32x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",38,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m1x16"]]],[11,"lanes","","Returns the number of vector lanes.",38,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",38,[[["bool"]],["m1x16"]]],[11,"extract","","Extracts the value at `index`.",38,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",38,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",38,[[["self"],["usize"],["bool"]],["m1x16"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",38,[[["self"],["usize"],["bool"]],["m1x16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",38,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",38,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",38,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",38,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",38,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",38,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",38,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"ne","","Lane-wise inequality comparison.",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"lt","","Lane-wise less-than comparison.",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"gt","","Lane-wise greater-than comparison.",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",38,[[["self"],["m1x16"]],["m1x16"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",27,[[["i16"],["i16"],["i16"],["i16"]],["i16x4"]]],[11,"lanes","","Returns the number of vector lanes.",27,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",27,[[["i16"]],["i16x4"]]],[11,"extract","","Extracts the value at `index`.",27,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",27,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",27,[[["self"],["usize"],["i16"]],["i16x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",27,[[["self"],["usize"],["i16"]],["i16x4"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",27,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",27,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",27,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",27,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",27,N],[11,"eq","","Lane-wise equality comparison.",27,[[["self"],["i16x4"]],["m16x4"]]],[11,"ne","","Lane-wise inequality comparison.",27,[[["self"],["i16x4"]],["m16x4"]]],[11,"lt","","Lane-wise less-than comparison.",27,[[["self"],["i16x4"]],["m16x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",27,[[["self"],["i16x4"]],["m16x4"]]],[11,"gt","","Lane-wise greater-than comparison.",27,[[["self"],["i16x4"]],["m16x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",27,[[["self"],["i16x4"]],["m16x4"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",27,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",27,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",27,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",27,[[["self"]],["i16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",27,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",27,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",27,[[["self"]],["i16"]]],[11,"min","","Minimum of two vectors.",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"max","","Maximum of two vectors.",27,[[["self"],["i16x4"]],["i16x4"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",27,[[["self"]],["i16x4"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",27,[[["self"]],["i16x4"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",27,[[["self"]],["i16x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",46,[[["bool"],["bool"],["bool"],["bool"]],["m8x4"]]],[11,"lanes","","Returns the number of vector lanes.",46,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",46,[[["bool"]],["m8x4"]]],[11,"extract","","Extracts the value at `index`.",46,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",46,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",46,[[["self"],["usize"],["bool"]],["m8x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",46,[[["self"],["usize"],["bool"]],["m8x4"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",46,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",46,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",46,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",46,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",46,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",46,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",46,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"ne","","Lane-wise inequality comparison.",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"lt","","Lane-wise less-than comparison.",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"gt","","Lane-wise greater-than comparison.",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",46,[[["self"],["m8x4"]],["m8x4"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",48,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m1x32"]]],[11,"lanes","","Returns the number of vector lanes.",48,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",48,[[["bool"]],["m1x32"]]],[11,"extract","","Extracts the value at `index`.",48,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",48,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",48,[[["self"],["usize"],["bool"]],["m1x32"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",48,[[["self"],["usize"],["bool"]],["m1x32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",48,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",48,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",48,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",48,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",48,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",48,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",48,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"ne","","Lane-wise inequality comparison.",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"lt","","Lane-wise less-than comparison.",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"gt","","Lane-wise greater-than comparison.",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",48,[[["self"],["m1x32"]],["m1x32"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",15,[[["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"],["bool"]],["m1x8"]]],[11,"lanes","","Returns the number of vector lanes.",15,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",15,[[["bool"]],["m1x8"]]],[11,"extract","","Extracts the value at `index`.",15,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",15,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",15,[[["self"],["usize"],["bool"]],["m1x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",15,[[["self"],["usize"],["bool"]],["m1x8"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",15,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",15,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",15,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",15,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",15,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",15,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",15,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",15,[[["self"],["m1x8"]],["m1x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",29,[[["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"],["i16"]],["i16x32"]]],[11,"lanes","","Returns the number of vector lanes.",29,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",29,[[["i16"]],["i16x32"]]],[11,"extract","","Extracts the value at `index`.",29,[[["self"],["usize"]],["i16"]]],[11,"extract_unchecked","","Extracts the value at `index`.",29,[[["self"],["usize"]],["i16"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",29,[[["self"],["usize"],["i16"]],["i16x32"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",29,[[["self"],["usize"],["i16"]],["i16x32"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",29,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",29,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",29,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",29,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",29,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",29,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",29,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",29,N],[11,"eq","","Lane-wise equality comparison.",29,[[["self"],["i16x32"]],["m1x32"]]],[11,"ne","","Lane-wise inequality comparison.",29,[[["self"],["i16x32"]],["m1x32"]]],[11,"lt","","Lane-wise less-than comparison.",29,[[["self"],["i16x32"]],["m1x32"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",29,[[["self"],["i16x32"]],["m1x32"]]],[11,"gt","","Lane-wise greater-than comparison.",29,[[["self"],["i16x32"]],["m1x32"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",29,[[["self"],["i16x32"]],["m1x32"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",29,[[["self"]],["i16"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",29,[[["self"]],["i16"]]],[11,"max_element","","Largest vector element value.",29,[[["self"]],["i16"]]],[11,"min_element","","Smallest vector element value.",29,[[["self"]],["i16"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",29,[[["self"]],["i16"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",29,[[["self"]],["i16"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",29,[[["self"]],["i16"]]],[11,"min","","Minimum of two vectors.",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"max","","Maximum of two vectors.",29,[[["self"],["i16x32"]],["i16x32"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",29,[[["self"]],["i16x32"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",29,[[["self"]],["i16x32"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",29,[[["self"]],["i16x32"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",58,[[["f64"],["f64"],["f64"],["f64"],["f64"],["f64"],["f64"],["f64"]],["f64x8"]]],[11,"lanes","","Returns the number of vector lanes.",58,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",58,[[["f64"]],["f64x8"]]],[11,"extract","","Extracts the value at `index`.",58,[[["self"],["usize"]],["f64"]]],[11,"extract_unchecked","","Extracts the value at `index`.",58,[[["self"],["usize"]],["f64"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",58,[[["self"],["usize"],["f64"]],["f64x8"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",58,[[["self"],["usize"],["f64"]],["f64x8"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",58,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",58,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",58,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",58,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",58,N],[11,"eq","","Lane-wise equality comparison.",58,[[["self"],["f64x8"]],["m1x8"]]],[11,"ne","","Lane-wise inequality comparison.",58,[[["self"],["f64x8"]],["m1x8"]]],[11,"lt","","Lane-wise less-than comparison.",58,[[["self"],["f64x8"]],["m1x8"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",58,[[["self"],["f64x8"]],["m1x8"]]],[11,"gt","","Lane-wise greater-than comparison.",58,[[["self"],["f64x8"]],["m1x8"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",58,[[["self"],["f64x8"]],["m1x8"]]],[11,"sum","","Horizontal sum of the vector elements.",58,[[["self"]],["f64"]]],[11,"product","","Horizontal product of the vector elements.",58,[[["self"]],["f64"]]],[11,"max_element","","Largest vector element value.",58,[[["self"]],["f64"]]],[11,"min_element","","Smallest vector element value.",58,[[["self"]],["f64"]]],[11,"min","","Minimum of two vectors.",58,[[["self"],["f64x8"]],["f64x8"]]],[11,"max","","Maximum of two vectors.",58,[[["self"],["f64x8"]],["f64x8"]]],[11,"abs","","Absolute-value",58,[[["self"]],["f64x8"]]],[11,"sqrt","","Square-root",58,[[["self"]],["f64x8"]]],[11,"sqrte","","Square-root estimate",58,[[["self"]],["f64x8"]]],[11,"rsqrte","","Reciprocal square-root estimate",58,[[["self"]],["f64x8"]]],[11,"fma","","Fused multiply add: `self * y + z`",58,[[["self"],["f64x8"],["f64x8"]],["f64x8"]]],[11,"sin","","Sin",58,[[["self"]],["f64x8"]]],[11,"cos","","Cos",58,[[["self"]],["f64x8"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",9,[[["u32"],["u32"]],["u32x2"]]],[11,"lanes","","Returns the number of vector lanes.",9,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",9,[[["u32"]],["u32x2"]]],[11,"extract","","Extracts the value at `index`.",9,[[["self"],["usize"]],["u32"]]],[11,"extract_unchecked","","Extracts the value at `index`.",9,[[["self"],["usize"]],["u32"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",9,[[["self"],["usize"],["u32"]],["u32x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",9,[[["self"],["usize"],["u32"]],["u32x2"]]],[11,"store_aligned","","Writes the values of the vector to the `slice`.",9,N],[11,"store_unaligned","","Writes the values of the vector to the `slice`.",9,N],[11,"store_aligned_unchecked","","Writes the values of the vector to the `slice`.",9,N],[11,"store_unaligned_unchecked","","Writes the values of the vector to the `slice`.",9,N],[11,"load_aligned","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"load_unaligned","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"load_aligned_unchecked","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"load_unaligned_unchecked","","Instantiates a new vector with the values of the `slice`.",9,N],[11,"eq","","Lane-wise equality comparison.",9,[[["self"],["u32x2"]],["m32x2"]]],[11,"ne","","Lane-wise inequality comparison.",9,[[["self"],["u32x2"]],["m32x2"]]],[11,"lt","","Lane-wise less-than comparison.",9,[[["self"],["u32x2"]],["m32x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",9,[[["self"],["u32x2"]],["m32x2"]]],[11,"gt","","Lane-wise greater-than comparison.",9,[[["self"],["u32x2"]],["m32x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",9,[[["self"],["u32x2"]],["m32x2"]]],[11,"wrapping_sum","","Horizontal sum of the vector elements.",9,[[["self"]],["u32"]]],[11,"wrapping_product","","Horizontal product of the vector elements.",9,[[["self"]],["u32"]]],[11,"max_element","","Largest vector element value.",9,[[["self"]],["u32"]]],[11,"min_element","","Smallest vector element value.",9,[[["self"]],["u32"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",9,[[["self"]],["u32"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",9,[[["self"]],["u32"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",9,[[["self"]],["u32"]]],[11,"min","","Minimum of two vectors.",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"max","","Maximum of two vectors.",9,[[["self"],["u32x2"]],["u32x2"]]],[11,"swap_bytes","","Reverses the byte order of the vector.",9,[[["self"]],["u32x2"]]],[11,"to_le","","Converts self to little endian from the target's endianness.",9,[[["self"]],["u32x2"]]],[11,"to_be","","Converts self to big endian from the target's endianness.",9,[[["self"]],["u32x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",53,[[["bool"],["bool"]],["m16x2"]]],[11,"lanes","","Returns the number of vector lanes.",53,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",53,[[["bool"]],["m16x2"]]],[11,"extract","","Extracts the value at `index`.",53,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",53,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",53,[[["self"],["usize"],["bool"]],["m16x2"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",53,[[["self"],["usize"],["bool"]],["m16x2"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",53,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",53,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",53,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",53,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",53,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",53,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",53,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"ne","","Lane-wise inequality comparison.",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"lt","","Lane-wise less-than comparison.",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"gt","","Lane-wise greater-than comparison.",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",53,[[["self"],["m16x2"]],["m16x2"]]],[11,"new","","Creates a new instance with each vector elements initialized with the provided values.",31,[[["bool"],["bool"],["bool"],["bool"]],["m32x4"]]],[11,"lanes","","Returns the number of vector lanes.",31,[[],["usize"]]],[11,"splat","","Constructs a new instance with each element initialized to `value`.",31,[[["bool"]],["m32x4"]]],[11,"extract","","Extracts the value at `index`.",31,[[["self"],["usize"]],["bool"]]],[11,"extract_unchecked","","Extracts the value at `index`.",31,[[["self"],["usize"]],["bool"]]],[11,"replace","","Returns a new vector where the value at `index` is replaced by `new_value`.",31,[[["self"],["usize"],["bool"]],["m32x4"]]],[11,"replace_unchecked","","Returns a new vector where the value at `index` is replaced by `new_value`.",31,[[["self"],["usize"],["bool"]],["m32x4"]]],[11,"and","","Lane-wise bitwise `and` of the vector elements.",31,[[["self"]],["bool"]]],[11,"or","","Lane-wise bitwise `or` of the vector elements.",31,[[["self"]],["bool"]]],[11,"xor","","Lane-wise bitwise `xor` of the vector elements.",31,[[["self"]],["bool"]]],[11,"all","","Are `all` vector lanes `true`?",31,[[["self"]],["bool"]]],[11,"any","","Is `any` vector lane `true`?",31,[[["self"]],["bool"]]],[11,"none","","Are `all` vector lanes `false`?",31,[[["self"]],["bool"]]],[11,"select","","Selects elements of `a` and `b` using mask.",31,[[["self"],["t"],["t"]],["t"]]],[11,"eq","","Lane-wise equality comparison.",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"ne","","Lane-wise inequality comparison.",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"lt","","Lane-wise less-than comparison.",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"le","","Lane-wise less-than-or-equals comparison.",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"gt","","Lane-wise greater-than comparison.",31,[[["self"],["m32x4"]],["m32x4"]]],[11,"ge","","Lane-wise greater-than-or-equals comparison.",31,[[["self"],["m32x4"]],["m32x4"]]]],"paths":[[8,"IntoBits"],[8,"FromBits"],[3,"CpuidResult"],[3,"m32x8"],[3,"u64x4"],[3,"u8x64"],[3,"i8x2"],[3,"u32x8"],[3,"u64x8"],[3,"u32x2"],[3,"i16x16"],[3,"m8x2"],[3,"u16x16"],[3,"i32x2"],[3,"u16x8"],[3,"m1x8"],[3,"u16x2"],[3,"m8x32"],[3,"u64x2"],[3,"u32x4"],[3,"m8x8"],[3,"i8x8"],[3,"i64x4"],[3,"u8x32"],[3,"u16x4"],[3,"m32x2"],[3,"m1x64"],[3,"i16x4"],[3,"m64x4"],[3,"i16x32"],[3,"u32x16"],[3,"m32x4"],[3,"m16x16"],[3,"u16x32"],[3,"i8x16"],[3,"i16x2"],[3,"i64x2"],[3,"i8x64"],[3,"m1x16"],[3,"i32x8"],[3,"m16x8"],[3,"i32x16"],[3,"m8x16"],[3,"m16x4"],[3,"u8x16"],[3,"u8x8"],[3,"m8x4"],[3,"i64x8"],[3,"m1x32"],[3,"i8x32"],[3,"u8x2"],[3,"u8x4"],[3,"i32x4"],[3,"m16x2"],[3,"m64x2"],[3,"i8x4"],[3,"i16x8"],[3,"f32x4"],[3,"f64x8"],[3,"f32x16"],[3,"f64x2"],[3,"f32x2"],[3,"f64x4"],[3,"f32x8"],[3,"__m64"],[3,"__m256d"],[3,"__m128d"],[3,"__m128"],[3,"__m128i"],[3,"__m256"],[3,"__m256i"]]};
initSearch(searchIndex);
